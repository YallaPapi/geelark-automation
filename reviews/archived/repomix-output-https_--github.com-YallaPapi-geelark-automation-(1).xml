This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<files>
This section contains the contents of the repository's files.

<file path=".taskmaster/docs/prd-posting.txt">
# Geelark Instagram Posting Automation

## Goal
Automatically post videos to Instagram accounts on Geelark cloud phones. Read videos and captions from a spreadsheet, post to each account.

## The Problem
- Geelark's built-in automation is unreliable and can't add captions
- VAs are slow and make mistakes
- Need to post across many accounts efficiently

## How It Works
1. Load spreadsheet with: account, video file, caption
2. For each row:
   - Open that account's Geelark device
   - Rotate proxy (hit rotation URL)
   - Take screenshot
   - Use Claude Vision to navigate Instagram posting flow
   - Upload video, add caption, post
   - Log result
3. Move to next row

## Posting Flow (what Claude Vision navigates)
1. Open Instagram app
2. Tap "+" button (create post)
3. Select "Reel" or post type
4. Select video from device gallery
5. Tap "Next"
6. Add caption (paste from spreadsheet)
7. Tap "Share"
8. Confirm post was successful
9. Done

## Inputs
- **Spreadsheet (CSV)**: columns = account_name, video_path, caption
- **Videos**: folder with video files (or already on Geelark devices)
- **Proxy rotation URL**: to rotate IP between posts
- **API keys**: Anthropic (Claude Vision), 2Captcha (if needed)

## Geelark Control
Need to figure out:
- How to take screenshots from Geelark
- How to tap/type on Geelark devices
- How to transfer videos to Geelark devices (or are they already there?)
- Options: RPA, ADB, API

## Output
- Log file with: account, video, status (success/fail), timestamp, error if any

## Edge Cases
- Instagram asks for login → handle or skip
- Captcha appears → use 2Captcha
- Post fails → log error, continue to next
- Rate limit → wait and retry

## MVP (Minimum to get working)
1. Control ONE Geelark device
2. Post ONE video with caption
3. Confirm it worked

Then scale to multiple accounts.

## Tech
- Python
- Claude Vision API
- Simple loop
- CSV for input/output
</file>

<file path=".taskmaster/docs/prd.txt">
# Geelark Instagram Account Setup Automation

## Goal
Automate Instagram account creation on Geelark cloud phones. One script, simple flow.

## How It Works
1. Take screenshot of Geelark device
2. Send to Claude Vision: "What screen is this? What should I tap/type? Give coordinates."
3. Execute the action (tap, type, scroll)
4. Repeat until account is created and set up

## External Services
- **DaisySMS**: Get phone number, receive SMS codes
- **2Captcha**: Solve captchas when they appear
- **Mobile Proxy**: Hit rotation URL before each new account

## Geelark Control
Research needed: How to programmatically control Geelark devices
- Option A: Their RPA feature
- Option B: ADB connection
- Option C: Their API (if exists)

## Account Setup Steps
Handle whatever Instagram shows (order varies):
- Enter birthday
- Enter phone number (from DaisySMS)
- Enter SMS code (from DaisySMS)
- Create username
- Create password
- Solve captcha if shown (via 2Captcha)
- Skip optional steps
- Add profile photo
- Add bio
- Switch to Creator account
- Follow ~20 accounts

## Inputs
- Profile photos (folder of images)
- Bios (text file, one per line)
- Accounts to follow (text file)
- Proxy rotation URL
- API keys (DaisySMS, 2Captcha, Anthropic)

## Output
- CSV with created accounts: username, password, phone used, status

## Success
- Create one account end-to-end
- Then scale to multiple

## Tech
- Python
- Claude Vision API for screen reading
- Simple loop, no fancy architecture
</file>

<file path=".taskmaster/tasks/tasks.json">
{
  "master": {
    "tasks": [
      {
        "id": 11,
        "title": "Project skeleton, configuration, and input/output handling",
        "description": "Set up the Python project, config management, and basic CLI to load inputs (photos, bios, follow list, proxies, API keys) and write CSV output for created accounts.",
        "details": "Implementation details:\n- Use Python 3.11+ with a simple, single-package structure (e.g., `geelark_ig_bot/`).\n- Create `config.py` to load configuration from a `.env` file (using `python-dotenv`) or a `config.yaml` file (using `pyyaml`). Keys: DAISY_SMS_KEY, TWO_CAPTCHA_KEY, ANTHROPIC_KEY, PROXY_ROTATE_URL, GEELARK_DEVICE_ID or connection params, paths for PHOTOS_DIR, BIOS_FILE, FOLLOW_FILE, OUTPUT_CSV.\n- Implement a small `models.py` with dataclasses such as `AccountProfile(photo_path, bio, follow_targets)` and `RunContext(proxy_url, device_id, session_id, logs_path)`.\n- Implement `io_inputs.py`:\n  - Load all image paths from the photos folder (validate file extensions and existence).\n  - Load bios from a text file, one bio per non-empty line.\n  - Load accounts-to-follow from a text file, one username per non-empty line.\n- Implement `io_outputs.py` with function `append_created_account(csv_path, username, password, phone, status, extra=None)` that appends a row; ensure the CSV is created with a header if missing.\n- Implement `main.py` with a CLI (using `argparse`) that supports parameters like `--accounts N`, `--device-id`, `--start-index`, `--output-csv`.\n- Add logging (built-in `logging` module) with INFO for high-level steps and DEBUG for low-level details; log to both console and a rotating file handler.\n- Ensure paths and config values are validated at startup, with clear error messages and non-zero exit codes on failure.\n- Keep architecture minimal: a main loop that calls a `create_single_account(profile: AccountProfile)` function implemented in later tasks.\n\nPseudo-code sketch:\n```python\n# main.py\nfrom config import load_config\nfrom io_inputs import load_photos, load_bios, load_follow_targets\nfrom io_outputs import append_created_account\nfrom workflow import create_single_account\n\nif __name__ == \"__main__\":\n    cfg = load_config()\n    photos = load_photos(cfg.PHOTOS_DIR)\n    bios = load_bios(cfg.BIOS_FILE)\n    follows = load_follow_targets(cfg.FOLLOW_FILE)\n\n    for i in range(cfg.NUM_ACCOUNTS):\n        profile = build_profile(photos, bios, follows, i)\n        result = create_single_account(profile, cfg)\n        append_created_account(\n            cfg.OUTPUT_CSV,\n            result.username,\n            result.password,\n            result.phone,\n            result.status,\n        )\n```",
        "testStrategy": "- Unit test config loading with missing/invalid keys.\n- Unit test input loaders with temporary directories and sample files.\n- Unit test CSV writer: create temp file, append multiple rows, verify header and data.\n- Run a dry-run mode (no device interaction) that uses mock `create_single_account` to verify CLI, logging, and CSV pipeline behave correctly.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Geelark device control abstraction (RPA/ADB/API)",
        "description": "Research and implement a minimal Python abstraction to control Geelark cloud phones (screenshot, tap, type, scroll) using the most reliable available method (RPA, ADB, or API).",
        "details": "Implementation details:\n- Investigate GeeLark’s RPA feature and any documented APIs from their dashboard/help center.[1]\n- Decide on a practical option:\n  - **Option A (preferred, if accessible):** Use GeeLark RPA/Custom tasks via HTTP or WebSocket if they expose an API to trigger actions on a running device (tap, input text, wait), or via a local bridge component.\n  - **Option B:** Connect via ADB over TCP to the cloud phone (if GeeLark exposes an ADB endpoint per phone). Use `adbutils` or `pure-python-adb` for screenshots and input events.\n  - **Option C:** If GeeLark has an official REST API to interact with cloud phones, wrap the relevant endpoints.\n- Define a Python interface `GeelarkDeviceController` in `geelark_device.py` with methods:\n  - `screenshot() -> bytes` (PNG/JPEG data)\n  - `tap(x: int, y: int)`\n  - `type_text(text: str)`\n  - `scroll(direction: Literal[\"up\",\"down\",\"left\",\"right\"], amount: int=500)`\n  - `back()` to press back button\n  - `home()` to go home\n  - `wait(seconds: float)` for simple delays.\n- Implement at least one concrete subclass, e.g., `AdbGeelarkDeviceController` or `RpaGeelarkDeviceController`, depending on what is feasible with GeeLark.\n- Include a simple device discovery/attachment function: `connect_device(device_id_or_host) -> GeelarkDeviceController`.\n- Ensure screenshot capturing is performant (e.g., ADB `exec-out screencap -p`), and images are in a format accepted by Claude Vision.\n\nExample using ADB-style pseudo-code:\n```python\nclass AdbGeelarkDeviceController(GeelarkDeviceController):\n    def __init__(self, serial: str):\n        self.adb = adbutils.AdbDevice(serial=serial)\n\n    def screenshot(self) -> bytes:\n        return self.adb.screencap()\n\n    def tap(self, x, y):\n        self.adb.shell(f\"input tap {x} {y}\")\n\n    def type_text(self, text):\n        safe = text.replace(\" \", \"%s\")\n        self.adb.shell(f\"input text '{safe}'\")\n\n    def scroll(self, direction, amount=500):\n        if direction == \"up\":\n            self.adb.shell(f\"input swipe 500 1000 500 {1000-amount}\")\n        # etc.\n```",
        "testStrategy": "- If ADB is used, test against a local Android emulator: verify that screenshot bytes are non-empty and tapping/types produce visible effects.\n- If GeeLark RPA/API is used, integration test on a disposable cloud phone: tap a known coordinate (e.g., Settings icon) and verify manually.\n- Add a `--test-device` CLI option that runs a quick health-check: take screenshot, tap a test area, log success/failure.\n- Use mocks in unit tests to assert high-level code calls `tap`, `type_text`, etc., with expected parameters.",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Claude Vision screen understanding client",
        "description": "Implement a Python client that sends device screenshots and the current context to Claude Vision, parses its response into actionable steps with coordinates and text.",
        "details": "Implementation details:\n- Use Anthropic’s Python SDK or plain HTTP with API key from config.\n- Define a prompt template that instructs Claude Vision explicitly:\n  - Provide **screen description**.\n  - Provide **next action** in a strict JSON format with fields like `{\"action\": \"tap\"|\"type\"|\"scroll\"|\"done\"|\"wait\",\"coordinates\": {\"x\": int, \"y\": int},\"text\": \"...\", \"reason\": \"...\"}`.\n  - Ask it to always respond with a single JSON object and no extra text.\n  - Instruct it that the goal is to create and fully set up an Instagram account according to the step list (birthday, phone, SMS, username, password, skip optional, photo, bio, creator, follow accounts).\n- Implement `claude_vision.py` with:\n  - `class ClaudeVisionClient:`\n    - `propose_action(image_bytes: bytes, state: dict) -> dict` where `state` includes progress markers (e.g., `has_entered_birthday`, `has_verified_phone`).\n- Implement robust JSON parsing:\n  - Strip any non-JSON prefix/suffix if Claude accidentally adds text.\n  - Validate that required keys exist; if not, log error and request again with a clarifying system message.\n- Include rate limiting/backoff and simple retry for network errors or malformed responses.\n- Maintain a small `state` object that encodes goal progress to share with Claude in the system/user message so it can choose the next step more reliably.\n\nPseudo-code:\n```python\nSYSTEM_PROMPT = \"\"\"You are controlling an Android phone to create a new Instagram account...\"\"\"\n\ndef propose_action(self, img, state):\n    msg = self._build_message(state)\n    resp = self.client.messages.create(\n        model=\"claude-3.5-sonnet\",  # or latest vision-capable model\n        max_tokens=300,\n        temperature=0.1,\n        messages=[\n          {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n          {\"role\": \"user\", \"content\": [\n              {\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/png\", \"data\": base64.b64encode(img).decode()}},\n              {\"type\": \"text\", \"text\": msg},\n          ]},\n        ],\n    )\n    json_str = extract_json(resp)\n    return json.loads(json_str)\n```",
        "testStrategy": "- Unit test prompt-building and JSON parsing with canned Claude-like responses.\n- Add an offline mode that uses a fake vision client returning predetermined actions for known test screenshots to validate the loop without spending API credits.\n- Log each request/response pair to a file (with redaction of secrets) and manually inspect a few runs to ensure action JSON is consistent.",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "DaisySMS integration for phone number and SMS code retrieval",
        "description": "Implement integration with DaisySMS to rent phone numbers and poll for Instagram verification SMS codes.",
        "details": "Implementation details:\n- Review DaisySMS API docs to identify endpoints for:\n  - Requesting a number for a specific service/country.\n  - Checking SMS status and retrieving the code.\n  - Canceling/finishing an activation.\n- Implement `daisysms_client.py` with:\n  - `request_number(service=\"instagram\", country=None) -> Activation` where `Activation` holds `id`, `phone_number`.\n  - `wait_for_sms(activation_id, timeout=300, poll_interval=5) -> str` returning the numeric code.\n  - `cancel_activation(activation_id)` and `finish_activation(activation_id)`.\n- Handle common failure cases: no numbers, timeout waiting for SMS, banned/invalid numbers.\n- Mask phone number in logs for privacy.\n- Provide helper to format phone for entering on the device (e.g., strip `+` if needed, or let Claude decide how to input it given the screenshot).\n\nPseudo-code sketch:\n```python\nclass DaisySmsClient:\n    def request_number(self):\n        # call API, parse JSON\n        return Activation(id=act_id, phone=phone)\n\n    def wait_for_sms(self, act_id, timeout=300):\n        # loop: GET status, parse text, extract 6-digit code via regex\n```",
        "testStrategy": "- Unit test JSON parsing with sample DaisySMS responses.\n- Use a mock HTTP server (e.g., `responses` or `httpretty`) for DaisySMS endpoints to validate retry and timeout behavior.\n- In a staging run, manually request a number and send a test SMS from another phone to verify code extraction logic.\n- Simulate failure modes (no number, timeout, malformed SMS) and confirm the calling workflow handles them gracefully (marks account as failed, logs reason, releases activation).",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "2Captcha integration for solving Instagram captchas",
        "description": "Integrate with 2Captcha to submit Instagram captchas (image or possibly hCaptcha/ReCaptcha) and retrieve solutions when they appear during signup.",
        "details": "Implementation details:\n- Check 2Captcha docs for supported captcha types on Instagram flows (likely image captcha or hCaptcha/ReCaptcha). Implement at least generic image captcha support; leave hooks for sitekey-based captchas if needed.\n- Implement `twocaptcha_client.py` with:\n  - `submit_image_captcha(image_bytes) -> captcha_id`.\n  - `wait_for_solution(captcha_id, timeout=180, poll_interval=5) -> str`.\n- Integrate with the main flow via a simple contract: when Claude identifies a captcha on the screen and indicates an `action: \"captcha\"` (we can define this), capture a high-resolution screenshot and crop if necessary:\n  - Either ask Claude to provide bounding box coordinates, then crop the relevant region before sending to 2Captcha.\n- After receiving the solution string, pass it back to the device using `type_text` or `tap`/`type` sequences as directed by Claude.\n- Implement error handling: if 2Captcha returns an error or times out, mark run as failed and log details.\n\nPseudo-code:\n```python\nclass TwoCaptchaClient:\n    def submit_image_captcha(self, img):\n        # POST multipart/form-data to 2Captcha\n\n    def wait_for_solution(self, cap_id, timeout):\n        # poll /res.php until status=1\n```",
        "testStrategy": "- Unit test polling and response parsing using mocked 2Captcha HTTP endpoints.\n- Manual integration test with a known captcha image to confirm that 2Captcha returns the expected text.\n- Simulate failures such as `ERROR_CAPTCHA_UNSOLVABLE` and ensure workflow either retries with a new captcha or aborts with a clear status.",
        "priority": "medium",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Mobile proxy rotation and network setup",
        "description": "Implement proxy rotation via a mobile proxy rotation URL before each new account and ensure all external calls from the device go through the rotated IP.",
        "details": "Implementation details:\n- Use the provided `PROXY_ROTATE_URL` config: before starting each new account creation, send a simple HTTP GET to this URL and wait a short delay (e.g., 5–10 seconds) for IP to change.\n- If GeeLark supports per-device proxy assignment, ensure the cloud phone is configured to use the mobile proxy; otherwise, rely on proxy at network edge.\n- Implement `proxy.py` with:\n  - `rotate_proxy() -> bool` which returns True on HTTP 2xx, False otherwise.\n- Add logging to record rotation attempts and results.\n- Optionally verify IP change using a cheap `https://api.ipify.org` style service via the device’s browser or host network (config-driven; disabled by default to avoid extra calls).\n- Integrate into `create_single_account` workflow: call `rotate_proxy()` once at the very beginning of each account run.\n\nPseudo-code:\n```python\ndef rotate_proxy(url, timeout=10):\n    try:\n        r = requests.get(url, timeout=timeout)\n        r.raise_for_status()\n        logger.info(\"Proxy rotated\")\n        time.sleep(8)\n        return True\n    except Exception as e:\n        logger.error(f\"Proxy rotation failed: {e}\")\n        return False\n```",
        "testStrategy": "- Unit test `rotate_proxy` with mocked HTTP responses (success, timeout, non-200).\n- In staging, call rotation multiple times and verify IP change manually using an external IP-check service.\n- Add a debug flag to log detected IPs (host-level) before and after rotation for manual verification.",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Core action loop: screenshot → Claude → device actions",
        "description": "Implement the main control loop that repeatedly screenshots the Geelark device, asks Claude Vision what to do, executes the returned action (tap/type/scroll), and tracks progress toward account creation.",
        "details": "Implementation details:\n- Implement `workflow.py` with a function `run_screen_loop(device: GeelarkDeviceController, vision: ClaudeVisionClient, state: dict, max_steps=200) -> state`.\n- Loop behavior:\n  - For each step:\n    - Take screenshot via `device.screenshot()`.\n    - Call `vision.propose_action(image_bytes, state)`.\n    - Parse action JSON and execute:\n      - `action == \"tap\"`: call `device.tap(x, y)`.\n      - `action == \"type\"`: call `device.type_text(text)`.\n      - `action == \"scroll\"`: call `device.scroll(direction, amount)`.\n      - `action == \"wait\"`: call `device.wait(seconds)`.\n      - `action == \"back\"`/`\"home\"`: call corresponding methods.\n      - `action == \"done\"`: break loop and return.\n      - `action == \"captcha\"`: delegate to 2Captcha handler (Task 15) then feed solution back.\n    - Update `state` with any progress hints returned (e.g., `state[\"phase\"] = resp[\"phase\"]`).\n    - Add random small delays (0.5–1.5 s) to mimic human interaction and let UI update.\n- Implement safety guards:\n  - If `max_steps` reached without `done`, mark run as failed.\n  - Detect repeated identical actions (same tap coordinates for many steps) and break to avoid loops.\n- Ensure the state encodes key information for later steps (e.g., whether phone number has been used, SMS verified, username set, account switched to creator, followed 20 accounts).\n\nPseudo-code:\n```python\ndef run_screen_loop(device, vision, state, max_steps=200):\n    for i in range(max_steps):\n        img = device.screenshot()\n        action = vision.propose_action(img, state)\n        if action[\"action\"] == \"done\":\n            state[\"status\"] = \"done\"\n            break\n        execute_action(device, action, state)\n    return state\n```",
        "testStrategy": "- Implement unit tests for `execute_action` using a mock `GeelarkDeviceController` to verify correct calls for each action type.\n- Use an offline fake-vision client (from Task 13 tests) returning a deterministic series of actions to validate that the loop terminates correctly and state progresses.\n- On a test device with Instagram already on a simple form screen, run a short loop and confirm taps and typing correspond roughly to what Claude suggests (manual spot check using logs and video capture).",
        "priority": "high",
        "dependencies": [
          12,
          13,
          15
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Account setup orchestration and Instagram-specific flow",
        "description": "Orchestrate a full Instagram account setup run, coordinating proxy rotation, device control, Claude-driven steps, DaisySMS phone/SMS handling, captchas, and the business logic for username/password, bio, photo, creator switch, and following accounts.",
        "details": "Implementation details:\n- Implement `create_single_account(profile: AccountProfile, cfg) -> AccountResult` in `workflow.py`.\n- High-level sequence:\n  1. Rotate proxy using Task 16.\n  2. Connect to Geelark device (Task 12) and ensure Instagram app is launched (via explicit launch intent or by tapping icon; you can teach Claude to tap the Instagram icon from home screen as part of loop).\n  3. Initialize `state` with:\n     - `target_bio`, `target_photo_path`, `follow_targets`.\n     - Flags: `birthday_entered`, `phone_requested`, `sms_verified`, `username_set`, `password_set`, `creator_switched`, `followed_count`.\n  4. Request DaisySMS number when the flow reaches phone entry stage:\n     - Either pre-request the number before starting, or better, when `state` indicates phone will be needed (e.g., when Claude says \"now enter phone number\").\n     - Store number and activation id in `state`.\n  5. Run `run_screen_loop` until `state[\"status\"] == \"done\"` or error.\n  6. In the loop integration, insert hooks based on `state`:\n     - When a screen expects the phone number, programmatically supply the DaisySMS number (you may give Claude the number in the context so it types it itself).\n     - After submitting phone, start a background `wait_for_sms` and when code is received, provide it to Claude in the next prompt so it can type it.\n     - For username/password, either auto-generate values in Python (e.g., random letters+digits) and provide them to Claude, or let Claude propose them but ensure Python records them in `state` so they can be output to CSV.\n  7. Ensure optional steps (such as contacts, notifications, etc.) are skipped—rely on Claude’s screen understanding but mention this explicitly in the prompt.\n  8. After reaching home feed, direct Claude (via state goal) to:\n     - Add profile photo from gallery: upload `target_photo_path` to the device or ensure the device already has a set of photos (outside of script scope) and instruct Claude accordingly.\n     - Add bio using `target_bio`.\n     - Switch to Creator account via settings (state flag `creator_switched=True` when done).\n     - Follow ~20 accounts from `follow_targets` list (give the list or next target to Claude in context, track `followed_count`).\n- Implement `AccountResult(username, password, phone, status, error_message=None)` dataclass.\n- On any unrecoverable error (DaisySMS/2Captcha failure, loop timeout, device disconnection), set `status=\"failed\"` and include `error_message`.\n",
        "testStrategy": "- Unit test orchestration logic with mocks for DaisySMS, 2Captcha, device controller, and Claude client to ensure correct call ordering and state changes.\n- Implement a dry-run mode that skips actual external calls and produces synthetic `AccountResult` to verify CSV output and control flow.\n- Run an end-to-end test on a single GeeLark device with manual observation, logging all key decisions; verify that a full account is created and appears in Instagram.\n- After a successful single-account run, test a small batch (e.g., 3 accounts) in series to validate that proxy rotation and resource cleanup between runs behave correctly.",
        "priority": "high",
        "dependencies": [
          12,
          13,
          14,
          15,
          16,
          17
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "Profile data assignment and username/password generation",
        "description": "Implement logic to map input photos, bios, and follow lists to each new account and deterministically generate secure usernames and passwords.",
        "details": "Implementation details:\n- Implement `profiles.py` with:\n  - `build_profile(photos, bios, follows, index) -> AccountProfile` using round-robin or randomized selection.\n  - `generate_username(index, base=None) -> str` using a configurable pattern (e.g., random adjectives+noun+digits) and allowed Instagram constraints.\n  - `generate_password() -> str` with 12–16 chars including letters, digits, and symbols.\n- Ensure that for each account run, `AccountProfile` includes:\n  - `photo_path`: may be None if fewer photos than accounts; handle gracefully (skip photo step).\n  - `bio`: may be randomly chosen or selected sequentially.\n  - `follow_targets`: either the full list or a subset of ~20 selected per account.\n- Pass generated username and password into `state` to be shared with Claude so it types them when appropriate.\n- Avoid reusing the same username; if Instagram rejects a username, have Claude propose alternatives but keep track in state and update `AccountResult` accordingly.\n\nPseudo-code:\n```python\n@dataclass\nclass AccountProfile:\n    username: str\n    password: str\n    photo_path: Optional[str]\n    bio: Optional[str]\n    follow_targets: list[str]\n```",
        "testStrategy": "- Unit test profile building to ensure fair rotation of bios/photos and correct slicing of follow targets (~20 per account).\n- Unit test username/password generation for uniqueness and complexity constraints.\n- Use a mock Claude client to simulate username rejection; verify that state and `AccountResult` update to the new accepted username.",
        "priority": "medium",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "Logging, error handling, and basic scaling for multiple accounts",
        "description": "Harden the script with structured logging, error handling, cleanup between runs, and simple sequential multi-account execution.",
        "details": "Implementation details:\n- Extend logging from Task 11:\n  - Include per-account correlation ID in all logs.\n  - Log key milestones (proxy rotated, number acquired, SMS received, captcha solved, account created, failures).\n- Implement a central exception handler in `main.py` that catches unexpected errors per account, records a failed `AccountResult`, and continues to the next account instead of crashing the whole batch.\n- Add cleanup hooks:\n  - Release DaisySMS activations on error.\n  - Optionally reset Instagram app state between runs (e.g., clear data or log out via Claude instructions at end of run).\n- For scaling:\n  - Keep initial implementation strictly sequential (one account after another) to minimize complexity.\n  - Design the code to allow future parallelization (e.g., by making `create_single_account` stateless other than its arguments and return value), but do not add concurrency yet.\n- Expose a few runtime knobs via CLI/config: `MAX_STEPS`, `SMS_TIMEOUT`, `CAPTCHA_TIMEOUT`, `RETRY_LIMIT`.\n",
        "testStrategy": "- Simulate multiple account runs with mocks where some accounts succeed and others fail; verify that all results are written to CSV and script exits cleanly.\n- Inject failures (e.g., raise exceptions from DaisySMS/2Captcha/Claude clients) and confirm they are caught and logged and do not stop subsequent accounts.\n- Manual multi-account test (2–3 accounts) to verify logs are readable and correlated with account IDs.",
        "priority": "medium",
        "dependencies": [
          18
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-12-10T03:59:28.494Z",
      "updated": "2025-12-10T04:21:12.826Z",
      "description": "Tasks for master context"
    }
  },
  "posting": {
    "tasks": [
      {
        "id": "1",
        "title": "Set up project structure, configuration, and API key management",
        "description": "Initialize a Python project for Geelark Instagram posting automation, including config management for CSV paths, Claude Vision, proxy rotation URL, and 2Captcha keys.",
        "details": "Implementation details:\n- Use Python 3.11+.\n- Create a package structure, e.g. `geelark_ig_bot/` with modules: `config.py`, `csv_io.py`, `geelark_control.py`, `instagram_flow.py`, `logging_utils.py`, `main.py`.\n- Use `python-dotenv` or similar to load secrets from `.env` (ANTHROPIC_API_KEY, CAPTCHA_API_KEY, PROXY_ROTATION_URL, etc.).\n- Define a `Config` dataclass in `config.py` holding: `input_csv_path`, `output_log_csv_path`, `video_root_dir`, `proxy_rotation_url`, `anthropic_api_key`, `captcha_api_key`, `geelark_api_base`, `mvp_mode` (single device vs multi-account).\n- Add a `requirements.txt` including: `requests`, `pandas` or `python-csv` (standard), `python-dotenv`, `anthropic` (official Claude client), and any chosen Geelark control SDK or ADB wrapper.\n- Provide a simple YAML or JSON config file for non-secret settings (file paths, default timeouts, retry counts).\n- Pseudo-code example:\n```python\n# config.py\nfrom dataclasses import dataclass\nimport os\n\n@dataclass\nclass Config:\n    input_csv_path: str\n    output_log_csv_path: str\n    video_root_dir: str\n    proxy_rotation_url: str\n    anthropic_api_key: str\n    captcha_api_key: str | None\n    geelark_api_base: str\n    mvp_mode: bool = True\n\n\ndef load_config() -> Config:\n    return Config(\n        input_csv_path=os.getenv(\"INPUT_CSV\", \"input.csv\"),\n        output_log_csv_path=os.getenv(\"OUTPUT_LOG_CSV\", \"post_log.csv\"),\n        video_root_dir=os.getenv(\"VIDEO_ROOT_DIR\", \"./videos\"),\n        proxy_rotation_url=os.getenv(\"PROXY_ROTATION_URL\", \"\"),\n        anthropic_api_key=os.environ[\"ANTHROPIC_API_KEY\"],\n        captcha_api_key=os.getenv(\"CAPTCHA_API_KEY\"),\n        geelark_api_base=os.getenv(\"GEELARK_API_BASE\", \"http://localhost:8000\"),\n    )\n```",
        "testStrategy": "- Unit test `load_config()` with different environment variable scenarios.\n- Verify that secrets are not hardcoded (only read from env/.env).\n- Run a dry `python -m geelark_ig_bot.main --dry-run` to confirm project imports and config loading work without runtime errors.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:00:11.686Z"
      },
      {
        "id": "2",
        "title": "Implement CSV input parsing and output logging",
        "description": "Create robust utilities to read posting instructions from a CSV and log results to an output CSV log file.",
        "details": "Implementation details:\n- Define required input columns: `account_name`, `video_path`, `caption`.\n- Implement `read_jobs(csv_path: str) -> list[PostJob]` where `PostJob` is a dataclass with `account_name`, `video_path`, `caption`.\n- Validate CSV: check mandatory columns exist; trim whitespace; skip or flag empty rows.\n- Normalize `video_path` by joining with `video_root_dir` if it is not absolute.\n- Implement `append_log_row(log_path, account, video, status, error=None, timestamp=None)` that appends to CSV, creating header if file does not exist.\n- Ensure logs are flushed after every job for crash resilience.\n- Pseudo-code:\n```python\n# csv_io.py\nfrom dataclasses import dataclass\nimport csv, os, datetime\n\n@dataclass\nclass PostJob:\n    account_name: str\n    video_path: str\n    caption: str\n\n\ndef read_jobs(path: str, video_root_dir: str) -> list[PostJob]:\n    jobs = []\n    with open(path, newline='', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if not row.get('account_name') or not row.get('video_path'):\n                continue\n            vp = row['video_path']\n            if not os.path.isabs(vp):\n                vp = os.path.join(video_root_dir, vp)\n            jobs.append(PostJob(row['account_name'].strip(), vp, row.get('caption', '')))\n    return jobs\n\n\ndef append_log_row(path: str, account: str, video: str, status: str, error: str | None = None):\n    file_exists = os.path.exists(path)\n    with open(path, 'a', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        if not file_exists:\n            writer.writerow(['timestamp', 'account', 'video', 'status', 'error'])\n        ts = datetime.datetime.utcnow().isoformat()\n        writer.writerow([ts, account, video, status, error or ''])\n```",
        "testStrategy": "- Unit test `read_jobs` with:\n  - Valid CSV.\n  - Missing columns (expect exception or empty list based on design).\n  - Relative vs absolute video paths.\n- Unit test `append_log_row`:\n  - First write creates header.\n  - Subsequent calls append new rows.\n  - Inspect resulting CSV to match expected line count and fields.\n- Perform an end-to-end dry run reading a small sample CSV and writing a sample log.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:00:20.864Z"
      },
      {
        "id": "3",
        "title": "Design Geelark device control abstraction",
        "description": "Create an abstraction layer to control Geelark cloud phones for screenshots, taps, typing, app launching, and file transfer, independent of the underlying mechanism (RPA, ADB, or API).",
        "details": "Implementation details:\n- Define an interface `GeelarkDeviceController` with methods:\n  - `connect(account_name: str) -> DeviceHandle`\n  - `launch_app(device: DeviceHandle, app_id: str)` (e.g. Instagram)\n  - `tap(device, x: int, y: int)`\n  - `type_text(device, text: str)`\n  - `screenshot(device) -> bytes` (PNG/JPEG bytes)\n  - `swipe(device, x1, y1, x2, y2, duration_ms)`\n  - `upload_file(device, local_path: str, remote_path: str) -> str` (returns remote path or URI).\n- Implement an initial MVP adapter that talks to Geelark via whichever is available first (e.g. ADB over TCP or a Geelark HTTP API). For now, define stub methods that raise `NotImplementedError` but with clear signatures.\n- Provide a mapping from `account_name` to `device_id` (config or simple dict) for the MVP single device.\n- Include sensible timeouts and retry wrappers around network calls.\n- Pseudo-code skeleton:\n```python\n# geelark_control.py\nfrom dataclasses import dataclass\n\n@dataclass\nclass DeviceHandle:\n    id: str\n\n\nclass GeelarkDeviceController:\n    def connect(self, account_name: str) -> DeviceHandle:\n        # map account -> device_id (MVP: single device)\n        raise NotImplementedError\n\n    def launch_app(self, device: DeviceHandle, app_id: str):\n        raise NotImplementedError\n\n    def tap(self, device: DeviceHandle, x: int, y: int):\n        raise NotImplementedError\n\n    def type_text(self, device: DeviceHandle, text: str):\n        raise NotImplementedError\n\n    def screenshot(self, device: DeviceHandle) -> bytes:\n        raise NotImplementedError\n\n    def upload_file(self, device: DeviceHandle, local_path: str, remote_path: str) -> str:\n        raise NotImplementedError\n```\n- Later tasks will fill implementations using the chosen low-level mechanism.",
        "testStrategy": "- Unit test that the interface exists and that stub methods raise `NotImplementedError`.\n- Create a fake/mock implementation `MockGeelarkDeviceController` for testing higher-level logic without real devices.\n- Verify that `account_name` to `device_id` mapping works as expected using the MVP single-device configuration.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:00:29.298Z"
      },
      {
        "id": "4",
        "title": "Implement low-level Geelark control (screenshots, taps, typing, file transfer)",
        "description": "Provide a concrete implementation of the Geelark device control abstraction using the chosen RPA/ADB/API mechanism.",
        "details": "Implementation details:\n- Decide a concrete mechanism based on what Geelark exposes:\n  - If Geelark offers an HTTP API: implement calls like `POST /devices/{id}/tap`, `POST /devices/{id}/type`, `GET /devices/{id}/screenshot`, etc.\n  - If using ADB: use `subprocess` to call `adb -s <serial> shell input tap x y`, `input text`, `screencap -p`, and `adb push` for file transfer.\n- Implement `GeelarkDeviceController` methods:\n  - `connect`: resolve `account_name` to a device identifier (e.g. `device_serial`), possibly via config mapping; validate connectivity.\n  - `launch_app`: `adb shell monkey -p com.instagram.android 1` or equivalent API.\n  - `tap`: execute appropriate tap command.\n  - `type_text`: escape special characters for ADB; for longer captions, implement paste via clipboard if device API supports it.\n  - `screenshot`: capture and return raw bytes; ensure correct image format for Claude Vision.\n  - `upload_file`: transfer video from host to device; return the device-side file path.\n- Add minimal rate limiting to avoid overwhelming Geelark/API.\n- Pseudo-code example (ADB-style):\n```python\nimport subprocess, io\n\nclass AdbGeelarkDeviceController(GeelarkDeviceController):\n    def __init__(self, mapping: dict[str, str]):\n        self.mapping = mapping\n\n    def connect(self, account_name: str) -> DeviceHandle:\n        serial = self.mapping.get(account_name) or next(iter(self.mapping.values()))\n        return DeviceHandle(serial)\n\n    def tap(self, device: DeviceHandle, x: int, y: int):\n        subprocess.run([\"adb\", \"-s\", device.id, \"shell\", \"input\", \"tap\", str(x), str(y)], check=True)\n\n    def screenshot(self, device: DeviceHandle) -> bytes:\n        out = subprocess.check_output([\"adb\", \"-s\", device.id, \"exec-out\", \"screencap\", \"-p\"])\n        return out\n\n    def upload_file(self, device: DeviceHandle, local_path: str, remote_path: str) -> str:\n        subprocess.run([\"adb\", \"-s\", device.id, \"push\", local_path, remote_path], check=True)\n        return remote_path\n```",
        "testStrategy": "- If using ADB: run integration tests against a test device or emulator.\n  - Verify `connect` returns a valid handle.\n  - Call `screenshot` and confirm returned bytes decode as an image.\n  - Call `tap` and `type_text` while observing the device screen.\n  - Transfer a small dummy video file and confirm existence on the device.\n- If using HTTP API: use a mock server to validate request payloads, paths, and error handling.\n- Add negative tests: simulate command/API failures and verify that exceptions are raised and propagated up.",
        "priority": "high",
        "dependencies": [
          "3"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:00:38.036Z"
      },
      {
        "id": "5",
        "title": "Integrate proxy rotation before each post",
        "description": "Implement a simple proxy rotation step that hits the configured rotation URL before each posting job.",
        "details": "Implementation details:\n- Add a `rotate_proxy()` function in a `network_utils.py` module.\n- Use `requests.get(config.proxy_rotation_url, timeout=10)` or equivalent; treat non-2xx responses as failures.\n- Add small backoff and retry (e.g. 3 attempts with exponential backoff) because this is a network call.\n- Pseudo-code:\n```python\nimport time, requests\n\ndef rotate_proxy(url: str, retries: int = 3, base_delay: float = 1.0) -> bool:\n    for attempt in range(retries):\n        try:\n            r = requests.get(url, timeout=10)\n            if 200 <= r.status_code < 300:\n                return True\n        except requests.RequestException:\n            pass\n        time.sleep(base_delay * (2 ** attempt))\n    return False\n```\n- Hook `rotate_proxy()` into the main posting loop: call it before connecting to the Geelark device for each row.\n- Log proxy rotation success/failure per job (but continue posting even if rotation fails if that is acceptable per requirements).",
        "testStrategy": "- Unit test `rotate_proxy` using a requests-mock server returning:\n  - 200: expect success on first attempt.\n  - 500: expect retries and final failure.\n  - Network timeout: expect retries and final failure.\n- In an integration-like test, configure a local HTTP server as rotation URL and verify that it is hit once per job in a multi-row CSV.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:00:56.695Z"
      },
      {
        "id": "6",
        "title": "Implement Claude Vision client for Instagram UI navigation",
        "description": "Create a module that sends device screenshots and minimal context to Claude Vision and receives structured navigation instructions for the Instagram posting flow.",
        "details": "Implementation details:\n- Use the official Anthropic Python SDK (`anthropic` package) and Claude Vision model.\n- Define a `ClaudeNavigator` class with:\n  - `plan_next_action(screenshot_bytes: bytes, context: dict) -> Action` where `Action` is a dataclass describing an operation such as `tap(x,y)`, `type(text)`, `wait(seconds)`, `verify_posted`.\n- Provide a system prompt that explains the device context (Android Instagram app on a cloud phone), the goal (post a Reel/video with a given caption), and a JSON schema for response.\n- Example pseudo-code:\n```python\nfrom anthropic import Anthropic\nimport base64, json\n\n@dataclass\nclass Action:\n    kind: str  # 'tap', 'type', 'wait', 'done', 'error'\n    x: int | None = None\n    y: int | None = None\n    text: str | None = None\n    seconds: float | None = None\n\n\nclass ClaudeNavigator:\n    def __init__(self, api_key: str):\n        self.client = Anthropic(api_key=api_key)\n\n    def plan_next_action(self, screenshot_bytes: bytes, context: dict) -> Action:\n        img_b64 = base64.b64encode(screenshot_bytes).decode('ascii')\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"input_image\",\n                        \"source\": {\"type\": \"base64\", \"media_type\": \"image/png\", \"data\": img_b64},\n                    },\n                    {\n                        \"type\": \"text\",\n                        \"text\": json.dumps(context),\n                    },\n                ],\n            }\n        ]\n        resp = self.client.messages.create(\n            model=\"claude-3-5-sonnet\",  # example vision-capable model\n            max_tokens=512,\n            messages=messages,\n            system=\"You control an Android Instagram app. Respond ONLY with a JSON object describing the next action to create and publish a video post.\",\n        )\n        action_dict = json.loads(resp.content[0].text)\n        return Action(**action_dict)\n```\n- The `context` should include the current step: e.g. `{\"step\": \"open_plus\", \"caption\": \"...\"}`.\n- Keep actions atomic and loop until `kind == 'done'` or an error is detected.",
        "testStrategy": "- Unit test `ClaudeNavigator` parsing: mock Anthropic client responses with known JSON and ensure `Action` is constructed correctly.\n- Add validation on returned actions (e.g. coordinates within screen bounds, non-empty `text` for `type` actions) and test these validators.\n- For manual testing, feed screenshots of Instagram app (from a real device) and confirm that the model returns sensible next-step actions by logging them without executing on device.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:01:05.856Z"
      },
      {
        "id": "7",
        "title": "Orchestrate Instagram posting flow with device control and Claude Vision",
        "description": "Combine CSV jobs, Geelark control, proxy rotation, and Claude Vision navigation to automate the full Instagram posting flow per row, including caption entry and success verification for one device (MVP).",
        "details": "Implementation details:\n- Implement a high-level function `run_post_job(job: PostJob, config: Config, controller: GeelarkDeviceController, navigator: ClaudeNavigator)` that:\n  1) Rotates proxy.\n  2) Connects to the Geelark device for `job.account_name`.\n  3) Ensures the Instagram app is running (`launch_app`).\n  4) Transfers the video file to the device via `upload_file` and records the device path.\n  5) Enters a loop to perform the posting flow:\n     - Take a `screenshot`.\n     - Provide `context` to Claude, including:\n       - `goal`: \"Post the specified video to this Instagram account as a Reel or standard video post.\"\n       - `step_state`: track state such as `{\"video_uploaded\": false, \"caption_pasted\": false}`.\n       - `video_device_path` and `caption`.\n     - Receive `Action` from `ClaudeNavigator`.\n     - Map `Action` to `GeelarkDeviceController` calls (`tap`, `type_text`, etc.).\n     - Track timeouts and max steps (e.g. 30 steps) to avoid infinite loops.\n  6) After `Action.kind == 'done'`, confirm success by having Claude inspect a final screenshot with a `verify_posted` context.\n- Ensure that errors (exceptions, invalid actions, timeouts) raise a `PostJobError` that carries a human-readable message.\n- Pseudo-code skeleton:\n```python\ndef run_post_job(job, config, controller, navigator):\n    rotate_proxy(config.proxy_rotation_url)\n    device = controller.connect(job.account_name)\n    controller.launch_app(device, app_id=\"com.instagram.android\")\n    remote_video_path = controller.upload_file(device, job.video_path, \"/sdcard/Download/post_video.mp4\")\n\n    state = {\"video_uploaded\": False, \"caption_pasted\": False, \"remote_video_path\": remote_video_path}\n    for step in range(30):\n        screenshot = controller.screenshot(device)\n        context = {\"goal\": \"post_video\", \"caption\": job.caption, \"state\": state}\n        action = navigator.plan_next_action(screenshot, context)\n        if action.kind == \"tap\":\n            controller.tap(device, action.x, action.y)\n        elif action.kind == \"type\":\n            controller.type_text(device, action.text)\n        elif action.kind == \"wait\":\n            time.sleep(action.seconds)\n        elif action.kind == \"done\":\n            break\n        else:\n            raise PostJobError(f\"Unknown action: {action.kind}\")\n\n    # final verification screenshot\n    final_shot = controller.screenshot(device)\n    verify_action = navigator.plan_next_action(final_shot, {\"goal\": \"verify_posted\"})\n    if verify_action.kind != \"done\":\n        raise PostJobError(\"Unable to verify post was successful\")\n```\n- Make the orchestrator initially target MVP: one device and single job; then scale to loop over all jobs from CSV in `main.py`.\n- Capture and return a success/failure status and error message to the caller for logging.",
        "testStrategy": "- Implement integration tests in a `--dry-run` mode where `GeelarkDeviceController` is a mock and `ClaudeNavigator` is replaced by a deterministic fake that returns a scripted sequence of actions; verify steps executed in correct order.\n- On a real Geelark device, manually run one job and visually confirm that Instagram opens, video is selected, caption is filled, and post is shared.\n- Test failure paths: simulate `upload_file` failure, invalid actions from navigator, and assert that errors propagate to logging.\n- Verify that the loop stops when max steps are reached and logs an appropriate error.",
        "priority": "high",
        "dependencies": [
          "2",
          "4",
          "5",
          "6"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:01:14.920Z"
      },
      {
        "id": "8",
        "title": "Handle login prompts, captchas, and rate limits",
        "description": "Add edge-case handling for Instagram login requests, captchas via 2Captcha, and rate-limit detection with backoff and retry.",
        "details": "Implementation details:\n- Extend Claude prompts to explicitly ask it to identify when the screen shows:\n  - A login screen.\n  - A captcha challenge.\n  - A rate-limit or \"try again later\" message.\n- In `ClaudeNavigator`, allow an `Action.kind` of `\"login_required\"`, `\"captcha\"`, or `\"rate_limited\"` with additional metadata if needed.\n- Implement logic in the orchestrator:\n  - `login_required`: for MVP, either skip the job and log `login_required`, or if credentials are available in config, allow navigator-guided login by providing `username`/`password` in context.\n  - `captcha`: integrate 2Captcha by:\n    - Taking a screenshot of the captcha area (or whole screen) and sending to 2Captcha's image API.\n    - Polling for the solved text and then issuing `type_text` or `tap` actions accordingly.\n  - `rate_limited`: pause posting for a configurable cooldown (e.g. 10–30 minutes per account/device) before retrying the current job once; if still rate limited, mark as failed and move on.\n- Pseudo-code snippet for 2Captcha integration:\n```python\nimport requests, time\n\nclass CaptchaSolver:\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n\n    def solve_image(self, image_bytes: bytes) -> str:\n        # send\n        resp = requests.post(\"http://2captcha.com/in.php\", data={\n            \"key\": self.api_key,\n            \"method\": \"base64\",\n            \"body\": base64.b64encode(image_bytes).decode('ascii'),\n            \"json\": 1,\n        })\n        captcha_id = resp.json()[\"request\"]\n        # poll result\n        for _ in range(24):\n            r = requests.get(\"http://2captcha.com/res.php\", params={\n                \"key\": self.api_key,\n                \"action\": \"get\",\n                \"id\": captcha_id,\n                \"json\": 1,\n            })\n            data = r.json()\n            if data[\"status\"] == 1:\n                return data[\"request\"]\n            time.sleep(5)\n        raise TimeoutError(\"Captcha solving timed out\")\n```\n- Log all edge-case events distinctly so they can be monitored later.",
        "testStrategy": "- Unit test captcha solver using mocked 2Captcha endpoints with typical success and timeout responses.\n- Extend fake `ClaudeNavigator` in tests to return `login_required`, `captcha`, and `rate_limited` actions and verify that the orchestrator:\n  - For `login_required`, either skips or performs login based on test configuration.\n  - For `captcha`, calls `CaptchaSolver.solve_image` and then attempts to type the solution.\n  - For `rate_limited`, waits the configured cooldown and retries at most once.\n- Manually induce a login-required state on a test account and confirm that it is handled as designed and logged appropriately.",
        "priority": "medium",
        "dependencies": [
          "6",
          "7"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:01:25.731Z"
      },
      {
        "id": "9",
        "title": "Implement main loop, error handling, and structured logging",
        "description": "Create the main entrypoint that iterates over CSV rows, invokes the posting orchestrator per job, and writes structured logs with status, timestamp, and errors.",
        "details": "Implementation details:\n- In `main.py`, implement:\n  - `load_config()`.\n  - Initialize `GeelarkDeviceController`, `ClaudeNavigator`, and optionally `CaptchaSolver`.\n  - Load jobs via `read_jobs(config.input_csv_path, config.video_root_dir)`.\n  - For each job:\n    - Call `run_post_job` inside a `try/except` block.\n    - On success, call `append_log_row(..., status=\"success\")`.\n    - On failure, log `status=\"fail\"` with the exception message.\n- Use Python `logging` module with JSON-ish log format (e.g. `%(asctime)s %(levelname)s %(message)s`) and include job identifiers.\n- Allow CLI flags/env for:\n  - `--mvp` (single job from CSV).\n  - `--max-jobs` to limit for testing.\n- Pseudo-code:\n```python\ndef main():\n    config = load_config()\n    controller = AdbGeelarkDeviceController(mapping=load_account_device_mapping())\n    navigator = ClaudeNavigator(api_key=config.anthropic_api_key)\n    jobs = read_jobs(config.input_csv_path, config.video_root_dir)\n\n    for i, job in enumerate(jobs):\n        try:\n            run_post_job(job, config, controller, navigator)\n            append_log_row(config.output_log_csv_path, job.account_name, job.video_path, \"success\")\n        except Exception as e:\n            append_log_row(config.output_log_csv_path, job.account_name, job.video_path, \"fail\", str(e))\n```\n- Ensure that an exception in one job does not terminate the loop; always continue to next row.\n- Optionally, add a small random delay between jobs to reduce pattern-like behavior and mitigate rate limits.",
        "testStrategy": "- Use a mock controller and navigator to simulate successful and failing jobs; verify that the main loop continues after failures and that the log CSV contains correct rows.\n- Run end-to-end in a test environment with 2–3 dummy jobs, visually inspect logs and confirm that timestamps and statuses are correct.\n- Intentionally raise an exception inside `run_post_job` for one job and confirm that others are still processed.",
        "priority": "high",
        "dependencies": [
          "2",
          "5",
          "7"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:01:36.963Z"
      },
      {
        "id": "10",
        "title": "MVP validation and scaling to multiple accounts/devices",
        "description": "Validate the MVP by successfully posting one video with caption on a single Geelark device, then extend to handle multiple accounts/devices from the spreadsheet.",
        "details": "Implementation details:\n- MVP validation steps:\n  - Configure one `account_name` in the CSV, one `video_path`, and a simple caption.\n  - Map that account to a Geelark device in the controller configuration.\n  - Run the tool and visually confirm that the video is posted with the correct caption.\n  - Confirm that the output log records `success` for this job.\n- Scaling steps:\n  - Extend account-to-device mapping to support many accounts; use a config file like `devices.yaml` with entries `{account_name, device_id}`.\n  - In `connect(account_name)`, look up the correct `device_id` and fall back to a default or raise an error if unmapped.\n  - If Geelark supports parallel control, optionally add a future-ready abstraction to run jobs concurrently (e.g. via a worker pool); for now keep them sequential to minimize complexity.\n  - Ensure that proxy rotation is still called once per job and that rate-limit logic is per account/device.\n- Add documentation (README) describing:\n  - How to prepare the CSV.\n  - How to organize video files.\n  - How to configure API keys and device mappings.\n  - Known edge cases and limitations.",
        "testStrategy": "- For MVP:\n  - Run manual test: verify the real post appears on Instagram from the target account with the expected caption and time.\n  - Check that logs show a single `success` entry with accurate timestamp and video path.\n- For multi-account:\n  - Prepare a CSV with at least 2 accounts mapped to different devices (or sequential runs on same device if that is the Geelark constraint).\n  - Run and verify that each account posts its respective video.\n  - Inspect logs to ensure each row has correct `account`, `video`, and `status`.\n- Perform a small load test with ~10 rows to confirm there are no memory leaks or unhandled exceptions across many iterations.",
        "priority": "medium",
        "dependencies": [
          "4",
          "7",
          "8",
          "9"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:01:47.805Z"
      },
      {
        "id": "11",
        "title": "Fix ADBKeyboard installation on Geelark cloud phones",
        "description": "Pivot to using Appium for Unicode text input on Geelark cloud phones, abandoning the ADBKeyboard approach due to Android 15 incompatibility where the package is hidden at the framework level and cannot be restored via ADB commands.",
        "status": "done",
        "dependencies": [
          "4"
        ],
        "priority": "high",
        "details": "PROBLEM SUMMARY:\n- ADBKeyboard works on Android 12/13 (SDK 31-33) but is blocked on Android 15 (SDK 35) with hidden=true flag at Android framework level\n- All ADB remediation attempts failed: pm uninstall, pm enable, pm unhide, cmd package install-existing all return success but package remains hidden\n- Geelark phones do not provide root access (su returns command not found)\n- ClipboardHelper + KEYCODE_PASTE fallback tested and FAILED - keyboard not visible during paste, text does not appear\n- Only podmindstudio (Android 13) works; reelwisdompod_ and talktrackhub (Android 15) are broken\n\nNEW APPROACH - APPIUM:\nPivot to using Appium for text input, which handles Unicode natively across all Android versions without requiring a custom keyboard IME.\n\nAppium UIAutomator2 driver can:\n- Type text directly into focused fields via send_keys() or mobile:type command\n- Works with Unicode/emojis natively\n- No need for ADBKeyboard, ClipboardHelper, or any IME installation\n- Connects to devices via ADB (same as current setup)\n- Cross-platform Android version support (works on Android 15)\n\nIMPLEMENTATION PLAN:\n1. Set up Appium server (can run locally or on a server)\n   - Install Node.js if not present\n   - npm install -g appium\n   - appium driver install uiautomator2\n\n2. Install Python Appium client:\n   - pip install Appium-Python-Client\n\n3. Connect to Geelark phones via Appium:\n   - Use ADB connection info from Geelark API (same as current flow)\n   - Create Appium driver session with desired capabilities:\n     - platformName: Android\n     - automationName: UiAutomator2\n     - deviceName: {adb_device_id}\n     - noReset: true\n     - appPackage/appActivity for Instagram\n\n4. Update post_reel_smart.py to use Appium:\n   - Create new AppiumController class or add Appium methods to SmartInstagramPoster\n   - Replace type_text() method (lines 225-245) with Appium's send_keys()\n   - Keep ADB for non-typing operations (tap, swipe, screenshot)\n   - Or migrate entirely to Appium for all interactions\n\n5. Testing:\n   - Test on Android 15 device (reelwisdompod_) first\n   - Verify Unicode/emoji typing works correctly\n   - Test full Instagram posting flow\n\nRELEVANT FILES TO MODIFY:\n- post_reel_smart.py: Replace type_text() with Appium-based implementation\n- requirements.txt: Add Appium-Python-Client dependency\n- New file: appium_controller.py (optional, for Appium setup logic)\n\nEXISTING ASSETS:\n- appium-uiautomator2-server.apk already exists in project root\n- package/ directory contains io.appium.settings source (UnicodeIME) but not needed with direct Appium approach\n- ADB connection flow in post_reel_smart.py connect() method can be reused",
        "testStrategy": "- Set up Appium server locally\n- Test Appium connection to reelwisdompod_ (Android 15) device first\n- Create test script that: 1) connects via Appium, 2) opens Instagram, 3) navigates to caption field, 4) types text with emojis using send_keys()\n- Verify text appears correctly in the caption field including Unicode characters and emojis\n- Run full posting flow on Android 15 device\n- Verify same flow still works on Android 13 device (podmindstudio) for backwards compatibility\n- Compare posting success rates before/after migration",
        "subtasks": [
          {
            "id": 3,
            "title": "Complete ADBKeyboard remediation research and document Android 15 blocker",
            "description": "Document the comprehensive ADBKeyboard remediation attempts and confirm that Android 15 hidden=true state is an unresolvable blocker without root access, leading to pivot to Appium.",
            "dependencies": [
              1,
              2
            ],
            "details": "All ADBKeyboard remediation approaches exhausted:\n- pm uninstall/install: Returns success but package remains hidden\n- cmd package install-existing: Returns success but pm path empty\n- pm enable/unhide: Requires root access not available on Geelark\n- Alternative keyboards: Same hidden=true issue affects new installs\n- ClipboardHelper fallback: FAILED - keyboard not visible during paste\n- Root API: Error 43016 indicates phones don't support root\n\nConclusion: ADBKeyboard approach is fundamentally incompatible with Android 15 on Geelark phones. Pivoting to Appium which handles Unicode typing natively without requiring IME installation.",
            "status": "done",
            "testStrategy": "Document all attempted remediation commands and their results. Confirm Android version correlation (SDK 35 = broken, SDK <= 33 = working).",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Set up Appium server and install UiAutomator2 driver",
            "description": "Install and configure Appium server locally with UiAutomator2 driver for Android automation that supports native Unicode text input across all Android versions.",
            "dependencies": [],
            "details": "Installation steps:\n1. Verify Node.js is installed (node --version), install if needed from https://nodejs.org\n2. Install Appium globally: npm install -g appium\n3. Install UiAutomator2 driver: appium driver install uiautomator2\n4. Verify installation: appium driver list (should show uiautomator2)\n5. Start Appium server: appium --allow-insecure chromedriver_autodownload\n6. Verify server is running on http://localhost:4723\n\nServer configuration:\n- Default port: 4723\n- May need to configure ANDROID_HOME environment variable pointing to Android SDK\n- May need to ensure platform-tools (adb) is in PATH\n\nFiles to create:\n- requirements.txt: Add 'Appium-Python-Client>=3.0.0'\n- Optional: appium_setup.py script to verify/start Appium service\n<info added on 2025-12-11T04:22:32.422Z>\nCOMPLETED SETUP STATUS:\n- Appium version: 3.1.2 installed globally via npm\n- UiAutomator2 driver: installed via appium driver install uiautomator2\n- Android SDK: ANDROID_HOME=C:/Users/asus/Downloads/android-sdk with platform-tools symlinked\n- Successfully connected to Geelark cloud phone at 98.98.125.37:20865 running Android 15 (SDK 35)\n- Connection verified via test_appium.py script which captured screenshot (appium_test.png) proving connection works\n- Appium-Python-Client needs to be added to requirements.txt (currently only has python-dotenv, requests, anthropic)\n- Platform version confirmed via driver.capabilities after successful Remote connection to http://127.0.0.1:4723\n</info added on 2025-12-11T04:22:32.422Z>",
            "status": "done",
            "testStrategy": "1) Run 'appium --version' to verify installation\n2) Run 'appium driver list' to verify uiautomator2 is installed\n3) Start Appium server and verify it responds on localhost:4723\n4) Create simple test script that imports appium and verifies client library version",
            "updatedAt": "2025-12-11T04:21:52.916Z",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Appium connection to Geelark cloud phones",
            "description": "Create AppiumController class that connects to Geelark devices via Appium using existing ADB connection info from GeelarkClient, enabling Unicode text input on Android 15.",
            "dependencies": [
              4
            ],
            "details": "Implementation in new file appium_controller.py:\n\nCreate AppiumController class with methods:\n- connect(): Get phone info from GeelarkClient, start phone, enable ADB, connect via Appium with UiAutomator2Options\n- type_text(text): Use driver.switch_to.active_element.send_keys(text) for Unicode support\n- close(): Quit Appium driver session\n\nKey Appium capabilities:\n- platformName: 'Android'\n- automationName: 'UiAutomator2'\n- deviceName: ADB device string (ip:port)\n- noReset: True (preserve app state)\n- newCommandTimeout: 300\n\nIntegration with existing code:\n- Reuse GeelarkClient for phone discovery and ADB setup\n- Reuse ADB connection logic from post_reel_smart.py lines 115-170\n- Add error handling for Appium connection failures",
            "status": "done",
            "testStrategy": "1) Connect to reelwisdompod_ (Android 15) via Appium\n2) Verify driver session is established\n3) Run driver.page_source to confirm UI access\n4) Take screenshot via driver.get_screenshot_as_png()\n5) Verify connection works on both Android 15 and Android 13 devices",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T04:35:32.773Z"
          },
          {
            "id": 6,
            "title": "Update post_reel_smart.py to use Appium for text input",
            "description": "Modify the SmartInstagramPoster class to use Appium's send_keys() for typing captions instead of ADBKeyboard broadcast, while keeping ADB for other operations.",
            "dependencies": [
              4,
              5
            ],
            "details": "Changes to post_reel_smart.py:\n\n1) Add Appium imports at top:\nfrom appium import webdriver\nfrom appium.options.android import UiAutomator2Options\n\n2) Add Appium driver initialization in connect() method\n\n3) Replace type_text() method (lines 225-245) with Appium-based implementation:\n- Use self.appium_driver.switch_to.active_element.send_keys(text)\n- Remove typing_method check since Appium works universally\n- Handle emojis and Unicode natively\n\n4) Add cleanup for Appium driver in disconnect/cleanup\n\n5) Keep existing ADB methods for tap(), swipe(), screenshot, etc.\n\nAlternative: Hybrid approach - try Appium first, fall back to ADBKeyboard if Appium unavailable for Android 13 devices",
            "status": "done",
            "testStrategy": "1) Start Appium server\n2) Run test on Android 15 device (reelwisdompod_) with caption containing emojis\n3) Verify caption appears correctly in Instagram caption field\n4) Run full posting flow and verify success\n5) Run same test on Android 13 device (podmindstudio) for backwards compatibility",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T04:35:36.719Z"
          },
          {
            "id": 7,
            "title": "Add Appium dependencies and update requirements.txt",
            "description": "Add Appium-Python-Client and any other required dependencies to the project requirements file.",
            "dependencies": [],
            "details": "Update requirements.txt to add:\nAppium-Python-Client>=3.0.0\nselenium>=4.0.0\n\nInstallation command: pip install Appium-Python-Client\n\nVerify installation:\nimport appium\nprint(appium.__version__)\n\nNote: Appium-Python-Client depends on selenium, which will be installed automatically.\n\nPreserve existing dependencies:\n- anthropic (for Claude API)\n- requests (for HTTP calls)\n- python-dotenv (for .env loading)",
            "status": "done",
            "testStrategy": "1) Run pip install -r requirements.txt\n2) Verify no dependency conflicts\n3) Test import: python -c \"from appium import webdriver; print('OK')\"\n4) Verify existing imports still work",
            "parentId": "undefined",
            "updatedAt": "2025-12-11T04:22:51.801Z"
          },
          {
            "id": 8,
            "title": "Test full Instagram posting flow with Appium on Android 15",
            "description": "Perform end-to-end testing of the complete Instagram Reel posting workflow using Appium for text input on an Android 15 device to validate the pivot from ADBKeyboard.",
            "dependencies": [
              4,
              5,
              6,
              7
            ],
            "details": "Test procedure:\n\n1) Pre-requisites:\n- Appium server running\n- Android 15 device available (reelwisdompod_ or talktrackhub)\n- Test video file and caption with Unicode/emojis prepared\n\n2) Test execution:\nStart Appium server in terminal 1: appium\nRun posting script in terminal 2: python post_reel_smart.py reelwisdompod_ test_video.mp4 \"Test caption with emojis 🎉✨🔥\"\n\n3) Verification steps:\n- Phone connects successfully\n- Instagram app opens\n- Video upload works (existing ADB-based file transfer)\n- Caption field is focused\n- Appium types caption including emojis correctly\n- Post is shared successfully\n- Verify post appears on Instagram with correct caption\n\n4) Performance comparison:\n- Time to type caption: Appium vs ADBKeyboard\n- Overall posting time\n- Success rate over multiple posts",
            "status": "pending",
            "testStrategy": "1) Execute full posting flow on Android 15 device with emoji-rich caption\n2) Verify caption appears correctly on published post\n3) Repeat test 3-5 times to verify consistency\n4) Test on Android 13 device for backwards compatibility\n5) Run batch_post.py with mix of Android versions to verify multi-device support",
            "parentId": "undefined"
          },
          {
            "id": 1,
            "title": "Research Android package manager ghost package and signature mismatch behaviors (cloud phones)",
            "description": "Investigate how Android handles ghost/orphaned package entries and INSTALL_FAILED_UPDATE_INCOMPATIBLE errors, especially on non-rootable or cloud-hosted devices like Geelark, and document feasible ADB-only remedies.",
            "dependencies": [],
            "details": "Use Perplexity to search Android developer docs, StackOverflow, and XDA for: (1) causes and fixes of INSTALL_FAILED_UPDATE_INCOMPATIBLE when pm uninstall fails; (2) techniques to clear or bypass ghost/orphaned packages without root (e.g., user 0 uninstall, package clear, disabling users, testharness, or resetting app state); (3) behavior differences for system apps vs. user apps in /system/app and /system/priv-app. Summarize which approaches are viable when you only have adb shell and no root, and call out any device-OEM-specific caveats relevant to cloud/virtual devices.\n<info added on 2025-12-11T02:49:23.733Z>\nBased on the codebase analysis and research findings, here is the new text to append:\n\nResearch findings for ADB-only ghost package remediation on Geelark cloud phones:\n\n1) Ghost package removal without root: Use `pm uninstall --user 0 com.android.adbkeyboard` (do NOT use -k flag as it keeps data and leaves ghost state). This removes the package for the current user even when standard pm uninstall fails with DELETE_FAILED_INTERNAL_ERROR.\n\n2) Restoring orphaned system apps: If ADBKeyboard was previously a system app (like on podmindstudio at /system/app/AdbKeyboard/AdbKeyboard.apk), use `cmd package install-existing com.android.adbkeyboard` to restore it from the system image.\n\n3) Alternative for DELETE_FAILED_INTERNAL_ERROR: Try `pm disable-user --user 0 com.android.adbkeyboard` first to disable the ghost entry before attempting uninstall.\n\n4) Detecting ghost packages: Compare output of `pm list packages` (installed) vs `pm list packages -u` (includes uninstalled-but-retained). Packages appearing only in -u output are ghosts.\n\n5) Fallback typing without ADBKeyboard: The codebase already has ClipboardHelper (setup_clipboard_helper.py) which sets clipboard via `am start -n com.geelark.clipboard/.CopyActivity -a com.geelark.clipboard.COPY --es base64 <b64text>`. After setting clipboard, use `input keyevent 279` (KEYCODE_PASTE) to paste content. This approach supports Unicode and emojis without requiring ADBKeyboard.\n\n6) Current setup_adbkeyboard.py (line 102) uses basic `pm uninstall` which fails on ghost packages. Fix requires updating to use `pm uninstall --user 0` approach.\n\nSources: XDA Forums, bayton.org, droidwin.com\n</info added on 2025-12-11T02:49:23.733Z>",
            "status": "done",
            "testStrategy": null,
            "updatedAt": "2025-12-11T02:49:43.751Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Probe Geelark cloud phones for ADBKeyboard package state and system app presence",
            "description": "Systematically inspect all relevant Geelark devices to understand current ADBKeyboard installation state, including ghost entries and potential system app copies.",
            "dependencies": [
              1
            ],
            "details": "On each Geelark phone (podmindstudio, miccliparchive, reelwisdompod_, talktrackhub), run a scripted adb diagnostic sequence: (1) `pm list packages | grep adbkeyboard`; (2) `pm list packages -s` and `-3` to see if it’s system or user; (3) `pm path com.android.adbkeyboard`; (4) `cmd package resolve-activity` and `dumpsys package com.android.adbkeyboard` to detect ghost entries or disabled states; (5) search filesystem for the APK (e.g., `/system/app`, `/system/priv-app`, `/product/app`) using `ls` patterns where allowed; (6) check `settings get secure default_input_method` and `ime list -a` to see if the IME is registered but disabled. Capture outputs in logs per device and infer whether each device has a system app copy, a broken/ghost entry, or no trace at all.\n<info added on 2025-12-11T02:52:30.810Z>\nDiagnosis Results:\n\n1) podmindstudio: INSTALLED and working - System app located at /system/app/AdbKeyboard/AdbKeyboard.apk. IME properly set to com.android.adbkeyboard/.AdbIME. No remediation needed.\n\n2) miccliparchive: GHOST PACKAGE - APK exists in /system/app but package uninstalled for user 0. Current IME set to Google keyboard (com.google.android.inputmethod.latin). Package appears in `pm list packages -u` but not in `pm list packages`. Remediation: Use `cmd package install-existing com.android.adbkeyboard` to restore system app for current user, then set IME.\n\n3) reelwisdompod_: GHOST PACKAGE - APK exists in /system/app but package uninstalled for user 0. IME setting still points to ADBKeyboard but keyboard non-functional since package not installed for user. Remediation: Same as miccliparchive - use `cmd package install-existing com.android.adbkeyboard` to restore.\n\n4) talktrackhub: NOT INSTALLED - Clean slate, no ADBKeyboard APK anywhere on the filesystem. No ghost package entries. Remediation options: (a) Copy APK from podmindstudio via `adb pull/push` and install, or (b) Use clipboard-based text input as fallback.\n\nFix Strategy for setup_adbkeyboard.py: Add detection logic to differentiate ghost package vs clean slate states. For ghost packages (miccliparchive, reelwisdompod_), use `cmd package install-existing com.android.adbkeyboard` instead of standard pm install. For clean installs (talktrackhub), either pull APK from working phone or use local ADBKeyboard.apk with pm install.\n</info added on 2025-12-11T02:52:30.810Z>",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-11T02:52:49.620Z"
          }
        ],
        "updatedAt": "2025-12-12T02:01:58.948Z"
      },
      {
        "id": "12",
        "title": "Investigate and fix empty Appium page_source on Android 15 Instagram sessions",
        "description": "Debug and instrument the Appium-based Android 15 setup so that page_source / dump_ui() returns a non-empty, correctly structured UI hierarchy for the Instagram app, and determine whether issues stem from app launch, hierarchy generation, or XML parsing.",
        "details": "Implementation plan:\n\n1. **Set up a focused Android 15/Appium debug harness**\n- Create a standalone Python script or test module (e.g. `debug/appium_source_debug.py`) that:\n  - Connects to the same Geelark Android 15 device configuration used in Task 11.\n  - Uses the same Appium capabilities (platformName, platformVersion, deviceName/UDID, automationName=UiAutomator2, appPackage/appActivity for Instagram, noReset, etc.).\n  - Logs all capabilities and the Appium server version at startup for reproducibility.\n- Ensure the harness is runnable independently from the main posting flow to speed up iteration.\n\n2. **Compare Appium page_source vs. uiautomator dump formats**\n- Use Appium’s `driver.page_source` and log the raw return value to a file (e.g. `artifacts/appium_source_raw.xml`) for multiple states: before Instagram launch, after launch, and after navigating to a known screen.[2]\n- On the same device and screen, use `adb shell uiautomator dump /sdcard/view.xml && adb pull /sdcard/view.xml artifacts/uiautomator_view.xml` and compare:\n  - Root element tag names and attributes (`hierarchy`, `node`, bounds, text, resource-id, content-desc).\n  - Character encoding and XML declaration.\n  - Presence/absence of expected views (e.g., Instagram home feed, buttons, bottom nav).\n- Document differences in a short markdown note (`docs/appium_vs_uiautomator.md`), highlighting any fields Appium normalizes or omits and confirming that Appium is returning **application hierarchy XML**, not a raw uiautomator dump.[2]\n\n3. **Verify that Instagram is truly launching and in foreground**\n- From the debug harness, add explicit steps:\n  - Call `driver.start_activity(appPackage, appActivity)` (or equivalent) and wait for a few seconds.\n  - Use `adb shell dumpsys window windows | grep -E 'mCurrentFocus|mFocusedApp'` to verify that the Instagram activity is in the foreground; log this output.\n  - Capture a screenshot via Appium (`driver.get_screenshot_as_png()`) and save to `artifacts/instagram_launch.png`; visually confirm the app is open.\n- If Appium connects but Instagram is not foregrounded, log this and add retries/explicit waits (e.g. wait for known accessibility id or resource-id) before calling `page_source`.\n\n4. **Instrument the page_source / dump_ui() call itself**\n- Wrap `driver.page_source` and any `dump_ui()` helper used in Task 11 in a small utility (e.g. `debug/get_hierarchy.py`) that:\n  - Measures call latency.\n  - Catches and logs exceptions.\n  - Logs the length of the returned XML string and the first 500–1000 characters.\n- Add verbose Appium server logging (log level `debug`) for these calls, capturing:\n  - The `Get Page Source` requests and responses.\n  - Any UiAutomator2/Android errors when traversing the hierarchy.\n- If `page_source` returns an empty hierarchy but no exception, investigate whether this is a known limitation with background apps, webviews, or Android 15 specifics.[1][6]\n\n5. **Check for webview / context or invisible-element issues**\n- Enumerate contexts using `driver.contexts` and log them; if a `WEBVIEW_` context exists for Instagram, switch contexts and compare `page_source` results to the native context.\n- Confirm whether the expected elements are off-screen or lazily created (e.g., lists or RecyclerViews)[3]; scroll a small amount and re-fetch `page_source` to see if the hierarchy populates.\n- Ensure that the harness requests **native context** when expecting native XML, and document how Instagram’s UI composition (native vs webview) affects what Appium can see.[4]\n\n6. **Rule out XML parsing issues in our code**\n- If Appium returns non-empty XML but our `dump_ui()` / parser reports no nodes, add unit-level diagnostics:\n  - Create a minimal parser module (e.g. `ui_parsing/xml_utils.py`) that loads the raw Appium XML using both `xml.etree.ElementTree` and `lxml` (if available) to handle any namespace/encoding quirks.\n  - Log any parsing errors, invalid characters, or namespace prefixes.\n  - Add defensive parsing: strip BOMs, normalize encoding to UTF‑8, and handle default namespaces.\n- Implement a small CLI (`python -m ui_parsing.debug_parse artifacts/appium_source_raw.xml`) that prints root tag, number of nodes, and a few sample attributes to quickly validate parsing.\n\n7. **Constrain work to Android 15 devices**\n- Ensure the harness inspects the device’s SDK level from `adb shell getprop ro.build.version.sdk` and asserts it is 35 (Android 15); otherwise, exit with a clear message.\n- If needed, parameterize the target device but keep the scope of this task to documenting and resolving the Android 15 behavior (other OS versions can be future work).\n\n8. **Output and documentation**\n- Produce a short troubleshooting doc `docs/android15_appium_empty_source.md` summarizing:\n  - Root cause(s): app not foregrounded, context mismatch, Android 15 UiAutomator behavior, or XML parsing bug.\n  - The final, recommended way to:\n    - Confirm Instagram is open.\n    - Fetch reliable page source.\n    - Parse and inspect the hierarchy.\n  - Any Appium capabilities or flags that improved results (e.g., waitForIdleTimeout, disableWindowAnimation, etc., if changed).\n- Expose any reusable utilities (e.g., `get_page_source_debug()`, `assert_instagram_foreground()`) in a `debug_utils` module so other tasks (like Task 11 and orchestrator work) can reuse them.\n",
        "testStrategy": "1. **Environment and connectivity sanity checks**\n- Run the debug harness against an Android 15 Geelark device and verify:\n  - Appium session is created without errors.\n  - Device SDK level is detected as 35; the script exits with an error on non‑15 devices.\n\n2. **Instagram launch verification**\n- Execute the harness with Instagram launch enabled and confirm:\n  - `dumpsys window` logs show an Instagram activity in `mCurrentFocus`/`mFocusedApp`.\n  - The saved screenshot clearly shows Instagram in the foreground.\n\n3. **Page source vs uiautomator comparison**\n- On the same screen, generate both `artifacts/appium_source_raw.xml` and `artifacts/uiautomator_view.xml`.\n- Manually inspect or script-compare them to confirm:\n  - Non-empty XML in both files.\n  - Similar numbers of nodes and presence of expected Instagram UI elements.\n\n4. **XML parsing validation**\n- Run the XML parser CLI against `appium_source_raw.xml` and verify it prints:\n  - Correct root element name.\n  - A positive node count (> 0).\n  - At least a few nodes with sensible attributes (e.g., text/resource-id not all empty).\n- Intentionally corrupt the XML file (e.g., truncate it) and confirm the parser reports clear parsing errors instead of silently returning zero nodes.\n\n5. **Context and visibility behavior tests**\n- From the harness, log `driver.contexts` and switch between native and any webview context, calling `page_source` in each and confirming non-empty output where expected.\n- Scroll within Instagram and re-run `page_source`, verifying the hierarchy updates and that elements entering/leaving the visible region appear/disappear from the XML.\n\n6. **Regression guard for empty source condition**\n- Add an automated check in the harness that fails if `page_source` length is below a small threshold (e.g., < 1 KB) while Instagram is reported as foreground.\n- Run the harness multiple times (at least 5) and confirm the check consistently passes on Android 15.\n\n7. **Documentation review**\n- Have a team member follow `docs/android15_appium_empty_source.md` on a fresh environment and verify they can reproduce the debug steps and obtain non-empty page source and parsed node counts without additional help.",
        "status": "done",
        "dependencies": [
          "4",
          "11"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:02:09.371Z"
      },
      {
        "id": "13",
        "title": "Apply Appium stability fixes with extended timeouts and crash recovery",
        "description": "Improve Appium connection reliability in post_reel_smart.py by adding missing timeout capabilities, increasing existing timeouts, implementing phone restart logic for UiAutomator2 crashes, and creating a typed exception for startup failures.",
        "details": "## Implementation Details\n\n### 1. Create typed UiAutomatorStartupError exception (top of file, after imports ~line 35)\n\n```python\nclass UiAutomatorStartupError(Exception):\n    \"\"\"Raised when UiAutomator2 fails to start on the device\"\"\"\n    pass\n```\n\n### 2. Update connect_appium() function (lines 730-763) with new capabilities\n\nAdd these capabilities to the `options` object:\n\n```python\ndef connect_appium(self, retries=3):\n    \"\"\"Connect Appium driver - REQUIRED for automation to work\"\"\"\n    print(\"Connecting Appium driver...\")\n\n    options = UiAutomator2Options()\n    options.platform_name = \"Android\"\n    options.automation_name = \"UiAutomator2\"\n    options.device_name = self.device\n    options.udid = self.device\n    options.no_reset = True\n    options.new_command_timeout = 60\n    \n    # Extended timeouts for stability (Android 15 devices need longer)\n    options.set_capability(\"appium:uiautomator2ServerLaunchTimeout\", 90000)  # NEW: 90s (was missing, defaulted to 30s)\n    options.set_capability(\"appium:uiautomator2ServerInstallTimeout\", 120000)  # INCREASED: 120s (was 60s)\n    options.set_capability(\"appium:adbExecTimeout\", 120000)  # INCREASED: 120s (was 30s)\n    options.set_capability(\"appium:androidDeviceReadyTimeout\", 60000)  # NEW: 60s device ready wait\n\n    last_error = None\n    for attempt in range(retries):\n        try:\n            self.appium_driver = webdriver.Remote(\n                command_executor=APPIUM_SERVER,\n                options=options\n            )\n            platform_ver = self.appium_driver.capabilities.get('platformVersion', 'unknown')\n            print(f\"  Appium connected! (Android {platform_ver})\")\n            return True\n        except Exception as e:\n            last_error = e\n            print(f\"  Appium connection failed (attempt {attempt + 1}/{retries}): {e}\")\n            self.appium_driver = None\n            \n            # Check if UiAutomator2 crashed - may need phone restart\n            if self.is_uiautomator2_crash(e):\n                print(f\"  [RECOVERY] UiAutomator2 crash detected, attempting phone restart...\")\n                self._restart_phone_for_recovery()\n            \n            if attempt < retries - 1:\n                print(f\"  Retrying in 15 seconds...\")  # INCREASED: 15s (was 5s)\n                time.sleep(15)\n\n    # All retries failed - raise typed exception\n    raise UiAutomatorStartupError(f\"Appium connection failed after {retries} attempts: {last_error}\")\n```\n\n### 3. Add phone restart recovery method (new method in SmartInstagramPoster class)\n\nAdd this method after `reconnect_appium()` (around line 84):\n\n```python\ndef _restart_phone_for_recovery(self):\n    \"\"\"Restart the Geelark phone to recover from UiAutomator2 crash\"\"\"\n    if not self.phone_id:\n        print(\"    Cannot restart phone - phone_id not set\")\n        return False\n    \n    try:\n        print(\"    Stopping phone...\")\n        self.client.stop_phone(self.phone_id)\n        time.sleep(5)\n        \n        print(\"    Starting phone...\")\n        self.client.start_phone(self.phone_id)\n        \n        # Wait for phone to boot (similar to connect() logic)\n        print(\"    Waiting for phone to boot...\")\n        for i in range(60):\n            time.sleep(2)\n            status_result = self.client.get_phone_status([self.phone_id])\n            items = status_result.get(\"successDetails\", [])\n            if items and items[0].get(\"status\") == 0:\n                print(f\"    Phone ready after restart! (took ~{(i+1)*2}s)\")\n                break\n            if i % 5 == 0:\n                print(f\"    Booting... ({(i+1)*2}s)\")\n        else:\n            print(\"    Warning: Phone boot timeout after restart\")\n            return False\n        \n        # Re-enable ADB after restart\n        time.sleep(3)\n        print(\"    Re-enabling ADB...\")\n        self.client.enable_adb(self.phone_id)\n        time.sleep(5)\n        \n        # Reconnect ADB\n        adb_info = self.client.get_adb_info(self.phone_id)\n        self.device = f\"{adb_info['ip']}:{adb_info['port']}\"\n        password = adb_info['pwd']\n        \n        import subprocess\n        subprocess.run([ADB_PATH, \"connect\", self.device], capture_output=True)\n        self.adb(f\"glogin {password}\")\n        time.sleep(3)\n        \n        print(\"    Phone restart recovery complete\")\n        return True\n        \n    except Exception as e:\n        print(f\"    Phone restart failed: {e}\")\n        return False\n```\n\n### 4. Update reconnect_appium() to use new exception (line 74-84)\n\n```python\ndef reconnect_appium(self):\n    \"\"\"Reconnect Appium driver after UiAutomator2 crash\"\"\"\n    print(\"  [RECOVERY] Reconnecting Appium driver...\")\n    try:\n        if self.appium_driver:\n            self.appium_driver.quit()\n    except:\n        pass\n    self.appium_driver = None\n    time.sleep(2)\n    try:\n        return self.connect_appium()\n    except UiAutomatorStartupError:\n        # If reconnect also fails, try phone restart\n        if self._restart_phone_for_recovery():\n            return self.connect_appium()\n        raise\n```\n\n### Summary of Changes\n\n| Item | Before | After |\n|------|--------|-------|\n| `uiautomator2ServerLaunchTimeout` | Missing (30s default) | 90000ms |\n| `uiautomator2ServerInstallTimeout` | 60000ms | 120000ms |\n| `adbExecTimeout` | 30000ms | 120000ms |\n| `androidDeviceReadyTimeout` | Missing | 60000ms |\n| Retry sleep | 5s | 15s |\n| Phone restart on crash | Not implemented | Implemented |\n| Typed exception | Generic Exception | UiAutomatorStartupError |\n\n### Files Modified\n- `post_reel_smart.py`: Add exception class, update `connect_appium()`, add `_restart_phone_for_recovery()`, update `reconnect_appium()`",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Tests for Exception Class\n- Verify `UiAutomatorStartupError` can be raised and caught\n- Verify it inherits from `Exception`\n- Verify error message is preserved correctly\n\n### 2. Timeout Configuration Tests\n- Start Appium with a mock device and verify the capabilities are set correctly:\n  - `uiautomator2ServerLaunchTimeout == 90000`\n  - `uiautomator2ServerInstallTimeout == 120000`\n  - `adbExecTimeout == 120000`\n  - `androidDeviceReadyTimeout == 60000`\n- Log the capabilities object before connection to verify values\n\n### 3. Retry Logic Tests\n- Mock Appium connection failures and verify:\n  - Retry happens 3 times\n  - Sleep between retries is 15 seconds (measure with time.time())\n  - `UiAutomatorStartupError` is raised after all retries fail\n\n### 4. Phone Restart Recovery Tests\n- Mock `is_uiautomator2_crash()` to return `True`\n- Verify `_restart_phone_for_recovery()` is called\n- Mock GeelarkClient methods (`stop_phone`, `start_phone`, `get_phone_status`, `enable_adb`, `get_adb_info`)\n- Verify the correct sequence of recovery calls\n\n### 5. Integration Test with Real Device\n```bash\n# Test on a Geelark Android 15 device\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\n\nposter = SmartInstagramPoster('test_phone_name')\nposter.connect()\n\n# Verify capabilities by checking the driver\ncaps = poster.appium_driver.capabilities\nprint(f'Platform: {caps.get(\\\"platformVersion\\\")}')\nprint(f'Appium connected successfully with extended timeouts')\n\nposter.cleanup()\n\"\n```\n\n### 6. Crash Recovery Simulation\n- Force a UiAutomator2 crash by killing the server process\n- Verify the recovery logic kicks in:\n  ```bash\n  # In a separate terminal while test is running:\n  adb shell \"pkill -f uiautomator\"\n  ```\n- Observe that phone restart and Appium reconnection occur\n\n### 7. End-to-End Test\n- Run full posting flow: `python post_reel_smart.py <phone> <video> <caption>`\n- Monitor logs for timeout-related errors\n- Verify no more \"30s timeout\" errors appear\n- Verify successful connection even under slow network conditions\n\n### 8. Regression Testing\n- Run the existing test suite to ensure no regressions\n- Verify `posting_scheduler.py` still works with the updated `connect_appium()`\n- Test with multiple concurrent phones to verify stability",
        "status": "done",
        "dependencies": [
          "11",
          "12"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:02:20.479Z"
      },
      {
        "id": "14",
        "title": "Analyze overnight scheduler run results (Dec 11-12)",
        "description": "Review batch_results_20251211*.csv files and scheduler logs to compute comprehensive metrics including success rates, error patterns, time correlations, and priority fixes needed.",
        "details": "## Implementation Details\n\n### 1. Create analysis script `analyze_scheduler_results.py`\n\n```python\nimport os\nimport csv\nimport json\nfrom datetime import datetime\nfrom collections import defaultdict\nfrom typing import Dict, List, Tuple, Optional\nimport statistics\n\nclass SchedulerAnalyzer:\n    def __init__(self, csv_pattern: str = \"batch_results_20251211*.csv\"):\n        self.csv_pattern = csv_pattern\n        self.records = []\n        \n    def load_data(self):\n        \"\"\"Load all matching CSV files\"\"\"\n        import glob\n        for filepath in glob.glob(self.csv_pattern):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                reader = csv.DictReader(f)\n                for row in reader:\n                    row['source_file'] = filepath\n                    row['timestamp_parsed'] = datetime.fromisoformat(row['timestamp']) if row.get('timestamp') else None\n                    self.records.append(row)\n```\n\n### 2. Metric Calculations\n\n#### Success Rate by Account\n```python\ndef success_rate_by_account(self) -> Dict[str, dict]:\n    \"\"\"Calculate success/fail/error counts per phone/account\"\"\"\n    by_account = defaultdict(lambda: {'success': 0, 'failed': 0, 'error': 0, 'total': 0})\n    for r in self.records:\n        account = r.get('phone', 'unknown')\n        status = r.get('status', 'unknown')\n        by_account[account][status] = by_account[account].get(status, 0) + 1\n        by_account[account]['total'] += 1\n    # Calculate rates\n    for acc, data in by_account.items():\n        data['success_rate'] = data['success'] / data['total'] * 100 if data['total'] > 0 else 0\n    return dict(sorted(by_account.items(), key=lambda x: x[1]['success_rate']))\n```\n\n#### Success Rate by Hour\n```python\ndef success_rate_by_hour(self) -> Dict[int, dict]:\n    \"\"\"Calculate success rates grouped by hour of day\"\"\"\n    by_hour = defaultdict(lambda: {'success': 0, 'total': 0})\n    for r in self.records:\n        if r.get('timestamp_parsed'):\n            hour = r['timestamp_parsed'].hour\n            by_hour[hour]['total'] += 1\n            if r.get('status') == 'success':\n                by_hour[hour]['success'] += 1\n    for hour, data in by_hour.items():\n        data['success_rate'] = data['success'] / data['total'] * 100 if data['total'] > 0 else 0\n    return dict(sorted(by_hour.items()))\n```\n\n#### Error Type Classification\n```python\ndef classify_errors(self) -> Dict[str, List[dict]]:\n    \"\"\"Categorize errors by type based on error message patterns\"\"\"\n    error_patterns = {\n        'upload_timeout': ['Upload timeout', 'status: 1'],\n        'uiautomator_crash': ['UiAutomator2', 'instrumentation process is not running', 'crashed'],\n        'adb_timeout': ['timed out after', 'adb.exe'],\n        'connection_failed': ['connection', 'offline', 'refused'],\n        'instagram_blocked': ['action blocked', 'suspended', 'captcha'],\n    }\n    \n    classified = defaultdict(list)\n    for r in self.records:\n        if r.get('status') in ['error', 'failed']:\n            error_msg = r.get('error', '')\n            error_type = 'unknown'\n            for etype, patterns in error_patterns.items():\n                if any(p.lower() in error_msg.lower() for p in patterns):\n                    error_type = etype\n                    break\n            classified[error_type].append(r)\n    return dict(classified)\n```\n\n#### Average Attempts Before Success\n```python\ndef avg_attempts_before_success(self) -> dict:\n    \"\"\"Calculate average attempts needed for successful posts.\n    Requires correlation with scheduler_state.json for attempt tracking.\"\"\"\n    # Load from scheduler_state.json if available\n    state_file = \"scheduler_state.json\"\n    attempts_data = []\n    try:\n        with open(state_file, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        for job in data.get('jobs', []):\n            if job.get('status') == 'success':\n                attempts_data.append(job.get('attempts', 1))\n    except Exception:\n        pass\n    \n    if attempts_data:\n        return {\n            'mean': statistics.mean(attempts_data),\n            'median': statistics.median(attempts_data),\n            'max': max(attempts_data),\n            'samples': len(attempts_data)\n        }\n    return {'error': 'No attempt data available'}\n```\n\n#### Phones with Highest Failure Rates\n```python\ndef phones_by_failure_rate(self, min_attempts: int = 2) -> List[Tuple[str, float, int]]:\n    \"\"\"Return phones sorted by failure rate (highest first)\"\"\"\n    rates = self.success_rate_by_account()\n    failures = []\n    for phone, data in rates.items():\n        if data['total'] >= min_attempts:\n            failure_rate = 100 - data['success_rate']\n            failures.append((phone, failure_rate, data['total']))\n    return sorted(failures, key=lambda x: -x[1])\n```\n\n#### Time Patterns in Failures\n```python\ndef failure_time_patterns(self) -> dict:\n    \"\"\"Analyze when failures occur - time of day, day of week, gaps between attempts\"\"\"\n    failures_by_hour = defaultdict(int)\n    failures_by_minute_bucket = defaultdict(int)  # 10-min buckets\n    \n    for r in self.records:\n        if r.get('status') in ['error', 'failed'] and r.get('timestamp_parsed'):\n            ts = r['timestamp_parsed']\n            failures_by_hour[ts.hour] += 1\n            bucket = ts.hour * 6 + ts.minute // 10\n            failures_by_minute_bucket[bucket] += 1\n    \n    return {\n        'by_hour': dict(failures_by_hour),\n        'peak_failure_hour': max(failures_by_hour.items(), key=lambda x: x[1]) if failures_by_hour else None,\n        'failure_distribution': failures_by_minute_bucket\n    }\n```\n\n#### Video Size Correlation (placeholder - needs video file access)\n```python\ndef video_size_correlation(self, video_folder: str = \"chunk_01c\") -> dict:\n    \"\"\"Correlate video file sizes with success/failure rates.\n    Requires access to video files to get sizes.\"\"\"\n    # Map shortcodes to file sizes\n    shortcode_sizes = {}\n    success_sizes = []\n    fail_sizes = []\n    \n    # Walk video folder to build size map\n    for root, dirs, files in os.walk(video_folder):\n        for f in files:\n            if f.endswith('.mp4'):\n                shortcode = f.replace('.mp4', '')\n                path = os.path.join(root, f)\n                shortcode_sizes[shortcode] = os.path.getsize(path)\n    \n    for r in self.records:\n        shortcode = r.get('shortcode', '')\n        if shortcode in shortcode_sizes:\n            size_mb = shortcode_sizes[shortcode] / (1024 * 1024)\n            if r.get('status') == 'success':\n                success_sizes.append(size_mb)\n            else:\n                fail_sizes.append(size_mb)\n    \n    return {\n        'avg_success_size_mb': statistics.mean(success_sizes) if success_sizes else 0,\n        'avg_fail_size_mb': statistics.mean(fail_sizes) if fail_sizes else 0,\n        'success_samples': len(success_sizes),\n        'fail_samples': len(fail_sizes),\n    }\n```\n\n### 3. Report Generator\n\n```python\ndef generate_report(self) -> str:\n    \"\"\"Generate a comprehensive markdown report\"\"\"\n    report = []\n    report.append(\"# Scheduler Run Analysis Report - Dec 11, 2025\\n\")\n    \n    # Overall stats\n    total = len(self.records)\n    success = sum(1 for r in self.records if r.get('status') == 'success')\n    report.append(f\"## Overall Statistics\")\n    report.append(f\"- Total attempts: {total}\")\n    report.append(f\"- Successful: {success} ({success/total*100:.1f}%)\")\n    report.append(f\"- Failed/Error: {total - success}\")\n    \n    # Add each metric section...\n    # (success by account, by hour, error types, etc.)\n    \n    # Priority Fixes section\n    report.append(\"\\n## Priority Fixes Needed\")\n    errors = self.classify_errors()\n    if errors.get('upload_timeout'):\n        report.append(\"1. **Upload Timeout** - Increase upload timeout beyond 180s or implement chunked upload\")\n    if errors.get('uiautomator_crash'):\n        report.append(\"2. **UiAutomator2 Crashes** - Implement phone restart recovery per Task 13\")\n    \n    return \"\\n\".join(report)\n```\n\n### 4. CLI Interface\n\n```python\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser(description='Analyze scheduler results')\n    parser.add_argument('--date', default='20251211', help='Date pattern YYYYMMDD')\n    parser.add_argument('--output', default='scheduler_analysis_report.md', help='Output report file')\n    parser.add_argument('--json', action='store_true', help='Output raw data as JSON')\n    \n    args = parser.parse_args()\n    \n    analyzer = SchedulerAnalyzer(f\"batch_results_{args.date}*.csv\")\n    analyzer.load_data()\n    \n    if args.json:\n        data = {\n            'by_account': analyzer.success_rate_by_account(),\n            'by_hour': analyzer.success_rate_by_hour(),\n            'errors': analyzer.classify_errors(),\n            'failure_patterns': analyzer.failure_time_patterns(),\n        }\n        print(json.dumps(data, indent=2, default=str))\n    else:\n        report = analyzer.generate_report()\n        with open(args.output, 'w', encoding='utf-8') as f:\n            f.write(report)\n        print(f\"Report saved to {args.output}\")\n```\n\n### 5. Files to Read\n\n- `batch_results_20251211*.csv` - All CSV files from Dec 11 runs\n- `scheduler_state.json` - For attempt counts and job metadata\n- `geelark_batch.log` - For detailed error stack traces and phase timing\n- `chunk_01c/` - Video folder for file size analysis",
        "testStrategy": "## Test Strategy\n\n### 1. Data Loading Tests\n- Verify all Dec 11 CSV files are found and loaded (expect ~14 files based on glob results)\n- Confirm all expected columns are present: shortcode, phone, status, error, timestamp\n- Test handling of empty error fields and malformed timestamps\n\n### 2. Metric Calculation Validation\n- **Success rate by account**: Cross-reference with manual count from sample CSV files\n- **Success rate by hour**: Verify hour extraction from ISO timestamps (e.g., \"2025-12-11T18:22:34\" → hour 18)\n- **Error classification**: Test pattern matching against known error strings:\n  - \"Upload timeout after 180s (last status: 1)\" → upload_timeout\n  - \"UiAutomator2 server...instrumentation process is not running\" → uiautomator_crash\n  - \"timed out after 30 seconds\" → adb_timeout\n\n### 3. Report Verification\n- Run analysis and verify report includes all 7 requested metrics\n- Compare overall success count with sum across all CSVs\n- Verify phones with highest failure rates list shows accounts that appear in error records\n\n### 4. Edge Cases\n- Test with empty CSV files\n- Test with single-record files\n- Test when scheduler_state.json is unavailable or malformed\n- Test when video folder doesn't exist (video size correlation should gracefully report 0 samples)\n\n### 5. Manual Spot-Check\n```bash\n# Quick validation commands\npython analyze_scheduler_results.py --json | jq '.by_account | length'\n# Should return number of unique accounts\n\npython analyze_scheduler_results.py --json | jq '.errors | keys'\n# Should show error type categories found\n```\n\n### 6. Cross-Reference with Raw Data\n- Compare report findings with direct CSV inspection\n- Verify error messages in report match actual error strings from CSVs\n- Confirm time patterns align with file timestamps on batch_results_*.csv files",
        "status": "cancelled",
        "dependencies": [
          "2",
          "9"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T00:29:55.262Z"
      },
      {
        "id": "15",
        "title": "Integrate reliability features into posting_scheduler worker loop",
        "description": "Wire up existing but unused reliability mechanisms (Appium health checks, account cooldown backoff) into the scheduler's worker loop, add a heartbeat thread to keep the lock file fresh, and classify infrastructure errors to trigger account-level backoff.",
        "details": "## Current State Analysis\n\nThe codebase already has several reliability features that are **implemented but NOT wired up**:\n\n1. **Single-instance lock** (lines 30-111): Fully working but uses static lock file without heartbeat\n2. **Appium health checks** (lines 114-170): `check_appium_health()` and `restart_appium()` exist but never called\n3. **Account cooldown** (lines 435-471): `is_on_cooldown()` and `record_post(is_infra_error)` exist but:\n   - `is_on_cooldown()` is NOT checked in `get_next_job()` (line 661-703)\n   - `record_post()` is always called with just `False`, never passing `is_infra_error=True` (line 815)\n\n## Implementation Details\n\n### 1. Add Heartbeat Thread for Lock Freshness\n\nUpdate the lock file with a timestamp periodically so other instances can detect truly stale locks:\n\n```python\n# Add to PostingScheduler.__init__()\nself.heartbeat_thread: Optional[threading.Thread] = None\nself.heartbeat_interval = 30  # seconds\n\n# Add heartbeat method\ndef _heartbeat_loop(self):\n    \"\"\"Periodically update lock file to prove we're still alive\"\"\"\n    while self.running:\n        try:\n            if os.path.exists(LOCK_FILE):\n                with open(LOCK_FILE, 'r') as f:\n                    lock_data = json.load(f)\n                if lock_data.get('pid') == os.getpid():\n                    lock_data['last_heartbeat'] = datetime.now().isoformat()\n                    with open(LOCK_FILE, 'w') as f:\n                        json.dump(lock_data, f)\n        except Exception as e:\n            logger.warning(f\"Heartbeat error: {e}\")\n        time.sleep(self.heartbeat_interval)\n```\n\nUpdate `acquire_lock()` to check heartbeat staleness:\n```python\n# In acquire_lock(), after is_process_running check:\nlast_heartbeat = lock_data.get('last_heartbeat')\nif last_heartbeat:\n    hb_time = datetime.fromisoformat(last_heartbeat)\n    stale_threshold = timedelta(minutes=2)  # 2 minutes without heartbeat = stale\n    if datetime.now() - hb_time > stale_threshold:\n        print(f\"[LOCK] Lock heartbeat stale ({hb_time}). Taking over.\")\n        # Proceed to take over\n```\n\n### 2. Integrate Appium Health Check into Worker Loop\n\nIn `_worker_loop()`, before processing a job:\n\n```python\ndef _worker_loop(self):\n    \"\"\"Main worker loop\"\"\"\n    self._log(\"Worker started\")\n    \n    # Track consecutive Appium failures for restart logic\n    appium_consecutive_failures = 0\n    max_appium_failures_before_restart = 3\n    \n    while self.running:\n        if self.paused:\n            time.sleep(1)\n            continue\n        \n        # Check Appium health before each job\n        if not check_appium_health():\n            self._log(\"[APPIUM] Health check failed\")\n            appium_consecutive_failures += 1\n            \n            if appium_consecutive_failures >= max_appium_failures_before_restart:\n                self._log(\"[APPIUM] Attempting auto-restart...\")\n                if restart_appium():\n                    appium_consecutive_failures = 0\n                else:\n                    self._log(\"[APPIUM] Restart failed, waiting 60s...\")\n                    time.sleep(60)\n                    continue\n            else:\n                time.sleep(10)\n                continue\n        else:\n            appium_consecutive_failures = 0  # Reset on success\n        \n        job = self.get_next_job()\n        # ... rest of loop\n```\n\n### 3. Integrate Account Cooldown into get_next_job()\n\nUpdate `get_next_job()` to filter out accounts on cooldown:\n\n```python\ndef get_next_job(self) -> Optional[PostJob]:\n    \"\"\"Get next job that's ready to post\"\"\"\n    accounts_posted_today = get_accounts_posted_today()\n    \n    # Filter: can post today AND not on cooldown\n    available_accounts = [\n        acc for acc in self.accounts.values()\n        if acc.can_post_today(self.posts_per_account_per_day)\n        and acc.name not in accounts_posted_today\n        and not acc.is_on_cooldown()  # ADD THIS LINE\n    ]\n    # ... rest of method unchanged\n```\n\n### 4. Classify Infrastructure Errors in execute_job()\n\nUpdate the error handling in `execute_job()` to detect infrastructure errors:\n\n```python\n# In execute_job(), in the except block (around line 783):\nexcept Exception as e:\n    error_msg = str(e)\n    error_type_name = type(e).__name__\n    \n    # Classify infrastructure errors\n    infra_error_patterns = [\n        'ADB', 'adb', 'device offline', 'glogin', 'phone not running',\n        'Appium', 'appium', 'UiAutomator', 'WebDriver', \n        'connection refused', 'timeout', 'Timeout'\n    ]\n    is_infra_error = any(pattern in error_msg for pattern in infra_error_patterns) or \\\n                     any(pattern in error_type_name for pattern in infra_error_patterns)\n    \n    job.last_error = f\"[{phase}] {error_type_name}: {error_msg}\"\n    \n    # ... existing error handling ...\n    \n    # Pass is_infra_error to trigger backoff\n    self.accounts[job.account].record_post(False, is_infra_error=is_infra_error)\n```\n\n### 5. Start Heartbeat Thread in start()\n\n```python\ndef start(self):\n    \"\"\"Start the scheduler\"\"\"\n    if self.running:\n        return\n    \n    # ... existing phone cleanup ...\n    \n    self.running = True\n    self.paused = False\n    \n    # Start heartbeat thread\n    self.heartbeat_thread = threading.Thread(target=self._heartbeat_loop, daemon=True)\n    self.heartbeat_thread.start()\n    self._log(\"[HEARTBEAT] Started heartbeat thread\")\n    \n    # Start worker thread\n    self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n    self.worker_thread.start()\n    self._log(\"Scheduler started\")\n```\n\n### 6. Add Account Cooldown Status to get_stats()\n\n```python\ndef get_stats(self) -> dict:\n    \"\"\"Get current statistics\"\"\"\n    accounts_on_cooldown = [acc.name for acc in self.accounts.values() if acc.is_on_cooldown()]\n    \n    return {\n        # ... existing stats ...\n        'accounts_on_cooldown': accounts_on_cooldown,\n    }\n```\n\n## Files to Modify\n\n- `posting_scheduler.py`: All changes concentrated in this single file",
        "testStrategy": "## Test Strategy\n\n### 1. Single-Instance Lock with Heartbeat Tests\n\n**Test stale lock detection:**\n```bash\n# Create a stale lock file manually\necho '{\"pid\": 99999, \"started\": \"2024-01-01T00:00:00\", \"last_heartbeat\": \"2024-01-01T00:00:00\"}' > scheduler.lock\n\n# Run scheduler - should take over the stale lock\npython posting_scheduler.py --status\n# Expected: \"Lock heartbeat stale\" message, then acquires lock\n```\n\n**Test heartbeat updates:**\n```bash\n# Start scheduler in background\npython posting_scheduler.py --add-folder chunk_test --add-accounts test1 --run &\n\n# Check lock file updates every 30s\nwatch -n 10 'cat scheduler.lock | python -m json.tool | grep last_heartbeat'\n# Expected: last_heartbeat timestamp updates every ~30 seconds\n```\n\n**Test duplicate instance prevention:**\n```bash\n# Terminal 1: Start scheduler\npython posting_scheduler.py --run\n\n# Terminal 2: Try to start another\npython posting_scheduler.py --run\n# Expected: \"[LOCK ERROR] Another scheduler instance is already running!\"\n```\n\n### 2. Appium Health Check Integration Tests\n\n**Test health check detection:**\n```bash\n# Stop Appium server\ntaskkill /F /IM node.exe\n\n# Run scheduler - should detect Appium down\npython posting_scheduler.py --run\n# Expected: \"[APPIUM] Health check failed\" messages\n```\n\n**Test auto-restart:**\n```bash\n# With Appium stopped, scheduler should attempt restart after 3 failures\n# Expected log sequence:\n# [APPIUM] Health check failed (1)\n# [APPIUM] Health check failed (2) \n# [APPIUM] Health check failed (3)\n# [APPIUM] Attempting auto-restart...\n# [APPIUM] Server ready on port 4723\n```\n\n### 3. Account Cooldown Integration Tests\n\n**Test cooldown filtering in get_next_job:**\n```python\n# Unit test\nscheduler = PostingScheduler()\nscheduler.add_account(\"test1\")\nscheduler.accounts[\"test1\"].cooldown_until = (datetime.now() + timedelta(minutes=10)).isoformat()\n\n# get_next_job should not return jobs for test1\njob = scheduler.get_next_job()\nassert job is None or job.account != \"test1\"\n```\n\n**Test infrastructure error classification:**\n```python\n# Simulate infra error in execute_job\n# After 3 consecutive failures, account should be on cooldown\nassert scheduler.accounts[\"test1\"].is_on_cooldown() == True\nassert scheduler.accounts[\"test1\"].consecutive_failures >= 3\n```\n\n### 4. Status Command Verification\n\n```bash\npython posting_scheduler.py --status\n# Expected output includes:\n# - Lock status with last_heartbeat timestamp\n# - Accounts on cooldown list (if any)\n# - Appium health status\n```\n\n### 5. Error Log Verification\n\nAfter a test run with simulated failures:\n```bash\ngrep \"is_infra_error\" geelark_batch.log\n# Should show infrastructure errors being correctly classified\n\ngrep \"on cooldown\" geelark_batch.log  \n# Should show accounts being put on cooldown after consecutive failures\n```\n\n### 6. Integration Test with Real Posting\n\n```bash\n# Run with a small test batch\npython posting_scheduler.py --add-folder chunk_test --add-accounts phone1 --run\n\n# Monitor logs for:\n# 1. Heartbeat updates\n# 2. Appium health checks before each job\n# 3. Proper cooldown behavior if failures occur\n# 4. Clean shutdown releasing lock\n```",
        "status": "done",
        "dependencies": [
          "9",
          "11",
          "13"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-12T01:42:53.832Z"
      },
      {
        "id": "16",
        "title": "Ensure ANDROID_HOME / ANDROID_SDK_ROOT Are Recognized by Appium Server",
        "description": "Make Appium reliably detect the Android SDK by standardizing how ANDROID_HOME and ANDROID_SDK_ROOT are set, exported, and propagated into the Appium server process across all deployment environments.",
        "details": "## Goal\nGuarantee that when the Appium server is started (locally, via scripts, or inside workers/containers), it always has valid access to the Android SDK through **ANDROID_HOME** and/or **ANDROID_SDK_ROOT**, so errors like “Neither ANDROID_HOME nor ANDROID_SDK_ROOT environment variable was exported” do not occur.[7][8]\n\n## High-Level Approach\n1. **Standardize environment variable configuration** for Android SDK on all supported OSes (Linux/macOS; Windows only if relevant).\n2. **Ensure variables are set in a *non-interactive* context** (systemd services, cron, Docker, background workers), not just in interactive shells.[7]\n3. **Unify Appium startup** through a single entry point (Python helper or shell script) that validates and, if needed, sets or maps ANDROID_SDK_ROOT/ANDROID_HOME before launching the server.\n4. **Add diagnostics** so misconfiguration is obvious in logs.\n\n## Implementation Steps\n\n### 1. Discover Current SDK Paths and Usage\n- Inspect how Appium is currently started:\n  - Python wrapper (e.g., `post_reel_smart.py` / scheduler), direct `appium` CLI, Docker, or a service unit.\n  - Note whether `appium` is started via `subprocess` in Python.\n- On at least one working dev machine and one production-like host:\n  - Run `echo $ANDROID_HOME` and `echo $ANDROID_SDK_ROOT` (or `set` on Windows) to see what is set.[4][6]\n  - Run `sdkmanager --list` from the same shell that starts Appium to confirm SDK accessibility.\n  - If using Android Studio, open SDK Manager and capture the **Android SDK Location** to use as canonical ANDROID_HOME.[5][6]\n\n### 2. Standard OS-Level Environment Setup (Best Practices)\nFollow current best-practice patterns for SDK env configuration so that Appium’s CLI sees them by default.[2][4][5][6]\n\n**Linux/macOS:**\n- In the system or service user profile, set (example):\n  ```bash\n  export ANDROID_HOME=\"$HOME/Android/Sdk\"\n  export ANDROID_SDK_ROOT=\"$ANDROID_HOME\"\n  export PATH=\"$PATH:$ANDROID_HOME/emulator:$ANDROID_HOME/platform-tools:$ANDROID_HOME/tools:$ANDROID_HOME/tools/bin\"\n  ```[4][5][6]\n- Add to the appropriate file for non-interactive shells (e.g., `/etc/profile.d/android-sdk.sh` or the service user’s `.profile`), not just `.bashrc`.\n\n**Windows (if used for Appium host):**\n- In *System Properties → Environment Variables*:\n  - Add **ANDROID_HOME** and/or **ANDROID_SDK_ROOT** pointing to the SDK directory (e.g., `C:\\Users\\<User>\\AppData\\Local\\Android\\Sdk`).[2][3][5][6]\n  - Add to **PATH**:\n    - `%ANDROID_HOME%\\emulator`\n    - `%ANDROID_HOME%\\platform-tools`\n    - `%ANDROID_HOME%\\tools`\n    - `%ANDROID_HOME%\\tools\\bin`[2][5]\n- Reboot or restart relevant services after setting system variables.[5]\n\nDocument the canonical SDK path and env configuration in `docs/appium_env.md` so all environments can be made consistent.\n\n### 3. Central Appium Launcher With Env Validation\nCreate a central launcher responsible for starting Appium with a guaranteed-good environment.\n\n**Option A – Shell wrapper (for CLI/containers):**\n- Add a script `scripts/start_appium.sh`:\n  ```bash\n  #!/usr/bin/env bash\n  set -euo pipefail\n\n  # 1. Infer or normalize SDK env\n  if [[ -z \"${ANDROID_HOME:-}\" && -n \"${ANDROID_SDK_ROOT:-}\" ]]; then\n    export ANDROID_HOME=\"$ANDROID_SDK_ROOT\"\n  elif [[ -z \"${ANDROID_SDK_ROOT:-}\" && -n \"${ANDROID_HOME:-}\" ]]; then\n    export ANDROID_SDK_ROOT=\"$ANDROID_HOME\"\n  fi\n\n  # 2. Fallback: attempt to detect SDK in common locations (optional)\n  if [[ -z \"${ANDROID_HOME:-}\" ]]; then\n    for candidate in \"$HOME/Android/Sdk\" \\\n                    \"$HOME/Library/Android/sdk\" \\\n                    \"/usr/local/android-sdk\"; do\n      if [[ -d \"$candidate/platform-tools\" ]]; then\n        export ANDROID_HOME=\"$candidate\"\n        export ANDROID_SDK_ROOT=\"$candidate\"\n        break\n      fi\n    done\n  fi\n\n  # 3. Validate\n  if [[ -z \"${ANDROID_HOME:-}\" || ! -d \"$ANDROID_HOME/platform-tools\" ]]; then\n    echo \"[FATAL] ANDROID_HOME/ANDROID_SDK_ROOT not set or invalid. Please install Android SDK and configure env vars.\" >&2\n    exit 1\n  fi\n\n  export PATH=\"$PATH:$ANDROID_HOME/emulator:$ANDROID_HOME/platform-tools:$ANDROID_HOME/tools:$ANDROID_HOME/tools/bin\"\n\n  echo \"[INFO] Using ANDROID_HOME=$ANDROID_HOME\" >&2\n  echo \"[INFO] Using ANDROID_SDK_ROOT=${ANDROID_SDK_ROOT:-$ANDROID_HOME}\" >&2\n\n  # 4. Finally run Appium\n  exec appium \"$@\"\n  ```\n- Ensure all automation (scheduler, local dev docs, CI, systemd unit) uses this script instead of invoking `appium` directly.\n\n**Option B – Python-side launcher (if Appium is started from Python):**\n- Implement a helper (e.g., in a shared module `appium_env.py`):\n  ```python\n  import os\n  import shutil\n  import subprocess\n\n  class AndroidEnvError(RuntimeError):\n      pass\n\n  def ensure_android_env() -> dict:\n      env = os.environ.copy()\n      home = env.get(\"ANDROID_HOME\")\n      root = env.get(\"ANDROID_SDK_ROOT\")\n\n      if not home and root:\n          home = root\n          env[\"ANDROID_HOME\"] = root\n      elif not root and home:\n          root = home\n          env[\"ANDROID_SDK_ROOT\"] = home\n\n      if not home:\n          # Optional: probe common locations\n          for candidate in [\n              os.path.expanduser(\"~/Android/Sdk\"),\n              os.path.expanduser(\"~/Library/Android/sdk\"),\n              \"/usr/local/android-sdk\",\n          ]:\n              if os.path.isdir(os.path.join(candidate, \"platform-tools\")):\n                  home = root = candidate\n                  env[\"ANDROID_HOME\"] = candidate\n                  env[\"ANDROID_SDK_ROOT\"] = candidate\n                  break\n\n      if not home or not os.path.isdir(os.path.join(home, \"platform-tools\")):\n          raise AndroidEnvError(\n              \"ANDROID_HOME/ANDROID_SDK_ROOT not set or invalid; install Android SDK and configure env vars.\"\n          )\n\n      pt = os.path.join(home, \"platform-tools\")\n      emulator = os.path.join(home, \"emulator\")\n      tools = os.path.join(home, \"tools\")\n      tools_bin = os.path.join(tools, \"bin\")\n      extra = os.pathsep.join(p for p in [pt, emulator, tools, tools_bin] if os.path.isdir(p))\n      if extra:\n          env[\"PATH\"] = env.get(\"PATH\", \"\") + os.pathsep + extra\n\n      return env\n\n  def start_appium_server(args: list[str]) -> subprocess.Popen:\n      env = ensure_android_env()\n      appium_cmd = shutil.which(\"appium\") or \"appium\"\n      return subprocess.Popen([appium_cmd, *args], env=env)\n  ```\n- Refactor all places that start Appium (e.g., utilities used by Task 11 and 13 flows) to use `start_appium_server` instead of raw `subprocess.Popen`.\n\n### 4. Integrate with Existing Reliability / Health Logic\n- In the same place where Appium health checks and restarts are wired (Task 15) and connection stability is being improved (Task 13), ensure the restart path *also* uses the standardized launcher so restarted servers see the correct env.\n- When an Appium startup or health check fails due to env problems (e.g., server logs mention missing `adb` or ANDROID_HOME), log a distinct error code / message so future analysis (Task 14) can differentiate env configuration problems from device/Appium bugs.\n\n### 5. Diagnostics and Logging\n- At Appium startup, log the detected **ANDROID_HOME**, **ANDROID_SDK_ROOT**, and whether `adb` is found on PATH (e.g., `which adb` / `where adb`).\n- Optionally, run a lightweight `adb version` and `adb devices` check immediately after starting the server and log the output to quickly spot SDK vs. device issues.[4][6]\n- Update developer/ops documentation with:\n  - Required env vars and their purpose.\n  - Example configuration snippets for each OS.\n  - How to run `appium-doctor --android` to validate setup before running tests.[1][2][6]\n\n### 6. CI / Container Integration (If Applicable)\n- For Docker images, bake the SDK and env variables into the image:\n  ```dockerfile\n  ENV ANDROID_HOME=/opt/android-sdk \\\n      ANDROID_SDK_ROOT=/opt/android-sdk\n  ENV PATH=\"$PATH:$ANDROID_HOME/emulator:$ANDROID_HOME/platform-tools:$ANDROID_HOME/tools:$ANDROID_HOME/tools/bin\"\n  ```\n- Ensure the CI job that runs mobile tests uses either the shell or Python launcher above.\n\n## Notes / Best Practices\n- Prefer **ANDROID_SDK_ROOT** (more modern) but keep **ANDROID_HOME** for compatibility; set both to the same directory.[7]\n- Always ensure that at least `platform-tools` and `emulator` are on PATH for Appium Android testing.[2][4][5][6]\n- When changing system environment variables on Windows, restart services or the whole machine so Appium inherits them.[5]\n",
        "testStrategy": "1. **Env Sanity Checks**\n- On each supported OS:\n  - Open a shell configured the same way the Appium server is started (service user, CI container, or scheduler process).\n  - Run `echo $ANDROID_HOME` / `echo $ANDROID_SDK_ROOT` (or `set ANDROID_` on Windows) and confirm they point to the actual SDK directory.\n  - Run `adb version` and confirm it succeeds.\n  - Run `appium-doctor --android` and verify there are no Android SDK-related errors.[1][2][6]\n\n2. **Launcher-Level Tests (Shell Wrapper)**\n- Temporarily unset ANDROID_HOME/ANDROID_SDK_ROOT, then:\n  - Create a mock SDK directory at a common default path with a dummy `platform-tools` folder.\n  - Run `scripts/start_appium.sh --log-level debug` and confirm:\n    - The script discovers the SDK and sets ANDROID_HOME/ANDROID_SDK_ROOT (check printed logs).\n    - `adb` from the mock SDK is picked up (check `which adb` output if added).\n- Set only ANDROID_HOME and confirm the wrapper mirrors it to ANDROID_SDK_ROOT and logs both.\n- Set only ANDROID_SDK_ROOT and confirm the wrapper mirrors it to ANDROID_HOME.\n- Intentionally point ANDROID_HOME to a non-existent directory and verify the script exits non‑zero with a clear fatal error message.\n\n3. **Launcher-Level Tests (Python Helper, if implemented)**\n- Unit-test `ensure_android_env()` using `monkeypatch`/`os.environ` manipulation:\n  - Case: both vars absent, no SDK dirs → expect `AndroidEnvError`.\n  - Case: only ANDROID_HOME set → expect ANDROID_SDK_ROOT to be added and PATH extended.\n  - Case: only ANDROID_SDK_ROOT set → expect ANDROID_HOME to be added and PATH extended.\n  - Case: neither set but a test SDK directory exists in a probed path → expect both vars to be set to that directory.\n- Unit-test `start_appium_server()` by stubbing `subprocess.Popen` and asserting it receives an `env` with properly set ANDROID_HOME/ANDROID_SDK_ROOT and PATH.\n\n4. **Integration Test with Appium and Device**\n- From the worker/scheduler context that will run real jobs:\n  - Start Appium using the new launcher (shell or Python).\n  - Check the Appium server logs to confirm:\n    - ANDROID_HOME/ANDROID_SDK_ROOT values are logged as expected.\n    - No warnings like \"Neither ANDROID_HOME nor ANDROID_SDK_ROOT environment variable was exported\" appear.[8]\n  - Run a minimal Android session (e.g., from Task 11’s test harness):\n    - Create an Appium session to a real or cloud Android device.\n    - Verify the session initializes, `adb devices` lists the device, and a simple `driver.get_page_source()` succeeds.\n\n5. **Failure-Mode Regression Test**\n- Temporarily misconfigure env (e.g., unset ANDROID_HOME in the service config) and start Appium through the new launcher:\n  - Confirm the launcher fails fast with a clear error instead of starting a broken server.\n  - Ensure higher-level reliability/health logic (from Task 13 and Task 15) logs an explicit env-configuration error category and does not enter an infinite restart loop.\n\n6. **Documentation Validation**\n- Follow the updated `docs/appium_env.md` from a clean machine:\n  - Configure the SDK and env exactly as documented.\n  - Start Appium using the documented command.\n  - Confirm that an Android session can be created without additional manual tweaks, demonstrating the docs are accurate and sufficient.",
        "status": "done",
        "dependencies": [
          "11",
          "13"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-12T01:54:53.017Z"
      },
      {
        "id": "17",
        "title": "Reduce UiAutomator2 launch timeout from 90s to 10s",
        "description": "Optimize the Appium UiAutomator2 server launch timeout based on the observation that instrumentation either starts immediately (~1s) or times out completely - there is no middle ground, so waiting 90 seconds on failure wastes time unnecessarily.",
        "details": "## Background\n\nAnalysis documented in `geelark_uiautomator2_timeout_report.txt` reveals a **binary behavior pattern** for UiAutomator2 initialization on Geelark cloud phones:\n\n- **Success case**: Instrumentation starts in ~1 second (observed: 1104ms)\n- **Failure case**: Times out after the full timeout period (previously 90s)\n- **No middle ground**: There are no cases where initialization takes 30s, 50s, or any intermediate time\n\nThis means the previous 90-second timeout was wasteful - if UiAutomator2 doesn't start within a few seconds, it won't start at all until retry.\n\n## Implementation\n\nIn `post_reel_smart.py`, update the `connect_appium()` method (around line 743):\n\n### Before (Task 13 implementation):\n```python\noptions.set_capability(\"appium:uiautomator2ServerLaunchTimeout\", 90000)  # 90s\n```\n\n### After:\n```python\noptions.set_capability(\"appium:uiautomator2ServerLaunchTimeout\", 10000)  # 10s for launch - binary: works in ~1s or not at all\n```\n\n## Rationale\n\n1. **Time savings**: Failed attempts now waste 10s instead of 90s (80s saved per failure)\n2. **Faster retry cycle**: With 15s delay between retries, a full 3-attempt cycle takes:\n   - Before: 90s + 15s + 90s + 15s + 90s = 300s (5 minutes)\n   - After: 10s + 15s + 10s + 15s + 10s = 60s (1 minute)\n3. **No false negatives**: 10s is still generous given the observed ~1s success time\n4. **Buffer for edge cases**: 10s provides 10x buffer over the ~1s typical success time\n\n## Other timeouts remain unchanged\n\nThe following timeouts in `connect_appium()` should NOT be reduced as they serve different purposes:\n\n- `newCommandTimeout: 120` - For slow cloud phone operations during the session\n- `adbExecTimeout: 120000` - For slow ADB commands over network tunnels\n- `uiautomator2ServerInstallTimeout: 120000` - First-time APK installation can be slow\n- `androidDeviceReadyTimeout: 60` - Device boot/ready detection\n\nOnly `uiautomator2ServerLaunchTimeout` exhibits the binary behavior pattern.",
        "testStrategy": "## Test Strategy\n\n### 1. Verify timeout value is correctly set\n\nRun a quick Appium session and check the capabilities:\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster('test_phone')\n# Connect to a phone and check capabilities\nposter.connect()\ncaps = poster.appium_driver.capabilities\nprint(f'Launch timeout: {caps.get(\\\"uiautomator2ServerLaunchTimeout\\\", \\\"not set\\\")}')\nposter.cleanup()\n\"\n```\n\n### 2. Timing verification on success\n\nStart a cloud phone and time the Appium connection:\n```bash\ntime python -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster('podclipcrafters')\nposter.connect()\nprint('Connected successfully')\nposter.cleanup()\n\"\n```\n\nExpected: Total connection time should be well under 60 seconds on success.\n\n### 3. Timing verification on failure\n\nSimulate a failure scenario by connecting to an invalid device:\n```bash\ntimeout 20 python -c \"\nfrom appium import webdriver\nfrom appium.options.android import UiAutomator2Options\noptions = UiAutomator2Options()\noptions.device_name = 'invalid:12345'\noptions.udid = 'invalid:12345'\noptions.set_capability('appium:uiautomator2ServerLaunchTimeout', 10000)\ndriver = webdriver.Remote('http://127.0.0.1:4723', options=options)\n\" 2>&1 | grep -i timeout\n```\n\nExpected: Should timeout within ~15 seconds (10s timeout + overhead), not 90+ seconds.\n\n### 4. Full retry cycle timing\n\nRun a posting operation to a phone that may have intermittent connectivity:\n```bash\ntime python posting_scheduler.py --add-accounts podclipcrafters --add-folder test_videos --run --max-accounts 1\n```\n\nMonitor `geelark_batch.log` for retry timing. Expected:\n- If first attempt fails, retry should start within 25-30 seconds (10s timeout + 15s delay)\n- Full 3-attempt cycle should complete in under 2 minutes even with all failures\n\n### 5. Regression test - no false negatives\n\nRun the scheduler on 5-10 phones overnight and compare:\n- Success rate should remain the same or improve (not decrease)\n- Average time per attempt should decrease significantly",
        "status": "done",
        "dependencies": [
          "13"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-12T02:04:02.231Z"
      },
      {
        "id": "18",
        "title": "Fix Appium Connection Failures with Device-Ready Checks and Thread Cleanup",
        "description": "Resolve Appium connection instability by ensuring device readiness before glogin execution, fixing ThreadPoolExecutor cleanup to prevent orphaned sessions, and managing stale ADB connections through robust connect() flow improvements.",
        "details": "Implement comprehensive fixes for the three identified Appium connection failure root causes following Appium best practices for ADB stability and resource management[1][2][6].\n\n## 1. Device Readiness Check Before glogin (Primary Fix)\n\n**Current Problem**: glogin executes before ADB reports device as 'device' status, causing connection failures[1].\n\n**Implementation**:\n```python\n# In connect_appium() or connect() flow (~lines 730+ from Task 13)\nimport subprocess\nimport time\n\nfrom typing import Optional\n\ndef wait_for_device_ready(udid: str, timeout: int = 60) -> bool:\n    \"\"\"Wait for device to report 'device' status in ADB\"\"\"\n    start_time = time.time()\n    while time.time() - start_time < timeout:\n        result = subprocess.run(\n            ['adb', '-s', udid, 'get-state'],\n            capture_output=True, text=True, timeout=5\n        )\n        if result.returncode == 0 and 'device' in result.stdout.strip().lower():\n            return True\n        time.sleep(2)\n    return False\n\ndef safe_glogin(udid: str) -> None:\n    \"\"\"Only run glogin after device is confirmed ready\"\"\"\n    if not wait_for_device_ready(udid):\n        raise UiAutomatorStartupError(f\"Device {udid} never reached 'device' state\")\n    # Run glogin subprocess here (existing logic)\n    subprocess.run(['glogin', udid], check=True)\n```\n\n**Integration**: Call `safe_glogin(self.device_udid)` **before** Appium driver initialization in `connect_appium()`.\n\n## 2. Fix/Remove ThreadPoolExecutor Wrapper\n\n**Current Problem**: ThreadPoolExecutor timeouts leave orphaned Appium sessions/threads[6].\n\n**Best Practice**: Use context managers for guaranteed cleanup. Remove ThreadPoolExecutor wrapper entirely[6].\n\n**Implementation**:\n```python\n# REPLACE ThreadPoolExecutor wrapper pattern with direct context-managed sessions\n\nclass AppiumSessionManager:\n    def __enter__(self):\n        self.driver = self.connect_appium(retries=3)\n        return self.driver\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Guaranteed cleanup - even on exceptions/timeouts\"\"\"\n        if hasattr(self, 'driver') and self.driver:\n            try:\n                self.driver.quit()\n                # Force ADB session cleanup\n                subprocess.run(['adb', 'kill-server'])\n                subprocess.run(['adb', 'start-server'])\n            except Exception as e:\n                logger.warning(f\"Cleanup failed: {e}\")\n\n# Usage in posting logic:\nwith AppiumSessionManager() as driver:\n    # All automation here\n    pass  # Auto-cleanup guaranteed\n```\n\n## 3. Stale ADB Connection Management\n\n**Implementation**:\n```python\ndef refresh_adb_connection(udid: Optional[str] = None) -> None:\n    \"\"\"Kill/restart ADB server to clear stale connections[1][2]\"\"\"\n    subprocess.run(['adb', 'kill-server'])\n    time.sleep(2)\n    subprocess.run(['adb', 'start-server'])\n    if udid:\n        # Wait for specific device\n        wait_for_device_ready(udid)\n\n# Call refresh_adb_connection() at start of connect_appium() and on UiAutomatorStartupError\n```\n\n## 4. Updated connect_appium() Flow\n```python\ndef connect_appium(self, retries=3):\n    for attempt in range(retries):\n        try:\n            refresh_adb_connection(self.device_udid)\n            safe_glogin(self.device_udid)\n            \n            # Existing Appium connection logic with 10s UiAutomator2 timeout (Task 17)\n            options = UiAutomator2Options()\n            options.set_capability('uiautomator2ServerLaunchTimeout', 10000)  # 10s\n            self.driver = u2.connect(options)\n            return self.driver\n        except (UiAutomatorStartupError, Exception) as e:\n            logger.warning(f\"Attempt {attempt+1} failed: {e}\")\n            if attempt == retries - 1:\n                raise\n            time.sleep(5)\n```\n\n**Dependencies**: Builds directly on Task 13 (connect_appium() structure, UiAutomatorStartupError), Task 17 (10s timeout), Task 16 (ADB env vars).[1][2]",
        "testStrategy": "**Comprehensive Test Strategy** (Critical for production stability)\n\n### 1. Device Readiness Tests\n```bash\n# Test 1: Simulate offline→online transition\nadb disconnect <udid>\nsleep 5\n# Start device connection\npython -m pytest test_appium_connect.py::test_wait_device_ready\n```\n- Verify `wait_for_device_ready()` polls correctly\n- Confirm `safe_glogin()` blocks until 'device' state\n- Test 60s timeout raises `UiAutomatorStartupError`\n\n### 2. ThreadPoolExecutor Replacement Tests\n- Create unit test simulating timeout during session\n```python\nfrom contextlib import contextmanager\n\n@contextmanager\ndef failing_appium():\n    yield\n    raise TimeoutError(\"Simulated timeout\")\n\n# Verify __exit__ still executes cleanup\n```\n- Confirm `driver.quit()` and `adb kill-server` called even on exceptions\n\n### 3. End-to-End Connection Tests\n```bash\n# Test full connect() flow 50x\nfor i in {1..50}; do\n    python test_appium_stability.py --device <udid> || echo \"FAIL $i\"\ndone\n```\n**Success Criteria**:\n- 100% success rate (0 connection failures)\n- No orphaned Appium processes (`ps aux | grep appium`)\n- No stale ADB connections (`adb devices -l` shows clean list)\n\n### 4. ADB Stale Connection Tests\n```bash\n# Force stale connections\nadb kill-server\nadb start-server\n# Run multiple parallel sessions\npytest test_adb_cleanup.py -n auto\n```\n- Verify `refresh_adb_connection()` restores clean state\n- Confirm no 'offline' devices after cleanup\n\n### 5. Integration with Existing Codebase\n- Run full scheduler loop (Task 15) for 2+ hours\n- Monitor `batch_results_*.csv` for zero Appium connection errors\n- Validate no lockfile/heartbeat issues (Task 15)\n\n**Tools**:\n- `lsof -i :5037` (ADB port conflicts)\n- `ps aux | grep -E 'appium|glogin'` (orphaned processes)\n- Appium logs with `--log-level debug`",
        "status": "cancelled",
        "dependencies": [
          "13",
          "16",
          "17"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T00:29:47.030Z"
      },
      {
        "id": "19",
        "title": "Implement multi-process Appium worker orchestration with isolated servers and CSV-based progress tracking",
        "description": "Design and implement a multi-worker posting system where each Python process manages its own Appium server, device, and job subset, coordinated by a simple orchestrator and CSV-based progress tracking to avoid duplicate posts.",
        "details": "Implementation outline:\n\n1) Overall architecture and process model\n- Introduce a new module (e.g. `parallel_orchestrator.py`) that is responsible for:\n  - Spawning N worker processes using `multiprocessing.Process` or `subprocess` (not threads) for true isolation.\n  - Assigning each worker a unique Appium configuration (Appium port, systemPort range, device mapping, and log paths).\n  - Managing lifecycle: start all workers, monitor, and perform clean shutdown on SIGINT/SIGTERM.\n- Each worker process will:\n  - Start its own Appium server instance (local `appium` binary or programmatic Node call) on a unique port (4723, 4725, 4727, etc.), following best practice that each device has a dedicated Appium server and unique port.[1][3]\n  - Use a unique `systemPort` (or narrow range) per worker for UiAutomator2 to avoid conflicts between parallel Android sessions.[3][6]\n  - Initialize its own `GeelarkDeviceController` and posting flow stack (`ClaudeNavigator`, etc.) to reuse existing single-device logic from Task 7.\n\n2) Port and systemPort allocation strategy\n- Define a configuration structure (in `config.py` or a new `parallel_config.py`) mapping worker IDs to Appium ports and systemPort ranges, e.g.:\n  - worker 0: appium_port=4723, system_port_start=8200, system_port_end=8209\n  - worker 1: appium_port=4725, system_port_start=8210, system_port_end=8219\n- When constructing desired capabilities for a worker’s Appium session, set:\n  - `\"udid\"` or equivalent device ID for that worker’s Geelark device.\n  - `\"systemPort\"` to a value in the allocated range for that worker.\n- Enforce uniqueness at runtime (assert no two workers share the same appium_port or overlapping systemPort ranges) to follow Appium parallel execution best practices.[1][3]\n\n3) Appium server lifecycle per worker\n- Implement a helper in a dedicated module, e.g. `appium_server_manager.py`:\n  - `start_appium_server(port: int, log_path: str, extra_args: list[str]) -> subprocess.Popen` that:\n    - Spawns `appium` with `--port`, and for Android also passes any required UiAutomator2/Chromedriver arguments.\n    - Redirects stdout/stderr to a per-worker log file for easier debugging, as recommended for parallel runs.[1]\n    - Waits for health-check (HTTP call to `/status`) with timeout and retry before proceeding.\n  - `stop_appium_server(proc: subprocess.Popen, timeout: float = 10.0)` that sends SIGTERM, then SIGKILL if necessary.\n- In the worker entrypoint:\n  - Start Appium.\n  - Run the worker job-processing loop.\n  - In a `try/finally`, always stop the Appium server and perform device cleanup.\n\n4) Worker process design and job acquisition\n- Implement a `worker_main(worker_id: int, config: Config, shared_state_paths: ...)` entry function that:\n  - Sets up logging with worker-specific identifiers.\n  - Starts Appium with that worker’s dedicated ports.\n  - Enters a loop where it repeatedly:\n    - Claims the next unprocessed job from a shared CSV-based tracker (see section 5).\n    - Runs `run_post_job(job, config, controller, navigator)` from Task 7, reusing the existing single-job flow.\n    - On success/failure, writes to both the existing output log CSV (Task 2, 9) and the progress tracker.\n  - Terminates cleanly when there are no remaining unclaimed jobs.\n- Ensure workers do not share Python objects in memory; they should communicate only via the filesystem (CSV files) or simple IPC if needed.\n\n5) CSV-based shared progress tracking (no duplicate posts)\n- Design a dedicated progress CSV (e.g. `progress.csv`) separate from the result log:\n  - Columns: `job_id`, `account_name`, `video_path`, `status` (pending/claimed/success/fail/skip), `worker_id`, `timestamp`, `error`.\n- Implement a small `progress_tracker.py` module with concurrency-safe operations based on file locking:\n  - Use `fcntl.flock` (Unix) or `msvcrt.locking`/`portalocker` (cross-platform) to protect updates so that parallel workers cannot claim the same job simultaneously (a best-practice for shared resources in parallel execution).[1]\n  - `claim_next_job(worker_id) -> Optional[PostJob]`:\n    - Acquire an exclusive lock on `progress.csv`.\n    - Load rows (in-memory or via streaming), find the first `status == \"pending\"` row.\n    - Mark it as `claimed` with `worker_id` and timestamp, rewrite the file atomically (e.g. write to temp file then rename).\n    - Release the lock and return the corresponding `PostJob`, or `None` if no pending jobs remain.\n  - `update_job_status(job_id, status, worker_id, error=None)`:\n    - Lock file, update the row, rewrite atomically, unlock.\n- Provide a bootstrap utility that, at orchestrator startup, seeds `progress.csv` from the main input CSV if it does not exist, assigning `job_id` indices that remain stable across runs.\n\n6) Orchestrator script to start/stop all workers\n- Implement a CLI script (e.g. `python -m geelark_ig_bot.parallel_orchestrator`) that:\n  - Loads `Config` using existing config mechanisms from Task 1 and compatible with Task 9.\n  - Reads desired `num_workers` and per-worker device/Appium port mapping from configuration.\n  - Initializes/validates the `progress.csv` file, ensuring all jobs are marked `pending` or appropriately resumed from a previous run.\n  - Starts worker processes with `multiprocessing.Process(target=worker_main, args=(...))` or by calling the module’s CLI via `subprocess.Popen`.\n  - Monitors children: optionally capture exit codes and restart on transient failure, or log and shut down gracefully.\n  - Handles signals:\n    - On SIGINT/SIGTERM, set a shared shutdown flag (e.g. `multiprocessing.Event` or a `shutdown` file), wait for workers to finish their current job, then terminate any stuck processes.\n\n7) Integration with existing posting logic\n- Reuse existing modules:\n  - Use Task 2’s `read_jobs` only in the orchestrator seeding step; workers should rely on `progress_tracker` for job acquisition.\n  - Use Task 7’s `run_post_job` as the per-job worker function, passing the worker-specific `GeelarkDeviceController` and `ClaudeNavigator` instances.\n  - Ensure proxy rotation (Task 5) and error-handling/logging (Task 9) continue to function as-is within each worker.\n- Avoid global singletons where possible; instantiate controller/navigator inside each worker process to keep state isolated.\n\n8) Clean shutdown, device cleanup, and fault tolerance\n- Within each worker:\n  - Track the current device session (driver) and ensure that on normal loop exit or exceptions, you:\n    - Attempt to close the app session and release the device (following typical parallel execution guidance to avoid dangling sessions).[1][3]\n    - Stop the Appium server via `stop_appium_server`.\n  - Make all teardown operations idempotent so that repeated shutdown attempts (from orchestrator and OS) do not crash.\n- Implement defensive behavior:\n  - If Appium fails to start or health-check fails, mark the worker as failed, log the error, and exit with a non-zero code.\n  - If a job fails due to Appium/device issues, mark job status as `fail` with error details in both progress and result logs.\n\n9) Logging and observability\n- Configure per-worker log files for:\n  - Worker Python logs (info, warning, error) including job IDs and account names.\n  - Appium server stdout/stderr.\n- Include job IDs and worker IDs in all structured logs (Task 9) to simplify debugging parallel issues, as recommended for parallel test execution environments.[1]\n\n10) Documentation and configuration\n- Add documentation to `README` or internal docs:\n  - How to configure the number of workers and mapping to devices.\n  - Port and systemPort allocation strategy.\n  - How progress tracking works and how to resume a partially completed run.\n  - Operational notes: typical CPU/memory impact when running multiple Appium servers concurrently.[1][3]\n- Expose the most important knobs via config: `num_workers`, `appium_start_cmd`, base Appium port, systemPort ranges, and log directory.\n",
        "testStrategy": "1) Unit tests for progress tracking\n- Test `claim_next_job` and `update_job_status` sequentially:\n  - Seed a temporary `progress.csv` with multiple pending jobs.\n  - Verify that `claim_next_job` returns jobs in order and marks them as `claimed` with the correct `worker_id`.\n  - Verify that `update_job_status` transitions rows to `success`, `fail`, or `skip` and persists changes.\n- Simulate contention by spawning 2–3 lightweight Python processes in tests that concurrently call `claim_next_job` against the same file and assert that no `job_id` is returned more than once.\n\n2) Unit tests for Appium server manager (where feasible with mocks)\n- Mock `subprocess.Popen` and the HTTP health-check:\n  - Ensure `start_appium_server` is called with the expected port and arguments.\n  - Verify that failed health-checks raise a clear exception.\n- Test `stop_appium_server` behavior when the process exits normally vs. hangs (ensure SIGKILL path is exercised).\n\n3) Unit/integration tests for worker logic (with fakes/mocks)\n- Use a fake `GeelarkDeviceController` and `ClaudeNavigator` that simulate successful postings without real devices.\n- Run `worker_main` against a small `progress.csv` and confirm that:\n  - All jobs transition from `pending` to `success`.\n  - The existing result log CSV contains one row per job with the correct status.\n  - The worker exits cleanly when no pending jobs remain.\n\n4) Multi-process integration test (local)\n- Start the orchestrator with 2–3 workers using the fake controller/navigator and a small input CSV (e.g. 10 jobs).\n- Assert that:\n  - All jobs are processed exactly once (no duplicates, no missing jobs) by inspecting `progress.csv`.\n  - Work is distributed across workers (different `worker_id` values present).\n  - Orchestrator exits with zero status and all worker processes have exited.\n\n5) Signal handling and clean shutdown tests\n- In an integration-style test, start the orchestrator with long-running fake jobs (each job sleeps a few seconds).\n- Send SIGINT (or simulated shutdown signal) to the orchestrator process and assert that:\n  - Workers finish or abort their current job, update job status appropriately (e.g. leave unstarted jobs as `pending`).\n  - Appium server processes (mocked) receive `stop_appium_server` calls.\n\n6) Real-device/Appium smoke test (manual or CI environment)\n- Connect at least two Android devices (or Geelark cloud devices mapped via the controller) and configure two workers with distinct Appium ports and systemPorts.\n- Start the orchestrator with a small CSV (e.g. 2–4 jobs) and visually confirm:\n  - Two Appium servers run on the expected ports.\n  - Each device is driven only by its assigned worker.\n  - Posts are successfully created and logged once per job.\n- Inspect logs to verify that no UiAutomator2/systemPort conflicts or session collisions occur, aligning with recommended Appium parallel execution patterns.[1][3][6]\n\n7) Regression tests with existing single-worker flow\n- Run a single-worker configuration and verify that behavior matches the existing Task 9/10 MVP: same success rate, logging format, and proxy rotation behavior.\n- Confirm that enabling parallel mode does not require changes to the per-job posting logic (i.e. `run_post_job` remains unchanged aside from Appium config injection).",
        "status": "done",
        "dependencies": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "7",
          "9",
          "10"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design parallel orchestration architecture and configuration for multi-process workers",
            "description": "Define the overall architecture for multi-process Appium workers, including process model, per-worker isolation strategy, and configuration structures for devices, ports, and logging.",
            "dependencies": [],
            "details": "- Specify how the orchestrator module (e.g. `parallel_orchestrator.py`) will spawn and manage N worker processes using `multiprocessing.Process` or `subprocess`.\n- Design a `ParallelConfig`/similar structure (in `config.py` or `parallel_config.py`) that maps worker IDs to: device identifier/UDID, Appium port, systemPort range, log directory paths, and any extra Appium args.\n- Define how configuration is loaded from existing config (Task 1/9) and extended with parallel-specific fields like `num_workers`, `base_appium_port`, `system_port_block_size`.\n- Document invariants (e.g. unique Appium ports, non-overlapping systemPort ranges, one device per worker) and how they will be validated at startup.\n- Decide on basic IPC/shared-state mechanisms (CSV files, optional shutdown flag via file or `multiprocessing.Event`) and how workers discover shared paths (e.g. `progress_csv_path`, `results_csv_path`, `logs_dir`).",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-13T00:34:05.624Z"
          },
          {
            "id": 2,
            "title": "Implement Appium server manager and per-worker process entrypoint",
            "description": "Create the Appium server lifecycle utilities and the worker main function that owns a dedicated Appium server, device controller, and posting loop.",
            "dependencies": [
              1
            ],
            "details": "- Implement `appium_server_manager.py` with:\n  - `start_appium_server(port: int, log_path: str, extra_args: list[str]) -> subprocess.Popen` that launches the `appium` binary with `--port` and other required arguments, redirects stdout/stderr to a per-worker log file, and performs `/status` health checks with retry and timeout.\n  - `stop_appium_server(proc: subprocess.Popen, timeout: float = 10.0)` that sends SIGTERM and escalates to SIGKILL if the server does not exit in time.\n- Implement `worker_main(worker_id: int, config: ParallelConfig, shared_paths: WorkerSharedPaths)` in a new worker module:\n  - Initialize worker-specific logging (file and console) including worker ID in log records.\n  - Resolve worker-specific device/Appium configuration (UDID, Appium port, systemPort range, log paths) from `ParallelConfig`.\n  - Start the Appium server using `start_appium_server` and construct desired capabilities with unique `udid` and `systemPort` values within the worker’s allocated range.\n  - Instantiate `GeelarkDeviceController`, `ClaudeNavigator`, and other dependencies, ensuring all state is local to the process.\n  - Implement a guarded `try/finally` to guarantee teardown: close active driver session, perform device cleanup, and call `stop_appium_server` even on errors or external shutdown.\n- Ensure no global singletons are shared across workers; all per-worker objects are created inside `worker_main`.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-13T00:35:25.054Z"
          },
          {
            "id": 3,
            "title": "Build CSV-based progress tracker with file locking and seeding from input jobs",
            "description": "Implement a concurrency-safe CSV progress tracking module that coordinates job claiming and status updates across workers, and a bootstrap step to seed it from the main input CSV.",
            "dependencies": [
              1
            ],
            "details": "- Design the schema for `progress.csv` with at least columns: `job_id`, `account_name`, `video_path`, `caption` (if needed for reconstruction), `status`, `worker_id`, `timestamp`, `error`.\n- Implement `progress_tracker.py` providing:\n  - Cross-platform file-locking utilities (e.g. using `fcntl.flock` on Unix and `msvcrt`/`portalocker` on Windows) to guard read-modify-write cycles.\n  - `claim_next_job(worker_id: int) -> Optional[PostJob]` that:\n    - Acquires an exclusive lock on `progress.csv`.\n    - Reads rows, finds the first `status == \"pending\"`, sets it to `\"claimed\"` with `worker_id` and timestamp.\n    - Rewrites the CSV atomically via a temp file and rename, then releases the lock.\n    - Returns a constructed `PostJob` (compatible with Task 2/7) or `None` if no pending jobs remain.\n  - `update_job_status(job_id: int, status: str, worker_id: int, error: str | None = None)` that locks, updates the row, rewrites atomically, and unlocks.\n- Implement a seeding/bootstrap utility (callable from the orchestrator) that:\n  - Uses existing `read_jobs` (Task 2) to load jobs from the main input CSV when `progress.csv` does not exist.\n  - Assigns stable `job_id`s, writes initial rows with `status=\"pending\"`, and preserves any existing progress when resuming.\n- Ensure functions are robust to partial files and can recover or fail clearly on CSV corruption.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-13T00:37:06.708Z"
          },
          {
            "id": 4,
            "title": "Implement worker job-processing loop integrating posting logic and progress tracking",
            "description": "Wire the worker loop to claim jobs from the progress tracker, run the existing posting flow, log outputs, and update job status with robust error handling and shutdown awareness.",
            "dependencies": [
              2,
              3
            ],
            "details": "- Inside `worker_main`, implement the main loop that:\n  - Periodically checks a shutdown flag (e.g. `multiprocessing.Event` passed from orchestrator or a special \"shutdown\" file) to determine whether to stop after the current job.\n  - Calls `claim_next_job(worker_id)` from `progress_tracker` and exits the loop when it returns `None` (no more pending jobs).\n  - For each claimed job:\n    - Ensures proxy rotation (Task 5) is invoked before posting, using existing network utilities.\n    - Calls `run_post_job(job, controller, navigator, config)` from Task 7 within a `try/except` block.\n    - On success, writes a row to the existing result log CSV via `append_log_row` (Task 2) and calls `update_job_status(job_id, \"success\", worker_id, error=None)`.\n    - On exception, logs structured error information, writes a `status=\"fail\"` row to the result log CSV, and calls `update_job_status(job_id, \"fail\", worker_id, error=str(exc))`.\n  - Ensures that any Appium/device-specific failures are surfaced clearly and that repeated failures do not corrupt `progress.csv`.\n- Include worker ID, job ID, and account name in all worker logs for observability consistent with Task 9.\n- Make the loop resilient to transient tracker I/O errors (e.g. small retry on file-lock failures) while avoiding duplicate job processing.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-13T00:38:09.363Z"
          },
          {
            "id": 5,
            "title": "Create orchestrator CLI to configure, launch, monitor, and gracefully shut down all workers",
            "description": "Implement the top-level orchestrator script that initializes configuration and progress tracking, spawns worker processes, monitors their lifecycle, and handles clean shutdown and restarts.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "- Implement a CLI entrypoint (e.g. `python -m geelark_ig_bot.parallel_orchestrator`) that:\n  - Loads the base `Config` and parallel extensions (num workers, device/port mappings, log directories).\n  - Validates the configuration invariants: unique Appium ports, non-overlapping systemPort ranges, valid device IDs, and accessible log directories.\n  - Initializes or resumes `progress.csv` via the seeding utility, ensuring consistent `job_id`s and correct `pending`/`claimed`/`success`/`fail` states.\n- Use `multiprocessing.Process` (or `subprocess.Popen` on the same module) to spawn one worker per configured device/worker ID, passing in the resolved `ParallelConfig` subset and shared paths.\n- Implement monitoring logic that:\n  - Tracks process handles, logs start/stop events with exit codes, and optionally restarts workers on transient failures according to a simple policy (e.g. limited restart count).\n  - Periodically checks for overall completion (all jobs non-pending and all workers idle/exited).\n- Implement signal handling for SIGINT/SIGTERM:\n  - Set a shared shutdown flag or create a `shutdown` file that workers poll, allowing them to finish the current job and exit their loops.\n  - After a grace period, terminate or kill any stuck worker processes and ensure Appium servers are torn down.\n- Add basic documentation/comments describing how to run the orchestrator, configure workers and ports, and resume from partial runs; update README or internal docs accordingly.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined",
            "updatedAt": "2025-12-13T00:40:29.724Z"
          }
        ],
        "updatedAt": "2025-12-13T00:40:29.724Z"
      },
      {
        "id": "20",
        "title": "Implement unified per-account daily posting limits and orchestrator safety controls",
        "description": "Implement a unified posting control system that enforces per-account daily limits, adds orchestrator process safety checks, and introduces a controlled daily reset flow with documentation updates.",
        "details": "Implementation should focus on two modules (`progress_tracker.py`, `parallel_orchestrator.py`) plus `CLAUDE.md`, building on the existing CSV-based progress tracking and multi-process orchestration from Task 19.\n\n1) Introduce unified per-account daily post limit configuration\n- Add a configuration entry (e.g. in existing `config.py` or equivalent used by Task 19) for **`max_posts_per_account_per_day`**.\n  - Default to **1**.\n  - Allow integer values 1–4 (validate and raise on invalid values; keep the API open for future extension).\n- Ensure this value is accessible to both `progress_tracker.py` and `parallel_orchestrator.py` without circular imports (pass via function parameters or a small config object where appropriate, instead of importing global state).\n- Follow current best practices for configuration: avoid hard-coded constants, and keep default in a single source of truth so tests can override it easily.\n\n2) Enhance `seed_from_scheduler_state()` for per-account limits\n- In `progress_tracker.py`, extend `seed_from_scheduler_state()` to:\n  - Read the existing progress CSV (the one introduced in Task 19) and compute a **`success_count_by_account: dict[str, int]`**.\n    - Count rows where the job is in a terminal **success** state (re-use existing status field semantics from Task 19 to avoid double-defining what “success” means).\n    - Use a streaming/iterator-based CSV read to avoid excessive memory use on large files.\n  - Filter candidate accounts when seeding from the scheduler/state so that only accounts where `success_count < max_posts_per_account_per_day` are considered for new assignments.\n  - Maintain an **in-memory** `success_count_by_account` during seeding and increment counts as new jobs are seeded, so that multiple jobs added in one seeding pass do not exceed the limit even before they are written back.\n- Refactor as needed:\n  - Extract small helpers such as `_load_success_counts(progress_path) -> dict[str, int]` for testability.\n  - Keep all file I/O atomic (e.g. write temp file and rename) if seeding mutates the CSV, to avoid corruption under concurrent reads.\n- Document function behavior clearly in docstrings so that both orchestrator and future tools can rely on the same semantics.\n\n3) Add orchestrator startup safety check for duplicate Python orchestrators\n- In `parallel_orchestrator.py`, before spawning worker processes, add a **startup guard** that checks for other running Python orchestrator processes.\n  - Use a cross-platform-friendly approach such as `psutil.process_iter()` if already available in the project; otherwise, add a minimal, well-scoped dependency or implement a simple `subprocess`-based check, keeping in mind:\n    - Only treat **other processes** as conflicts (ignore the current PID).\n    - Match by a robust criterion, e.g. command line including the orchestrator entrypoint/module name or a specific `--orchestrator` flag.\n  - If another orchestrator is detected, log a clear error and exit non-zero instead of starting new workers.\n- Ensure the check is **read-only** (no OS-level locks, per requirements) and fails fast before creating any worker processes or touching progress files.\n- Make the behavior configurable for tests (e.g. allow an environment variable or explicit flag to bypass the check in unit tests), but keep the default behavior strict in production.\n\n4) Implement controlled daily reset command with archival behavior\n- In `parallel_orchestrator.py` (or a small CLI wrapper if that’s where CLI parsing lives), add a **`--reset-day`** command/flag.\n  - On invocation, the command should:\n    - Locate the current progress CSV (respecting existing config from Task 19).\n    - Compute an archive filename: `parallel_progress_YYYYMMDD.csv` based on **current local date** or a configurable timezone; document the choice and keep it consistent.\n      - If a file with that name already exists, either:\n        - Append a suffix such as `_1`, `_2`, etc., or\n        - Fail with a clear error; pick one strategy and document it.\n    - Move/rename the current progress file to the archive filename (not copy+delete; use atomic rename where possible).\n    - Create a **fresh progress CSV** initialized with the correct header and any required initial state for a new day (e.g. pending jobs seeded from the scheduler, if that is part of reset semantics).\n  - Never delete the progress file outright; the reset command must only archive and recreate.\n- Implement reset logic in a dedicated function (e.g. `reset_day(progress_path, archive_dir=None)`), which can be called from CLI parsing and unit tests.\n- Consider concurrency: ensure the reset operation is performed when no orchestrator workers are running; if needed, add a defensive check that refuses to reset when an orchestrator process is currently detected (re-use the process detection logic).\n\n5) Update progress handling and `claim_next_job()` for defense in depth\n- In `progress_tracker.py`, update `claim_next_job()` (introduced in Task 19) to enforce the same **per-account daily limit** in addition to seeding-time checks.\n  - Before returning a job for a given account, compute or reuse `success_count_by_account` so that jobs are skipped when `success_count >= max_posts_per_account_per_day`.\n  - Decide on behavior when a job is skipped because of the limit (e.g. treat as permanently skipped with a specific status like `daily_limit_reached`, or simply not claim it and move on to the next row). Document this behavior and ensure it is consistent with reporting.\n  - Avoid O(N²) scans over the CSV for large inputs: if feasible, maintain a cached `success_count_by_account` that can be refreshed when needed, or compute counts once per orchestrator run rather than per-claim.\n- Ensure that both `seed_from_scheduler_state()` and `claim_next_job()` share the same limit logic and do not diverge over time (e.g. via a `_within_daily_limit(account, counts, max_per_day)` helper).\n\n6) Documentation updates in CLAUDE.md\n- Edit `CLAUDE.md` to include **strict operational rules** around progress tracking and resets:\n  - Explicitly state: **NEVER delete the progress file manually.**\n  - For starting a new operational day, always run the **`--reset-day`** command instead of deleting or editing progress CSVs by hand.\n  - Include a short explanation of the per-account daily limit behavior so human operators understand why some jobs may remain unposted once the limit is hit.\n  - Add example CLI invocations for:\n    - Starting the orchestrator normally.\n    - Running `--reset-day`.\n- Keep language concise and imperative so it can be used as a system prompt or operator runbook.\n\n7) General code quality and patterns\n- Maintain consistency with patterns established in Task 19: structured logging, error handling, and CLI parsing.\n- Add type hints and docstrings for new/changed functions, and keep them in sync with behavior.\n- Ensure any new dependencies (e.g. `psutil`) are declared in the project’s dependency management (requirements file, Poetry, etc.) and are optional where appropriate.\n- Where feasible, design new logic to be testable without real orchestrator processes or actual CSV files by abstracting filesystem and process listing behind small helpers that can be mocked.\n",
        "testStrategy": "1) Unit tests for per-account daily limits\n- Create a temporary progress CSV with multiple accounts and a mix of `success`, `fail`, and `pending` rows.\n- Test `_load_success_counts` (or equivalent) to ensure only successful posts are counted per account, and counts match expectations.\n- Configure `max_posts_per_account_per_day = 1` and verify that `seed_from_scheduler_state()` only seeds accounts with `success_count < 1`.\n- With `max_posts_per_account_per_day = 2`, simulate seeding multiple jobs for the same account in a single call and assert that in-memory counts prevent creating more than 2 total for that account.\n\n2) Unit tests for `claim_next_job()` enforcement\n- Seed a test progress CSV with:\n  - An account already at the daily limit (based on existing `success` rows).\n  - Another account below the limit.\n- Call `claim_next_job()` repeatedly and assert that:\n  - Jobs for the over-limit account are not claimed (either skipped or marked with `daily_limit_reached`, according to the chosen design).\n  - Jobs for accounts under the limit are claimed and marked as such, and that repeated calls never exceed the per-account limit.\n- Verify that performance is acceptable by running `claim_next_job()` over a CSV with hundreds or thousands of rows in tests (avoid quadratic behavior).\n\n3) Tests for orchestrator startup safety check\n- Implement the process-detection logic in a function that accepts a list of mock process descriptors to enable pure unit testing.\n- Provide fake process lists including:\n  - Only the current process (should not block startup).\n  - Another process whose command line clearly indicates it is an orchestrator (should block startup).\n  - Unrelated Python processes (should not block startup, assuming matching criteria are specific enough).\n- Assert that when a conflicting orchestrator is detected, the orchestrator entrypoint logs an appropriate error and exits with a non-zero code.\n\n4) Tests for `--reset-day` archival behavior\n- Use a temporary directory to host a fake progress CSV file with a known name and simple contents.\n- Invoke the reset function directly (e.g. `reset_day(path)`):\n  - Assert that the original file is no longer present and an archive file `parallel_progress_YYYYMMDD.csv` exists with identical contents.\n  - Assert that a new progress CSV is created with the correct header and no historical rows.\n- Test the behavior when an archive for the current date already exists:\n  - If the design appends a numeric suffix, verify the new name (e.g. `parallel_progress_YYYYMMDD_1.csv`).\n  - If the design is to fail, assert that an appropriate exception or error code is produced.\n- Add a test ensuring reset refuses to run (or logs a strong warning) if the process-detection logic indicates an orchestrator is currently running.\n\n5) Integration tests for end-to-end posting control\n- With a small test CSV of jobs for multiple accounts, run the orchestrator in a test mode that uses a mock/posting stub instead of real devices.\n- Set `max_posts_per_account_per_day = 1` and verify after a full run that:\n  - No account has more than one `success` row in the progress CSV.\n  - Jobs beyond the limit remain unposted or are marked according to the chosen policy.\n- Repeat with `max_posts_per_account_per_day = 2` to ensure the system respects higher limits as well.\n\n6) Documentation verification\n- Add a test (or CI check) that ensures `CLAUDE.md` contains the key phrases: `NEVER delete progress file` and `--reset-day` (e.g. a simple text search in a docs-checking script).\n- Optionally include a human-reviewed checklist item during code review to confirm that examples and instructions in `CLAUDE.md` match actual CLI flags and behavior.\n",
        "status": "done",
        "dependencies": [
          "1",
          "2",
          "9",
          "19"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Add configurable per-account daily posting limit to parallel_config.py",
            "description": "Introduce a unified max_posts_per_account_per_day configuration entry in parallel_config.py that can be used by both progress_tracker.py and parallel_orchestrator.py without circular imports.",
            "dependencies": [],
            "details": "Add max_posts_per_account_per_day field to ParallelConfig dataclass in parallel_config.py with default value of 1. Implement validation to allow only integer values 1-4 with clear error on invalid values. Update get_config() to accept this parameter. The config should be passable via function parameters to seed_from_scheduler_state() and claim_next_job() to avoid global state imports. Add a _validate_daily_limit() helper that raises ValueError for out-of-range values. Update print_config() to display the limit setting. Ensure the default is a single source of truth that tests can override.",
            "status": "pending",
            "testStrategy": "Unit test that ParallelConfig validates max_posts_per_account_per_day correctly: accepts 1-4, rejects 0, 5, negative numbers, and non-integers. Test that get_config() properly returns configs with custom limit values. Test that print_config() displays the limit.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enhance seed_from_scheduler_state() with configurable per-account limits and success counting",
            "description": "Extend progress_tracker.py's seed_from_scheduler_state() to count successful posts per account from the progress CSV and filter accounts that have reached their daily limit, using the configurable max_posts_per_account_per_day parameter.",
            "dependencies": [
              1
            ],
            "details": "In progress_tracker.py: 1) Add _load_success_counts(progress_path) -> Dict[str,int] helper that iterates through CSV rows and counts STATUS_SUCCESS entries per account using a streaming reader to avoid memory issues. 2) Modify seed_from_scheduler_state() signature to accept max_posts_per_day: int = 1 parameter. 3) Replace the current hardcoded '1 post per account' logic with dynamic limit checking: compute success_count_by_account, filter available_accounts where count < max_posts_per_day, and maintain in-memory counts during seeding to prevent exceeding limit within a single seeding pass. 4) Add _within_daily_limit(account, counts, max_per_day) -> bool helper to share limit logic between seeding and claiming. 5) Ensure atomic file I/O is preserved - the existing temp file + rename pattern already handles this. Add clear docstrings documenting the behavior.",
            "status": "pending",
            "testStrategy": "Create temp progress CSV with multiple accounts having varying success counts (0, 1, 2 successes). Test _load_success_counts returns correct counts per account. Test seed_from_scheduler_state() with max_posts_per_day=2: verify accounts with 2+ successes are excluded, accounts with 0-1 are included. Test in-memory count tracking prevents assigning multiple jobs to same account in one seed pass when limit would be exceeded.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add orchestrator startup guard to detect duplicate running orchestrators",
            "description": "Add a process detection check at startup in parallel_orchestrator.py that prevents running multiple orchestrator instances simultaneously, using subprocess-based approach to avoid adding psutil dependency.",
            "dependencies": [],
            "details": "In parallel_orchestrator.py: 1) Add _check_duplicate_orchestrator() -> Tuple[bool, str] function that uses subprocess to check for other Python processes running parallel_orchestrator.py. On Windows: use 'wmic process where \"name='python.exe'\" get processid,commandline' or 'tasklist /v'. On Unix: use 'ps aux | grep parallel_orchestrator'. 2) Filter out current process by comparing PIDs (os.getpid()). 3) Match by command line containing 'parallel_orchestrator' to identify orchestrator processes. 4) Call this check at the very start of run_parallel_posting() before any cleanup or worker spawning. 5) If another orchestrator is detected, log a clear error message with the detected PID and exit with sys.exit(1). 6) Add BYPASS_ORCHESTRATOR_CHECK environment variable that tests can set to skip the check. 7) Keep the check read-only (no OS-level locks as specified in requirements). Add to main() CLI as well.",
            "status": "pending",
            "testStrategy": "Test _check_duplicate_orchestrator() in isolation by mocking subprocess output to simulate another orchestrator running. Verify it correctly identifies other orchestrator processes and ignores current PID. Verify BYPASS_ORCHESTRATOR_CHECK environment variable allows bypassing the check. Verify run_parallel_posting exits early when duplicate detected.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement --reset-day command with progress file archival",
            "description": "Add a --reset-day CLI flag to parallel_orchestrator.py that archives the current progress CSV to a dated filename and creates a fresh progress file, with safety checks to prevent reset while workers are running.",
            "dependencies": [
              3
            ],
            "details": "In parallel_orchestrator.py: 1) Add reset_day(progress_path: str, archive_dir: str = None) -> str function that: a) Computes archive filename as parallel_progress_YYYYMMDD.csv using local date; b) If archive file exists, append _1, _2, etc. suffix; c) Uses shutil.move() for atomic rename to archive; d) Creates fresh progress CSV with correct headers only. 2) Before reset, call _check_duplicate_orchestrator() to refuse reset if any orchestrator is running - reuse the detection logic from subtask 3. 3) Add --reset-day flag to argparse in main(). 4) When invoked, check no orchestrator running, perform reset, log archive path. 5) Document timezone assumption (local time) in docstring. 6) Return the archive filename for logging/testing. Handle case where progress file doesn't exist - just create empty one.",
            "status": "pending",
            "testStrategy": "Test reset_day() creates archive with correct YYYYMMDD format. Test suffix incrementing when archive already exists (_1, _2). Test fresh CSV has correct headers. Test reset refuses to run when orchestrator detection reports duplicate. Test reset works when progress file doesn't exist (creates new empty file).",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Update claim_next_job() for defense-in-depth limit enforcement and update CLAUDE.md documentation",
            "description": "Add per-account daily limit enforcement to claim_next_job() as defense-in-depth against seeding-time limit bypass, and update CLAUDE.md with operational rules for the new features.",
            "dependencies": [
              1,
              2
            ],
            "details": "In progress_tracker.py: 1) Modify claim_next_job() signature to accept max_posts_per_day: int = 1 parameter. 2) Within _claim_operation, compute success_count_by_account once at the start using the same counting logic as _load_success_counts. 3) When iterating pending jobs, add check: if success count for job's account >= max_posts_per_day, skip the job (log at debug level 'Skipping job X - account Y at daily limit'). 4) Reuse _within_daily_limit() helper from subtask 2 to ensure consistent logic. 5) Avoid O(N^2) by computing counts once before the loop. In CLAUDE.md: Add new section '## Parallel Posting Daily Limits' documenting: a) NEVER delete progress file manually - always use --reset-day; b) Per-account daily limit behavior and how to change the limit; c) Example CLI invocations for starting orchestrator and running --reset-day; d) Explain jobs may remain unposted when account limits are hit.",
            "status": "pending",
            "testStrategy": "Test claim_next_job() with progress file containing account at limit - verify it skips jobs for that account. Test claim_next_job() correctly claims jobs for accounts under limit. Test that seeding and claiming use consistent limit logic (same account excluded by both). Review CLAUDE.md updates for accuracy and completeness.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-12-13T08:11:06.639Z"
      },
      {
        "id": "21",
        "title": "Port retry logic from PostingScheduler to parallel orchestrator/worker system",
        "description": "Add automatic retry capabilities to the parallel posting system by porting the existing retry patterns from PostingScheduler, including attempts tracking, RETRYING status, retry delay configuration, and periodic retry job reclamation.",
        "details": "## Overview\nThe existing `posting_scheduler.py` has a robust auto-retry mechanism (lines 294-300, 809-924) that needs to be ported to the parallel orchestrator/worker architecture. Currently, jobs that fail in the parallel system remain permanently failed.\n\n## Implementation Details\n\n### 1. Extend progress_tracker.py with retry fields and status\n\n**Add new status constant (around line 83):**\n```python\nSTATUS_RETRYING = 'retrying'\n```\n\n**Extend COLUMNS list (line 73-76) to include retry tracking:**\n```python\nCOLUMNS = [\n    'job_id', 'account', 'video_path', 'caption', 'status',\n    'worker_id', 'claimed_at', 'completed_at', 'error',\n    'attempts', 'max_attempts', 'last_attempt', 'error_type'  # NEW\n]\n```\n\n**Add new method `get_retry_jobs()` to ProgressTracker class:**\n```python\ndef get_retry_jobs(self, retry_delay_minutes: float = 0.25) -> List[Dict[str, Any]]:\n    \"\"\"Get jobs that are in RETRYING status and ready for retry.\n    \n    A job is ready for retry if:\n    1. status == STATUS_RETRYING\n    2. (now - last_attempt) >= retry_delay_minutes\n    \n    Args:\n        retry_delay_minutes: Minimum time since last attempt before retry\n        \n    Returns:\n        List of jobs ready to be retried\n    \"\"\"\n    jobs = self._read_all_jobs()\n    ready_jobs = []\n    now = datetime.now()\n    \n    for job in jobs:\n        if job.get('status') == self.STATUS_RETRYING:\n            last_attempt = job.get('last_attempt', '')\n            if last_attempt:\n                try:\n                    attempt_time = datetime.fromisoformat(last_attempt)\n                    elapsed_minutes = (now - attempt_time).total_seconds() / 60\n                    if elapsed_minutes >= retry_delay_minutes:\n                        ready_jobs.append(job)\n                except:\n                    ready_jobs.append(job)  # If can't parse, allow retry\n            else:\n                ready_jobs.append(job)\n    \n    return ready_jobs\n```\n\n**Update seed_from_scheduler_state() to initialize retry fields in new jobs (around line 307-317):**\n```python\nnew_jobs.append({\n    'job_id': job.get('id', ''),\n    'account': assigned_account,\n    'video_path': job.get('video_path', ''),\n    'caption': job.get('caption', ''),\n    'status': self.STATUS_PENDING,\n    'worker_id': '',\n    'claimed_at': '',\n    'completed_at': '',\n    'error': '',\n    'attempts': '0',           # NEW\n    'max_attempts': '3',       # NEW - default from posting_scheduler.py\n    'last_attempt': '',        # NEW\n    'error_type': ''           # NEW\n})\n```\n\n### 2. Extend parallel_config.py with retry settings\n\nAdd these fields to ParallelConfig dataclass:\n```python\n@dataclass\nclass ParallelConfig:\n    # ... existing fields ...\n    retry_delay_minutes: float = 0.25  # 15 seconds, same as PostingScheduler\n    max_attempts: int = 3  # Same as PostJob.max_attempts default\n    non_retryable_errors: tuple = ('suspended', 'captcha', 'logged_out', 'action_blocked')\n```\n\n### 3. Update parallel_worker.py to handle retries\n\n**Modify the main job processing loop (around lines 279-340) to:**\n\na) **Increment attempts when claiming a job:**\n   - After claiming, increment the `attempts` field\n   - Update `last_attempt` timestamp\n\nb) **Check claim_next_job AND get_retry_jobs:**\n```python\n# First try to claim a pending job\njob = tracker.claim_next_job(worker_id, max_posts_per_account_per_day=config.max_posts_per_account_per_day)\n\n# If no pending jobs, check for retry jobs that are ready\nif job is None:\n    retry_jobs = tracker.get_retry_jobs(retry_delay_minutes=config.retry_delay_minutes)\n    if retry_jobs:\n        # Claim the first ready retry job\n        job = tracker.claim_retry_job(retry_jobs[0]['job_id'], worker_id)\n```\n\nc) **After job failure, decide retry vs permanent fail (port logic from posting_scheduler.py lines 905-915):**\n```python\ndef should_retry(job: dict, error_type: str, config: ParallelConfig) -> bool:\n    \"\"\"Determine if a failed job should be retried.\"\"\"\n    # Don't retry account-level errors\n    if error_type in config.non_retryable_errors:\n        return False\n    \n    attempts = int(job.get('attempts', 0))\n    max_attempts = int(job.get('max_attempts', config.max_attempts))\n    \n    return attempts < max_attempts\n```\n\nd) **Update job status based on retry decision:**\n```python\nif success:\n    tracker.update_job_status(job_id, 'success', worker_id)\nelse:\n    error_type = extract_error_type(error)  # Parse error message\n    if should_retry(job, error_type, config):\n        tracker.update_job_status(\n            job_id, \n            tracker.STATUS_RETRYING,  # Move to RETRYING instead of FAILED\n            worker_id, \n            error=error,\n            attempts=int(job.get('attempts', 0)) + 1,\n            error_type=error_type\n        )\n        logger.info(f\"Job {job_id} will retry (attempt {attempts}/{max_attempts})\")\n    else:\n        tracker.update_job_status(job_id, 'failed', worker_id, error=error)\n        logger.info(f\"Job {job_id} permanently failed: {error_type}\")\n```\n\n### 4. Add claim_retry_job method to ProgressTracker\n\n```python\ndef claim_retry_job(self, job_id: str, worker_id: int, max_posts_per_account_per_day: int = 1) -> Optional[Dict[str, Any]]:\n    \"\"\"Claim a specific job that is in RETRYING status.\n    \n    This is similar to claim_next_job but for a specific retry job.\n    Still enforces account-in-use and daily limit checks.\n    \"\"\"\n    def _claim_retry_operation(jobs):\n        # Build accounts in use and success counts (same as claim_next_job)\n        accounts_in_use = set()\n        success_counts = {}\n        for job in jobs:\n            if job.get('status') == self.STATUS_CLAIMED:\n                if job.get('account'):\n                    accounts_in_use.add(job.get('account'))\n            elif job.get('status') == self.STATUS_SUCCESS:\n                acc = job.get('account', '')\n                if acc:\n                    success_counts[acc] = success_counts.get(acc, 0) + 1\n        \n        # Find and claim the target job\n        for job in jobs:\n            if job.get('job_id') == job_id and job.get('status') == self.STATUS_RETRYING:\n                account = job.get('account', '')\n                \n                # Safety checks\n                if not account:\n                    return jobs, None\n                if account in accounts_in_use:\n                    return jobs, None\n                if success_counts.get(account, 0) >= max_posts_per_account_per_day:\n                    return jobs, None\n                \n                # Claim the job\n                job['status'] = self.STATUS_CLAIMED\n                job['worker_id'] = str(worker_id)\n                job['claimed_at'] = datetime.now().isoformat()\n                return jobs, dict(job)\n        \n        return jobs, None\n    \n    return self._locked_operation(_claim_retry_operation)\n```\n\n### 5. Update update_job_status to handle retry fields\n\nModify `update_job_status` method signature and implementation:\n```python\ndef update_job_status(\n    self,\n    job_id: str,\n    status: str,\n    worker_id: int,\n    error: str = '',\n    attempts: int = None,\n    error_type: str = ''\n) -> bool:\n    \"\"\"Update job status with optional retry tracking fields.\"\"\"\n    def _update_operation(jobs):\n        for job in jobs:\n            if job.get('job_id') == job_id:\n                job['status'] = status\n                job['worker_id'] = str(worker_id)\n                job['completed_at'] = datetime.now().isoformat()\n                job['error'] = error[:500] if error else ''\n                job['last_attempt'] = datetime.now().isoformat()  # Always update\n                \n                if attempts is not None:\n                    job['attempts'] = str(attempts)\n                if error_type:\n                    job['error_type'] = error_type\n                    \n                return jobs, True\n        return jobs, False\n    \n    return self._locked_operation(_update_operation)\n```\n\n### 6. Update get_stats to include retrying count\n\n```python\ndef get_stats(self) -> Dict[str, int]:\n    \"\"\"Get job status statistics.\"\"\"\n    jobs = self._read_all_jobs()\n    stats = {\n        'total': len(jobs),\n        'pending': 0,\n        'claimed': 0,\n        'success': 0,\n        'failed': 0,\n        'skipped': 0,\n        'retrying': 0  # NEW\n    }\n    for job in jobs:\n        status = job.get('status', '')\n        if status in stats:\n            stats[status] += 1\n    return stats\n```\n\n### Reference Files\n- Source patterns: `posting_scheduler.py` lines 294-300 (PostStatus enum), 809-924 (execute_job retry logic), 793-795 (get_retry_jobs)\n- Target files: `progress_tracker.py`, `parallel_worker.py`, `parallel_config.py`",
        "testStrategy": "## Testing Strategy\n\n### 1. Unit Tests for ProgressTracker\n\n**Test new STATUS_RETRYING constant:**\n```python\ndef test_status_retrying_exists():\n    assert ProgressTracker.STATUS_RETRYING == 'retrying'\n```\n\n**Test get_retry_jobs() method:**\n- Create progress file with jobs in various states (pending, claimed, success, failed, retrying)\n- Set `last_attempt` timestamps at different times\n- Verify only RETRYING jobs with elapsed delay are returned\n- Test edge cases: missing last_attempt, unparseable timestamps\n\n**Test claim_retry_job() method:**\n- Verify it claims only RETRYING jobs (not pending/claimed/failed)\n- Verify account-in-use check prevents claiming\n- Verify daily limit check prevents claiming\n- Verify job transitions to CLAIMED status after successful claim\n\n**Test updated update_job_status():**\n- Verify attempts field is updated correctly\n- Verify error_type field is stored\n- Verify last_attempt is updated\n\n### 2. Integration Tests for Parallel Worker\n\n**Test retry flow end-to-end:**\n1. Seed progress file with test jobs\n2. Manually claim a job\n3. Call update_job_status with RETRYING status\n4. Verify job appears in get_retry_jobs() after delay\n5. Verify worker can claim the retry job\n6. Complete job, verify it reaches success or permanent fail\n\n**Test non-retryable errors:**\n1. Simulate failure with error_type='suspended'\n2. Verify job goes directly to FAILED (not RETRYING)\n3. Verify job does NOT appear in get_retry_jobs()\n\n**Test max_attempts exhaustion:**\n1. Create job with attempts=2, max_attempts=3\n2. Fail the job\n3. Verify it moves to RETRYING (attempt 3)\n4. Fail again\n5. Verify it moves to FAILED (exhausted retries)\n\n### 3. Live Tests (Per CLAUDE.md Instructions)\n\n**Run with actual orchestrator:**\n```bash\n# Seed with a few test accounts\npython parallel_orchestrator.py --seed-only\n\n# Manually edit one job in parallel_progress.csv to have a bad video path (will fail)\n# Run with 1 worker to observe retry behavior\npython parallel_orchestrator.py --run --workers 1\n```\n\n**Verify in logs:**\n- Check worker log for \"will retry\" messages\n- Check progress CSV for RETRYING status entries\n- Verify retrying jobs get re-claimed after delay\n- Verify jobs eventually succeed or reach permanent failure\n\n### 4. Regression Tests\n\n**Verify backward compatibility:**\n- Progress files without new columns should still work\n- Workers should handle missing attempts/max_attempts gracefully (use defaults)\n- Existing pending/claimed/success/failed flows unchanged\n\n### 5. Stress Test\n\n**Run with 5 workers as specified in review1.txt:**\n```bash\npython parallel_orchestrator.py --run --workers 5\n```\nVerify:\n- Multiple workers can claim retry jobs without conflicts\n- No duplicate posts occur during retry handling\n- Stats correctly show retrying count",
        "status": "done",
        "dependencies": [
          "19"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T05:21:54.104Z"
      },
      {
        "id": "22",
        "title": "Fix per-account daily cap enforcement with robust progress file handling",
        "description": "Strengthen the per-account daily posting limits by implementing claim-time enforcement that considers both success and claimed job counts, preventing same-account reuse during reseeding, hardening progress file validation to never delete non-empty files, and requiring --reset-day when using --force-reseed.",
        "details": "## Overview\n\nThis task addresses 4 specific violations identified in the code review (review1.txt Section 1.1-1.4) that can cause accounts to exceed daily posting limits or lose posting history.\n\n## Implementation Details\n\n### 1.1 Modify `claim_next_job()` to check success+claimed counts at claim time\n\n**File:** `progress_tracker.py`\n**Function:** `claim_next_job()` (lines 374-451)\n\nThe current implementation checks success counts and accounts_in_use separately. Modify to combine both for total count comparison:\n\n```python\ndef claim_next_job(self, worker_id: int, max_posts_per_account_per_day: int = 1) -> Optional[Dict[str, Any]]:\n    def _claim_operation(jobs):\n        # Build combined counts: success + currently claimed\n        total_assigned_by_account = {}\n        accounts_in_use = set()\n        \n        for job in jobs:\n            account = job.get('account', '')\n            if not account:\n                continue\n            status = job.get('status', '')\n            \n            if status == self.STATUS_SUCCESS:\n                total_assigned_by_account[account] = total_assigned_by_account.get(account, 0) + 1\n            elif status == self.STATUS_CLAIMED:\n                total_assigned_by_account[account] = total_assigned_by_account.get(account, 0) + 1\n                accounts_in_use.add(account)\n        \n        # Find accounts at daily limit (success + claimed >= max)\n        accounts_at_limit = {\n            acc for acc, cnt in total_assigned_by_account.items() \n            if cnt >= max_posts_per_account_per_day\n        }\n        \n        # Find pending job where:\n        # 1. Has assigned account\n        # 2. Account not currently claimed by another worker  \n        # 3. Account total (success+claimed) < daily limit\n        for job in jobs:\n            if job.get('status') != self.STATUS_PENDING:\n                continue\n            account = job.get('account', '')\n            if not account:\n                continue\n            if account in accounts_in_use:\n                logger.debug(f\"Skipping job {job['job_id']} - account {account} in use\")\n                continue\n            if account in accounts_at_limit:\n                logger.warning(f\"Skipping job {job['job_id']} - account {account} at daily limit\")\n                continue\n            \n            # Claim the job\n            job['status'] = self.STATUS_CLAIMED\n            job['worker_id'] = str(worker_id)\n            job['claimed_at'] = datetime.now().isoformat()\n            logger.info(f\"Worker {worker_id} claimed job {job['job_id']} (account: {account})\")\n            return jobs, dict(job)\n        \n        return jobs, None\n    \n    return self._locked_operation(_claim_operation)\n```\n\n### 1.2 In `seed_from_scheduler_state()`, consider existing pending/claimed jobs\n\n**File:** `progress_tracker.py`\n**Function:** `seed_from_scheduler_state()` (lines 212-330)\n\nCurrently only checks success counts. Modify to also exclude accounts with existing pending/claimed jobs for the day:\n\n```python\ndef seed_from_scheduler_state(self, state_file: str, ...):\n    # ... existing code to load state ...\n    \n    # CRITICAL: Build success_count AND assigned_accounts from existing progress\n    success_count_by_account = self._load_success_counts()\n    existing_job_ids = set()\n    existing_jobs = []\n    assigned_accounts_today = set()  # NEW: Track accounts with any job status\n    \n    if os.path.exists(self.progress_file):\n        existing_jobs = self._read_all_jobs()\n        for job in existing_jobs:\n            existing_job_ids.add(job.get('job_id', ''))\n            # NEW: Track accounts that already have ANY job (pending/claimed/success)\n            acc = job.get('account', '')\n            status = job.get('status', '')\n            if acc and status in (self.STATUS_PENDING, self.STATUS_CLAIMED, self.STATUS_SUCCESS):\n                assigned_accounts_today.add(acc)\n    \n    # Filter accounts - exclude those at success limit OR already assigned\n    available_accounts = [\n        acc for acc in accounts\n        if (success_count_by_account.get(acc, 0) < max_posts_per_account_per_day \n            and acc not in assigned_accounts_today)  # NEW condition\n    ]\n    \n    logger.info(f\"Available accounts: {len(available_accounts)} \"\n                f\"(excluded {len(assigned_accounts_today)} with existing jobs)\")\n    \n    # ... rest of seeding logic ...\n```\n\n### 1.3 Tighten `validate_progress_file()` to NEVER delete non-empty files\n\n**File:** `parallel_orchestrator.py`\n**Function:** `validate_progress_file()` (lines 491-522)\n\nReplace the current aggressive deletion behavior with error logging and abort:\n\n```python\ndef validate_progress_file(progress_file: str) -> bool:\n    \"\"\"\n    Check if progress file is valid.\n    \n    CRITICAL: This function NEVER deletes files. It only validates and reports.\n    If the file is empty or corrupt, it logs an error and returns False.\n    The operator must manually resolve using --reset-day.\n    \n    Returns:\n        True if file is valid or doesn't exist\n        False if file exists but is empty/corrupt (requires manual intervention)\n    \"\"\"\n    if not os.path.exists(progress_file):\n        return True\n    \n    try:\n        import csv\n        with open(progress_file, 'r', encoding='utf-8') as f:\n            reader = csv.DictReader(f)\n            rows = list(reader)\n            \n            if len(rows) == 0:\n                # CHANGED: Log error and return False instead of deleting\n                logger.error(\n                    f\"VALIDATION FAILED: Progress file {progress_file} is empty (header only).\\n\"\n                    f\"  This may indicate a crash during write.\\n\"\n                    f\"  ACTION REQUIRED: Run with --reset-day to archive and start fresh,\\n\"\n                    f\"  or manually inspect the file before proceeding.\"\n                )\n                return False\n        return True\n        \n    except Exception as e:\n        # CHANGED: Log error and return False instead of deleting\n        logger.error(\n            f\"VALIDATION FAILED: Progress file {progress_file} appears corrupt: {e}\\n\"\n            f\"  ACTION REQUIRED: Run with --reset-day to archive and start fresh,\\n\"\n            f\"  or manually inspect/repair the file.\"\n        )\n        return False\n```\n\nAlso update `full_cleanup()` (line 557) to check the return value:\n\n```python\n# In full_cleanup():\n# 4. Validate progress file - but DO NOT delete it\nif not validate_progress_file(config.progress_file):\n    logger.warning(\"Progress file validation failed - manual intervention may be required\")\n```\n\n### 1.4 Make `--force-reseed` require `--reset-day`\n\n**File:** `parallel_orchestrator.py`\n**Functions:** `main()` (lines 921-1016) and `run_parallel_posting()` (lines 820-918)\n\nAdd validation in `main()` before executing:\n\n```python\ndef main():\n    # ... argparse setup ...\n    args = parser.parse_args()\n    \n    # NEW: Validate --force-reseed requires --reset-day\n    if args.force_reseed and not args.reset_day:\n        logger.error(\"=\"*60)\n        logger.error(\"SAFETY CHECK FAILED: --force-reseed requires --reset-day\")\n        logger.error(\"=\"*60)\n        logger.error(\"\")\n        logger.error(\"Using --force-reseed without --reset-day would wipe posting history\")\n        logger.error(\"for the current day, allowing duplicate posts to accounts.\")\n        logger.error(\"\")\n        logger.error(\"If you intend to start a new day, run:\")\n        logger.error(\"  python parallel_orchestrator.py --reset-day --force-reseed --run\")\n        logger.error(\"\")\n        logger.error(\"If you need to reseed mid-day (DANGEROUS), manually archive the\")\n        logger.error(\"progress file first, then run with both flags.\")\n        logger.error(\"=\"*60)\n        sys.exit(1)\n    \n    # ... rest of main() ...\n```\n\nAlso update `run_parallel_posting()` to validate similarly when called programmatically.\n\n## Files to Modify\n\n1. **`progress_tracker.py`**:\n   - `claim_next_job()` (lines 374-451): Add success+claimed counting\n   - `seed_from_scheduler_state()` (lines 212-330): Consider pending/claimed jobs in seeding\n\n2. **`parallel_orchestrator.py`**:\n   - `validate_progress_file()` (lines 491-522): Remove deletion, only log errors\n   - `full_cleanup()` (line 557): Handle validation failure gracefully\n   - `main()` (lines 921-1016): Add --force-reseed + --reset-day requirement\n   - `run_parallel_posting()` (lines 820-918): Validate force_reseed parameter\n\n## Constants/Config Changes\n\nNo new configuration needed - these changes enforce existing `max_posts_per_account_per_day` more strictly.",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Tests for `claim_next_job()` Daily Limit Enforcement\n\n**Test: Claimed jobs count toward daily limit**\n```python\n# Setup: Create progress CSV with account_a having 1 success\n# Add pending job for account_a\n# Call claim_next_job with max_posts_per_account_per_day=1\n# Expected: Job should NOT be claimed (account at limit)\n\n# Verify with max_posts_per_account_per_day=2\n# Expected: Job SHOULD be claimed (1 success < 2 limit)\n```\n\n**Test: Account with claimed job cannot get second claim**\n```python\n# Setup: Create progress CSV with account_a having status=claimed\n# Add another pending job for account_a\n# Call claim_next_job\n# Expected: Second job NOT claimed (account already has 1 claimed)\n```\n\n### 2. Unit Tests for `seed_from_scheduler_state()` Reuse Prevention\n\n**Test: Existing pending jobs block reseeding**\n```python\n# Setup: Create progress CSV with pending job for account_a\n# Run seed_from_scheduler_state with jobs for account_a\n# Expected: No new jobs added for account_a (already has pending)\n```\n\n**Test: Only success jobs were previously counted**\n```python\n# Regression test: Verify failed jobs don't block seeding\n# Setup: Progress CSV with failed job for account_a\n# Expected: New job CAN be seeded for account_a\n```\n\n### 3. Integration Test for `validate_progress_file()` Safety\n\n**Test: Empty file is NOT deleted**\n```bash\n# Create empty progress file (header only)\necho \"job_id,account,video_path,caption,status,worker_id,claimed_at,completed_at,error\" > parallel_progress.csv\n\n# Run orchestrator\npython parallel_orchestrator.py --status\n\n# Expected: Error logged, file still exists, orchestrator does NOT proceed\ntest -f parallel_progress.csv && echo \"PASS: File preserved\"\n```\n\n**Test: Corrupt file is NOT deleted**\n```bash\n# Create corrupt progress file\necho \"garbage data\" > parallel_progress.csv\n\n# Run validation\npython -c \"from parallel_orchestrator import validate_progress_file; print(validate_progress_file('parallel_progress.csv'))\"\n\n# Expected: Returns False, file still exists\n```\n\n### 4. CLI Validation Test for --force-reseed Safety\n\n**Test: --force-reseed alone is rejected**\n```bash\npython parallel_orchestrator.py --force-reseed --run 2>&1 | grep -q \"requires --reset-day\"\n# Expected: Exit code 1, error message shown\n```\n\n**Test: --force-reseed with --reset-day is accepted**\n```bash\n# Create dummy progress file\ntouch parallel_progress.csv\n\n# Run with both flags (won't actually post without accounts)\npython parallel_orchestrator.py --force-reseed --reset-day --status\n# Expected: No error about --force-reseed\n```\n\n### 5. End-to-End Scenario Tests\n\n**Scenario A: Mid-day reseed attempt blocked**\n1. Run orchestrator, let some jobs complete\n2. Attempt `--force-reseed --run` without `--reset-day`\n3. Verify: Rejected with clear error message\n4. Verify: Progress file unchanged, history preserved\n\n**Scenario B: Same account cannot get 2 posts in one day**\n1. Seed with account_a having 1 pending job\n2. Worker claims and completes job (status=success)\n3. Run `--force-reseed --reset-day` to start new batch\n4. Seed new jobs\n5. Verify: account_a gets NO new job (already at limit=1 success)\n\n**Scenario C: Crash recovery preserves limits**\n1. Seed jobs, worker claims job for account_a\n2. Simulate crash (kill worker mid-job, claim status remains)\n3. Restart orchestrator\n4. Verify: account_a job NOT re-claimed until stale claim released\n5. Verify: After release, account_a can be claimed again (was only claimed, not success)\n\n### 6. Logging Verification\n\nFor each test, verify appropriate log messages:\n- `claim_next_job`: \"Skipping job X - account Y at daily limit of N\"\n- `seed_from_scheduler_state`: \"excluded N with existing jobs\"\n- `validate_progress_file`: \"VALIDATION FAILED\" with action instructions\n- `main()`: \"SAFETY CHECK FAILED: --force-reseed requires --reset-day\"",
        "status": "done",
        "dependencies": [
          "19",
          "20"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T05:56:33.379Z"
      },
      {
        "id": "23",
        "title": "Add ADB/Appium Lifecycle State Machine with Device Readiness Checks and Recovery",
        "description": "Implement robust ADB device lifecycle management by adding a wait_for_adb() helper that polls until device is present, an ensure_device_alive() function for mid-run ADB loss detection with recovery, and a formal state machine in parallel_worker.py governing phone/Appium transitions.",
        "details": "## Overview\n\nThis task addresses Section 2.1-2.3 from reviews/review1.txt, implementing robust ADB/Appium lifecycle management to handle device readiness and mid-run failures. The current implementation in `parallel_worker.py` lacks explicit ADB readiness gates and recovery mechanisms for device loss during job execution.\n\n## Current State Analysis\n\n- `parallel_worker.py` (lines 268-341): Main job loop relies on `appium_manager.ensure_healthy()` for Appium checks but has no explicit ADB device readiness verification\n- `post_reel_smart.py` has `verify_adb_connection()` (line 819) and `reconnect_adb()` (line 838) but these are not integrated into the parallel worker flow\n- `parallel_config.py` already exposes `adb_path` (line 81): `r\"C:\\Users\\asus\\Downloads\\android-sdk\\platform-tools\\adb.exe\"`\n- `appium_server_manager.py` manages Appium lifecycle but is unaware of underlying ADB device state\n\n## Implementation Details\n\n### 2.1 Add `wait_for_adb(device_id, timeout)` helper\n\n**File:** Create new `adb_utils.py` or add to `parallel_worker.py` (recommend separate module for reusability)\n\n```python\nimport subprocess\nimport time\nimport logging\nfrom typing import Optional\n\nlogger = logging.getLogger(__name__)\n\ndef wait_for_adb(\n    device_id: str,\n    adb_path: str,\n    timeout: int = 90,\n    poll_interval: float = 2.0\n) -> bool:\n    \"\"\"\n    Poll adb devices until the specified device is present and ready.\n    \n    Args:\n        device_id: The device UDID/serial (e.g., \"192.168.1.100:5555\")\n        adb_path: Full path to adb executable\n        timeout: Maximum seconds to wait (default 90)\n        poll_interval: Seconds between polls (default 2)\n        \n    Returns:\n        True if device became ready, False if timeout\n    \"\"\"\n    deadline = time.time() + timeout\n    attempts = 0\n    \n    while time.time() < deadline:\n        attempts += 1\n        try:\n            result = subprocess.run(\n                [adb_path, \"devices\"],\n                capture_output=True,\n                encoding='utf-8',\n                timeout=10\n            )\n            \n            for line in result.stdout.splitlines():\n                # Line format: \"192.168.1.100:5555\\tdevice\"\n                if device_id in line and '\\tdevice' in line:\n                    logger.info(f\"ADB device {device_id} ready after {attempts} attempts\")\n                    return True\n                    \n            # Device exists but wrong status (offline, unauthorized)?\n            for line in result.stdout.splitlines():\n                if device_id in line:\n                    status = line.split('\\t')[-1] if '\\t' in line else 'unknown'\n                    logger.debug(f\"Device {device_id} found but status is '{status}', waiting...\")\n                    break\n                    \n        except subprocess.TimeoutExpired:\n            logger.warning(f\"ADB command timed out on attempt {attempts}\")\n        except Exception as e:\n            logger.warning(f\"ADB check error on attempt {attempts}: {e}\")\n            \n        time.sleep(poll_interval)\n    \n    logger.error(f\"Device {device_id} did not become ready within {timeout}s ({attempts} attempts)\")\n    return False\n```\n\n### 2.2 Add `ensure_device_alive()` for mid-run ADB loss detection\n\n**File:** Add to `adb_utils.py` or `parallel_worker.py`\n\n```python\ndef ensure_device_alive(device_id: str, adb_path: str, timeout: float = 5.0) -> bool:\n    \"\"\"\n    Quick check if device is still connected and responsive.\n    \n    Unlike wait_for_adb(), this is a single-shot check intended for\n    periodic verification during job execution.\n    \n    Args:\n        device_id: The device UDID/serial\n        adb_path: Full path to adb executable\n        timeout: Command timeout in seconds\n        \n    Returns:\n        True if device is alive, False otherwise\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [adb_path, \"devices\"],\n            capture_output=True,\n            encoding='utf-8',\n            timeout=timeout\n        )\n        \n        for line in result.stdout.splitlines():\n            if device_id in line and '\\tdevice' in line:\n                return True\n                \n        return False\n        \n    except Exception as e:\n        logger.debug(f\"ensure_device_alive failed: {e}\")\n        return False\n\n\ndef recover_device(\n    device_id: str,\n    phone_name: str,\n    adb_path: str,\n    worker_config: 'WorkerConfig',\n    config: 'ParallelConfig',\n    appium_manager: 'AppiumServerManager',\n    logger: logging.Logger\n) -> bool:\n    \"\"\"\n    Full recovery sequence when device is lost mid-run.\n    \n    Sequence:\n    1. Stop Appium server\n    2. Stop Geelark phone\n    3. Wait for cleanup\n    4. Restart Geelark phone\n    5. Wait for ADB readiness\n    6. Restart Appium server\n    \n    Args:\n        device_id: The device UDID/serial\n        phone_name: Geelark phone serial name\n        adb_path: Full path to adb\n        worker_config: Worker's configuration\n        config: Parallel configuration\n        appium_manager: The worker's AppiumServerManager\n        logger: Worker logger\n        \n    Returns:\n        True if recovery successful, False otherwise\n    \"\"\"\n    from geelark_client import GeelarkClient\n    \n    logger.warning(f\"[RECOVERY] Device {device_id} lost, initiating recovery sequence...\")\n    \n    # 1. Stop Appium\n    logger.info(\"[RECOVERY] Step 1/6: Stopping Appium server...\")\n    try:\n        appium_manager.stop()\n    except Exception as e:\n        logger.warning(f\"[RECOVERY] Appium stop error (non-fatal): {e}\")\n    \n    # 2. Disconnect ADB\n    logger.info(\"[RECOVERY] Step 2/6: Disconnecting ADB...\")\n    try:\n        subprocess.run([adb_path, \"disconnect\", device_id], capture_output=True, timeout=10)\n    except Exception as e:\n        logger.debug(f\"[RECOVERY] ADB disconnect error: {e}\")\n    \n    time.sleep(2)\n    \n    # 3. Stop Geelark phone\n    logger.info(\"[RECOVERY] Step 3/6: Stopping Geelark phone...\")\n    try:\n        client = GeelarkClient()\n        phones = client.list_phones(page_size=100)\n        for phone in phones.get('items', []):\n            if phone.get('serialName') == phone_name:\n                if phone.get('status') == 1:  # Running\n                    client.stop_phone(phone['id'])\n                    logger.info(f\"[RECOVERY] Stopped phone {phone_name}\")\n                break\n    except Exception as e:\n        logger.warning(f\"[RECOVERY] Phone stop error: {e}\")\n    \n    time.sleep(5)  # Let phone fully stop\n    \n    # 4. Restart phone (handled by the caller via SmartInstagramPoster.connect())\n    # The state machine will transition back to PHONE_STARTING\n    logger.info(\"[RECOVERY] Step 4/6: Phone stop complete, ready for restart\")\n    \n    # 5. Wait for ADB (will be done in state machine's ADB_PENDING state)\n    logger.info(\"[RECOVERY] Step 5/6: Recovery cleanup complete\")\n    \n    # 6. Appium restart (will be done in state machine's ADB_READY state)\n    logger.info(\"[RECOVERY] Step 6/6: Ready for state machine restart sequence\")\n    \n    return True\n```\n\n### 2.3 Implement State Machine in `parallel_worker.py`\n\n**File:** `parallel_worker.py` - Major refactor of `run_worker()` function\n\n```python\nfrom enum import Enum, auto\nfrom dataclasses import dataclass\nfrom typing import Optional, Tuple\n\nclass WorkerState(Enum):\n    \"\"\"State machine states for worker phone/Appium lifecycle.\"\"\"\n    IDLE = auto()              # Initial state, no phone assigned\n    PHONE_STARTING = auto()    # Geelark phone being started\n    ADB_PENDING = auto()       # Waiting for ADB device to appear\n    ADB_READY = auto()         # ADB device connected, starting Appium\n    APPIUM_READY = auto()      # Appium healthy, ready to process jobs\n    JOB_RUNNING = auto()       # Currently executing a posting job\n    ERROR_RECOVERY = auto()    # Recovery in progress after failure\n    SHUTDOWN = auto()          # Clean shutdown requested\n\n\n@dataclass\nclass WorkerContext:\n    \"\"\"Context carried through state transitions.\"\"\"\n    device_id: Optional[str] = None\n    phone_name: Optional[str] = None\n    phone_id: Optional[str] = None\n    recovery_attempts: int = 0\n    max_recovery_attempts: int = 3\n    last_error: Optional[str] = None\n\n\ndef run_worker_state_machine(\n    worker_id: int,\n    config: ParallelConfig,\n    progress_file: str,\n    delay_between_jobs: int,\n    logger: logging.Logger\n) -> dict:\n    \"\"\"\n    State machine-based worker loop.\n    \n    State transitions:\n    IDLE -> PHONE_STARTING: When claiming a job\n    PHONE_STARTING -> ADB_PENDING: After Geelark start_phone() called\n    ADB_PENDING -> ADB_READY: After wait_for_adb() returns True\n    ADB_PENDING -> ERROR_RECOVERY: After wait_for_adb() timeout\n    ADB_READY -> APPIUM_READY: After Appium starts successfully\n    ADB_READY -> ERROR_RECOVERY: Appium start failure\n    APPIUM_READY -> JOB_RUNNING: When executing a job\n    JOB_RUNNING -> APPIUM_READY: Job complete (success or fail)\n    JOB_RUNNING -> ERROR_RECOVERY: Device lost mid-job\n    ERROR_RECOVERY -> PHONE_STARTING: After cleanup, retry\n    ERROR_RECOVERY -> SHUTDOWN: Max retries exceeded\n    Any -> SHUTDOWN: Shutdown signal received\n    \"\"\"\n    global _shutdown_requested\n    \n    worker_config = config.get_worker(worker_id)\n    tracker = ProgressTracker(progress_file)\n    appium_manager = AppiumServerManager(worker_config, config)\n    \n    state = WorkerState.IDLE\n    ctx = WorkerContext()\n    stats = {\n        'worker_id': worker_id,\n        'jobs_completed': 0,\n        'jobs_failed': 0,\n        'recovery_cycles': 0,\n        'start_time': datetime.now().isoformat(),\n        'end_time': None,\n        'exit_reason': None\n    }\n    \n    current_job = None\n    \n    while state != WorkerState.SHUTDOWN:\n        if _shutdown_requested:\n            state = WorkerState.SHUTDOWN\n            continue\n            \n        logger.debug(f\"State: {state.name}, Context: recovery_attempts={ctx.recovery_attempts}\")\n        \n        # --- IDLE: Wait for a job to claim ---\n        if state == WorkerState.IDLE:\n            progress_stats = tracker.get_stats()\n            if progress_stats['pending'] == 0 and progress_stats['claimed'] == 0:\n                logger.info(\"No more jobs to process\")\n                stats['exit_reason'] = 'all_jobs_complete'\n                state = WorkerState.SHUTDOWN\n                continue\n            \n            current_job = tracker.claim_next_job(\n                worker_id, \n                max_posts_per_account_per_day=config.max_posts_per_account_per_day\n            )\n            \n            if current_job is None:\n                if progress_stats['claimed'] > 0:\n                    time.sleep(5)  # Other workers processing\n                    continue\n                else:\n                    stats['exit_reason'] = 'all_jobs_complete'\n                    state = WorkerState.SHUTDOWN\n                    continue\n            \n            ctx.phone_name = current_job['account']\n            ctx.recovery_attempts = 0\n            state = WorkerState.PHONE_STARTING\n            \n        # --- PHONE_STARTING: Start Geelark phone ---\n        elif state == WorkerState.PHONE_STARTING:\n            logger.info(f\"Starting phone for account: {ctx.phone_name}\")\n            # Phone startup is handled by SmartInstagramPoster.connect()\n            # which calls Geelark API, enables ADB, and gets device_id\n            # For now, we transition to ADB_PENDING and let execute_posting_job handle it\n            # In future: explicit Geelark phone start here\n            state = WorkerState.ADB_PENDING\n            \n        # --- ADB_PENDING: Wait for device to appear in adb devices ---\n        elif state == WorkerState.ADB_PENDING:\n            # Note: device_id is obtained during SmartInstagramPoster.connect()\n            # For explicit ADB waiting, we'd need device_id earlier\n            # This state confirms the pattern; actual waiting happens in execute_posting_job\n            logger.info(f\"ADB pending for {ctx.phone_name}, proceeding to start Appium...\")\n            state = WorkerState.ADB_READY\n            \n        # --- ADB_READY: Start Appium server ---\n        elif state == WorkerState.ADB_READY:\n            try:\n                appium_manager.ensure_healthy()\n                logger.info(f\"Appium ready at {worker_config.appium_url}\")\n                state = WorkerState.APPIUM_READY\n            except AppiumServerError as e:\n                ctx.last_error = str(e)\n                logger.error(f\"Appium start failed: {e}\")\n                state = WorkerState.ERROR_RECOVERY\n                \n        # --- APPIUM_READY: Ready to execute jobs ---\n        elif state == WorkerState.APPIUM_READY:\n            if current_job is None:\n                state = WorkerState.IDLE\n                continue\n            state = WorkerState.JOB_RUNNING\n            \n        # --- JOB_RUNNING: Execute the posting job ---\n        elif state == WorkerState.JOB_RUNNING:\n            job_id = current_job['job_id']\n            \n            try:\n                success, error = execute_posting_job(\n                    current_job, worker_config, config, logger,\n                    tracker=tracker, worker_id=worker_id\n                )\n                \n                if success:\n                    tracker.update_job_status(job_id, 'success', worker_id)\n                    stats['jobs_completed'] += 1\n                else:\n                    tracker.update_job_status(job_id, 'failed', worker_id, error=error)\n                    stats['jobs_failed'] += 1\n                    \n                    # Check if error indicates device loss\n                    device_loss_errors = [\n                        'device offline', 'not found', 'connection reset',\n                        'adb', 'device not ready', 'UiAutomator'\n                    ]\n                    if any(e in error.lower() for e in device_loss_errors):\n                        state = WorkerState.ERROR_RECOVERY\n                        continue\n                \n                current_job = None\n                ctx.recovery_attempts = 0  # Reset on successful cycle\n                \n                # Delay between jobs\n                if delay_between_jobs > 0:\n                    logger.info(f\"Waiting {delay_between_jobs}s before next job...\")\n                    time.sleep(delay_between_jobs)\n                    \n                state = WorkerState.IDLE\n                \n            except Exception as e:\n                error_msg = f\"{type(e).__name__}: {str(e)}\"\n                logger.error(f\"Job {job_id} exception: {error_msg}\")\n                tracker.update_job_status(job_id, 'failed', worker_id, error=error_msg)\n                stats['jobs_failed'] += 1\n                ctx.last_error = error_msg\n                state = WorkerState.ERROR_RECOVERY\n                \n        # --- ERROR_RECOVERY: Clean up and retry ---\n        elif state == WorkerState.ERROR_RECOVERY:\n            ctx.recovery_attempts += 1\n            stats['recovery_cycles'] += 1\n            \n            logger.warning(\n                f\"[RECOVERY] Attempt {ctx.recovery_attempts}/{ctx.max_recovery_attempts}, \"\n                f\"last error: {ctx.last_error}\"\n            )\n            \n            if ctx.recovery_attempts > ctx.max_recovery_attempts:\n                logger.error(\"[RECOVERY] Max attempts exceeded, shutting down worker\")\n                stats['exit_reason'] = 'max_recovery_attempts'\n                state = WorkerState.SHUTDOWN\n                continue\n            \n            # Full cleanup\n            try:\n                appium_manager.stop()\n            except:\n                pass\n                \n            if ctx.phone_name:\n                stop_phone_by_name(ctx.phone_name, logger)\n            \n            # Backoff before retry\n            backoff = min(30, 5 * ctx.recovery_attempts)\n            logger.info(f\"[RECOVERY] Backing off {backoff}s before retry...\")\n            time.sleep(backoff)\n            \n            # Return to PHONE_STARTING to try again\n            state = WorkerState.PHONE_STARTING\n            \n    # --- SHUTDOWN: Clean exit ---\n    logger.info(\"Worker shutting down...\")\n    \n    try:\n        appium_manager.stop()\n    except:\n        pass\n        \n    if ctx.phone_name:\n        stop_phone_by_name(ctx.phone_name, logger)\n    \n    stats['end_time'] = datetime.now().isoformat()\n    if stats['exit_reason'] is None:\n        stats['exit_reason'] = 'shutdown_requested'\n    \n    return stats\n```\n\n## File Changes Summary\n\n1. **New file: `adb_utils.py`** (recommended)\n   - `wait_for_adb(device_id, adb_path, timeout)` - Polls until device present\n   - `ensure_device_alive(device_id, adb_path)` - Quick liveness check\n   - `recover_device(...)` - Full recovery sequence\n\n2. **Modified: `parallel_worker.py`**\n   - Add `WorkerState` enum with states: IDLE, PHONE_STARTING, ADB_PENDING, ADB_READY, APPIUM_READY, JOB_RUNNING, ERROR_RECOVERY, SHUTDOWN\n   - Add `WorkerContext` dataclass for state machine context\n   - Refactor `run_worker()` to use `run_worker_state_machine()`\n   - Import and use `wait_for_adb`, `ensure_device_alive` from adb_utils\n   - Add periodic `ensure_device_alive()` checks during JOB_RUNNING state\n\n3. **Optional: `parallel_config.py`**\n   - Add `adb_timeout: int = 90` for configurable ADB wait timeout\n   - Add `max_recovery_attempts: int = 3` for worker resilience config\n\n## Integration Points\n\n- `execute_posting_job()` should call `ensure_device_alive()` before Appium operations\n- State machine replaces the flat while loop in current `run_worker()`\n- Recovery state properly cleans up Appium, disconnects ADB, stops phone, then retries\n- Stats now track `recovery_cycles` for observability",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Tests for ADB Helper Functions\n\n**Test `wait_for_adb()` timeout behavior:**\n```bash\n# Simulate by running with a non-existent device\npython -c \"\nfrom adb_utils import wait_for_adb\n# Should return False after timeout\nresult = wait_for_adb('192.168.99.99:5555', \n    r'C:\\Users\\asus\\Downloads\\android-sdk\\platform-tools\\adb.exe',\n    timeout=10)\nassert result == False, 'Should timeout for non-existent device'\nprint('PASS: wait_for_adb timeout test')\n\"\n```\n\n**Test `wait_for_adb()` success case:**\n```bash\n# With a real running phone\npython -c \"\nfrom adb_utils import wait_for_adb\nfrom geelark_client import GeelarkClient\nimport time\n\nclient = GeelarkClient()\n# Find a phone and start it\nphones = client.list_phones(page_size=1)\nif phones['items']:\n    phone = phones['items'][0]\n    # Get ADB info\n    adb_info = client.enable_adb(phone['id'])\n    device_id = f\\\"{adb_info['ip']}:{adb_info['port']}\\\"\n    \n    # Test wait_for_adb\n    result = wait_for_adb(device_id, \n        r'C:\\\\Users\\\\asus\\\\Downloads\\\\android-sdk\\\\platform-tools\\\\adb.exe',\n        timeout=60)\n    print(f'wait_for_adb result: {result}')\n    assert result == True, 'Should find started device'\n    \n    client.stop_phone(phone['id'])\n    print('PASS: wait_for_adb success test')\n\"\n```\n\n**Test `ensure_device_alive()` quick check:**\n```bash\npython -c \"\nfrom adb_utils import ensure_device_alive\n# Quick check should return fast\nimport time\nstart = time.time()\nresult = ensure_device_alive('192.168.99.99:5555', \n    r'C:\\Users\\asus\\Downloads\\android-sdk\\platform-tools\\adb.exe')\nelapsed = time.time() - start\nassert elapsed < 10, f'Should be quick, took {elapsed}s'\nassert result == False, 'Non-existent device should return False'\nprint(f'PASS: ensure_device_alive quick check ({elapsed:.1f}s)')\n\"\n```\n\n### 2. State Machine Integration Tests\n\n**Test state transitions logging:**\n```bash\n# Run worker with verbose logging to verify state transitions\npython parallel_worker.py --worker-id 0 --num-workers 1 --progress-file test_progress.csv --delay 5 2>&1 | grep -E \"State:|RECOVERY|transition\"\n```\n\n**Expected state flow for successful job:**\n```\nState: IDLE\nState: PHONE_STARTING\nState: ADB_PENDING  \nState: ADB_READY\nState: APPIUM_READY\nState: JOB_RUNNING\nState: IDLE (back to claim next job)\n```\n\n**Test recovery flow by simulating ADB loss:**\n```bash\n# Start worker, then during JOB_RUNNING, manually disconnect ADB\n# Worker should transition: JOB_RUNNING -> ERROR_RECOVERY -> PHONE_STARTING -> ...\nadb disconnect <device_id>\n# Watch logs for \"[RECOVERY]\" messages\n```\n\n### 3. End-to-End Recovery Test\n\n**Simulate device loss and recovery:**\n```bash\n# 1. Seed a test job\npython -c \"\nimport csv\nwith open('test_recovery.csv', 'w', newline='') as f:\n    w = csv.writer(f)\n    w.writerow(['job_id','account','video_path','caption','status','worker_id','claimed_at','completed_at','error'])\n    w.writerow(['test1','testaccount1','chunk_01c/video.mp4','Test caption','pending','','','',''])\n\"\n\n# 2. Start worker\npython parallel_worker.py --worker-id 0 --num-workers 1 --progress-file test_recovery.csv &\n\n# 3. While job is running, kill ADB connection\nsleep 30\nadb disconnect all\n\n# 4. Verify worker enters ERROR_RECOVERY and attempts restart\n# Check logs/worker_0.log for:\n#   [RECOVERY] Device ... lost, initiating recovery sequence...\n#   [RECOVERY] Step 1/6: Stopping Appium server...\n#   ...\n#   State: PHONE_STARTING\n```\n\n### 4. Stress Test with Multiple Workers\n\n**Run 3 workers and verify independent recovery:**\n```bash\n# Seed jobs for 3 workers\npython parallel_orchestrator.py --seed-only --accounts acc1 acc2 acc3\n\n# Start orchestrator\npython parallel_orchestrator.py --run --workers 3\n\n# During execution, manually stop one phone via Geelark dashboard\n# Verify:\n# - Only affected worker enters ERROR_RECOVERY\n# - Other workers continue normally\n# - Affected worker recovers and continues\n```\n\n### 5. Max Recovery Attempts Test\n\n**Verify worker exits after max retries:**\n```bash\n# Configure impossibly short ADB timeout to force failures\n# Edit test to set ctx.max_recovery_attempts = 2\n\n# Watch for log:\n#   [RECOVERY] Max attempts exceeded, shutting down worker\n#   exit_reason: max_recovery_attempts\n```\n\n### 6. Metrics Validation\n\n**Verify stats include recovery_cycles:**\n```bash\n# After worker completes/exits, check returned stats\npython -c \"\n# Mock test\nstats = {'recovery_cycles': 2, 'jobs_completed': 5, 'jobs_failed': 1}\nassert 'recovery_cycles' in stats\nprint(f'Recovery cycles tracked: {stats[\\\"recovery_cycles\\\"]}')\n\"\n```\n\n### 7. Live Production Test (5 Workers)\n\n**Final validation per CLAUDE.md instructions:**\n```bash\n# Use live accounts and real videos\npython parallel_orchestrator.py --run --workers 5 --accounts $(head -5 accounts.txt | tr '\\n' ' ')\n\n# Monitor for:\n# - No duplicate posts to same account\n# - Clean recovery from any ADB flakiness\n# - All phones stopped after completion\n```\n\n### 8. Post-Test Phone Cleanup Verification\n\n```bash\n# CRITICAL: Verify all phones stopped\npython -c \"\nfrom geelark_client import GeelarkClient\nclient = GeelarkClient()\nrunning = []\nfor page in range(1, 20):\n    result = client.list_phones(page=page, page_size=100)\n    for phone in result['items']:\n        if phone['status'] == 1:\n            running.append(phone['serialName'])\n    if len(result['items']) < 100:\n        break\nif running:\n    print(f'WARNING: {len(running)} phones still running: {running}')\nelse:\n    print('PASS: All phones stopped')\n\"\n```",
        "status": "done",
        "dependencies": [
          "13",
          "16"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T05:58:09.305Z"
      },
      {
        "id": "24",
        "title": "Enforce strict worker-phone-Appium bindings with explicit phone assignment",
        "description": "Add phone_id field to WorkerConfig, implement --phones CLI argument for the orchestrator to map each worker to a specific phone, update get_config() to assign phones to workers, pass --phone-id to parallel_worker.py, and validate phone assignments are unique and exist in Geelark before starting.",
        "details": "## Overview\n\nThis task addresses Section 3.1-3.2 from reviews/review1.txt, implementing strict worker-phone-Appium bindings to prevent phone-level collisions. Currently, workers can implicitly \"grab phones\" rather than being bound to a pre-assigned phone identity, making phone-level collisions possible when multiple workers run concurrently.\n\n## Current State Analysis\n\n- `parallel_config.py` (lines 26-53): `WorkerConfig` dataclass has no `phone_id` field\n- `parallel_config.py` (lines 172-174): `get_config()` only accepts `num_workers` parameter, no phone assignment\n- `parallel_orchestrator.py` (lines 626-657): `start_worker_process()` passes `--worker-id`, `--num-workers`, `--progress-file`, `--delay` but no `--phone-id`\n- `parallel_worker.py` (lines 368-399): `main()` parser accepts `--worker-id`, `--num-workers`, `--progress-file`, `--delay` but no `--phone-id`\n- `parallel_worker.py` (lines 131-216): `execute_posting_job()` uses `account` from job dict as phone_name, not a worker-bound phone_id\n- Workers currently select phones dynamically based on the account name from jobs, not from a pre-assigned binding\n\n## Implementation Details\n\n### 3.1 Add phone_id field to WorkerConfig and orchestrator CLI\n\n**File:** `parallel_config.py`\n\n1. Extend `WorkerConfig` dataclass (around line 26):\n```python\n@dataclass\nclass WorkerConfig:\n    \"\"\"Configuration for a single worker process.\"\"\"\n    worker_id: int\n    appium_port: int\n    system_port_start: int\n    system_port_end: int\n    log_file: str\n    appium_log_file: str\n    phone_id: Optional[str] = None  # NEW: Geelark phone ID or serialName\n```\n\n2. Modify `get_config()` function (around line 172) to accept phones parameter:\n```python\ndef get_config(num_workers: int = 3, phones: Optional[List[str]] = None) -> ParallelConfig:\n    \"\"\"\n    Get a parallel configuration with the specified number of workers.\n    \n    Args:\n        num_workers: Number of parallel workers\n        phones: Optional list of phone IDs/names to assign to workers (must match num_workers)\n    \n    Returns:\n        ParallelConfig with phone assignments if provided\n    \"\"\"\n    config = ParallelConfig(num_workers=num_workers)\n    if phones:\n        if len(phones) != num_workers:\n            raise ValueError(f\"Number of phones ({len(phones)}) must match number of workers ({num_workers})\")\n        for worker, phone in zip(config.workers, phones):\n            worker.phone_id = phone\n    return config\n```\n\n**File:** `parallel_orchestrator.py`\n\n3. Add `--phones` CLI argument (around line 959):\n```python\nparser.add_argument('--phones', '-p',\n                    help='Comma-separated list of phone IDs/names (must match --workers count)')\n```\n\n4. Parse phones list in `main()` (around line 967):\n```python\n# Parse phones list if provided\nphones_list = None\nif args.phones:\n    phones_list = [p.strip() for p in args.phones.split(',') if p.strip()]\n```\n\n5. Update `get_config()` calls throughout orchestrator to pass phones:\n```python\nconfig = get_config(num_workers=args.workers, phones=phones_list)\n```\n\n6. Add phone validation function before starting workers:\n```python\ndef validate_phone_assignments(config: ParallelConfig) -> Tuple[bool, List[str]]:\n    \"\"\"\n    Validate that all phone_id values are unique and exist in Geelark.\n    \n    Returns:\n        (valid: bool, list of error messages)\n    \"\"\"\n    errors = []\n    \n    # Check for phone assignments\n    phone_ids = [w.phone_id for w in config.workers if w.phone_id]\n    if not phone_ids:\n        errors.append(\"No phones assigned to workers. Use --phones phone1,phone2,...\")\n        return False, errors\n    \n    if len(phone_ids) != config.num_workers:\n        errors.append(f\"Only {len(phone_ids)} phones assigned but {config.num_workers} workers configured\")\n        return False, errors\n    \n    # Check for duplicates\n    if len(phone_ids) != len(set(phone_ids)):\n        duplicates = [p for p in phone_ids if phone_ids.count(p) > 1]\n        errors.append(f\"Duplicate phone assignments: {set(duplicates)}\")\n        return False, errors\n    \n    # Validate phones exist in Geelark\n    try:\n        client = GeelarkClient()\n        all_phones = {}\n        for page in range(1, 20):\n            result = client.list_phones(page=page, page_size=100)\n            for phone in result.get('items', []):\n                all_phones[phone['id']] = phone['serialName']\n                all_phones[phone['serialName']] = phone['id']\n            if len(result.get('items', [])) < 100:\n                break\n        \n        for phone_id in phone_ids:\n            if phone_id not in all_phones:\n                errors.append(f\"Phone '{phone_id}' not found in Geelark\")\n    except Exception as e:\n        errors.append(f\"Failed to validate phones with Geelark: {e}\")\n    \n    return len(errors) == 0, errors\n```\n\n7. Call validation before `start_all_workers()` in `run_parallel_posting()`:\n```python\n# Validate phone assignments\nlogger.info(\"Validating phone assignments...\")\nvalid, errors = validate_phone_assignments(config)\nif not valid:\n    for err in errors:\n        logger.error(f\"  - {err}\")\n    return {'error': 'invalid_phone_assignments', 'details': errors}\nlogger.info(\"Phone assignments validated successfully\")\n```\n\n### 3.2 Pass --phone-id to parallel_worker.py and enforce exclusive use\n\n**File:** `parallel_orchestrator.py`\n\n8. Update `start_worker_process()` (around line 626) to pass phone_id:\n```python\ndef start_worker_process(worker_id: int, config: ParallelConfig) -> subprocess.Popen:\n    \"\"\"Start a single worker subprocess.\"\"\"\n    worker_config = config.get_worker(worker_id)\n    \n    cmd = [\n        sys.executable,\n        'parallel_worker.py',\n        '--worker-id', str(worker_id),\n        '--num-workers', str(config.num_workers),\n        '--progress-file', config.progress_file,\n        '--delay', str(config.delay_between_jobs),\n        '--phone-id', worker_config.phone_id,  # NEW: Pass assigned phone\n    ]\n    # ... rest of function\n```\n\n**File:** `parallel_worker.py`\n\n9. Add `--phone-id` argument to parser (around line 371):\n```python\nparser.add_argument('--phone-id', required=True,\n                    help='Geelark phone ID or serialName assigned to this worker')\n```\n\n10. Store phone_id in worker state and pass to job execution (around line 385):\n```python\n# Run worker with assigned phone\nstats = run_worker(\n    worker_id=args.worker_id,\n    config=config,\n    progress_file=args.progress_file,\n    delay_between_jobs=args.delay,\n    phone_id=args.phone_id  # NEW\n)\n```\n\n11. Update `run_worker()` signature and enforce phone binding (around line 218):\n```python\ndef run_worker(\n    worker_id: int,\n    config: ParallelConfig,\n    progress_file: str = None,\n    delay_between_jobs: int = None,\n    phone_id: str = None  # NEW: Required phone assignment\n) -> dict:\n    \"\"\"\n    Main worker loop.\n    \n    Args:\n        worker_id: This worker's ID\n        config: Parallel configuration\n        progress_file: Override progress file path\n        delay_between_jobs: Override delay between jobs\n        phone_id: Assigned Geelark phone (required - worker uses ONLY this phone)\n    \"\"\"\n    if not phone_id:\n        raise ValueError(\"phone_id is required - worker must have an assigned phone\")\n```\n\n12. Update `execute_posting_job()` to use worker's assigned phone instead of job account (around line 131):\n```python\ndef execute_posting_job(\n    job: dict,\n    worker_config: WorkerConfig,\n    config: ParallelConfig,\n    logger: logging.Logger,\n    tracker=None,\n    worker_id: int = None,\n    phone_id: str = None  # NEW: Worker's assigned phone\n) -> tuple:\n    \"\"\"\n    Execute a single posting job using the worker's assigned phone.\n    \n    IMPORTANT: The worker uses its assigned phone_id, NOT the account from the job.\n    The 'account' in the job refers to the Instagram account to post to,\n    while phone_id is the Geelark cloud phone this worker exclusively controls.\n    \"\"\"\n```\n\n13. Pass phone_id when calling execute_posting_job in run_worker():\n```python\nsuccess, error = execute_posting_job(\n    job, worker_config, config, logger,\n    tracker=tracker, worker_id=worker_id,\n    phone_id=phone_id  # Pass worker's assigned phone\n)\n```\n\n## File-level Change Summary\n\n| File | Changes |\n|------|---------|\n| `parallel_config.py` | Add `phone_id: Optional[str] = None` to WorkerConfig, update `get_config()` to accept phones list |\n| `parallel_orchestrator.py` | Add `--phones` CLI arg, add `validate_phone_assignments()`, update `start_worker_process()` to pass `--phone-id`, call validation before starting |\n| `parallel_worker.py` | Add `--phone-id` arg (required), update `run_worker()` and `execute_posting_job()` to use assigned phone exclusively |\n\n## Key Invariants Enforced\n\n1. **One worker ↔ one phone**: Each worker is bound to exactly one Geelark phone at startup\n2. **No dynamic phone selection**: Workers do not scan for \"any available phone\"\n3. **Uniqueness**: No two workers can be assigned the same phone\n4. **Existence validation**: All assigned phones must exist in Geelark before orchestrator starts\n5. **Explicit binding**: Phone assignment is explicit via CLI, not implicit",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Tests for WorkerConfig phone_id Field\n\n**Test phone_id field exists and is optional:**\n```python\ndef test_worker_config_phone_id_optional():\n    config = WorkerConfig(\n        worker_id=0, appium_port=4723,\n        system_port_start=8200, system_port_end=8209,\n        log_file=\"test.log\", appium_log_file=\"appium.log\"\n    )\n    assert config.phone_id is None\n\ndef test_worker_config_phone_id_set():\n    config = WorkerConfig(\n        worker_id=0, appium_port=4723,\n        system_port_start=8200, system_port_end=8209,\n        log_file=\"test.log\", appium_log_file=\"appium.log\",\n        phone_id=\"test_phone_123\"\n    )\n    assert config.phone_id == \"test_phone_123\"\n```\n\n### 2. Unit Tests for get_config() with phones\n\n**Test get_config with matching phones:**\n```bash\npython -c \"\nfrom parallel_config import get_config\nconfig = get_config(num_workers=3, phones=['phone1', 'phone2', 'phone3'])\nassert len(config.workers) == 3\nassert config.workers[0].phone_id == 'phone1'\nassert config.workers[1].phone_id == 'phone2'\nassert config.workers[2].phone_id == 'phone3'\nprint('PASS: get_config with phones')\n\"\n```\n\n**Test get_config with mismatched phones count (should raise):**\n```bash\npython -c \"\nfrom parallel_config import get_config\ntry:\n    config = get_config(num_workers=3, phones=['phone1', 'phone2'])\n    print('FAIL: Should have raised ValueError')\nexcept ValueError as e:\n    print(f'PASS: Raised ValueError: {e}')\n\"\n```\n\n### 3. Integration Tests for Phone Validation\n\n**Test validate_phone_assignments with duplicates:**\n```bash\npython -c \"\nfrom parallel_orchestrator import validate_phone_assignments\nfrom parallel_config import get_config\n\n# Create config with duplicate phones\nconfig = get_config(num_workers=2)\nconfig.workers[0].phone_id = 'same_phone'\nconfig.workers[1].phone_id = 'same_phone'\n\nvalid, errors = validate_phone_assignments(config)\nassert not valid, 'Should be invalid'\nassert any('Duplicate' in e for e in errors)\nprint(f'PASS: Duplicate detection - {errors}')\n\"\n```\n\n**Test validate_phone_assignments with non-existent phone:**\n```bash\npython -c \"\nfrom parallel_orchestrator import validate_phone_assignments\nfrom parallel_config import get_config\n\nconfig = get_config(num_workers=1, phones=['nonexistent_phone_xyz123'])\nvalid, errors = validate_phone_assignments(config)\nassert not valid, 'Should be invalid'\nassert any('not found' in e for e in errors)\nprint(f'PASS: Non-existent phone detection - {errors}')\n\"\n```\n\n### 4. CLI Argument Tests\n\n**Test --phones argument parsing:**\n```bash\n# Test with matching phones\npython parallel_orchestrator.py --workers 2 --phones phone1,phone2 --status\n\n# Test with mismatched count (should error)\npython parallel_orchestrator.py --workers 3 --phones phone1,phone2 --run 2>&1 | grep -i \"must match\"\n```\n\n### 5. Worker phone_id Enforcement Tests\n\n**Test worker refuses to start without phone_id:**\n```bash\npython -c \"\nfrom parallel_worker import run_worker\nfrom parallel_config import get_config\n\nconfig = get_config(num_workers=1)\ntry:\n    run_worker(worker_id=0, config=config, phone_id=None)\n    print('FAIL: Should have raised ValueError')\nexcept ValueError as e:\n    print(f'PASS: Worker requires phone_id - {e}')\n\"\n```\n\n### 6. End-to-End Test with Real Phones\n\n**Prerequisites:** Have at least 2 Geelark phones available (e.g., from accounts.txt)\n\n```bash\n# Step 1: Get two available phone names\npython -c \"\nfrom geelark_client import GeelarkClient\nclient = GeelarkClient()\nresult = client.list_phones(page_size=5)\nphones = [p['serialName'] for p in result['items'][:2]]\nprint(f'Available phones: {phones}')\nprint(f'Use: --phones {phones[0]},{phones[1]}')\n\"\n\n# Step 2: Test orchestrator with phone binding (dry run)\npython parallel_orchestrator.py --workers 2 --phones <phone1>,<phone2> --status\n\n# Step 3: Full test with 2 workers on 2 phones\npython parallel_orchestrator.py --workers 2 --phones <phone1>,<phone2> --seed-only --accounts acc1,acc2\n\n# Verify logs show phone binding\ngrep \"phone_id\" logs/worker_0.log\ngrep \"phone_id\" logs/worker_1.log\n```\n\n### 7. Collision Prevention Test\n\n**Test that workers use only assigned phones:**\n```bash\n# Start orchestrator with explicit phone bindings\n# Monitor that worker 0 only uses phone1, worker 1 only uses phone2\n# Check logs for any attempts to use non-assigned phones\npython parallel_orchestrator.py --workers 2 --phones phone1,phone2 --run &\n\n# In another terminal, monitor:\ntail -f logs/worker_0.log | grep -i phone\ntail -f logs/worker_1.log | grep -i phone\n\n# Verify no cross-phone operations\n```\n\n### 8. Regression Tests\n\n**Ensure backwards compatibility when --phones not provided:**\n```bash\n# Without --phones should show error or warning, not crash\npython parallel_orchestrator.py --workers 2 --status  # Should work (no phone validation for status)\npython parallel_orchestrator.py --workers 2 --run  # Should error gracefully asking for --phones\n```",
        "status": "deferred",
        "dependencies": [
          "19"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:59:43.228Z"
      },
      {
        "id": "25",
        "title": "Create centralized config.py with all paths and settings",
        "description": "Consolidate ADB_PATH, ANDROID_HOME, and other configuration values into a single config.py module that all other modules import from, eliminating scattered hardcoded paths and providing a single source of truth.",
        "details": "## Current State Analysis\n\nA `config.py` already exists (lines 1-186) with a well-structured `Config` class containing:\n- `ANDROID_SDK_PATH`, `ADB_PATH`, `PROJECT_ROOT`\n- Appium settings (`APPIUM_BASE_PORT`, `DEFAULT_APPIUM_URL`)\n- Parallel execution settings (`DEFAULT_NUM_WORKERS`, `MAX_WORKERS`, `SYSTEM_PORT_BASE`)\n- Job execution settings (`MAX_POSTS_PER_ACCOUNT_PER_DAY`, `DELAY_BETWEEN_JOBS`, `JOB_TIMEOUT`)\n- Retry settings (`MAX_RETRY_ATTEMPTS`, `RETRY_DELAY_MINUTES`, `NON_RETRYABLE_ERRORS`)\n- File paths (`PROGRESS_FILE`, `STATE_FILE`, `LOGS_DIR`, `ACCOUNTS_FILE`)\n- Timeout constants (`ADB_TIMEOUT`, `ADB_READY_TIMEOUT`, `APPIUM_CONNECT_TIMEOUT`, `PHONE_BOOT_TIMEOUT`)\n- Helper functions: `setup_environment()`, `get_adb_env()`, `_validate_config()`\n\n**Files already using config.py correctly:**\n- `post_reel_smart.py` (lines 18-38): imports `Config, setup_environment`\n- `parallel_config.py` (lines 25-87): imports `Config` and uses its values as defaults\n- `parallel_worker.py` (line 47): uses `ADB_PATH = Config.ADB_PATH`\n- `parallel_orchestrator.py` (line 412): uses `Config.ADB_PATH`\n\n**Files with hardcoded paths that need migration:**\n1. `adb_controller.py` (line 9): `ADB_PATH = r\"C:\\Users\\...\\adb.exe\"` (different path!)\n2. `diagnose_adbkeyboard.py` (line 10): `ADB_PATH = r\"C:\\Users\\...\\adb.exe\"`\n3. `setup_adbkeyboard.py` (line 17): `ADB_PATH = r\"C:\\Users\\...\\adb.exe\"`\n4. `setup_clipboard_helper.py` (line 17): `ADB_PATH = r\"C:\\Users\\...\\adb.exe\"`\n5. `fix_adbkeyboard.py` (line 18): `ADB_PATH = r\"C:\\Users\\...\\adb.exe\"`\n6. `reprovision_phone.py` (line 21): `ADB_PATH = r\"C:\\Users\\...\\adb.exe\"`\n7. `test_typing.py` (line 17): `ADB_PATH = r\"C:\\Users\\...\\adb.exe\"`\n8. `posting_scheduler.py` (lines 17-19): directly sets `os.environ['ANDROID_HOME']`\n9. `debug_page_source.py` (line 6): sets `os.environ['ANDROID_HOME']`\n10. `test_appium.py` (line 15): sets `os.environ['ANDROID_HOME']`\n11. `test_appium_typing.py` (line 10): sets `os.environ['ANDROID_HOME']`\n12. `test_dump_ui_fix.py` (line 6): sets `os.environ['ANDROID_HOME']`\n13. `test_full_flow_android15.py` (line 6): sets `os.environ['ANDROID_HOME']`\n\n## Implementation Steps\n\n### 1. Expand config.py if needed\nThe existing `config.py` is well-structured. Verify it contains all needed settings. Add if missing:\n- `APK_DIR` for APK file locations (ADBKeyboard.apk, ClipboardHelper.apk)\n\n```python\n# Add to Config class:\nAPK_DIR: str = os.path.dirname(os.path.abspath(__file__))\nADBKEYBOARD_APK: str = os.path.join(APK_DIR, \"ADBKeyboard.apk\")\nCLIPBOARD_HELPER_APK: str = os.path.join(APK_DIR, \"ClipboardHelper.apk\")\n```\n\n### 2. Migrate adb_controller.py\n```python\n# Replace line 9\n# OLD: ADB_PATH = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n# NEW:\nfrom config import Config\nADB_PATH = Config.ADB_PATH\n```\n\n### 3. Migrate utility scripts\nFor each of these files, add at the top:\n```python\nfrom config import Config, setup_environment\nsetup_environment()  # Only if they use Appium\n\nADB_PATH = Config.ADB_PATH\nAPK_PATH = Config.ADBKEYBOARD_APK  # or CLIPBOARD_HELPER_APK as appropriate\n```\n\nFiles: `diagnose_adbkeyboard.py`, `setup_adbkeyboard.py`, `setup_clipboard_helper.py`, `fix_adbkeyboard.py`, `reprovision_phone.py`, `test_typing.py`\n\n### 4. Migrate posting_scheduler.py\n```python\n# Replace lines 17-19\n# OLD:\n# os.environ['ANDROID_HOME'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\n# os.environ['ANDROID_SDK_ROOT'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\n# NEW:\nfrom config import Config, setup_environment\nsetup_environment()\n```\n\nAlso remove duplicate `get_appium_env()` function (lines 186-199) and use `get_adb_env()` from config.py instead.\n\n### 5. Migrate test files\nFor `debug_page_source.py`, `test_appium.py`, `test_appium_typing.py`, `test_dump_ui_fix.py`, `test_full_flow_android15.py`:\n```python\n# Replace direct os.environ calls\nfrom config import Config, setup_environment\nsetup_environment()\nADB_PATH = Config.ADB_PATH\n```\n\n### 6. Address the ADB_PATH discrepancy\nNote: Some files use `C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe` while config.py uses `C:\\Users\\asus\\Downloads\\android-sdk\\platform-tools\\adb.exe`. Verify which is correct and update config.py if needed:\n```python\n# If the standalone platform-tools is preferred:\nADB_PATH: str = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n# OR keep deriving from ANDROID_SDK_PATH if SDK path is correct\n```\n\n### 7. Update CLAUDE.md documentation\nUpdate the Key Files table to emphasize config.py as the single source of truth:\n```markdown\n| File | Purpose |\n|------|---------|\n| `config.py` | **SINGLE SOURCE OF TRUTH** - All paths, settings, timeouts |\n```\n\n## Important Considerations\n\n1. **Import order matters**: `setup_environment()` must be called BEFORE any Appium imports\n2. **Backward compatibility**: Keep the module-level `ADB_PATH` variable for files that use it\n3. **Validation**: `_validate_config()` runs on import and warns about missing paths\n4. **Environment propagation**: Use `get_adb_env()` when spawning subprocesses",
        "testStrategy": "## Test Strategy\n\n### 1. Verify config.py loads without errors\n```bash\npython -c \"from config import Config, setup_environment; setup_environment(); print('OK')\"\n```\n\n### 2. Verify all migrated files import successfully\n```bash\n# Test each migrated file\npython -c \"import adb_controller; print('adb_controller OK')\"\npython -c \"import diagnose_adbkeyboard; print('diagnose_adbkeyboard OK')\"\npython -c \"import setup_adbkeyboard; print('setup_adbkeyboard OK')\"\npython -c \"import setup_clipboard_helper; print('setup_clipboard_helper OK')\"\npython -c \"import fix_adbkeyboard; print('fix_adbkeyboard OK')\"\npython -c \"import reprovision_phone; print('reprovision_phone OK')\"\npython -c \"import posting_scheduler; print('posting_scheduler OK')\"\n```\n\n### 3. Verify ADB_PATH is consistent across all modules\n```bash\npython -c \"\nfrom config import Config\nimport adb_controller\nimport post_reel_smart\nimport parallel_worker\n\npaths = [\n    ('config', Config.ADB_PATH),\n    ('adb_controller', adb_controller.ADB_PATH),\n    ('post_reel_smart', post_reel_smart.ADB_PATH),\n    ('parallel_worker', parallel_worker.ADB_PATH),\n]\nfor name, path in paths:\n    print(f'{name}: {path}')\n\n# All should be identical\nunique = set(p for _, p in paths)\nassert len(unique) == 1, f'ADB_PATH mismatch: {unique}'\nprint('All ADB_PATH values match!')\n\"\n```\n\n### 4. Verify environment is set up correctly\n```bash\npython -c \"\nimport os\nfrom config import setup_environment\nsetup_environment()\nprint(f\\\"ANDROID_HOME={os.environ.get('ANDROID_HOME')}\\\")\nprint(f\\\"ANDROID_SDK_ROOT={os.environ.get('ANDROID_SDK_ROOT')}\\\")\nassert 'ANDROID_HOME' in os.environ\nassert 'ANDROID_SDK_ROOT' in os.environ\nprint('Environment setup OK')\n\"\n```\n\n### 5. Grep verification - no hardcoded paths remain\n```bash\n# Search for hardcoded ADB paths (should only find config.py)\ngrep -r \"platform-tools-latest-windows\" *.py --include=\"*.py\" | grep -v \"archived/\" | grep -v \"config.py\"\n# Expected: no output (empty)\n\n# Search for direct ANDROID_HOME assignments (should only find config.py)\ngrep -rn \"os.environ\\['ANDROID_HOME'\\]\" *.py --include=\"*.py\" | grep -v \"archived/\" | grep -v \"config.py\"\n# Expected: no output (empty)\n```\n\n### 6. Integration test - run actual posting workflow\n```bash\n# Test parallel orchestrator starts correctly\npython parallel_orchestrator.py --status\n\n# Test posting scheduler loads state\npython posting_scheduler.py --status\n```\n\n### 7. Verify subprocess environment propagation\n```bash\npython -c \"\nfrom config import get_adb_env\nenv = get_adb_env()\nassert 'ANDROID_HOME' in env\nassert 'ANDROID_SDK_ROOT' in env\nassert 'platform-tools' in env.get('PATH', '')\nprint('Subprocess environment OK')\n\"\n```",
        "status": "done",
        "dependencies": [
          "16"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:10:58.126Z"
      },
      {
        "id": "26",
        "title": "Archive deprecated files to archived/ folder",
        "description": "Move all .backup.py files, batch_post_ARCHIVED.py, batch_post_concurrent_ARCHIVED.py, post_to_instagram.py, and post_reel.py to an archived/ directory to clean up the main codebase while preserving historical code.",
        "details": "## Current State Analysis\n\nBased on codebase analysis, the deprecated files have already been moved to `archived/`:\n- `archived/batch_post_ARCHIVED.py` (8,988 bytes)\n- `archived/batch_post_concurrent_ARCHIVED.py` (7,743 bytes)\n- `archived/post_reel.py` (14,372 bytes)\n- `archived/post_reel_smart.backup.py` (29,764 bytes)\n- `archived/post_to_instagram.py` (7,420 bytes)\n- `archived/setup_adbkeyboard.backup.py` (4,993 bytes)\n- `archived/setup_clipboard_helper.backup.py` (5,071 bytes)\n\nGit status shows these files as deleted from the main directory (marked with `D`), indicating they've been moved but not yet committed.\n\n## Implementation Details\n\n### 1. Verify No Active Imports\n\nGrep analysis confirms no active Python files import from the deprecated modules:\n- No `from batch_post` imports found\n- No `from post_reel` (excluding `post_reel_smart`) imports found  \n- No `from post_to_instagram` imports found\n\n### 2. Update .gitignore (Optional)\n\nConsider whether to track `archived/` in git:\n- **Option A (Recommended)**: Keep `archived/` tracked in git for historical reference\n- **Option B**: Add `archived/` to `.gitignore` if disk space is a concern\n\nCurrent `.gitignore` does not exclude `archived/`, which is the correct default.\n\n### 3. Update Documentation References\n\nThe following documentation files reference deprecated files and may need updates:\n- `reviews/coupling_cohesion_analysis.md` (lines 163, 300, 308, 516) - References `post_to_instagram.py` in historical context\n- These references are acceptable as they document the evolution of the codebase\n\n### 4. Add README to archived/ Folder\n\nCreate `archived/README.md` to document why these files were archived:\n\n```markdown\n# Archived Files\n\nThis directory contains deprecated scripts that are no longer in active use.\nThese files are preserved for historical reference only.\n\n## Why Archived\n\n- **batch_post_ARCHIVED.py** - Replaced by `posting_scheduler.py` with better state management\n- **batch_post_concurrent_ARCHIVED.py** - Replaced by `parallel_orchestrator.py` \n- **post_reel.py** - Original posting script, replaced by `post_reel_smart.py` with Appium support\n- **post_to_instagram.py** - Early implementation using ADBController, deprecated in favor of Appium-based `post_reel_smart.py`\n- **setup_adbkeyboard.backup.py** - Backup of ADB keyboard setup before Android 15 migration\n- **setup_clipboard_helper.backup.py** - Backup of clipboard helper setup\n- **post_reel_smart.backup.py** - Pre-Appium version of smart posting script\n\n## DO NOT USE\n\nThese scripts are NOT maintained and should NOT be used for any purpose other than historical reference.\nThe current production scripts are:\n- `parallel_orchestrator.py` - Main batch posting entry point\n- `posting_scheduler.py` - Single-threaded alternative\n- `post_reel_smart.py` - Core posting logic (used by both)\n```\n\n### 5. Stage and Commit Changes\n\nThe files have been moved but the git changes need to be staged and committed:\n\n```bash\ngit add archived/\ngit add -A  # Stage deletions from root\ngit status  # Verify changes\ngit commit -m \"chore: archive deprecated posting scripts to archived/ folder\"\n```\n\n### 6. Verify No Broken References\n\nAfter archiving, verify the main scripts still work:\n- `python -c \"import posting_scheduler\"` should succeed\n- `python -c \"import parallel_orchestrator\"` should succeed\n- `python -c \"import post_reel_smart\"` should succeed",
        "testStrategy": "## Test Strategy\n\n### 1. Verify Archive Directory Contents\n\n```bash\n# List all files in archived/\nls -la archived/\n\n# Expected: 7 Python files + optional README.md\n# - batch_post_ARCHIVED.py\n# - batch_post_concurrent_ARCHIVED.py\n# - post_reel.py\n# - post_reel_smart.backup.py\n# - post_to_instagram.py\n# - setup_adbkeyboard.backup.py\n# - setup_clipboard_helper.backup.py\n```\n\n### 2. Verify Main Directory is Clean\n\n```bash\n# Check no .backup.py files remain in root\nls *.backup.py 2>/dev/null && echo \"ERROR: backup files still in root\" || echo \"OK: no backup files in root\"\n\n# Check deprecated scripts are gone from root\nls batch_post_ARCHIVED.py batch_post_concurrent_ARCHIVED.py post_reel.py post_to_instagram.py 2>/dev/null && echo \"ERROR: deprecated files in root\" || echo \"OK: deprecated files moved\"\n```\n\n### 3. Verify No Broken Imports\n\n```bash\n# Test all main scripts can be imported\npython -c \"import posting_scheduler; print('posting_scheduler: OK')\"\npython -c \"import parallel_orchestrator; print('parallel_orchestrator: OK')\"\npython -c \"import post_reel_smart; print('post_reel_smart: OK')\"\npython -c \"import parallel_worker; print('parallel_worker: OK')\"\npython -c \"import progress_tracker; print('progress_tracker: OK')\"\npython -c \"import geelark_client; print('geelark_client: OK')\"\n```\n\n### 4. Verify Git Status\n\n```bash\n# Check git status shows clean working directory after commit\ngit status\n\n# Expected output after commit:\n# \"nothing to commit, working tree clean\" (or only untracked files)\n```\n\n### 5. Verify No Import References to Archived Files\n\n```bash\n# Search for any imports of archived modules in active code\ngrep -r \"from batch_post\" --include=\"*.py\" --exclude-dir=archived || echo \"No batch_post imports found\"\ngrep -r \"from post_reel\\b\" --include=\"*.py\" --exclude-dir=archived || echo \"No post_reel imports found\"\ngrep -r \"from post_to_instagram\" --include=\"*.py\" --exclude-dir=archived || echo \"No post_to_instagram imports found\"\ngrep -r \"import batch_post\" --include=\"*.py\" --exclude-dir=archived || echo \"No batch_post imports found\"\ngrep -r \"import post_reel\\b\" --include=\"*.py\" --exclude-dir=archived || echo \"No post_reel imports found\"\n```\n\n### 6. Run Smoke Test of Main Entry Points\n\n```bash\n# Verify main scripts can show their help/usage\npython posting_scheduler.py --status\npython parallel_orchestrator.py --status\n```\n\n### 7. Verify README Exists in archived/ (if created)\n\n```bash\ntest -f archived/README.md && echo \"README exists\" || echo \"README missing (optional)\"\n```",
        "status": "done",
        "dependencies": [
          "25"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:13:20.950Z"
      },
      {
        "id": "27",
        "title": "Add retry_all_failed() convenience methods to ProgressTracker",
        "description": "Implement retry_failed_job(job_id) and retry_all_failed() methods that reset failed jobs back to RETRYING status for another attempt, with automatic invocation when the orchestrator starts with --run.",
        "details": "## NOTE: This task is ALREADY IMPLEMENTED\n\nAfter analyzing the codebase, I found that both methods and the orchestrator integration already exist:\n\n### Existing Implementation in progress_tracker.py\n\n**1. retry_failed_job(job_id: str) -> bool (lines 753-786):**\n- Resets a single failed job back to RETRYING status\n- Clears attempts counter to '0', error_type, retry_at, worker_id, and completed_at\n- Returns True if job was found and reset, False otherwise\n- Only operates on jobs with STATUS_FAILED status\n\n**2. retry_all_failed(include_non_retryable: bool = False) -> int (lines 788-833):**\n- Bulk-resets ALL failed jobs back to RETRYING status\n- Uses NON_RETRYABLE_ERRORS set: {'suspended', 'captcha', 'loggedout', 'actionblocked', 'banned'}\n- When include_non_retryable=False (default), skips jobs with non-retryable error types\n- When include_non_retryable=True, also retries suspended/captcha/loggedout jobs\n- Returns count of jobs reset\n\n### Existing Integration in parallel_orchestrator.py\n\n**Automatic invocation on --run (lines 886-899):**\n```python\nif retry_all_failed and tracker.exists():\n    stats_before = tracker.get_stats()\n    if stats_before['failed'] > 0:\n        logger.info(\"RETRYING FAILED JOBS FROM PREVIOUS RUNS\")\n        count = tracker.retry_all_failed(include_non_retryable=retry_include_non_retryable)\n```\n\n**CLI flag support (lines 984-987):**\n- `--retry-all-failed`: Standalone command to reset failed jobs\n- `--retry-include-non-retryable`: Include non-retryable errors when retrying\n\n**run_parallel_posting() parameters (lines 832-834):**\n- `retry_all_failed: bool = True` - Always enabled by default on --run\n- `retry_include_non_retryable: bool = False` - Respects non-retryable classification by default\n\n### If Task Requires Changes, Consider:\n1. **No changes needed** - Mark this task as already done\n2. **Enhancement requests**: Add additional retry options like retry delay, max retry count override, or selective retry by error type",
        "testStrategy": "## Verification of Existing Implementation\n\n### 1. Unit Test retry_failed_job()\n```bash\npython -c \"\nfrom progress_tracker import ProgressTracker\nimport tempfile, os\n\n# Create temp progress file with failed job\ntracker = ProgressTracker(tempfile.mktemp(suffix='.csv'))\ntracker.seed_from_jobs([{'job_id': 'test1', 'account': 'acc1', 'video_path': '/v1.mp4', 'caption': 'test'}])\ntracker.claim_next_job(worker_id=0)\ntracker.update_job_status('test1', 'failed', worker_id=0, error='Test error')\n\n# Verify job is failed\nstats = tracker.get_stats()\nassert stats['failed'] == 1, f'Expected 1 failed, got {stats}'\n\n# Retry the failed job\nresult = tracker.retry_failed_job('test1')\nassert result == True, 'retry_failed_job should return True'\n\n# Verify job is now retrying\nstats = tracker.get_stats()\nassert stats['retrying'] == 1, f'Expected 1 retrying, got {stats}'\nassert stats['failed'] == 0, f'Expected 0 failed, got {stats}'\n\nprint('PASS: retry_failed_job() works correctly')\n\"\n```\n\n### 2. Unit Test retry_all_failed() with non-retryable filtering\n```bash\npython -c \"\nfrom progress_tracker import ProgressTracker\nimport tempfile\n\ntracker = ProgressTracker(tempfile.mktemp(suffix='.csv'))\ntracker.seed_from_jobs([\n    {'job_id': 'j1', 'account': 'a1', 'video_path': '/v1.mp4', 'caption': 't1'},\n    {'job_id': 'j2', 'account': 'a2', 'video_path': '/v2.mp4', 'caption': 't2'},\n    {'job_id': 'j3', 'account': 'a3', 'video_path': '/v3.mp4', 'caption': 't3'},\n])\n\n# Claim and fail with different error types\nfor jid, err in [('j1', 'timeout'), ('j2', 'account suspended'), ('j3', 'network error')]:\n    tracker.claim_next_job(worker_id=0)\n    tracker.update_job_status(jid, 'failed', worker_id=0, error=err)\n\n# Without include_non_retryable: should retry j1, j3 but NOT j2 (suspended)\ncount = tracker.retry_all_failed(include_non_retryable=False)\nstats = tracker.get_stats()\nassert count == 2, f'Expected 2 retried, got {count}'\nassert stats['failed'] == 1, f'Expected 1 still failed (suspended), got {stats}'\n\n# With include_non_retryable: should retry j2 too\ncount2 = tracker.retry_all_failed(include_non_retryable=True)\nassert count2 == 1, f'Expected 1 more retried, got {count2}'\n\nprint('PASS: retry_all_failed() respects non-retryable errors')\n\"\n```\n\n### 3. Integration Test with Orchestrator --run\n```bash\n# Create a test scenario with failed jobs\npython -c \"\nfrom progress_tracker import ProgressTracker\ntracker = ProgressTracker('parallel_progress.csv')\nif tracker.exists():\n    stats = tracker.get_stats()\n    print(f'Before: {stats[\\\"failed\\\"]} failed, {stats[\\\"retrying\\\"]} retrying')\n\"\n\n# Run orchestrator - verify it auto-retries failed jobs\npython parallel_orchestrator.py --status\n\n# If failed > 0, run with --run (dry) to see retry logic trigger:\n# python parallel_orchestrator.py --workers 1 --run\n# Look for log: \"RETRYING FAILED JOBS FROM PREVIOUS RUNS\"\n```\n\n### 4. Manual CLI Test\n```bash\n# Test standalone retry command\npython parallel_orchestrator.py --retry-all-failed\npython parallel_orchestrator.py --retry-all-failed --retry-include-non-retryable\n```",
        "status": "done",
        "dependencies": [
          "19",
          "20"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:14:43.997Z"
      },
      {
        "id": "28",
        "title": "Update CLAUDE.md documentation with parallel orchestrator architecture",
        "description": "Document the parallel_orchestrator.py as the primary entry point for batch posting, explain the worker architecture (separate processes with dedicated Appium servers), document progress tracking via parallel_progress.csv, and update the Key Files table with new modules.",
        "details": "## Current State Analysis\n\nThe CLAUDE.md file (399 lines) has basic parallel orchestrator documentation at lines 199-239, but it is outdated and incomplete. The following areas need updating:\n\n### 1. Key Files Table Update (Lines 263-274)\n\n**Current Table (missing new modules):**\n```markdown\n| File | Purpose |\n|------|---------|\n| `posting_scheduler.py` | **MAIN SCRIPT** - scheduler with tracking, retry, state persistence |\n| `post_reel_smart.py` | Core posting logic for single phone (Appium timeout: 60s) |\n| `geelark_client.py` | Geelark API wrapper (upload timeout: 60s) |\n| `dashboard.py` | Real-time web dashboard (http://localhost:5000) |\n| `scheduler_state.json` | Persistent state (auto-generated) |\n| `geelark_batch.log` | Execution log with phase info |\n| `geelark_api.log` | API response log (for Geelark support) |\n```\n\n**Add these new modules to the table:**\n- `parallel_orchestrator.py` - **PRIMARY ENTRY POINT** for parallel batch posting\n- `parallel_worker.py` - Individual worker process (one per Appium server)\n- `parallel_config.py` - Worker configuration (ports, systemPorts, log files)\n- `progress_tracker.py` - File-locked CSV progress tracking with retry support\n- `config.py` - Centralized configuration (all paths, timeouts, constants)\n- `parallel_progress.csv` - Daily job ledger (file-locked, NEVER delete manually)\n\n### 2. Parallel Orchestrator Architecture Section Update (Lines 199-239)\n\nExpand the architecture documentation to include:\n\n**Worker Architecture Details:**\n```\nparallel_orchestrator.py (main process)\n    │\n    ├── Worker 0 ──► Appium:4723 ──► systemPort:8200-8209 ──► Phone\n    ├── Worker 1 ──► Appium:4725 ──► systemPort:8210-8219 ──► Phone\n    ├── Worker 2 ──► Appium:4727 ──► systemPort:8220-8229 ──► Phone\n    └── Worker N ──► Appium:472X ──► systemPort:82X0-82X9 ──► Phone\n\n    Coordination: Workers communicate via file-locked parallel_progress.csv\n    Logs: logs/worker_N.log, logs/appium_N.log per worker\n```\n\n**Key Implementation Details to Document:**\n- Each worker is a SEPARATE PROCESS (subprocess.Popen), not a thread\n- Port allocation: Appium on odd ports (4723, 4725, ...), systemPorts in 10-port ranges\n- Workers coordinate via ProgressTracker using portalocker file locking\n- Config from config.py: MAX_POSTS_PER_ACCOUNT_PER_DAY=1, MAX_RETRY_ATTEMPTS=3\n- State machine states in parallel_worker.py: STARTING → ADB_PENDING → ADB_READY → APPIUM_READY → JOB_RUNNING\n\n### 3. Progress Tracking Documentation (New Section)\n\nAdd detailed documentation about the progress tracking system:\n\n```markdown\n## Progress Tracking (parallel_progress.csv)\n\nThe daily job ledger that tracks ALL posting jobs. Uses file locking (portalocker)\nto ensure only one worker can claim a job at a time.\n\n### CSV Columns:\n- job_id, account, video_path, caption\n- status: pending/claimed/success/failed/skipped/retrying\n- worker_id, claimed_at, completed_at, error\n- attempts, max_attempts, retry_at, error_type\n\n### Status Transitions:\npending → claimed (worker claims job)\nclaimed → success (post succeeded)\nclaimed → retrying (post failed, will retry)\nretrying → claimed (worker claims retry job)\nretrying → failed (max attempts reached or non-retryable error)\n\n### Non-Retryable Errors:\nsuspended, captcha, loggedout, actionblocked, banned\n```\n\n### 4. Config.py Documentation (New Section)\n\nDocument the centralized configuration:\n\n```markdown\n## Centralized Configuration (config.py)\n\nAll paths and settings are defined in config.py. NEVER hardcode paths elsewhere.\n\nKey Settings:\n- ANDROID_SDK_PATH: C:\\Users\\asus\\Downloads\\android-sdk\n- ADB_PATH: {SDK}\\platform-tools\\adb.exe\n- MAX_POSTS_PER_ACCOUNT_PER_DAY: 1\n- MAX_RETRY_ATTEMPTS: 3\n- RETRY_DELAY_MINUTES: 5\n- JOB_TIMEOUT: 300s\n```\n\n### 5. Update MAIN ENTRY POINTS Section (Lines 185-195)\n\nEmphasize parallel_orchestrator.py as the PRIMARY method:\n\n```markdown\n## MAIN ENTRY POINTS\n\n### For Parallel Posting (PRIMARY - RECOMMENDED):\n```bash\npython parallel_orchestrator.py --workers 5 --run\n```\n\n### For Single-Threaded Posting (Legacy):\n```bash\npython posting_scheduler.py --add-folder chunk_01c --run\n```\n```\n\n### Implementation Notes\n\n1. Update the Key Files table to include all new modules with accurate descriptions\n2. Expand the worker architecture diagram with systemPort allocations\n3. Add a new \"Progress Tracking\" section explaining the CSV ledger\n4. Add a new \"Centralized Configuration\" section documenting config.py\n5. Update the \"MAIN ENTRY POINTS\" section to emphasize parallel_orchestrator\n6. Ensure worker stagger timing (60s between starts) is documented\n7. Document the retry system (attempts, delay, non-retryable errors)",
        "testStrategy": "## Test Strategy\n\n### 1. Documentation Accuracy Verification\n\n**Verify Key Files table matches actual files:**\n```bash\n# Check all documented files exist\nls -la parallel_orchestrator.py parallel_worker.py parallel_config.py progress_tracker.py config.py\n\n# Verify CSV columns match ProgressTracker.COLUMNS\npython -c \"from progress_tracker import ProgressTracker; print(ProgressTracker.COLUMNS)\"\n```\n\n**Verify port allocations match code:**\n```bash\npython -c \"\nfrom config import Config\nprint(f'Base Appium: {Config.APPIUM_BASE_PORT}')\nprint(f'System port base: {Config.SYSTEM_PORT_BASE}')\nfor i in range(3):\n    print(f'Worker {i}: Appium {Config.get_worker_appium_port(i)}, systemPort {Config.get_worker_system_port_range(i)}')\n\"\n```\n\n### 2. Documentation Completeness Check\n\n**Ensure all CLI flags are documented:**\n```bash\npython parallel_orchestrator.py --help\n```\n\nCompare output against CLAUDE.md documentation for completeness.\n\n**Verify config values match documentation:**\n```bash\npython -c \"\nfrom config import Config\nprint(f'MAX_POSTS_PER_ACCOUNT_PER_DAY: {Config.MAX_POSTS_PER_ACCOUNT_PER_DAY}')\nprint(f'MAX_RETRY_ATTEMPTS: {Config.MAX_RETRY_ATTEMPTS}')\nprint(f'RETRY_DELAY_MINUTES: {Config.RETRY_DELAY_MINUTES}')\nprint(f'JOB_TIMEOUT: {Config.JOB_TIMEOUT}')\n\"\n```\n\n### 3. Code-Documentation Consistency\n\n**Verify worker architecture matches implementation:**\n```bash\n# Check worker startup in orchestrator\ngrep -n \"start_worker_process\\|Popen\\|stagger\" parallel_orchestrator.py\n\n# Check state machine states in worker\ngrep -n \"WorkerState\\|STARTING\\|ADB_PENDING\\|ADB_READY\" parallel_worker.py\n```\n\n**Verify status values match code:**\n```bash\npython -c \"\nfrom progress_tracker import ProgressTracker\nprint('Statuses:', [s for s in dir(ProgressTracker) if s.startswith('STATUS_')])\nprint('Non-retryable:', ProgressTracker.NON_RETRYABLE_ERRORS)\n\"\n```\n\n### 4. Functional Verification\n\n**Test that documented commands work:**\n```bash\n# Test status command\npython parallel_orchestrator.py --status\n\n# Test reset-day (dry run - just verify it parses)\npython parallel_orchestrator.py --help | grep reset-day\n```\n\n### 5. Cross-Reference Check\n\nVerify all CRITICAL sections in CLAUDE.md reference the correct files:\n- \"PROGRESS FILE MANAGEMENT\" → parallel_progress.csv\n- \"ACCOUNT MANAGEMENT\" → accounts.txt, scheduler_state.json\n- \"STOP PHONES\" → stop script uses GeelarkClient correctly\n\n### 6. Markdown Rendering Test\n\nOpen CLAUDE.md in a markdown viewer or VS Code preview to ensure:\n- Tables render correctly\n- Code blocks have proper syntax highlighting\n- Architecture diagrams are properly formatted\n- All links (if any) are valid",
        "status": "done",
        "dependencies": [
          "25",
          "26"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:16:55.800Z"
      },
      {
        "id": "29",
        "title": "Add HTTP timeout to GeelarkClient._request()",
        "description": "Add a configurable timeout parameter to all HTTP requests in geelark_client.py to prevent indefinite hangs on network issues, ensuring posting operations fail fast and can be retried rather than blocking workers indefinitely.",
        "details": "## Problem Statement\n\nThe `GeelarkClient._request()` method at line 49 of `geelark_client.py` uses `requests.post()` without a timeout parameter:\n```python\nresp = requests.post(url, json=data or {}, headers=headers)\n```\n\nSimilarly, `upload_file_to_geelark()` at line 161 uses `requests.put()` without a timeout:\n```python\nresp = requests.put(upload_url, data=f)\n```\n\nWithout timeouts, these calls can hang indefinitely on network issues, causing workers to become stuck and reducing system throughput.\n\n## Implementation Steps\n\n### 1. Add HTTP_TIMEOUT constant to config.py\n\nAdd to the TIMEOUTS section (around line 106-118):\n```python\n# HTTP request timeout for Geelark API calls (seconds)\nHTTP_API_TIMEOUT: int = 30\n\n# HTTP timeout for file uploads (larger files need more time)\nHTTP_UPLOAD_TIMEOUT: int = 120\n```\n\n### 2. Update GeelarkClient._request() to use timeout\n\nIn `geelark_client.py`, import Config and add timeout to the POST request:\n\n```python\nfrom config import Config\n\n# In _request() method (line 49):\nresp = requests.post(url, json=data or {}, headers=headers, timeout=Config.HTTP_API_TIMEOUT)\n```\n\n### 3. Update upload_file_to_geelark() to use timeout\n\n```python\n# In upload_file_to_geelark() method (line 161):\nresp = requests.put(upload_url, data=f, timeout=Config.HTTP_UPLOAD_TIMEOUT)\n```\n\n### 4. Add proper exception handling for timeout errors\n\nWrap the requests calls in try-except to handle `requests.exceptions.Timeout` and `requests.exceptions.ConnectionError`:\n\n```python\ndef _request(self, endpoint, data=None):\n    \"\"\"Make API request with full response logging\"\"\"\n    url = f\"{API_BASE}{endpoint}\"\n    headers = self._get_headers()\n    \n    start_time = time.time()\n    api_logger.debug(f\"REQUEST: {endpoint} data={data}\")\n    \n    try:\n        resp = requests.post(\n            url, \n            json=data or {}, \n            headers=headers, \n            timeout=Config.HTTP_API_TIMEOUT\n        )\n    except requests.exceptions.Timeout:\n        api_logger.error(f\"TIMEOUT: {endpoint} after {Config.HTTP_API_TIMEOUT}s\")\n        raise Exception(f\"API timeout: {endpoint} did not respond within {Config.HTTP_API_TIMEOUT}s\")\n    except requests.exceptions.ConnectionError as e:\n        api_logger.error(f\"CONNECTION ERROR: {endpoint} - {e}\")\n        raise Exception(f\"API connection error: {endpoint} - {e}\")\n    \n    elapsed = time.time() - start_time\n    # ... rest of method unchanged\n```\n\n### 5. Similar handling for upload_file_to_geelark()\n\n```python\ndef upload_file_to_geelark(self, local_path):\n    \"\"\"Upload a local file to Geelark's temp storage, return resource URL\"\"\"\n    # ... existing code to get upload_url and resource_url ...\n    \n    try:\n        with open(local_path, \"rb\") as f:\n            resp = requests.put(upload_url, data=f, timeout=Config.HTTP_UPLOAD_TIMEOUT)\n    except requests.exceptions.Timeout:\n        raise Exception(f\"Upload timeout: file upload did not complete within {Config.HTTP_UPLOAD_TIMEOUT}s\")\n    except requests.exceptions.ConnectionError as e:\n        raise Exception(f\"Upload connection error: {e}\")\n    \n    # ... rest of method unchanged\n```\n\n## Rationale for Timeout Values\n\n- **HTTP_API_TIMEOUT = 30s**: Most Geelark API calls are simple JSON exchanges. 30 seconds is generous for normal operations while preventing indefinite hangs.\n- **HTTP_UPLOAD_TIMEOUT = 120s**: File uploads (videos) can be several MB, requiring more time. 120 seconds accommodates larger files over slower connections.\n\n## Files to Modify\n\n1. `config.py` - Add HTTP_API_TIMEOUT and HTTP_UPLOAD_TIMEOUT constants\n2. `geelark_client.py` - Add timeout parameter and exception handling to _request() and upload_file_to_geelark()",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Test - Verify timeout parameter is passed\n\n```bash\n# Quick verification that requests.post is called with timeout\npython -c \"\nimport geelark_client\nimport requests\nfrom unittest.mock import patch, MagicMock\n\n# Mock successful response\nmock_resp = MagicMock()\nmock_resp.status_code = 200\nmock_resp.json.return_value = {'code': 0, 'data': {'items': []}}\nmock_resp.text = '{}'\nmock_resp.headers = {}\n\nwith patch.object(requests, 'post', return_value=mock_resp) as mock_post:\n    client = geelark_client.GeelarkClient()\n    client._request('/test/endpoint', {'test': 'data'})\n    \n    # Verify timeout was passed\n    call_kwargs = mock_post.call_args.kwargs\n    assert 'timeout' in call_kwargs, 'timeout parameter not passed to requests.post'\n    assert call_kwargs['timeout'] == 30, f'Expected timeout=30, got {call_kwargs[\\\"timeout\\\"]}'\n    print('✓ requests.post called with timeout=30')\n\"\n```\n\n### 2. Unit Test - Verify timeout exception handling\n\n```bash\npython -c \"\nimport geelark_client\nimport requests\nfrom unittest.mock import patch\n\n# Test Timeout exception is caught and re-raised with descriptive message\nwith patch.object(requests, 'post', side_effect=requests.exceptions.Timeout()):\n    client = geelark_client.GeelarkClient()\n    try:\n        client._request('/test/endpoint', {})\n        print('✗ Expected exception was not raised')\n    except Exception as e:\n        assert 'timeout' in str(e).lower(), f'Exception message should mention timeout: {e}'\n        print(f'✓ Timeout properly caught and re-raised: {e}')\n\"\n```\n\n### 3. Unit Test - Verify connection error handling\n\n```bash\npython -c \"\nimport geelark_client\nimport requests\nfrom unittest.mock import patch\n\n# Test ConnectionError exception is caught and re-raised\nwith patch.object(requests, 'post', side_effect=requests.exceptions.ConnectionError('Network unreachable')):\n    client = geelark_client.GeelarkClient()\n    try:\n        client._request('/test/endpoint', {})\n        print('✗ Expected exception was not raised')\n    except Exception as e:\n        assert 'connection' in str(e).lower(), f'Exception message should mention connection: {e}'\n        print(f'✓ ConnectionError properly caught and re-raised: {e}')\n\"\n```\n\n### 4. Verify config.py has timeout constants\n\n```bash\npython -c \"\nfrom config import Config\nassert hasattr(Config, 'HTTP_API_TIMEOUT'), 'Missing HTTP_API_TIMEOUT'\nassert hasattr(Config, 'HTTP_UPLOAD_TIMEOUT'), 'Missing HTTP_UPLOAD_TIMEOUT'\nassert Config.HTTP_API_TIMEOUT == 30, f'Expected HTTP_API_TIMEOUT=30, got {Config.HTTP_API_TIMEOUT}'\nassert Config.HTTP_UPLOAD_TIMEOUT == 120, f'Expected HTTP_UPLOAD_TIMEOUT=120, got {Config.HTTP_UPLOAD_TIMEOUT}'\nprint(f'✓ Config.HTTP_API_TIMEOUT = {Config.HTTP_API_TIMEOUT}')\nprint(f'✓ Config.HTTP_UPLOAD_TIMEOUT = {Config.HTTP_UPLOAD_TIMEOUT}')\n\"\n```\n\n### 5. Integration Test - Live API call with timeout\n\n```bash\n# Test that actual API calls work with the timeout\npython -c \"\nfrom geelark_client import GeelarkClient\nclient = GeelarkClient()\ntry:\n    result = client.list_phones(page_size=1)\n    print(f'✓ API call succeeded with timeout: {len(result.get(\\\"items\\\", []))} phones')\nexcept Exception as e:\n    if 'timeout' in str(e).lower():\n        print(f'⚠ API timed out (may indicate slow network): {e}')\n    else:\n        print(f'✗ API call failed: {e}')\n\"\n```\n\n### 6. Verify upload timeout on upload_file_to_geelark()\n\n```bash\npython -c \"\nimport geelark_client\nimport requests\nfrom unittest.mock import patch, MagicMock\n\n# Mock get_upload_url response\nmock_get_url = MagicMock()\nmock_get_url.return_value = {'uploadUrl': 'https://test.com/upload', 'resourceUrl': 'https://test.com/resource'}\n\n# Mock successful PUT response\nmock_resp = MagicMock()\nmock_resp.status_code = 200\n\nwith patch.object(requests, 'put', return_value=mock_resp) as mock_put:\n    with patch.object(geelark_client.GeelarkClient, 'get_upload_url', mock_get_url):\n        client = geelark_client.GeelarkClient()\n        # Create a small temp file for testing\n        import tempfile\n        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as f:\n            f.write(b'test data')\n            temp_path = f.name\n        \n        try:\n            client.upload_file_to_geelark(temp_path)\n            call_kwargs = mock_put.call_args.kwargs\n            assert 'timeout' in call_kwargs, 'timeout parameter not passed to requests.put'\n            assert call_kwargs['timeout'] == 120, f'Expected timeout=120, got {call_kwargs[\\\"timeout\\\"]}'\n            print('✓ requests.put called with timeout=120')\n        finally:\n            import os\n            os.unlink(temp_path)\n\"\n```",
        "status": "done",
        "dependencies": [
          "25"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:55:34.203Z"
      },
      {
        "id": "30",
        "title": "Add credential validation to GeelarkClient.__init__()",
        "description": "Add fail-fast validation to GeelarkClient.__init__() that checks for required GEELARK_TOKEN at initialization time and raises a clear, actionable error immediately if missing, rather than failing later in the posting flow with cryptic authentication errors.",
        "details": "## Problem Statement\n\nCurrently, `GeelarkClient.__init__()` (lines 26-29 of `geelark_client.py`) simply assigns environment variables without validation:\n```python\ndef __init__(self):\n    self.app_id = os.getenv(\"GEELARK_APP_ID\")\n    self.api_key = os.getenv(\"GEELARK_API_KEY\")\n    self.token = os.getenv(\"GEELARK_TOKEN\")\n```\n\nWhen `GEELARK_TOKEN` is missing, the first API call fails deep in the posting flow at `_get_headers()` (line 37) with `Authorization: Bearer None`, resulting in a confusing HTTP 401 error that doesn't clearly indicate the root cause.\n\n## Implementation Requirements\n\n### 1. Add credential validation in `__init__()`\n\n```python\ndef __init__(self):\n    self.app_id = os.getenv(\"GEELARK_APP_ID\")\n    self.api_key = os.getenv(\"GEELARK_API_KEY\")\n    self.token = os.getenv(\"GEELARK_TOKEN\")\n    \n    # Fail-fast validation\n    self._validate_credentials()\n\ndef _validate_credentials(self):\n    \"\"\"Validate required credentials are present. Raises ValueError if missing.\"\"\"\n    missing = []\n    \n    if not self.token:\n        missing.append(\"GEELARK_TOKEN\")\n    \n    # Optional: validate legacy credentials if used\n    # if not self.app_id:\n    #     missing.append(\"GEELARK_APP_ID\")\n    # if not self.api_key:\n    #     missing.append(\"GEELARK_API_KEY\")\n    \n    if missing:\n        raise ValueError(\n            f\"Missing required Geelark credentials: {', '.join(missing)}. \"\n            f\"Set these in your .env file or environment variables.\"\n        )\n```\n\n### 2. Error message requirements\n\nThe error message should:\n- Clearly state which credentials are missing\n- Mention `.env` file as the expected location\n- Be actionable (tell user what to do)\n\n### 3. Follow existing patterns\n\nThe implementation mirrors the `_validate_config()` pattern in `config.py` (lines 174-185) which validates paths at import time. However, use `ValueError` instead of print warnings since missing credentials make the client non-functional.\n\n### 4. Backward compatibility considerations\n\n- The `app_id` and `api_key` are legacy credentials that may still be used in some code paths\n- Focus validation on `GEELARK_TOKEN` which is the primary auth mechanism (used in `_get_headers()`)\n- Consider making `app_id`/`api_key` validation optional or behind a flag\n\n### 5. Update import error handling in consuming modules\n\nModules like `parallel_worker.py` (line 220), `parallel_orchestrator.py` (lines 379, 812), and `post_reel_smart.py` (line 43) instantiate `GeelarkClient()`. These should catch the `ValueError` if graceful startup failure is needed, though the default behavior of letting it propagate is often correct for fail-fast.",
        "testStrategy": "## Test Strategy\n\n### 1. Manual validation - missing token\n```bash\n# Temporarily rename .env to test missing credentials\nmv .env .env.backup\n\n# Attempt to instantiate client\npython -c \"from geelark_client import GeelarkClient; c = GeelarkClient()\"\n\n# Expected: ValueError with message about missing GEELARK_TOKEN\n# Restore .env\nmv .env.backup .env\n```\n\n### 2. Manual validation - valid credentials\n```bash\n# With valid .env in place\npython -c \"from geelark_client import GeelarkClient; c = GeelarkClient(); print('OK')\"\n\n# Expected: prints 'OK' without error\n```\n\n### 3. Integration test - orchestrator startup\n```bash\n# Test that orchestrator fails fast with clear error\nmv .env .env.backup\npython parallel_orchestrator.py --status 2>&1 | grep -i \"GEELARK_TOKEN\"\n\n# Expected: Error message mentions GEELARK_TOKEN\nmv .env.backup .env\n```\n\n### 4. Verify error message clarity\n```bash\n# Create .env without GEELARK_TOKEN\necho \"ANTHROPIC_API_KEY=test\" > .env.test\nenv -i python -c \"\nimport os\nos.chdir('.')\n# Load empty env\nfrom geelark_client import GeelarkClient\ntry:\n    c = GeelarkClient()\nexcept ValueError as e:\n    print(f'Good: {e}')\n    assert 'GEELARK_TOKEN' in str(e)\n    assert '.env' in str(e)\n\"\nrm .env.test\n```\n\n### 5. Verify existing functionality still works\n```bash\n# Run the client's __main__ test (lists phones)\npython geelark_client.py\n\n# Expected: Should list phones if credentials valid, or clear error if not\n```",
        "status": "done",
        "dependencies": [
          "25"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:55:40.574Z"
      },
      {
        "id": "31",
        "title": "Add HTTP connection pooling to GeelarkClient",
        "description": "Create a requests.Session() with HTTPAdapter connection pooling in GeelarkClient.__init__() and migrate all HTTP calls from requests.post()/requests.put() to self.session.post()/self.session.put() to prevent connection exhaustion under parallel worker load.",
        "details": "## Problem Statement\n\nThe current `GeelarkClient` (geelark_client.py lines 40-68) creates a new HTTP connection for every API call via `requests.post()` and `requests.put()`. Under parallel worker load (5+ workers making concurrent API calls), this can lead to:\n- Connection exhaustion (too many simultaneous connections)\n- TCP TIME_WAIT accumulation\n- Increased latency (no connection reuse)\n- Resource leaks under high load\n\n## Current Implementation Analysis\n\n**geelark_client.py line 49:**\n```python\nresp = requests.post(url, json=data or {}, headers=headers)\n```\n\n**geelark_client.py line 161:**\n```python\nresp = requests.put(upload_url, data=f)\n```\n\nEach `GeelarkClient()` instance (created in parallel_worker.py:220, parallel_orchestrator.py:379, post_reel_smart.py:43, etc.) opens fresh connections per request.\n\n## Implementation Steps\n\n### 1. Add requests.Session with HTTPAdapter in __init__()\n\n```python\n# geelark_client.py - imports (add at top)\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\n# In __init__() after line 29:\ndef __init__(self):\n    self.app_id = os.getenv(\"GEELARK_APP_ID\")\n    self.api_key = os.getenv(\"GEELARK_API_KEY\")\n    self.token = os.getenv(\"GEELARK_TOKEN\")\n    \n    # Create session with connection pooling\n    self.session = requests.Session()\n    \n    # Configure HTTPAdapter with connection pooling\n    adapter = HTTPAdapter(\n        pool_connections=10,  # Number of connection pools to cache\n        pool_maxsize=10,      # Max connections per pool\n        max_retries=Retry(\n            total=3,\n            backoff_factor=0.5,\n            status_forcelist=[502, 503, 504]\n        )\n    )\n    self.session.mount('http://', adapter)\n    self.session.mount('https://', adapter)\n```\n\n### 2. Update _request() to use self.session.post()\n\n```python\n# geelark_client.py line 49 - change:\n# FROM:\nresp = requests.post(url, json=data or {}, headers=headers)\n# TO:\nresp = self.session.post(url, json=data or {}, headers=headers)\n```\n\n### 3. Update upload_file_to_geelark() to use self.session.put()\n\n```python\n# geelark_client.py line 161 - change:\n# FROM:\nresp = requests.put(upload_url, data=f)\n# TO:\nresp = self.session.put(upload_url, data=f)\n```\n\n### 4. Add optional close() method for cleanup\n\n```python\ndef close(self):\n    \"\"\"Close the session and release connections.\"\"\"\n    if hasattr(self, 'session') and self.session:\n        self.session.close()\n\ndef __enter__(self):\n    return self\n\ndef __exit__(self, exc_type, exc_val, exc_tb):\n    self.close()\n```\n\n## Configuration Recommendations\n\nThe `pool_connections=10` and `pool_maxsize=10` values are appropriate because:\n- `Config.MAX_WORKERS` is 10 (config.py line 57)\n- Geelark API is a single host (API_BASE = \"https://openapi.geelark.com\")\n- Each worker may have 1-2 concurrent requests at most\n\n## Integration with Existing Tasks\n\nThis task complements:\n- **Task 29**: HTTP timeout parameter (can be added to session.post/put calls)\n- **Task 30**: Credential validation (should run before session creation)\n\n## Edge Cases to Handle\n\n1. **Session reuse across methods**: All methods inherit the pooled session\n2. **File uploads**: Large file PUT requests should still benefit from pooling\n3. **Concurrent access**: requests.Session is thread-safe for most operations\n4. **Error recovery**: Built-in retry via Retry adapter handles transient failures",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Test - Session Creation\n```bash\npython -c \"\nfrom geelark_client import GeelarkClient\nclient = GeelarkClient()\n\n# Verify session exists\nassert hasattr(client, 'session'), 'Session not created'\nassert client.session is not None, 'Session is None'\n\n# Verify adapters mounted\nadapters = client.session.adapters\nassert 'https://' in adapters, 'HTTPS adapter not mounted'\nassert 'http://' in adapters, 'HTTP adapter not mounted'\n\nprint('Session creation: PASS')\n\"\n```\n\n### 2. Unit Test - Connection Pooling Configuration\n```bash\npython -c \"\nfrom geelark_client import GeelarkClient\nfrom requests.adapters import HTTPAdapter\n\nclient = GeelarkClient()\nadapter = client.session.get_adapter('https://')\n\n# Verify it's an HTTPAdapter (not default)\nassert isinstance(adapter, HTTPAdapter), f'Wrong adapter type: {type(adapter)}'\n\n# Verify pool settings (introspect the adapter)\nconfig = adapter.config\nassert config.get('pool_connections', 0) >= 10, 'pool_connections too low'\nassert config.get('pool_maxsize', 0) >= 10, 'pool_maxsize too low'\n\nprint('Connection pooling config: PASS')\n\"\n```\n\n### 3. Functional Test - API Calls Use Session\n```bash\npython -c \"\nfrom geelark_client import GeelarkClient\nfrom unittest.mock import patch, MagicMock\n\nclient = GeelarkClient()\n\n# Mock the session.post method\nwith patch.object(client.session, 'post') as mock_post:\n    mock_response = MagicMock()\n    mock_response.status_code = 200\n    mock_response.json.return_value = {'code': 0, 'data': {'items': [], 'total': 0}}\n    mock_response.text = '{}'\n    mock_response.headers = {}\n    mock_post.return_value = mock_response\n    \n    # Call list_phones which uses _request()\n    client.list_phones(page_size=1)\n    \n    # Verify session.post was called (not requests.post)\n    assert mock_post.called, 'session.post was not called'\n    print('API calls use session: PASS')\n\"\n```\n\n### 4. Live Test - Parallel Workers\n```bash\n# Start orchestrator with 5 workers briefly\npython parallel_orchestrator.py --workers 5 --status\n\n# Check geelark_api.log for connection patterns\n# Should NOT see TCP connection errors or exhaustion warnings\ntail -20 geelark_api.log\n```\n\n### 5. Load Test - Multiple Concurrent Clients\n```bash\npython -c \"\nimport threading\nimport time\nfrom geelark_client import GeelarkClient\n\nresults = []\nerrors = []\n\ndef make_requests(client_id):\n    try:\n        client = GeelarkClient()\n        # Make 5 requests in quick succession\n        for i in range(5):\n            result = client.list_phones(page_size=1)\n            results.append((client_id, i, 'success'))\n            time.sleep(0.1)\n    except Exception as e:\n        errors.append((client_id, str(e)))\n\n# Spawn 5 threads (simulating 5 workers)\nthreads = []\nfor i in range(5):\n    t = threading.Thread(target=make_requests, args=(i,))\n    threads.append(t)\n    t.start()\n\nfor t in threads:\n    t.join()\n\nprint(f'Successful requests: {len(results)}')\nprint(f'Errors: {len(errors)}')\nif errors:\n    for e in errors:\n        print(f'  Client {e[0]}: {e[1]}')\nelse:\n    print('All concurrent requests succeeded: PASS')\n\"\n```\n\n### 6. Context Manager Test\n```bash\npython -c \"\nfrom geelark_client import GeelarkClient\n\n# Test context manager usage\nwith GeelarkClient() as client:\n    result = client.list_phones(page_size=1)\n    print(f'Got {result.get(\\\"total\\\", 0)} phones')\n\n# Session should be closed after exiting context\nprint('Context manager: PASS')\n\"\n```",
        "status": "done",
        "dependencies": [
          "25",
          "29",
          "30"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:55:47.649Z"
      },
      {
        "id": "32",
        "title": "Fix hardcoded ADB path in adb_controller.py",
        "description": "Replace the hardcoded ADB_PATH constant in adb_controller.py with an import from config.py, using Config.ADB_PATH to ensure consistent ADB path usage across the entire codebase.",
        "details": "## Problem Statement\n\nThe `adb_controller.py` module (line 9) has a hardcoded ADB path that differs from the centralized configuration:\n\n**Current hardcoded path in adb_controller.py:**\n```python\nADB_PATH = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n```\n\n**Centralized config.py path (lines 35-38):**\n```python\nANDROID_SDK_PATH: str = r\"C:\\Users\\asus\\Downloads\\android-sdk\"\nADB_PATH: str = os.path.join(ANDROID_SDK_PATH, \"platform-tools\", \"adb.exe\")\n```\n\nThis inconsistency means `adb_controller.py` uses a different ADB executable than the rest of the codebase (parallel_worker.py, post_reel_smart.py, parallel_config.py, parallel_orchestrator.py), which all correctly import from Config.\n\n## Implementation Steps\n\n### Step 1: Add import statement\nAt the top of `adb_controller.py`, add the import for Config:\n\n```python\n\"\"\"\nADB Controller - connects to Geelark devices and runs commands\n\"\"\"\nimport subprocess\nimport time\nimport os\nfrom config import Config\n```\n\n### Step 2: Replace hardcoded ADB_PATH\nRemove line 9 which defines:\n```python\nADB_PATH = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n```\n\nReplace with:\n```python\n# ADB executable path - use centralized config\nADB_PATH = Config.ADB_PATH\n```\n\n### Step 3: Verify no other hardcoded paths\nConfirm the module has no other hardcoded paths that should be centralized.\n\n## Code Changes Summary\n\n**File: adb_controller.py**\n\nBefore (lines 1-10):\n```python\n\"\"\"\nADB Controller - connects to Geelark devices and runs commands\n\"\"\"\nimport subprocess\nimport time\nimport os\n\n# ADB executable path\nADB_PATH = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n```\n\nAfter (lines 1-11):\n```python\n\"\"\"\nADB Controller - connects to Geelark devices and runs commands\n\"\"\"\nimport subprocess\nimport time\nimport os\nfrom config import Config\n\n# ADB executable path - use centralized config\nADB_PATH = Config.ADB_PATH\n```\n\n## Impact Analysis\n\n- **ADBController class**: All methods (connect, disconnect, shell, tap, swipe, type_text, key_event, screenshot_to_file, push_file, launch_app) will use the centralized ADB path\n- **Consistency**: The module will now use the same ADB executable as parallel_worker.py, post_reel_smart.py, and parallel_orchestrator.py\n- **Maintainability**: Future ADB path changes only need to be made in config.py\n\n## Files Modified\n- `adb_controller.py` - Single file modification",
        "testStrategy": "## Test Strategy\n\n### 1. Import verification\n```bash\npython -c \"from adb_controller import ADB_PATH; from config import Config; assert ADB_PATH == Config.ADB_PATH, f'Mismatch: {ADB_PATH} != {Config.ADB_PATH}'; print(f'SUCCESS: ADB_PATH = {ADB_PATH}')\"\n```\n\nExpected output: `SUCCESS: ADB_PATH = C:\\Users\\asus\\Downloads\\android-sdk\\platform-tools\\adb.exe`\n\n### 2. Module import test\n```bash\npython -c \"from adb_controller import ADBController; print('ADBController imported successfully')\"\n```\n\n### 3. Path consistency verification\n```bash\npython -c \"\nfrom adb_controller import ADB_PATH as adb_ctrl_path\nfrom parallel_worker import ADB_PATH as worker_path\nfrom post_reel_smart import ADB_PATH as smart_path\nfrom config import Config\n\nprint(f'adb_controller.py: {adb_ctrl_path}')\nprint(f'parallel_worker.py: {worker_path}')\nprint(f'post_reel_smart.py: {smart_path}')\nprint(f'config.py: {Config.ADB_PATH}')\n\n# All should match\nassert adb_ctrl_path == Config.ADB_PATH, 'adb_controller mismatch'\nassert worker_path == Config.ADB_PATH, 'parallel_worker mismatch'\nassert smart_path == Config.ADB_PATH, 'post_reel_smart mismatch'\nprint('SUCCESS: All ADB paths are consistent')\n\"\n```\n\n### 4. ADB executable existence check\n```bash\npython -c \"\nimport os\nfrom adb_controller import ADB_PATH\nexists = os.path.exists(ADB_PATH)\nprint(f'ADB_PATH exists: {exists} ({ADB_PATH})')\nassert exists, f'ADB not found at {ADB_PATH}'\n\"\n```\n\n### 5. Functional test (if device available)\n```bash\npython -c \"\nfrom adb_controller import ADBController, ADB_PATH\nimport subprocess\n\n# Quick test that ADB can run\nresult = subprocess.run([ADB_PATH, 'version'], capture_output=True, text=True, timeout=10)\nprint(f'ADB version check: {result.stdout.strip()}')\nprint('Functional test PASSED')\n\"\n```\n\n### 6. No regression in existing code\nRun the parallel orchestrator status check to ensure the system still works:\n```bash\npython parallel_orchestrator.py --status\n```",
        "status": "done",
        "dependencies": [
          "25",
          "16"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T08:58:46.461Z"
      },
      {
        "id": "33",
        "title": "Add JSON error handling to vision.py analyze functions",
        "description": "Add try/except JSONDecodeError handling to analyze_screen() and analyze_for_instagram_post() functions in vision.py to prevent crashes when Claude returns malformed JSON responses, using the same error handling pattern already established in post_reel_smart.py.",
        "details": "## Problem Statement\n\nThe `vision.py` module has two functions that call `json.loads()` without error handling:\n- `analyze_screen()` at line 90: `return json.loads(text)`\n- `analyze_for_instagram_post()` at line 174: `return json.loads(text)`\n\nWhen Claude returns malformed JSON (due to truncation, formatting issues, or model errors), these calls raise `json.JSONDecodeError` and crash without graceful error handling.\n\n## Implementation Pattern\n\nFollow the existing error handling pattern from `post_reel_smart.py` (lines 646-655):\n\n```python\ntry:\n    return json.loads(text)\nexcept json.JSONDecodeError as e:\n    # Log full raw response for debugging JSON issues\n    print(f\"  [JSON PARSE ERROR] attempt {attempt+1}: {e}\")\n    print(f\"  Raw response (full): {text}\")\n    if attempt < 2:\n        time.sleep(1)\n        continue\n    raise ValueError(f\"JSON parse failed after 3 attempts: {e}. Response: {text[:100]}\")\n```\n\n## Changes Required\n\n### 1. Update imports at top of vision.py (line 6-7)\n\nAdd `json` to explicit imports (currently imported inline at lines 80, 165) and add `time` for retry delays:\n\n```python\nimport anthropic\nimport base64\nimport json\nimport os\nimport time\n```\n\n### 2. Refactor analyze_screen() (lines 57-90)\n\nWrap the Claude API call and JSON parsing in a retry loop with proper error handling:\n\n```python\n# Replace lines 57-90 with:\nfor attempt in range(3):\n    try:\n        response = client.messages.create(\n            model=\"claude-sonnet-4-20250514\",\n            max_tokens=500,\n            messages=[{\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image\",\n                        \"source\": {\n                            \"type\": \"base64\",\n                            \"media_type\": \"image/png\",\n                            \"data\": image_data\n                        }\n                    },\n                    {\n                        \"type\": \"text\",\n                        \"text\": prompt\n                    }\n                ]\n            }]\n        )\n\n        # Check for empty response\n        if not response.content:\n            if attempt < 2:\n                time.sleep(1)\n                continue\n            return {\"action\": \"error\", \"message\": \"Claude returned empty response after 3 attempts\"}\n\n        text = response.content[0].text.strip()\n\n        # Check for empty text\n        if not text:\n            if attempt < 2:\n                time.sleep(1)\n                continue\n            return {\"action\": \"error\", \"message\": \"Claude returned empty text after 3 attempts\"}\n\n        # Handle markdown code blocks\n        if text.startswith(\"```\"):\n            text = text.split(\"```\")[1]\n            if text.startswith(\"json\"):\n                text = text[4:]\n            text = text.strip()\n\n        try:\n            return json.loads(text)\n        except json.JSONDecodeError as e:\n            print(f\"  [JSON PARSE ERROR in analyze_screen] attempt {attempt+1}: {e}\")\n            print(f\"  Raw response: {text}\")\n            if attempt < 2:\n                time.sleep(1)\n                continue\n            return {\"action\": \"error\", \"message\": f\"JSON parse failed: {e}. Response: {text[:200]}\"}\n\n    except anthropic.APIError as e:\n        print(f\"  [API ERROR in analyze_screen] attempt {attempt+1}: {e}\")\n        if attempt < 2:\n            time.sleep(1)\n            continue\n        return {\"action\": \"error\", \"message\": f\"Claude API error after 3 attempts: {e}\"}\n\nreturn {\"action\": \"error\", \"message\": \"Failed to get valid response from Claude after 3 attempts\"}\n```\n\n### 3. Refactor analyze_for_instagram_post() (lines 143-174)\n\nApply the same retry and error handling pattern:\n\n```python\n# Replace lines 143-174 with similar retry loop structure\n# Return dict with action=\"error\" and message field on failure\n# Include video_selected=False in error response for API consistency\n```\n\n### 4. Error Return Format\n\nBoth functions should return a consistent error structure that calling code can handle:\n\n```python\n# analyze_screen error return:\n{\"action\": \"error\", \"message\": \"descriptive error message\"}\n\n# analyze_for_instagram_post error return:\n{\"action\": \"error\", \"message\": \"descriptive error message\", \"video_selected\": False}\n```\n\n### 5. Remove inline imports\n\nRemove the inline `import json` statements at lines 80 and 165 since json will be imported at module level.\n\n## Key Considerations\n\n1. **Graceful degradation**: Return error dict instead of raising exceptions, allowing callers to handle gracefully\n2. **Debugging support**: Log raw responses on parse failure for troubleshooting\n3. **Retry logic**: 3 attempts with 1-second delays matches existing pattern\n4. **API error handling**: Also catch anthropic.APIError for network/rate limit issues\n5. **Consistent API**: Error responses include all expected fields to prevent KeyError in callers",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Test - Malformed JSON Handling\n\n```bash\n# Create test script to verify error handling\npython -c \"\nimport json\nfrom unittest.mock import patch, MagicMock\n\n# Mock anthropic client to return malformed JSON\nmock_response = MagicMock()\nmock_response.content = [MagicMock(text='not valid json {{{')]\n\nwith patch('anthropic.Anthropic') as mock_client:\n    mock_client.return_value.messages.create.return_value = mock_response\n    \n    from vision import analyze_screen\n    result = analyze_screen('test.png', 'test context')\n    \n    # Should return error dict, not raise exception\n    assert result['action'] == 'error', f'Expected error action, got: {result}'\n    assert 'message' in result, 'Error response missing message field'\n    print(f'SUCCESS: Malformed JSON handled gracefully')\n    print(f'Result: {result}')\n\"\n```\n\n### 2. Unit Test - Empty Response Handling\n\n```bash\npython -c \"\nfrom unittest.mock import patch, MagicMock\n\n# Mock empty response\nmock_response = MagicMock()\nmock_response.content = []\n\nwith patch('anthropic.Anthropic') as mock_client:\n    mock_client.return_value.messages.create.return_value = mock_response\n    \n    from vision import analyze_screen\n    result = analyze_screen('test.png', 'test context')\n    \n    assert result['action'] == 'error', f'Expected error action, got: {result}'\n    print('SUCCESS: Empty response handled gracefully')\n\"\n```\n\n### 3. Unit Test - analyze_for_instagram_post Error Fields\n\n```bash\npython -c \"\nfrom unittest.mock import patch, MagicMock\n\nmock_response = MagicMock()\nmock_response.content = [MagicMock(text='invalid')]\n\nwith patch('anthropic.Anthropic') as mock_client:\n    mock_client.return_value.messages.create.return_value = mock_response\n    \n    from vision import analyze_for_instagram_post\n    result = analyze_for_instagram_post('test.png', 'caption')\n    \n    assert result['action'] == 'error', f'Expected error action'\n    assert 'video_selected' in result, 'Missing video_selected field in error response'\n    print('SUCCESS: analyze_for_instagram_post error includes video_selected field')\n\"\n```\n\n### 4. Integration Test - Valid JSON Still Works\n\n```bash\npython -c \"\nfrom unittest.mock import patch, MagicMock\nimport json\n\n# Mock valid JSON response\nvalid_response = {'action': 'tap', 'x': 100, 'y': 200, 'message': 'Tap button'}\nmock_response = MagicMock()\nmock_response.content = [MagicMock(text=json.dumps(valid_response))]\n\nwith patch('anthropic.Anthropic') as mock_client:\n    mock_client.return_value.messages.create.return_value = mock_response\n    \n    from vision import analyze_screen\n    result = analyze_screen('test.png', 'test context')\n    \n    assert result == valid_response, f'Expected {valid_response}, got {result}'\n    print('SUCCESS: Valid JSON parsing still works correctly')\n\"\n```\n\n### 5. Manual Verification - Code Review\n\n```bash\n# Verify imports are at module level\nhead -10 vision.py | grep -E \"^import json|^import time\"\n\n# Verify no inline imports remain\ngrep -n \"import json\" vision.py  # Should only show line ~6\n\n# Verify try/except exists for json.loads\ngrep -A2 \"json.loads\" vision.py | grep -c \"except\"  # Should be 2\n```\n\n### 6. Test Retry Behavior\n\n```bash\npython -c \"\nfrom unittest.mock import patch, MagicMock, call\nimport json\n\n# Track call count\ncall_count = 0\n\ndef failing_create(*args, **kwargs):\n    global call_count\n    call_count += 1\n    mock = MagicMock()\n    mock.content = [MagicMock(text='invalid json')]\n    return mock\n\nwith patch('anthropic.Anthropic') as mock_client:\n    mock_client.return_value.messages.create.side_effect = failing_create\n    \n    from vision import analyze_screen\n    result = analyze_screen('test.png', 'test')\n    \n    # Should have retried 3 times\n    assert call_count == 3, f'Expected 3 attempts, got {call_count}'\n    print(f'SUCCESS: Retry logic executed {call_count} attempts')\n\"\n```",
        "status": "done",
        "dependencies": [
          "6"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T09:06:02.607Z"
      },
      {
        "id": "34",
        "title": "Fix hardcoded ANDROID_HOME in posting_scheduler.py",
        "description": "Replace hardcoded ANDROID_HOME paths at lines 17-19 and 193-197 in posting_scheduler.py with centralized config.py imports, using setup_environment() for early initialization and Config.ANDROID_SDK_PATH in get_android_env().",
        "details": "## Problem Statement\n\nThe `posting_scheduler.py` module has hardcoded ANDROID_HOME paths in two locations that should use the centralized `config.py`:\n\n**Location 1: Lines 17-19 (module-level initialization)**\n```python\n# Current hardcoded:\nos.environ['ANDROID_HOME'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\nos.environ['ANDROID_SDK_ROOT'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\n```\n\n**Location 2: Lines 193-197 (get_android_env function)**\n```python\n# Current hardcoded:\nandroid_sdk = r'C:\\Users\\asus\\Downloads\\android-sdk'\nenv['ANDROID_HOME'] = android_sdk\nenv['ANDROID_SDK_ROOT'] = android_sdk\n```\n\n## Implementation Steps\n\n### Step 1: Add import at the top of posting_scheduler.py\n\nAfter `import sys` (line 15), add:\n```python\nfrom config import Config, setup_environment\n```\n\n### Step 2: Replace lines 17-19 with setup_environment() call\n\nRemove:\n```python\nos.environ['ANDROID_HOME'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\nos.environ['ANDROID_SDK_ROOT'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\n```\n\nReplace with:\n```python\n# Set ANDROID_HOME early for Appium - MUST be before any Appium imports\nsetup_environment()\n```\n\n### Step 3: Update get_android_env() function (lines 185-204)\n\nReplace the hardcoded path with Config.ANDROID_SDK_PATH:\n```python\ndef get_android_env() -> dict:\n    \"\"\"Get environment with ANDROID_HOME/ANDROID_SDK_ROOT properly set.\n\n    This ensures Appium can find the Android SDK regardless of how\n    the parent process was started.\n    \"\"\"\n    env = os.environ.copy()\n\n    # Use centralized config for Android SDK path\n    android_sdk = Config.ANDROID_SDK_PATH\n\n    env['ANDROID_HOME'] = android_sdk\n    env['ANDROID_SDK_ROOT'] = android_sdk\n\n    # Add platform-tools to PATH if not already there\n    platform_tools = os.path.join(android_sdk, 'platform-tools')\n    if platform_tools not in env.get('PATH', ''):\n        env['PATH'] = platform_tools + os.pathsep + env.get('PATH', '')\n\n    return env\n```\n\n### Alternative: Use get_adb_env() directly\n\nNote: `config.py` already provides `get_adb_env()` which does the same thing as `get_android_env()`. Consider whether to:\n1. Keep `get_android_env()` but use Config.ANDROID_SDK_PATH (recommended for minimal change)\n2. Replace calls to `get_android_env()` with `get_adb_env()` from config (more DRY but larger change)\n\nOption 1 is recommended for this task to minimize scope and risk.\n\n## Files Modified\n\n- `posting_scheduler.py` - lines 15-19 and 185-204\n\n## Dependencies on This Change\n\nThis aligns with Task 32 (ADB path centralization) and Task 16 (Appium SDK detection), ensuring all Android SDK references flow through config.py.",
        "testStrategy": "## Test Strategy\n\n### 1. Import verification\n```bash\npython -c \"from posting_scheduler import get_android_env; from config import Config; env = get_android_env(); assert env['ANDROID_HOME'] == Config.ANDROID_SDK_PATH, f'Mismatch: {env[\\\"ANDROID_HOME\\\"]} != {Config.ANDROID_SDK_PATH}'; print(f'SUCCESS: ANDROID_HOME = {env[\\\"ANDROID_HOME\\\"]}')\"\n```\n\nExpected output: `SUCCESS: ANDROID_HOME = C:\\Users\\asus\\Downloads\\android-sdk`\n\n### 2. Environment variable test\n```bash\npython -c \"\nimport os\n# Clear any existing values\nos.environ.pop('ANDROID_HOME', None)\nos.environ.pop('ANDROID_SDK_ROOT', None)\n\n# Import should trigger setup_environment()\nimport posting_scheduler\n\n# Verify environment was set\nfrom config import Config\nassert os.environ.get('ANDROID_HOME') == Config.ANDROID_SDK_PATH, 'ANDROID_HOME not set'\nassert os.environ.get('ANDROID_SDK_ROOT') == Config.ANDROID_SDK_PATH, 'ANDROID_SDK_ROOT not set'\nprint('SUCCESS: Environment variables set correctly on import')\n\"\n```\n\n### 3. No hardcoded paths remaining\n```bash\n# Verify no hardcoded android-sdk paths remain in posting_scheduler.py\ngrep -n \"android-sdk\" posting_scheduler.py\n# Expected: No matches or only matches in comments\n```\n\n### 4. Functional test - Appium startup\n```bash\n# Test that Appium can still find Android SDK after the change\npython -c \"\nfrom posting_scheduler import get_android_env, restart_appium\nenv = get_android_env()\nprint(f'ANDROID_HOME: {env.get(\\\"ANDROID_HOME\\\")}')\nprint(f'ANDROID_SDK_ROOT: {env.get(\\\"ANDROID_SDK_ROOT\\\")}')\nprint(f'PATH includes platform-tools: {\\\"platform-tools\\\" in env.get(\\\"PATH\\\", \\\"\\\")}')\n\"\n```\n\n### 5. Full scheduler status test\n```bash\npython posting_scheduler.py --status\n# Should work without errors, showing Appium health status\n```\n\n### 6. Config consistency check\n```bash\npython -c \"\nfrom config import Config, get_adb_env\nfrom posting_scheduler import get_android_env\n\nconfig_env = get_adb_env()\nsched_env = get_android_env()\n\nassert config_env['ANDROID_HOME'] == sched_env['ANDROID_HOME'], 'ANDROID_HOME mismatch'\nassert config_env['ANDROID_SDK_ROOT'] == sched_env['ANDROID_SDK_ROOT'], 'ANDROID_SDK_ROOT mismatch'\nprint('SUCCESS: Both modules use consistent Android SDK path')\n\"\n```",
        "status": "done",
        "dependencies": [
          "16",
          "32"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T09:06:54.435Z"
      },
      {
        "id": "35",
        "title": "Move timedelta import to top of progress_tracker.py per PEP8",
        "description": "Move the `from datetime import timedelta` import statement from inside the `update_job_status()` method (line 632) to the module-level imports at the top of progress_tracker.py, alongside the existing `from datetime import datetime` import on line 40.",
        "details": "## Problem Statement\n\nThe `progress_tracker.py` module has an import statement inside a function, violating PEP8 style guidelines:\n\n**Location: Line 632 (inside `update_job_status()` method)**\n```python\n# Lines 629-633 in update_job_status():\nelse:\n    # Retryable - set to retrying with delay\n    job['status'] = self.STATUS_RETRYING\n    from datetime import timedelta  # <-- THIS SHOULD BE AT TOP\n    retry_at = datetime.now() + timedelta(minutes=retry_delay_minutes)\n```\n\n## Existing Import (Line 40)\n```python\nfrom datetime import datetime\n```\n\n## Implementation Steps\n\n### Step 1: Modify the existing datetime import at line 40\nChange:\n```python\nfrom datetime import datetime\n```\nTo:\n```python\nfrom datetime import datetime, timedelta\n```\n\n### Step 2: Remove the inline import at line 632\nDelete the entire line:\n```python\nfrom datetime import timedelta\n```\n\nThe surrounding code (lines 629-635) should become:\n```python\nelse:\n    # Retryable - set to retrying with delay\n    job['status'] = self.STATUS_RETRYING\n    retry_at = datetime.now() + timedelta(minutes=retry_delay_minutes)\n    job['retry_at'] = retry_at.isoformat()\n```\n\n## Why This Matters\n\n1. **PEP8 Compliance**: All imports should be at the top of the module\n2. **Performance**: While Python caches imports, having them at module level makes the import cost explicit at load time rather than hidden in function execution\n3. **Readability**: Developers can see all dependencies at the top of the file\n4. **Consistency**: The module already imports `datetime` from the `datetime` module - adding `timedelta` to the same import follows a clean pattern",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify the file has no syntax errors and imports correctly\npython -c \"import progress_tracker; print('Import successful')\"\n```\n\n### 2. Verify timedelta is in module-level imports\n```bash\n# Check that timedelta is imported at module level\npython -c \"from progress_tracker import ProgressTracker; import progress_tracker; print('timedelta' in dir(progress_tracker))\"\n```\n\n### 3. Verify no inline import remains\n```bash\n# Search for any remaining inline imports of timedelta\ngrep -n \"from datetime import timedelta\" progress_tracker.py\n# Should return NO results after the fix\n```\n\n### 4. Functional Test - Retry Logic\n```bash\n# Test that the retry functionality still works correctly\npython -c \"\nfrom progress_tracker import ProgressTracker\nimport os\nimport tempfile\n\n# Create a temp progress file\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:\n    test_file = f.name\n\ntracker = ProgressTracker(test_file)\n\n# Seed a test job\ntracker.seed_from_jobs([{\n    'job_id': 'test123',\n    'account': 'test_account',\n    'video_path': '/fake/path.mp4',\n    'caption': 'Test caption'\n}])\n\n# Claim the job\njob = tracker.claim_next_job(worker_id=0)\nassert job is not None, 'Failed to claim job'\nassert job['job_id'] == 'test123', 'Wrong job claimed'\n\n# Fail the job - this triggers the timedelta usage for retry scheduling\ntracker.update_job_status('test123', 'failed', worker_id=0, error='Test error', retry_delay_minutes=5)\n\n# Verify job is in retrying status with retry_at set\njobs = tracker._read_all_jobs()\nassert len(jobs) == 1, f'Expected 1 job, got {len(jobs)}'\nassert jobs[0]['status'] == 'retrying', f'Expected retrying status, got {jobs[0][\\\"status\\\"]}'\nassert jobs[0]['retry_at'], 'retry_at should be set'\n\nprint('SUCCESS: Retry logic works correctly with moved import')\n\n# Cleanup\nos.remove(test_file)\nif os.path.exists(test_file + '.lock'):\n    os.remove(test_file + '.lock')\n\"\n```\n\n### 5. Verify PEP8 compliance\n```bash\n# Run flake8 or pycodestyle on the imports section\npython -m py_compile progress_tracker.py && echo \"Compilation successful\"\n```\n\n### 6. Line 40 structure verification\n```bash\n# Confirm the new import structure at line 40\npython -c \"\nwith open('progress_tracker.py', 'r') as f:\n    lines = f.readlines()\n    # Check line 40 (0-indexed: line 39)\n    import_line = lines[39]\n    assert 'from datetime import datetime, timedelta' in import_line, f'Expected combined import, got: {import_line}'\n    print(f'Line 40: {import_line.strip()}')\n    print('SUCCESS: Import structure correct')\n\"\n```",
        "status": "done",
        "dependencies": [],
        "priority": "low",
        "subtasks": [],
        "updatedAt": "2025-12-13T10:45:17.394Z"
      },
      {
        "id": "36",
        "title": "Fix hardcoded ADB paths in utility scripts",
        "description": "Replace hardcoded ADB_PATH constants in 8 utility scripts with imports from config.py, using Config.ADB_PATH for the ADB executable and setup_environment() for ANDROID_HOME initialization where needed.",
        "details": "## Problem Statement\n\nEight utility scripts have hardcoded ADB paths that differ from the centralized `config.py`:\n\n**Hardcoded path in utility scripts:**\n```python\nADB_PATH = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n```\n\n**Centralized config.py path (lines 35-38):**\n```python\nANDROID_SDK_PATH: str = r\"C:\\Users\\asus\\Downloads\\android-sdk\"\nADB_PATH: str = os.path.join(ANDROID_SDK_PATH, \"platform-tools\", \"adb.exe\")\n```\n\nThe hardcoded path points to a different location than the centralized config, which could cause issues if the ADB location changes.\n\n## Files to Update\n\n| File | ADB_PATH Line | ANDROID_HOME Line | Changes Needed |\n|------|---------------|-------------------|----------------|\n| debug_page_source.py | 12 | 6 | Replace both |\n| fix_adbkeyboard.py | 18 | N/A | Replace ADB_PATH only |\n| diagnose_adbkeyboard.py | 10 | N/A | Replace ADB_PATH only |\n| setup_adbkeyboard.py | 17 | N/A | Replace ADB_PATH only |\n| reprovision_phone.py | 21 | N/A | Replace ADB_PATH only |\n| setup_clipboard_helper.py | 17 | N/A | Replace ADB_PATH only |\n| test_full_flow_android15.py | 70 | 6 | Replace both |\n| test_typing.py | 17 | N/A | Replace ADB_PATH only |\n\n## Implementation Steps\n\n### 1. Files with both ANDROID_HOME and ADB_PATH (2 files)\n\n**debug_page_source.py:**\n```python\n# BEFORE (lines 5-12):\nimport os\nos.environ['ANDROID_HOME'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\n...\nADB_PATH = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n\n# AFTER:\nimport os\nfrom config import Config, setup_environment\nsetup_environment()\n...\n# Remove ADB_PATH constant, use Config.ADB_PATH directly in subprocess calls\n```\n\n**test_full_flow_android15.py:**\n```python\n# BEFORE (lines 5-6, 70):\nimport os\nos.environ['ANDROID_HOME'] = r'C:\\Users\\asus\\Downloads\\android-sdk'\n...\nADB = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n\n# AFTER:\nimport os\nfrom config import Config, setup_environment\nsetup_environment()\n...\n# Replace ADB variable with Config.ADB_PATH\n```\n\n### 2. Files with ADB_PATH only (6 files)\n\nFor each file, add the import and replace the constant:\n\n```python\n# BEFORE:\nADB_PATH = r\"C:\\Users\\asus\\Downloads\\platform-tools-latest-windows\\platform-tools\\adb.exe\"\n\n# AFTER:\nfrom config import Config\nADB_PATH = Config.ADB_PATH  # Or use Config.ADB_PATH directly\n```\n\nThe files and their specific changes:\n\n**fix_adbkeyboard.py (line 18):**\n- Add `from config import Config` after line 16 (after geelark_client import)\n- Replace line 18 with `ADB_PATH = Config.ADB_PATH`\n\n**diagnose_adbkeyboard.py (line 10):**\n- Add `from config import Config` after line 8 (after geelark_client import)\n- Replace line 10 with `ADB_PATH = Config.ADB_PATH`\n\n**setup_adbkeyboard.py (line 17):**\n- Add `from config import Config` after line 15 (after geelark_client import)\n- Replace line 17 with `ADB_PATH = Config.ADB_PATH`\n\n**reprovision_phone.py (line 21):**\n- Add `from config import Config` after line 19 (after geelark_client import)\n- Replace line 21 with `ADB_PATH = Config.ADB_PATH`\n\n**setup_clipboard_helper.py (line 17):**\n- Add `from config import Config` after line 15 (after geelark_client import)\n- Replace line 17 with `ADB_PATH = Config.ADB_PATH`\n\n**test_typing.py (line 17):**\n- Add `from config import Config` after line 15 (after geelark_client import)\n- Replace line 17 with `ADB_PATH = Config.ADB_PATH`\n\n## Alternative Approach: Direct Config.ADB_PATH Usage\n\nInstead of aliasing `ADB_PATH = Config.ADB_PATH`, you could use `Config.ADB_PATH` directly in all subprocess calls. This is more explicit but requires more changes:\n\n```python\n# Instead of:\nsubprocess.run([ADB_PATH, \"-s\", device, \"shell\", cmd], ...)\n\n# Use:\nsubprocess.run([Config.ADB_PATH, \"-s\", device, \"shell\", cmd], ...)\n```\n\nThe alias approach (`ADB_PATH = Config.ADB_PATH`) minimizes code changes while still achieving centralization.\n\n## Notes\n\n- The hardcoded path (`platform-tools-latest-windows`) differs from config.py's path (`android-sdk/platform-tools`), indicating these files may have been using a different ADB installation\n- After this change, all ADB operations will use the same ADB binary as the rest of the codebase\n- The `setup_environment()` function should be called early (before Appium imports) in files that need ANDROID_HOME set",
        "testStrategy": "## Test Strategy\n\n### 1. Import Verification for All Files\n```bash\n# Verify each file imports successfully after changes\npython -c \"import debug_page_source; print('debug_page_source OK')\"\npython -c \"import fix_adbkeyboard; print('fix_adbkeyboard OK')\"\npython -c \"import diagnose_adbkeyboard; print('diagnose_adbkeyboard OK')\"\npython -c \"import setup_adbkeyboard; print('setup_adbkeyboard OK')\"\npython -c \"import reprovision_phone; print('reprovision_phone OK')\"\npython -c \"import setup_clipboard_helper; print('setup_clipboard_helper OK')\"\npython -c \"import test_full_flow_android15; print('test_full_flow_android15 OK')\"\npython -c \"import test_typing; print('test_typing OK')\"\n```\n\n### 2. Verify ADB_PATH Resolution\n```bash\n# For files using ADB_PATH alias\npython -c \"\nfrom config import Config\nfrom fix_adbkeyboard import ADB_PATH\nassert ADB_PATH == Config.ADB_PATH, f'Mismatch: {ADB_PATH} != {Config.ADB_PATH}'\nprint(f'SUCCESS: ADB_PATH = {ADB_PATH}')\n\"\n\n# Repeat for other files with ADB_PATH\npython -c \"from diagnose_adbkeyboard import ADB_PATH; from config import Config; assert ADB_PATH == Config.ADB_PATH; print('diagnose_adbkeyboard OK')\"\npython -c \"from setup_adbkeyboard import ADB_PATH; from config import Config; assert ADB_PATH == Config.ADB_PATH; print('setup_adbkeyboard OK')\"\npython -c \"from reprovision_phone import ADB_PATH; from config import Config; assert ADB_PATH == Config.ADB_PATH; print('reprovision_phone OK')\"\npython -c \"from setup_clipboard_helper import ADB_PATH; from config import Config; assert ADB_PATH == Config.ADB_PATH; print('setup_clipboard_helper OK')\"\npython -c \"from test_typing import ADB_PATH; from config import Config; assert ADB_PATH == Config.ADB_PATH; print('test_typing OK')\"\n```\n\n### 3. Verify ANDROID_HOME Environment Variable\n```bash\n# For files that call setup_environment()\npython -c \"\nimport os\n# Clear any existing value\nif 'ANDROID_HOME' in os.environ:\n    del os.environ['ANDROID_HOME']\n\nfrom config import Config, setup_environment\nsetup_environment()\n\nassert os.environ.get('ANDROID_HOME') == Config.ANDROID_SDK_PATH, \\\n    f\\\"ANDROID_HOME mismatch: {os.environ.get('ANDROID_HOME')} != {Config.ANDROID_SDK_PATH}\\\"\nprint(f'SUCCESS: ANDROID_HOME = {os.environ[\\\"ANDROID_HOME\\\"]}')\n\"\n```\n\n### 4. Grep Verification - No Hardcoded Paths Remain\n```bash\n# Verify no hardcoded ADB paths remain in utility scripts\ngrep -l \"platform-tools-latest-windows\" debug_page_source.py fix_adbkeyboard.py diagnose_adbkeyboard.py setup_adbkeyboard.py reprovision_phone.py setup_clipboard_helper.py test_full_flow_android15.py test_typing.py\n\n# Expected: No output (no files contain the hardcoded path)\n```\n\n### 5. Functional Smoke Test\n```bash\n# Test that ADB commands still work (requires a connected device)\npython -c \"\nimport subprocess\nfrom config import Config\n\nresult = subprocess.run([Config.ADB_PATH, 'devices'], capture_output=True, text=True)\nprint('ADB devices output:')\nprint(result.stdout)\nassert result.returncode == 0, 'ADB command failed'\nprint('SUCCESS: ADB command executed successfully')\n\"\n```\n\n### 6. Optional: Run Utility Script Help/Usage\n```bash\n# Verify scripts don't crash on startup\npython fix_adbkeyboard.py --help 2>/dev/null || python fix_adbkeyboard.py 2>&1 | head -5\npython diagnose_adbkeyboard.py --help 2>/dev/null || python diagnose_adbkeyboard.py 2>&1 | head -5\npython setup_adbkeyboard.py --help 2>/dev/null || python setup_adbkeyboard.py 2>&1 | head -5\npython reprovision_phone.py --help 2>/dev/null || python reprovision_phone.py 2>&1 | head -5\npython setup_clipboard_helper.py --help 2>/dev/null || python setup_clipboard_helper.py 2>&1 | head -5\npython test_typing.py --help 2>/dev/null || python test_typing.py 2>&1 | head -5\n```",
        "status": "done",
        "dependencies": [
          "25",
          "32"
        ],
        "priority": "low",
        "subtasks": [],
        "updatedAt": "2025-12-13T10:47:24.337Z"
      },
      {
        "id": "37",
        "title": "Extract DeviceConnectionManager from SmartInstagramPoster",
        "description": "Create device_connection.py with a DeviceConnectionManager class that handles the device connection lifecycle, extracting the connect() method logic (~150 lines) from post_reel_smart.py that currently mixes Geelark API calls, ADB subprocess commands, and Appium connection.",
        "details": "## Current State Analysis\n\nThe `SmartInstagramPoster.connect()` method in `post_reel_smart.py` (lines 665-819, ~155 lines) currently handles:\n\n1. **Geelark API calls** (via GeelarkClient):\n   - `list_phones()` to find phone by name\n   - `start_phone()` to boot the phone if not running\n   - `get_phone_status()` to poll for boot completion\n   - `enable_adb()` with retry loop for API failures\n   - `get_adb_info()` to get IP/port/password\n\n2. **ADB subprocess commands** (via subprocess.run):\n   - `adb disconnect` to clean stale connections\n   - `adb connect` to establish connection\n   - `adb devices` polling to wait for device readiness\n   - `adb shell glogin` for Geelark authentication\n\n3. **Appium connection** (calls `connect_appium()` at the end)\n\n## Implementation Plan\n\n### 1. Create `device_connection.py` with DeviceConnectionManager class\n\n```python\n\"\"\"\nDevice Connection Manager - handles Geelark phone lifecycle and ADB connection.\n\nSeparates device connection concerns from Instagram posting logic.\n\"\"\"\nimport subprocess\nimport time\nimport logging\nfrom typing import Optional, Tuple\nfrom dataclasses import dataclass\n\nfrom config import Config\nfrom geelark_client import GeelarkClient\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass DeviceInfo:\n    \"\"\"Information about a connected device.\"\"\"\n    phone_id: str\n    phone_name: str\n    device_address: str  # ip:port\n    adb_password: str\n\nclass DeviceConnectionError(Exception):\n    \"\"\"Raised when device connection fails.\"\"\"\n    pass\n\nclass DeviceConnectionManager:\n    \"\"\"\n    Manages the lifecycle of connecting to a Geelark cloud phone.\n    \n    Responsibilities:\n    - Find phone by name via Geelark API\n    - Start phone if not running\n    - Enable ADB with retry logic\n    - Establish ADB connection\n    - Authenticate via glogin\n    \n    Usage:\n        manager = DeviceConnectionManager(phone_name)\n        device_info = manager.connect()\n        # ... use device_info.device_address for Appium ...\n        manager.disconnect()\n    \"\"\"\n    \n    ADB_PATH = Config.ADB_PATH\n    \n    def __init__(self, phone_name: str, client: GeelarkClient = None):\n        self.phone_name = phone_name\n        self.client = client or GeelarkClient()\n        self.device_info: Optional[DeviceInfo] = None\n        self._connected = False\n```\n\n### 2. Extract connection logic into methods\n\nThe DeviceConnectionManager should have these methods:\n\n- `connect() -> DeviceInfo`: Main entry point, orchestrates the full connection\n- `_find_phone() -> dict`: Find phone by name across multiple pages\n- `_ensure_phone_running(phone_id: str) -> None`: Start phone and wait for boot\n- `_enable_adb_with_retry(phone_id: str) -> dict`: Enable ADB with retry on API failures\n- `_establish_adb_connection(ip: str, port: int, password: str) -> str`: Connect ADB and run glogin\n- `_wait_for_adb_device(device_address: str, timeout: int) -> bool`: Poll until device appears in adb devices\n- `disconnect() -> None`: Clean up connection\n- `verify_connection() -> bool`: Check if ADB connection is still alive\n- `reconnect() -> bool`: Re-establish dropped connection\n\n### 3. Key implementation details from existing code\n\n**Phone lookup with pagination** (lines 669-678):\n```python\nfor page in range(1, 10):\n    result = self.client.list_phones(page=page, page_size=100)\n    for p in result[\"items\"]:\n        if p[\"serialName\"] == self.phone_name or p[\"id\"] == self.phone_name:\n            # found\n```\n\n**ADB enable retry loop** (lines 703-758):\n- Max 3 retries for enable_adb() API call\n- 30 attempts × 2 seconds for get_adb_info() verification\n- On failure, restart phone and retry the whole process\n\n**ADB connection with device readiness** (lines 773-793):\n- 30 attempts × 2 seconds = 60 seconds max wait\n- Check for `\\tdevice` in adb devices output (not `offline` or `unauthorized`)\n\n**glogin retry** (lines 796-814):\n- 3 attempts for glogin command\n- Check for \"success\" or absence of \"error\"\n\n### 4. Modify SmartInstagramPoster to use composition\n\n```python\nclass SmartInstagramPoster:\n    def __init__(self, phone_name, system_port=8200, appium_url=None):\n        self.connection_manager = DeviceConnectionManager(phone_name)\n        # ... rest of init ...\n        \n    def connect(self):\n        \"\"\"Connect to device using DeviceConnectionManager.\"\"\"\n        device_info = self.connection_manager.connect()\n        self.phone_id = device_info.phone_id\n        self.device = device_info.device_address\n        self.connect_appium()\n        return True\n        \n    def cleanup(self):\n        \"\"\"Cleanup after posting.\"\"\"\n        # ... existing cleanup ...\n        self.connection_manager.disconnect()\n```\n\n### 5. Additional helper methods to extract\n\nAlso extract these related methods from SmartInstagramPoster:\n- `verify_adb_connection()` (lines 821-829) → `DeviceConnectionManager.verify_connection()`\n- `reconnect_adb()` (lines 831-863) → `DeviceConnectionManager.reconnect()`\n\n### 6. Configuration integration\n\nUse `Config.ADB_PATH` from centralized config (already done in post_reel_smart.py).\n\n### 7. Logging\n\nUse the module logger pattern consistent with other modules:\n```python\nlogger = logging.getLogger(__name__)\n```\n\n### 8. Error handling\n\nCreate specific exceptions:\n- `DeviceNotFoundError(DeviceConnectionError)`: Phone not found in Geelark\n- `ADBEnableError(DeviceConnectionError)`: Failed to enable ADB after retries\n- `ADBConnectionError(DeviceConnectionError)`: Failed to establish ADB connection",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Test - Module imports successfully\n```bash\npython -c \"from device_connection import DeviceConnectionManager, DeviceInfo, DeviceConnectionError; print('Import OK')\"\n```\n\n### 2. Unit Test - DeviceConnectionManager instantiation\n```bash\npython -c \"\nfrom device_connection import DeviceConnectionManager\nmanager = DeviceConnectionManager('test_phone')\nassert manager.phone_name == 'test_phone'\nassert manager.device_info is None\nassert manager._connected is False\nprint('Instantiation OK')\n\"\n```\n\n### 3. Integration Test - Full connection flow (requires running phone)\n```bash\n# Use a known test account from accounts.txt\npython -c \"\nfrom device_connection import DeviceConnectionManager\n\nmanager = DeviceConnectionManager('reelwisdompod_')\ntry:\n    device_info = manager.connect()\n    print(f'Connected to {device_info.device_address}')\n    assert manager.verify_connection(), 'Connection verification failed'\nfinally:\n    manager.disconnect()\nprint('Full flow OK')\n\"\n```\n\n### 4. Verify SmartInstagramPoster still works\n```bash\n# Test that the refactored SmartInstagramPoster works with DeviceConnectionManager\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\n\nposter = SmartInstagramPoster('reelwisdompod_')\n# Check composition is set up correctly\nassert hasattr(poster, 'connection_manager'), 'Missing connection_manager'\nprint('SmartInstagramPoster composition OK')\n\"\n```\n\n### 5. Verify parallel_worker.py still works\n```bash\n# Ensure the worker can still import and use SmartInstagramPoster\npython -c \"\nfrom parallel_worker import execute_posting_job\nprint('parallel_worker imports OK')\n\"\n```\n\n### 6. End-to-end posting test (optional - uses real account)\n```bash\n# Only run if willing to make a real post\npython posting_scheduler.py --add-folder chunk_01c --add-accounts reelwisdompod_ --run --limit 1\n```\n\n### 7. Verify error handling\n```bash\n# Test DeviceNotFoundError is raised for non-existent phone\npython -c \"\nfrom device_connection import DeviceConnectionManager, DeviceConnectionError\n\nmanager = DeviceConnectionManager('nonexistent_phone_xyz123')\ntry:\n    manager.connect()\n    print('ERROR: Should have raised exception')\nexcept DeviceConnectionError as e:\n    print(f'Correctly raised DeviceConnectionError: {e}')\nexcept Exception as e:\n    print(f'Wrong exception type: {type(e).__name__}: {e}')\n\"\n```\n\n### 8. ADB path uses centralized config\n```bash\npython -c \"\nfrom device_connection import DeviceConnectionManager\nfrom config import Config\nassert DeviceConnectionManager.ADB_PATH == Config.ADB_PATH, 'ADB_PATH mismatch'\nprint(f'ADB_PATH correctly uses Config: {Config.ADB_PATH}')\n\"\n```",
        "status": "done",
        "dependencies": [
          "25",
          "29",
          "31",
          "32"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:00:04.365Z"
      },
      {
        "id": "38",
        "title": "Extract ClaudeUIAnalyzer from SmartInstagramPoster",
        "description": "Create claude_analyzer.py with a ClaudeUIAnalyzer class that encapsulates all AI-based UI analysis logic, extracting the analyze_ui() method (~125 lines) from post_reel_smart.py that mixes prompt construction, Claude API calls, and JSON response parsing into a single class with a clean interface: analyze(elements, state) -> action_dict.",
        "details": "## Current State Analysis\n\nThe `SmartInstagramPoster.analyze_ui()` method in `post_reel_smart.py` (lines 539-663, ~125 lines) currently handles:\n\n1. **UI Element Formatting** (lines 543-554):\n   - Iterates through parsed UI elements\n   - Builds a text description with bounds, center coords, text, desc, id, clickable status\n   - Creates `ui_description` string for Claude\n\n2. **Prompt Construction** (lines 556-612):\n   - Builds a large multi-section prompt including:\n     - Current posting state (video_uploaded, caption_entered, share_clicked)\n     - Caption to post\n     - UI element descriptions\n     - Instagram posting flow instructions (8 steps)\n     - JSON response format specification\n     - Critical rules for action handling (~20 rules)\n\n3. **Claude API Calls with Retry** (lines 615-663):\n   - 3-attempt retry loop for transient errors\n   - Uses `anthropic.Anthropic()` client\n   - Model: `claude-sonnet-4-20250514`, max_tokens: 500\n   - Handles empty responses\n   - Parses markdown code blocks (```json)\n   - JSON parsing with error handling\n\n## Implementation Plan\n\n### Step 1: Create claude_analyzer.py module\n\n```python\n\"\"\"\nClaude UI Analyzer - AI-based UI analysis for Instagram posting automation.\n\nExtracts UI analysis logic from SmartInstagramPoster for better separation of concerns.\n\"\"\"\n\nimport json\nimport time\nfrom dataclasses import dataclass\nfrom typing import Optional\nimport anthropic\n\n\n@dataclass\nclass PostingState:\n    \"\"\"Current state of the Instagram posting flow.\"\"\"\n    video_uploaded: bool = False\n    caption_entered: bool = False\n    share_clicked: bool = False\n    caption: str = \"\"\n\n\n@dataclass\nclass UIAction:\n    \"\"\"Parsed action from Claude's analysis.\"\"\"\n    action: str  # tap, tap_and_type, back, scroll_down, scroll_up, home, open_instagram, done\n    element_index: Optional[int] = None\n    text: Optional[str] = None\n    reason: str = \"\"\n    video_selected: bool = False\n    caption_entered: bool = False\n    share_clicked: bool = False\n\n    @classmethod\n    def from_dict(cls, data: dict) -> \"UIAction\":\n        \"\"\"Create UIAction from Claude's JSON response.\"\"\"\n        return cls(\n            action=data.get(\"action\", \"\"),\n            element_index=data.get(\"element_index\"),\n            text=data.get(\"text\"),\n            reason=data.get(\"reason\", \"\"),\n            video_selected=data.get(\"video_selected\", False),\n            caption_entered=data.get(\"caption_entered\", False),\n            share_clicked=data.get(\"share_clicked\", False),\n        )\n\n\nclass ClaudeUIAnalyzer:\n    \"\"\"Handles AI-based UI analysis for Instagram posting automation.\"\"\"\n\n    # Default model configuration\n    DEFAULT_MODEL = \"claude-sonnet-4-20250514\"\n    DEFAULT_MAX_TOKENS = 500\n    DEFAULT_RETRIES = 3\n\n    def __init__(\n        self,\n        model: str = DEFAULT_MODEL,\n        max_tokens: int = DEFAULT_MAX_TOKENS,\n        retries: int = DEFAULT_RETRIES,\n    ):\n        self.client = anthropic.Anthropic()\n        self.model = model\n        self.max_tokens = max_tokens\n        self.retries = retries\n\n    def analyze(\n        self,\n        elements: list[dict],\n        state: PostingState,\n    ) -> UIAction:\n        \"\"\"\n        Analyze UI elements and determine next action.\n\n        Args:\n            elements: List of UI element dicts with keys:\n                - text, desc, id, bounds, center, clickable\n            state: Current posting flow state\n\n        Returns:\n            UIAction with the next action to take\n\n        Raises:\n            ValueError: If Claude returns invalid/unparseable response after retries\n        \"\"\"\n        ui_description = self._format_elements(elements)\n        prompt = self._build_prompt(ui_description, state)\n        response_json = self._call_claude(prompt)\n        return UIAction.from_dict(response_json)\n\n    def _format_elements(self, elements: list[dict]) -> str:\n        \"\"\"Format UI elements into a description string for Claude.\"\"\"\n        lines = [\"Current UI elements:\"]\n        for i, elem in enumerate(elements):\n            parts = []\n            if elem.get(\"text\"):\n                parts.append(f'text=\"{elem[\"text\"]}\"')\n            if elem.get(\"desc\"):\n                parts.append(f'desc=\"{elem[\"desc\"]}\"')\n            if elem.get(\"id\"):\n                parts.append(f\"id={elem['id']}\")\n            if elem.get(\"clickable\"):\n                parts.append(\"CLICKABLE\")\n            lines.append(\n                f\"{i}. {elem.get('bounds', '')} center={elem.get('center', '')} | {' | '.join(parts)}\"\n            )\n        return \"\\n\".join(lines)\n\n    def _build_prompt(self, ui_description: str, state: PostingState) -> str:\n        \"\"\"Build the prompt for Claude analysis.\"\"\"\n        # Full prompt extracted from post_reel_smart.py lines 556-612\n        return f\"\"\"You are controlling an Android phone to post a Reel to Instagram.\n\nCurrent state:\n- Video uploaded to phone: {state.video_uploaded}\n- Caption entered: {state.caption_entered}\n- Share button clicked: {state.share_clicked}\n- Caption to post: \"{state.caption}\"\n\n{ui_description}\n\nBased on the UI elements, decide the next action to take.\n\nInstagram posting flow:\n1. Find and tap Create/+ button. IMPORTANT: On different Instagram versions:\n   - Some have \"Create\" in bottom nav bar\n   - Some have \"Create New\" in top left corner (only visible from Profile tab)\n   - If you don't see Create, tap \"Profile\" tab first to find \"Create New\"\n2. Select \"Reel\" option if a menu appears\n3. Select the video from gallery (look for video thumbnails, usually most recent)\n4. Tap \"Next\" to proceed to editing\n5. Tap \"Next\" again to proceed to sharing\n6. When you see the caption field (\"Write a caption\" or similar), return \"type\" action with the caption text\n7. Tap \"Share\" to publish\n8. Done when you see confirmation, \"Sharing to Reels\", or back on feed\n\nRespond with JSON:\n{{\n    \"action\": \"tap\" | \"tap_and_type\" | \"back\" | \"scroll_down\" | \"scroll_up\" | \"home\" | \"open_instagram\" | \"done\",\n    \"element_index\": <index of element to tap>,\n    \"text\": \"<text to type if action is tap_and_type>\",\n    \"reason\": \"<brief explanation>\",\n    \"video_selected\": true/false,\n    \"caption_entered\": true/false,\n    \"share_clicked\": true/false\n}}\n\nCRITICAL RULES - NEVER GIVE UP:\n- NEVER return \"error\". There is no error action. Always try to recover.\n- If you see Play Store, Settings, or any non-Instagram app: return \"home\" to go back to home screen\n- If you see home screen or launcher: return \"open_instagram\" to reopen Instagram\n- If you see a popup, dialog, or unexpected screen: return \"back\" to dismiss it\n- If you're lost or confused: return \"back\" and try again\n- If you don't see Create button, tap Profile tab first\n- Look for \"Create New\" in desc field (top left area, small button)\n- Look for \"Profile\" in desc field (bottom nav, usually id=profile_tab)\n- If you see \"Reel\" or \"Create new reel\" option, tap it\n- If you see gallery thumbnails with video, tap the video\n- If you see \"Next\" button anywhere, tap it\n- IMPORTANT: When you see a caption field (text containing \"Write a caption\", \"Add a caption\", or similar placeholder) AND \"Caption entered\" is False, return action=\"tap_and_type\" with the element_index of the caption field and text set to the caption\n- CRITICAL: If \"Caption entered: True\" is shown above, DO NOT return tap_and_type! The caption is already typed. Just tap the Share button directly.\n- Allow/OK buttons should be tapped for permissions\n- IMPORTANT: Return \"done\" ONLY when Share button clicked is True AND you see \"Sharing to Reels\" confirmation\n- If Share button clicked is False but you see \"Sharing to Reels\", that's from a previous post - ignore it and start the posting flow\n- Set share_clicked=true when you tap the Share button\n- CRITICAL OK BUTTON RULE: After caption has been entered (Caption entered: True), if you see an \"OK\" button visible on screen (text='OK' or desc='OK'), you MUST tap the OK button FIRST before tapping Next or Share. This OK button dismisses the keyboard or a dialog and must be tapped for Next/Share to work properly.\n\nOnly output JSON.\"\"\"\n\n    def _call_claude(self, prompt: str) -> dict:\n        \"\"\"Call Claude API with retry logic and parse JSON response.\"\"\"\n        for attempt in range(self.retries):\n            try:\n                response = self.client.messages.create(\n                    model=self.model,\n                    max_tokens=self.max_tokens,\n                    messages=[{\"role\": \"user\", \"content\": prompt}],\n                )\n\n                # Check for empty response\n                if not response.content:\n                    if attempt < self.retries - 1:\n                        time.sleep(1)\n                        continue\n                    raise ValueError(\"Claude returned empty response\")\n\n                text = response.content[0].text.strip()\n\n                # Check for empty text\n                if not text:\n                    if attempt < self.retries - 1:\n                        time.sleep(1)\n                        continue\n                    raise ValueError(\"Claude returned empty text\")\n\n                return self._parse_json_response(text, attempt)\n\n            except json.JSONDecodeError as e:\n                if attempt < self.retries - 1:\n                    time.sleep(1)\n                    continue\n                raise ValueError(f\"JSON parse failed after {self.retries} attempts: {e}\")\n\n            except Exception as e:\n                if attempt < self.retries - 1 and \"rate\" not in str(e).lower():\n                    time.sleep(1)\n                    continue\n                raise\n\n        raise ValueError(f\"Failed to get valid response from Claude after {self.retries} attempts\")\n\n    def _parse_json_response(self, text: str, attempt: int) -> dict:\n        \"\"\"Parse JSON from Claude's response, handling markdown code blocks.\"\"\"\n        # Handle markdown code blocks\n        if text.startswith(\"```\"):\n            text = text.split(\"```\")[1]\n            if text.startswith(\"json\"):\n                text = text[4:]\n            text = text.strip()\n\n        try:\n            return json.loads(text)\n        except json.JSONDecodeError as e:\n            print(f\"  [JSON PARSE ERROR] attempt {attempt+1}: {e}\")\n            print(f\"  Raw response (full): {text}\")\n            raise\n```\n\n### Step 2: Update SmartInstagramPoster to use ClaudeUIAnalyzer\n\n```python\n# In post_reel_smart.py\n\nfrom claude_analyzer import ClaudeUIAnalyzer, PostingState\n\nclass SmartInstagramPoster:\n    def __init__(self, phone_name, system_port=8200, appium_url=None):\n        self.client = GeelarkClient()\n        self.ui_analyzer = ClaudeUIAnalyzer()  # Replace self.anthropic\n        # ... rest of __init__\n\n    def analyze_ui(self, elements, caption):\n        \"\"\"Use Claude to analyze UI and decide next action\"\"\"\n        state = PostingState(\n            video_uploaded=self.video_uploaded,\n            caption_entered=self.caption_entered,\n            share_clicked=self.share_clicked,\n            caption=caption,\n        )\n        action = self.ui_analyzer.analyze(elements, state)\n        return {\n            \"action\": action.action,\n            \"element_index\": action.element_index,\n            \"text\": action.text,\n            \"reason\": action.reason,\n            \"video_selected\": action.video_selected,\n            \"caption_entered\": action.caption_entered,\n            \"share_clicked\": action.share_clicked,\n        }\n```\n\n## Key Design Decisions\n\n1. **Dataclasses for State and Actions**: Use `PostingState` and `UIAction` dataclasses for type safety and clear interfaces.\n\n2. **Configurable Model/Tokens**: Allow customization of Claude model and token limits via constructor.\n\n3. **Clean analyze() Interface**: Single entry point that takes elements and state, returns action.\n\n4. **Backwards Compatibility**: The `analyze_ui()` method in SmartInstagramPoster delegates to ClaudeUIAnalyzer but returns the same dict format for minimal changes to calling code.\n\n5. **Separation of Concerns**:\n   - `_format_elements()`: UI element → text conversion\n   - `_build_prompt()`: Prompt construction\n   - `_call_claude()`: API call with retries\n   - `_parse_json_response()`: JSON parsing\n\n## Relationship to Existing vision.py\n\nThe existing `vision.py` module handles screenshot-based (image) analysis, while this new `claude_analyzer.py` handles UI hierarchy (XML dump) analysis. They serve complementary purposes:\n- `vision.py`: Image → action (pixel-coordinate based)\n- `claude_analyzer.py`: UI elements → action (element-index based)",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Test - Module imports successfully\n```bash\npython -c \"from claude_analyzer import ClaudeUIAnalyzer, PostingState, UIAction; print('Import OK')\"\n```\n\n### 2. Unit Test - ClaudeUIAnalyzer instantiation\n```bash\npython -c \"\nfrom claude_analyzer import ClaudeUIAnalyzer\nanalyzer = ClaudeUIAnalyzer()\nassert analyzer.model == 'claude-sonnet-4-20250514'\nassert analyzer.max_tokens == 500\nassert analyzer.retries == 3\nprint('Instantiation OK')\n\"\n```\n\n### 3. Unit Test - PostingState dataclass\n```bash\npython -c \"\nfrom claude_analyzer import PostingState\nstate = PostingState(video_uploaded=True, caption='Test', caption_entered=False, share_clicked=False)\nassert state.video_uploaded == True\nassert state.caption == 'Test'\nprint('PostingState OK')\n\"\n```\n\n### 4. Unit Test - UIAction.from_dict() parsing\n```bash\npython -c \"\nfrom claude_analyzer import UIAction\ndata = {\n    'action': 'tap',\n    'element_index': 5,\n    'reason': 'Tap Create button',\n    'video_selected': False,\n    'caption_entered': False,\n    'share_clicked': False\n}\naction = UIAction.from_dict(data)\nassert action.action == 'tap'\nassert action.element_index == 5\nassert action.reason == 'Tap Create button'\nprint('UIAction.from_dict OK')\n\"\n```\n\n### 5. Unit Test - _format_elements() output format\n```bash\npython -c \"\nfrom claude_analyzer import ClaudeUIAnalyzer\nanalyzer = ClaudeUIAnalyzer()\nelements = [\n    {'text': 'Home', 'desc': '', 'id': 'home_tab', 'bounds': '[0,0][100,100]', 'center': (50, 50), 'clickable': True},\n    {'text': '', 'desc': 'Create', 'id': 'create_btn', 'bounds': '[100,0][200,100]', 'center': (150, 50), 'clickable': True},\n]\nresult = analyzer._format_elements(elements)\nassert 'text=\\\"Home\\\"' in result\nassert 'desc=\\\"Create\\\"' in result\nassert 'CLICKABLE' in result\nassert 'center=' in result\nprint('_format_elements OK')\n\"\n```\n\n### 6. Unit Test - _parse_json_response() handles code blocks\n```bash\npython -c \"\nfrom claude_analyzer import ClaudeUIAnalyzer\nanalyzer = ClaudeUIAnalyzer()\n\n# Test plain JSON\nplain = '{\\\"action\\\": \\\"tap\\\", \\\"element_index\\\": 0}'\nresult = analyzer._parse_json_response(plain, 0)\nassert result['action'] == 'tap'\n\n# Test markdown code block\nmarkdown = '\\`\\`\\`json\\n{\\\"action\\\": \\\"back\\\"}\\n\\`\\`\\`'\nresult = analyzer._parse_json_response(markdown, 0)\nassert result['action'] == 'back'\nprint('_parse_json_response OK')\n\"\n```\n\n### 7. Unit Test - _build_prompt() includes all required sections\n```bash\npython -c \"\nfrom claude_analyzer import ClaudeUIAnalyzer, PostingState\nanalyzer = ClaudeUIAnalyzer()\nstate = PostingState(video_uploaded=True, caption='Test caption', caption_entered=False, share_clicked=False)\nprompt = analyzer._build_prompt('UI elements here', state)\nassert 'Video uploaded to phone: True' in prompt\nassert 'Caption entered: False' in prompt\nassert 'Test caption' in prompt\nassert 'Instagram posting flow:' in prompt\nassert 'CRITICAL RULES' in prompt\nassert 'Only output JSON' in prompt\nprint('_build_prompt OK')\n\"\n```\n\n### 8. Integration Test - SmartInstagramPoster uses ClaudeUIAnalyzer\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster('test_phone')\nassert hasattr(poster, 'ui_analyzer'), 'SmartInstagramPoster should have ui_analyzer attribute'\nprint('Integration OK')\n\"\n```\n\n### 9. Integration Test - Full analyze() call (requires ANTHROPIC_API_KEY)\n```bash\npython -c \"\nimport os\nif not os.getenv('ANTHROPIC_API_KEY'):\n    print('SKIP: ANTHROPIC_API_KEY not set')\nelse:\n    from claude_analyzer import ClaudeUIAnalyzer, PostingState\n    analyzer = ClaudeUIAnalyzer()\n    elements = [\n        {'text': 'Home', 'desc': '', 'id': 'home_tab', 'bounds': '[0,1200][144,1280]', 'center': (72, 1240), 'clickable': True},\n        {'text': '', 'desc': 'Create', 'id': 'creation_tab', 'bounds': '[288,1200][432,1280]', 'center': (360, 1240), 'clickable': True},\n    ]\n    state = PostingState(video_uploaded=False, caption='Test', caption_entered=False, share_clicked=False)\n    action = analyzer.analyze(elements, state)\n    assert action.action in ['tap', 'tap_and_type', 'back', 'scroll_down', 'scroll_up', 'home', 'open_instagram', 'done']\n    print(f'Integration test passed: action={action.action}, reason={action.reason}')\n\"\n```\n\n### 10. Regression Test - Existing post_reel_smart.py behavior unchanged\n```bash\n# Run a quick dry test to ensure posting_scheduler still works\npython posting_scheduler.py --status\n```",
        "status": "done",
        "dependencies": [
          "6",
          "25",
          "37"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:02:05.391Z"
      },
      {
        "id": "39",
        "title": "Extract AppiumUIController from SmartInstagramPoster",
        "description": "Create appium_ui_controller.py with an AppiumUIController class that encapsulates all Appium-based UI interaction methods, extracting tap(), swipe(), press_key(), type_text_via_appium(), and dump_ui() from post_reel_smart.py to create a clean interface between posting logic and device control.",
        "details": "## Current State Analysis\n\nThe `SmartInstagramPoster` class in `post_reel_smart.py` contains several Appium-based UI interaction methods that should be extracted:\n\n### Methods to Extract (with line numbers):\n\n1. **`tap(x, y)`** (lines 91-97): Taps at coordinates using Appium driver\n   - Requires `self.appium_driver`\n   - Includes 1.5s sleep after tap\n\n2. **`swipe(x1, y1, x2, y2, duration_ms)`** (lines 99-103): Swipes between points\n   - Requires `self.appium_driver`\n\n3. **`press_key(keycode)`** (lines 105-117): Presses Android key codes\n   - Maps string keycodes ('KEYCODE_BACK') to integers\n   - Requires `self.appium_driver`\n\n4. **`type_text(text)`** (lines 441-473): Types text using Appium send_keys\n   - Finds EditText elements or uses active element\n   - Requires `self.appium_driver`\n\n5. **`dump_ui()`** (lines 475-537): Dumps UI hierarchy via Appium page_source\n   - Parses XML, extracts clickable elements with bounds\n   - Handles UiAutomator2 crash recovery via `reconnect_appium()`\n   - Returns tuple of (elements_list, raw_xml)\n\n### Supporting Methods to Also Extract:\n\n6. **`is_uiautomator2_crash(exception)`** (lines 69-77): Detects UiAutomator2 crash signatures\n7. **`reconnect_appium()`** (lines 79-89): Reconnects Appium after crash\n8. **`is_keyboard_visible()`** (lines 422-439): Checks keyboard visibility via ADB dumpsys\n\n## Implementation Plan\n\n### 1. Create `appium_ui_controller.py`\n\n```python\n\"\"\"\nAppium UI Controller - encapsulates all Appium-based UI interactions.\n\nThis module provides a clean interface for device UI control, separating\nposting logic from low-level Appium operations.\n\"\"\"\nimport re\nimport time\nimport xml.etree.ElementTree as ET\nfrom typing import List, Dict, Tuple, Optional, Union, Callable\nfrom dataclasses import dataclass\n\nfrom appium import webdriver\nfrom appium.webdriver.common.appiumby import AppiumBy\n\nfrom config import Config\n\n\n@dataclass\nclass UIElement:\n    \"\"\"Represents a parsed UI element from the hierarchy.\"\"\"\n    text: str\n    desc: str\n    resource_id: str\n    bounds: str\n    center: Tuple[int, int]\n    clickable: bool\n\n\nclass AppiumUIControllerError(Exception):\n    \"\"\"Base exception for AppiumUIController errors.\"\"\"\n    pass\n\n\nclass UIAutomator2CrashError(AppiumUIControllerError):\n    \"\"\"Raised when UiAutomator2 crashes on device.\"\"\"\n    pass\n\n\nclass AppiumUIController:\n    \"\"\"\n    Encapsulates all Appium-based UI interaction methods.\n    \n    This class provides a clean interface for device UI control operations,\n    handling Appium driver interactions, crash recovery, and UI hierarchy parsing.\n    \n    Usage:\n        driver = webdriver.Remote(...)\n        controller = AppiumUIController(driver)\n        \n        # Basic interactions\n        controller.tap(500, 500)\n        controller.swipe(100, 500, 100, 200)\n        controller.press_key('KEYCODE_BACK')\n        controller.type_text(\"Hello world\")\n        \n        # UI inspection\n        elements, xml = controller.dump_ui()\n    \"\"\"\n    \n    # Android keycode mapping\n    KEYCODES = {\n        'KEYCODE_BACK': 4,\n        'KEYCODE_HOME': 3,\n        'KEYCODE_ENTER': 66,\n        'KEYCODE_TAB': 61,\n        'KEYCODE_MENU': 82,\n    }\n    \n    def __init__(\n        self,\n        driver: webdriver.Remote,\n        adb_shell_func: Optional[Callable[[str], str]] = None,\n        reconnect_func: Optional[Callable[[], bool]] = None,\n        tap_delay: float = 1.5\n    ):\n        \"\"\"\n        Initialize AppiumUIController.\n        \n        Args:\n            driver: Appium WebDriver instance\n            adb_shell_func: Optional function to run ADB shell commands (for keyboard detection)\n            reconnect_func: Optional function to reconnect Appium after crash\n            tap_delay: Delay in seconds after tap (default 1.5)\n        \"\"\"\n        self._driver = driver\n        self._adb_shell = adb_shell_func\n        self._reconnect = reconnect_func\n        self._tap_delay = tap_delay\n    \n    @property\n    def driver(self) -> webdriver.Remote:\n        \"\"\"Get the underlying Appium driver.\"\"\"\n        return self._driver\n    \n    def set_driver(self, driver: webdriver.Remote) -> None:\n        \"\"\"Update the Appium driver (e.g., after reconnection).\"\"\"\n        self._driver = driver\n    \n    def _ensure_driver(self) -> None:\n        \"\"\"Ensure driver is connected, raise if not.\"\"\"\n        if not self._driver:\n            raise AppiumUIControllerError(\"Appium driver not connected\")\n    \n    def tap(self, x: int, y: int, delay: Optional[float] = None) -> None:\n        \"\"\"\n        Tap at coordinates.\n        \n        Args:\n            x: X coordinate\n            y: Y coordinate\n            delay: Optional custom delay after tap (uses tap_delay if not specified)\n        \"\"\"\n        self._ensure_driver()\n        self._driver.tap([(x, y)])\n        time.sleep(delay if delay is not None else self._tap_delay)\n    \n    def swipe(\n        self,\n        x1: int, y1: int,\n        x2: int, y2: int,\n        duration_ms: int = 300\n    ) -> None:\n        \"\"\"\n        Swipe from one point to another.\n        \n        Args:\n            x1, y1: Start coordinates\n            x2, y2: End coordinates\n            duration_ms: Swipe duration in milliseconds\n        \"\"\"\n        self._ensure_driver()\n        self._driver.swipe(x1, y1, x2, y2, duration_ms)\n    \n    def press_key(self, keycode: Union[int, str]) -> None:\n        \"\"\"\n        Press an Android key.\n        \n        Args:\n            keycode: Integer keycode or string like 'KEYCODE_BACK'\n        \"\"\"\n        self._ensure_driver()\n        if isinstance(keycode, str):\n            keycode = self.KEYCODES.get(keycode, 4)  # Default to BACK\n        self._driver.press_keycode(keycode)\n    \n    def type_text(self, text: str) -> bool:\n        \"\"\"\n        Type text into the currently focused field.\n        \n        Args:\n            text: Text to type (supports Unicode, emojis, newlines)\n            \n        Returns:\n            True if text was sent successfully, False otherwise\n        \"\"\"\n        self._ensure_driver()\n        \n        try:\n            # Find EditText elements\n            edit_texts = self._driver.find_elements(\n                AppiumBy.CLASS_NAME, \"android.widget.EditText\"\n            )\n            \n            for et in edit_texts:\n                if et.is_displayed():\n                    et.send_keys(text)\n                    time.sleep(0.8)\n                    return True\n            \n            # Fallback: try active element\n            active = self._driver.switch_to.active_element\n            if active:\n                active.send_keys(text)\n                time.sleep(0.8)\n                return True\n            \n            return False\n            \n        except Exception as e:\n            raise AppiumUIControllerError(f\"Typing failed: {e}\")\n    \n    def is_uiautomator2_crash(self, exception: Exception) -> bool:\n        \"\"\"Check if exception indicates UiAutomator2 crashed.\"\"\"\n        error_msg = str(exception).lower()\n        crash_indicators = [\n            'instrumentation process is not running',\n            'uiautomator2 server',\n            'cannot be proxied',\n            'probably crashed',\n        ]\n        return any(indicator in error_msg for indicator in crash_indicators)\n    \n    def is_keyboard_visible(self) -> bool:\n        \"\"\"\n        Check if the keyboard is currently visible.\n        \n        Requires adb_shell_func to be set.\n        \"\"\"\n        if not self._adb_shell:\n            return False  # Cannot determine without ADB\n        \n        # Method 1: Check dumpsys for keyboard visibility\n        result = self._adb_shell(\"dumpsys input_method | grep mInputShown\")\n        if \"mInputShown=true\" in result:\n            return True\n        \n        # Method 2: Check window visibility\n        result = self._adb_shell(\"dumpsys window | grep -i keyboard\")\n        if \"isVisible=true\" in result.lower() or \"mhasfocus=true\" in result.lower():\n            return True\n        \n        # Method 3: Check InputMethod window\n        result = self._adb_shell(\"dumpsys window windows | grep -E 'mCurrentFocus|mFocusedApp'\")\n        if \"InputMethod\" in result:\n            return True\n        \n        return False\n    \n    def dump_ui(self) -> Tuple[List[Dict], str]:\n        \"\"\"\n        Dump UI hierarchy and return parsed elements.\n        \n        Returns:\n            Tuple of (elements_list, raw_xml_string)\n            \n        Raises:\n            AppiumUIControllerError: If UI dump fails after recovery attempts\n        \"\"\"\n        self._ensure_driver()\n        \n        elements = []\n        xml_str = \"\"\n        \n        try:\n            xml_str = self._driver.page_source\n        except Exception as e:\n            if self.is_uiautomator2_crash(e):\n                # Try to recover\n                if self._reconnect and self._reconnect():\n                    try:\n                        xml_str = self._driver.page_source\n                    except Exception as e2:\n                        raise UIAutomator2CrashError(\n                            f\"Recovery failed: {type(e2).__name__}: {e2}\"\n                        )\n                else:\n                    raise UIAutomator2CrashError(\"Appium reconnect failed\")\n            else:\n                raise AppiumUIControllerError(\n                    f\"UI dump failed: {type(e).__name__}: {str(e)[:100]}\"\n                )\n        \n        if '<?xml' not in xml_str:\n            return elements, xml_str\n        \n        xml_clean = xml_str[xml_str.find('<?xml'):]\n        try:\n            root = ET.fromstring(xml_clean)\n            # Appium uses class names as tags, not <node>\n            for elem in root.iter():\n                text = elem.get('text', '')\n                desc = elem.get('content-desc', '')\n                res_id = elem.get('resource-id', '')\n                bounds = elem.get('bounds', '')\n                clickable = elem.get('clickable', 'false')\n                \n                if bounds and (text or desc or clickable == 'true'):\n                    m = re.match(r'\\[(\\d+),(\\d+)\\]\\[(\\d+),(\\d+)\\]', bounds)\n                    if m:\n                        x1, y1, x2, y2 = map(int, m.groups())\n                        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n                        elements.append({\n                            'text': text,\n                            'desc': desc,\n                            'id': res_id.split('/')[-1] if '/' in res_id else res_id,\n                            'bounds': bounds,\n                            'center': (cx, cy),\n                            'clickable': clickable == 'true'\n                        })\n        except ET.ParseError as e:\n            pass  # Return partial results\n        \n        return elements, xml_str\n```\n\n### 2. Update SmartInstagramPoster to Use AppiumUIController\n\nAfter creating the controller, update `post_reel_smart.py`:\n\n```python\nfrom appium_ui_controller import AppiumUIController, AppiumUIControllerError\n\nclass SmartInstagramPoster:\n    def __init__(self, phone_name, system_port=8200, appium_url=None):\n        # ... existing init code ...\n        self.ui_controller = None  # Will be set after Appium connects\n    \n    def connect_appium(self, retries=3):\n        # ... existing connection code ...\n        # After successful connection:\n        self.ui_controller = AppiumUIController(\n            driver=self.appium_driver,\n            adb_shell_func=self.adb,\n            reconnect_func=self._do_reconnect_appium,\n            tap_delay=1.5\n        )\n    \n    # Delegate methods to controller (thin wrappers for backward compatibility)\n    def tap(self, x, y):\n        print(f\"  [TAP] ({x}, {y})\")\n        self.ui_controller.tap(x, y)\n    \n    def swipe(self, x1, y1, x2, y2, duration_ms=300):\n        self.ui_controller.swipe(x1, y1, x2, y2, duration_ms)\n    \n    def press_key(self, keycode):\n        self.ui_controller.press_key(keycode)\n    \n    def type_text(self, text):\n        print(f\"    Typing via Appium ({len(text)} chars)...\")\n        result = self.ui_controller.type_text(text)\n        if result:\n            print(\"    Appium: text sent successfully\")\n        else:\n            print(\"    ERROR: No text field found to type into\")\n        return result\n    \n    def dump_ui(self):\n        return self.ui_controller.dump_ui()\n    \n    def is_keyboard_visible(self):\n        return self.ui_controller.is_keyboard_visible()\n```\n\n### 3. Integration with Task 37 (DeviceConnectionManager)\n\nThe `AppiumUIController` should receive the driver from `DeviceConnectionManager`. When Task 37 is implemented:\n\n```python\n# In SmartInstagramPoster after Task 37 integration\nconnection_manager = DeviceConnectionManager(geelark_client)\ndevice_info = connection_manager.connect(phone_name)\n\n# Create UI controller with the Appium driver\nself.ui_controller = AppiumUIController(\n    driver=device_info.appium_driver,\n    adb_shell_func=lambda cmd: connection_manager.adb_shell(cmd),\n    reconnect_func=lambda: connection_manager.reconnect_appium()\n)\n```\n\n### Key Design Decisions:\n\n1. **Constructor Injection**: The Appium driver is injected via constructor, not created internally\n2. **Optional ADB**: `adb_shell_func` is optional - keyboard detection gracefully degrades\n3. **Optional Recovery**: `reconnect_func` callback allows crash recovery without tight coupling\n4. **Backward Compatibility**: SmartInstagramPoster keeps thin wrapper methods for existing callers\n5. **Clean Interface**: All Appium operations go through the controller\n6. **Exception Hierarchy**: Custom exceptions for different failure modes",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Test - Module imports successfully\n```bash\npython -c \"from appium_ui_controller import AppiumUIController, AppiumUIControllerError, UIAutomator2CrashError; print('Import OK')\"\n```\n\n### 2. Unit Test - AppiumUIController instantiation\n```bash\npython -c \"\nfrom appium_ui_controller import AppiumUIController\n\n# Create with mock driver\nclass MockDriver:\n    def tap(self, coords): pass\n    def swipe(self, *args): pass\n    def press_keycode(self, code): pass\n    def find_elements(self, by, value): return []\n    @property\n    def page_source(self): return '<hierarchy></hierarchy>'\n\ncontroller = AppiumUIController(MockDriver())\nprint('Instantiation OK')\nprint(f'Driver set: {controller.driver is not None}')\n\"\n```\n\n### 3. Unit Test - tap() delegates correctly\n```bash\npython -c \"\nfrom appium_ui_controller import AppiumUIController\n\ntap_calls = []\n\nclass MockDriver:\n    def tap(self, coords):\n        tap_calls.append(coords)\n\ncontroller = AppiumUIController(MockDriver(), tap_delay=0)\ncontroller.tap(100, 200)\n\nassert tap_calls == [[(100, 200)]], f'Expected [[(100, 200)]], got {tap_calls}'\nprint('tap() delegation OK')\n\"\n```\n\n### 4. Unit Test - press_key() maps string keycodes\n```bash\npython -c \"\nfrom appium_ui_controller import AppiumUIController\n\npressed = []\n\nclass MockDriver:\n    def press_keycode(self, code):\n        pressed.append(code)\n\ncontroller = AppiumUIController(MockDriver())\ncontroller.press_key('KEYCODE_BACK')\ncontroller.press_key('KEYCODE_HOME')\ncontroller.press_key(66)  # Raw int\n\nassert pressed == [4, 3, 66], f'Expected [4, 3, 66], got {pressed}'\nprint('press_key() mapping OK')\n\"\n```\n\n### 5. Unit Test - dump_ui() parses XML correctly\n```bash\npython -c \"\nfrom appium_ui_controller import AppiumUIController\n\nclass MockDriver:\n    @property\n    def page_source(self):\n        return '''<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\n<hierarchy>\n  <android.widget.Button text=\\\"OK\\\" bounds=\\\"[10,20][100,80]\\\" clickable=\\\"true\\\" resource-id=\\\"com.app/btn\\\" content-desc=\\\"Confirm\\\" />\n</hierarchy>'''\n\ncontroller = AppiumUIController(MockDriver())\nelements, xml = controller.dump_ui()\n\nassert len(elements) == 1, f'Expected 1 element, got {len(elements)}'\nelem = elements[0]\nassert elem['text'] == 'OK', f'Expected text=OK, got {elem[\\\"text\\\"]}'\nassert elem['center'] == (55, 50), f'Expected center=(55,50), got {elem[\\\"center\\\"]}'\nassert elem['clickable'] == True, f'Expected clickable=True'\nprint('dump_ui() parsing OK')\n\"\n```\n\n### 6. Unit Test - is_uiautomator2_crash() detection\n```bash\npython -c \"\nfrom appium_ui_controller import AppiumUIController\n\ncontroller = AppiumUIController(None)\n\n# Should detect crash\ne1 = Exception('instrumentation process is not running')\nassert controller.is_uiautomator2_crash(e1) == True\n\ne2 = Exception('Original error: cannot be proxied')\nassert controller.is_uiautomator2_crash(e2) == True\n\n# Should not detect crash\ne3 = Exception('Connection timeout')\nassert controller.is_uiautomator2_crash(e3) == False\n\nprint('is_uiautomator2_crash() detection OK')\n\"\n```\n\n### 7. Unit Test - Error raised when no driver\n```bash\npython -c \"\nfrom appium_ui_controller import AppiumUIController, AppiumUIControllerError\n\ncontroller = AppiumUIController(None)\n\ntry:\n    controller.tap(100, 100)\n    print('ERROR: Should have raised exception')\n    exit(1)\nexcept AppiumUIControllerError as e:\n    assert 'not connected' in str(e).lower()\n    print('No-driver error handling OK')\n\"\n```\n\n### 8. Integration Test - SmartInstagramPoster uses AppiumUIController\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\n\nposter = SmartInstagramPoster('test_phone')\n# Before connect, ui_controller should be None\nprint(f'UI controller before connect: {getattr(poster, \\\"ui_controller\\\", \\\"NOT_ATTR\\\")}')\nprint('SmartInstagramPoster integration structure OK')\n\"\n```\n\n### 9. Integration Test - Full flow with mock Appium\n```bash\npython -c \"\nfrom appium_ui_controller import AppiumUIController\n\nactions = []\n\nclass MockDriver:\n    def tap(self, coords):\n        actions.append(('tap', coords))\n    def swipe(self, x1, y1, x2, y2, duration):\n        actions.append(('swipe', x1, y1, x2, y2))\n    def press_keycode(self, code):\n        actions.append(('key', code))\n    @property\n    def page_source(self):\n        return '<?xml version=\\\"1.0\\\"?><hierarchy><btn bounds=\\\"[0,0][100,100]\\\" clickable=\\\"true\\\"/></hierarchy>'\n\nadb_calls = []\ndef mock_adb(cmd):\n    adb_calls.append(cmd)\n    return 'mInputShown=true' if 'input_method' in cmd else ''\n\ncontroller = AppiumUIController(\n    MockDriver(),\n    adb_shell_func=mock_adb,\n    tap_delay=0\n)\n\n# Run sequence\ncontroller.tap(50, 50)\ncontroller.swipe(0, 100, 0, 0, 300)\ncontroller.press_key('KEYCODE_BACK')\nelements, _ = controller.dump_ui()\nkb_visible = controller.is_keyboard_visible()\n\nassert len(actions) == 3, f'Expected 3 actions, got {actions}'\nassert len(elements) == 1, f'Expected 1 element'\nassert kb_visible == True, 'Expected keyboard visible'\nprint('Full flow integration OK')\n\"\n```\n\n### 10. Live Test - With real Appium server (manual)\n```bash\n# Start Appium server first: appium --port 4723\n\npython -c \"\nfrom appium import webdriver\nfrom appium.options.android import UiAutomator2Options\nfrom appium_ui_controller import AppiumUIController\n\n# Connect to a test device (update device address)\noptions = UiAutomator2Options()\noptions.platform_name = 'Android'\noptions.automation_name = 'UiAutomator2'\noptions.device_name = '192.168.1.100:5555'  # Update this\noptions.no_reset = True\n\ntry:\n    driver = webdriver.Remote('http://127.0.0.1:4723', options=options)\n    controller = AppiumUIController(driver)\n    \n    # Test dump_ui\n    elements, xml = controller.dump_ui()\n    print(f'Found {len(elements)} UI elements')\n    \n    # Test tap (tap center of screen)\n    controller.tap(360, 640)\n    print('Tap executed')\n    \n    driver.quit()\n    print('Live test PASSED')\nexcept Exception as e:\n    print(f'Live test skipped or failed: {e}')\n\"\n```",
        "status": "done",
        "dependencies": [
          "25",
          "37",
          "23"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:06:16.759Z"
      },
      {
        "id": "40",
        "title": "Consolidate ADB operations into DeviceConnectionManager",
        "description": "Extract all ADB subprocess calls from SmartInstagramPoster and route them through DeviceConnectionManager, establishing a clear boundary where the posting engine never calls subprocess directly for ADB operations.",
        "details": "## Current State Analysis\n\n### SmartInstagramPoster.adb() - Lines 113-120 in post_reel_smart.py:\n```python\ndef adb(self, cmd, timeout=30):\n    \"\"\"Run ADB shell command\"\"\"\n    result = subprocess.run(\n        [ADB_PATH, \"-s\", self.device, \"shell\", cmd],\n        capture_output=True, timeout=timeout,\n        encoding='utf-8', errors='replace'\n    )\n    return result.stdout.strip() if result.stdout else \"\"\n```\n\n### DeviceConnectionManager.adb_command() - Lines 53-62 in device_connection.py:\n```python\ndef adb_command(self, cmd: str, timeout: int = 30) -> str:\n    \"\"\"Run ADB shell command on the connected device.\"\"\"\n    if not self.device:\n        raise Exception(\"No device connected - call connect() first\")\n    result = subprocess.run(\n        [ADB_PATH, \"-s\", self.device, \"shell\", cmd],\n        capture_output=True, timeout=timeout,\n        encoding='utf-8', errors='replace'\n    )\n    return result.stdout.strip() if result.stdout else \"\"\n```\n\nBoth methods are functionally identical. SmartInstagramPoster already has `self._conn` which is a DeviceConnectionManager instance.\n\n## Implementation Steps\n\n### Step 1: Update SmartInstagramPoster.adb() to delegate\nReplace lines 113-120 in `post_reel_smart.py`:\n```python\ndef adb(self, cmd, timeout=30):\n    \"\"\"Run ADB shell command - delegates to DeviceConnectionManager\"\"\"\n    return self._conn.adb_command(cmd, timeout=timeout)\n```\n\n### Step 2: Remove subprocess import\nRemove line 23 from `post_reel_smart.py`:\n```python\nimport subprocess  # REMOVE THIS LINE\n```\n\n### Step 3: Verify all ADB callers work unchanged\nThe following calls in `post_reel_smart.py` use `self.adb()` and should continue working:\n- Line 459: `self.adb(\"dumpsys input_method | grep mInputShown\")` in `is_keyboard_visible()`\n- Line 464: `self.adb(\"dumpsys window | grep -i keyboard\")` in `is_keyboard_visible()`\n- Line 469: `self.adb(\"dumpsys window windows | grep -E 'mCurrentFocus|mFocusedApp'\")` in `is_keyboard_visible()`\n- Line 586: `self.adb(\"am broadcast -a android.intent.action.MEDIA_SCANNER_SCAN_FILE...\")` in `upload_video()`\n- Lines 590-591: `self.adb(\"rm -f /sdcard/DCIM/Camera/IMG_*.png\")` and screenshot cleanup in `upload_video()`\n- Line 612: `self.adb(\"am force-stop com.instagram.android\")` in `post()`\n- Line 614: `self.adb(\"monkey -p com.instagram.android 1\")` in `post()`\n- Lines 695, 697, 771, 773: More `adb input swipe` and app control commands in `post()`\n- Lines 804, 806: App restart commands in loop recovery\n- Line 822: `self.adb(\"rm -f /sdcard/Download/*.mp4\")` in `cleanup()`\n\n## Architecture After Change\n\n```\nBefore:\nSmartInstagramPoster.adb() -> subprocess.run() [direct infrastructure coupling]\n\nAfter:\nSmartInstagramPoster.adb() -> self._conn.adb_command() -> subprocess.run()\n                              [single point of ADB access via DeviceConnectionManager]\n```\n\n## Benefits\n1. **Clear boundary**: SmartInstagramPoster becomes a pure posting logic class\n2. **Single responsibility**: DeviceConnectionManager owns ALL device communication\n3. **Testability**: Can mock DeviceConnectionManager for unit testing SmartInstagramPoster\n4. **Consistency**: All ADB operations go through the same path with consistent error handling",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify the file has no syntax errors and imports correctly\npython -c \"from post_reel_smart import SmartInstagramPoster; print('Import successful')\"\n```\n\n### 2. Verify subprocess is NOT imported in post_reel_smart.py\n```bash\n# This should return empty (no matches)\npython -c \"\nwith open('post_reel_smart.py') as f:\n    content = f.read()\n    lines = [l for l in content.split('\\n') if 'import subprocess' in l and not l.strip().startswith('#')]\n    if lines:\n        print('FAIL: subprocess still imported:', lines)\n        exit(1)\n    print('PASS: subprocess not imported')\n\"\n```\n\n### 3. Verify adb() method delegates to DeviceConnectionManager\n```bash\n# Inspect the adb method to confirm it calls self._conn.adb_command\npython -c \"\nimport inspect\nfrom post_reel_smart import SmartInstagramPoster\nsource = inspect.getsource(SmartInstagramPoster.adb)\nif 'self._conn.adb_command' in source:\n    print('PASS: adb() delegates to self._conn.adb_command()')\nelse:\n    print('FAIL: adb() does not delegate to DeviceConnectionManager')\n    print(source)\n    exit(1)\n\"\n```\n\n### 4. Integration Test - Existing Scripts Work Unchanged\n```bash\n# Test that posting_scheduler.py still imports and runs\npython -c \"from posting_scheduler import PostingScheduler; print('PostingScheduler import OK')\"\n\n# Test that parallel_worker.py still imports and runs\npython -c \"from parallel_worker import ParallelWorker; print('ParallelWorker import OK')\"\n\n# Test that parallel_orchestrator.py still imports and runs\npython -c \"from parallel_orchestrator import run_orchestrator; print('Orchestrator import OK')\"\n```\n\n### 5. Manual Test - Full Posting Flow (Optional)\n```bash\n# Run a single phone posting test to verify all ADB commands work\n# This requires a running Appium server and available Geelark phone\npython post_reel_smart.py <test_phone_name> <test_video.mp4> \"Test caption\"\n```\n\n### 6. Verify DeviceConnectionManager.adb_command() Still Works\n```bash\n# Unit test the underlying adb_command method\npython -c \"\nfrom device_connection import DeviceConnectionManager\n# Just verify the method exists and has correct signature\nimport inspect\nsig = inspect.signature(DeviceConnectionManager.adb_command)\nparams = list(sig.parameters.keys())\nassert 'cmd' in params, 'Missing cmd parameter'\nassert 'timeout' in params, 'Missing timeout parameter'\nprint('PASS: DeviceConnectionManager.adb_command() has correct signature')\n\"\n```\n\n### 7. Regression Check - No Other subprocess Usages\n```bash\n# Ensure no stray subprocess calls remain in post_reel_smart.py\ngrep -n \"subprocess\" post_reel_smart.py && echo \"FAIL: Found subprocess references\" || echo \"PASS: No subprocess references\"\n```",
        "status": "done",
        "dependencies": [
          "37",
          "25"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:12:44.672Z"
      },
      {
        "id": "41",
        "title": "Extract _handle_tap_and_type helper from post() method",
        "description": "Extract the tap_and_type action handler (lines 701-758) from the post() method into a dedicated _handle_tap_and_type() helper method to reduce nesting complexity and improve code organization.",
        "details": "## Current State Analysis\n\nThe `post()` method in `post_reel_smart.py` contains an inline tap_and_type handler at lines 701-758 with 4 levels of nesting for keyboard state management:\n\n### Current Structure (lines 701-758):\n```python\nelif action['action'] == 'tap_and_type':\n    # Level 1: Check if caption already entered\n    if self.caption_entered:\n        # Skip logic - find Share button\n        continue\n    \n    # Get element info\n    idx = action.get('element_index', 0)\n    text = action.get('text', caption)\n    \n    # Level 2: Check keyboard visibility\n    keyboard_up = self.is_keyboard_visible()\n    \n    if not keyboard_up:\n        # Level 3: Tap and recheck\n        if 0 <= idx < len(elements):\n            self.tap(...)\n        keyboard_up = self.is_keyboard_visible()\n        \n        if not keyboard_up:\n            # Level 4: Tap again\n            if 0 <= idx < len(elements):\n                self.tap(...)\n            keyboard_up = self.is_keyboard_visible()\n    \n    if keyboard_up:\n        # Type text and verify\n        self.type_text(text)\n        # Verification logic\n        self.caption_entered = True\n        self.press_key('KEYCODE_BACK')\n    else:\n        print(\"ERROR: Could not get keyboard\")\n```\n\n## Implementation Plan\n\n### Step 1: Create the _handle_tap_and_type() method\n\nAdd a new private method to `SmartInstagramPoster` class (place it before `post()` method, around line 589):\n\n```python\ndef _handle_tap_and_type(self, action: dict, elements: list, caption: str) -> bool:\n    \"\"\"Handle tap_and_type action with keyboard state management.\n    \n    Args:\n        action: Action dict from Claude analysis with element_index and text\n        elements: Current UI elements list\n        caption: Original caption text (used as fallback for text)\n    \n    Returns:\n        True if loop should continue to next step (handled internally)\n        False if normal flow should continue\n    \"\"\"\n    # Early exit if caption already entered - tap Share instead\n    if self.caption_entered:\n        print(\"  [SKIP] Caption already entered! Tapping Share instead.\")\n        share_elements = [\n            e for e in elements \n            if e.get('text', '').lower() == 'share' \n            or e.get('desc', '').lower() == 'share'\n        ]\n        if share_elements:\n            self.tap(share_elements[0]['center'][0], share_elements[0]['center'][1])\n            self.share_clicked = True\n        return True  # Signal to continue loop\n    \n    idx = action.get('element_index', 0)\n    text = action.get('text', caption)\n    \n    # Ensure keyboard is visible before typing\n    keyboard_up = self._ensure_keyboard_visible(idx, elements)\n    \n    if keyboard_up:\n        self._type_and_verify_caption(text)\n    else:\n        print(\"  ERROR: Could not get keyboard to appear. Will retry on next step.\")\n    \n    return False  # Normal flow continues\n```\n\n### Step 2: Create _ensure_keyboard_visible() helper\n\n```python\ndef _ensure_keyboard_visible(self, element_index: int, elements: list) -> bool:\n    \"\"\"Ensure keyboard is visible by tapping element if needed.\n    \n    Args:\n        element_index: Index of element to tap\n        elements: Current UI elements list\n    \n    Returns:\n        True if keyboard is now visible\n    \"\"\"\n    print(\"  Checking if keyboard is up...\")\n    keyboard_up = self.is_keyboard_visible()\n    \n    if keyboard_up:\n        return True\n    \n    # First tap attempt\n    if 0 <= element_index < len(elements):\n        elem = elements[element_index]\n        print(f\"  Keyboard not up. Tapping caption field at ({elem['center'][0]}, {elem['center'][1]})\")\n        self.tap(elem['center'][0], elem['center'][1])\n        time.sleep(1.5)\n    \n    print(\"  Checking keyboard again...\")\n    keyboard_up = self.is_keyboard_visible()\n    \n    if keyboard_up:\n        return True\n    \n    # Second tap attempt\n    print(\"  Keyboard still not up. Tapping again...\")\n    if 0 <= element_index < len(elements):\n        elem = elements[element_index]\n        self.tap(elem['center'][0], elem['center'][1])\n        time.sleep(1.5)\n    \n    return self.is_keyboard_visible()\n```\n\n### Step 3: Create _type_and_verify_caption() helper\n\n```python\ndef _type_and_verify_caption(self, text: str) -> None:\n    \"\"\"Type caption text and verify it was entered.\n    \n    Args:\n        text: Caption text to type\n    \"\"\"\n    print(f\"  Keyboard is up. Typing: {text[:50]}...\")\n    self.type_text(text)\n    time.sleep(1)\n    \n    # Best-effort verification\n    print(\"  Verifying caption was typed...\")\n    verify_elements, _ = self.dump_ui()\n    caption_found = any(text[:20] in elem.get('text', '') for elem in verify_elements)\n    \n    if caption_found:\n        print(\"  Caption appears in UI dump.\")\n    else:\n        print(\"  Caption not visible in UI dump (normal for IG caption field); assuming entered.\")\n    \n    self.caption_entered = True\n    \n    # Hide keyboard\n    self.press_key('KEYCODE_BACK')\n    time.sleep(0.5)\n```\n\n### Step 4: Update post() method to use the helper\n\nReplace lines 701-758 with:\n```python\nelif action['action'] == 'tap_and_type':\n    if self._handle_tap_and_type(action, elements, caption):\n        continue  # Handler signaled to skip to next step\n```\n\n## Method Placement\n\nInsert the new methods in this order before `post()`:\n1. `_ensure_keyboard_visible()` - around line 565 (after `connect_appium()`)\n2. `_type_and_verify_caption()` - around line 590\n3. `_handle_tap_and_type()` - around line 610\n\n## Benefits of Extraction\n\n1. **Reduced nesting**: post() goes from 4 nested levels to 1 level for tap_and_type handling\n2. **Single responsibility**: Each helper method does one thing\n3. **Testability**: Individual helpers can be unit tested\n4. **Readability**: post() main loop is cleaner and easier to follow\n5. **Reusability**: _ensure_keyboard_visible() could be reused elsewhere",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify the file has no syntax errors and imports correctly\npython -c \"from post_reel_smart import SmartInstagramPoster; print('Import successful')\"\n```\n\n### 2. Method Existence Verification\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)\nassert hasattr(poster, '_handle_tap_and_type'), 'Missing _handle_tap_and_type'\nassert hasattr(poster, '_ensure_keyboard_visible'), 'Missing _ensure_keyboard_visible'\nassert hasattr(poster, '_type_and_verify_caption'), 'Missing _type_and_verify_caption'\nprint('All helper methods exist')\n\"\n```\n\n### 3. Method Signature Verification\n```bash\npython -c \"\nimport inspect\nfrom post_reel_smart import SmartInstagramPoster\n\n# Check _handle_tap_and_type signature\nsig = inspect.signature(SmartInstagramPoster._handle_tap_and_type)\nparams = list(sig.parameters.keys())\nassert 'action' in params, 'Missing action parameter'\nassert 'elements' in params, 'Missing elements parameter'\nassert 'caption' in params, 'Missing caption parameter'\nprint('_handle_tap_and_type signature correct:', params)\n\n# Check _ensure_keyboard_visible signature\nsig = inspect.signature(SmartInstagramPoster._ensure_keyboard_visible)\nparams = list(sig.parameters.keys())\nassert 'element_index' in params, 'Missing element_index parameter'\nassert 'elements' in params, 'Missing elements parameter'\nprint('_ensure_keyboard_visible signature correct:', params)\n\n# Check _type_and_verify_caption signature\nsig = inspect.signature(SmartInstagramPoster._type_and_verify_caption)\nparams = list(sig.parameters.keys())\nassert 'text' in params, 'Missing text parameter'\nprint('_type_and_verify_caption signature correct:', params)\n\"\n```\n\n### 4. Return Type Verification\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nimport inspect\n\n# Check that _handle_tap_and_type returns bool\nsource = inspect.getsource(SmartInstagramPoster._handle_tap_and_type)\nassert 'return True' in source, '_handle_tap_and_type should return True'\nassert 'return False' in source, '_handle_tap_and_type should return False'\nprint('_handle_tap_and_type has correct return statements')\n\"\n```\n\n### 5. Integration Test - Verify tap_and_type action handling\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nimport inspect\n\n# Get post method source to verify it uses the helper\nsource = inspect.getsource(SmartInstagramPoster.post)\n\n# Verify inline tap_and_type logic is removed\nassert 'Checking if keyboard is up...' not in source, 'Old inline keyboard check still in post()'\nassert 'Keyboard still not up. Tapping again' not in source, 'Old inline retry logic still in post()'\n\n# Verify helper is called\nassert '_handle_tap_and_type' in source, 'post() should call _handle_tap_and_type'\nprint('post() correctly delegates to _handle_tap_and_type helper')\n\"\n```\n\n### 6. Line Count Reduction Verification\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nimport inspect\n\n# Get post method source\nsource = inspect.getsource(SmartInstagramPoster.post)\nlines = [l for l in source.split('\\n') if l.strip()]\n\n# Count lines related to tap_and_type in post()\ntap_type_lines = [l for l in lines if 'tap_and_type' in l.lower()]\nprint(f'Lines mentioning tap_and_type in post(): {len(tap_type_lines)}')\n\n# The tap_and_type block in post() should be minimal (< 5 lines)\n# The logic is now in the helper methods\n\"\n```\n\n### 7. Live Test with Actual Posting (Optional)\n```bash\n# Only run if you want to test with a real account\n# Uses the parallel orchestrator which calls post() internally\npython parallel_orchestrator.py --workers 1 --run --max-posts 1\n```\n\n### 8. Behavioral Equivalence Test\nVerify the refactored code behaves identically:\n1. Start a post that requires caption entry\n2. Verify keyboard detection still works\n3. Verify caption typing still works\n4. Verify caption verification still works\n5. Verify keyboard dismissal still happens",
        "status": "done",
        "dependencies": [
          "39",
          "40"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:24:31.758Z"
      },
      {
        "id": "42",
        "title": "Extract _detect_and_recover_from_loop helper from post() method",
        "description": "Extract the loop detection and recovery logic (lines 769-804) from the post() method into a dedicated _detect_and_recover_from_loop() helper method to improve readability and reduce the complexity of the main posting loop.",
        "details": "## Current State Analysis\n\nThe `post()` method in `post_reel_smart.py` contains inline loop detection and recovery logic at lines 769-804:\n\n### Current Structure (lines 614-618, 769-804):\n\n**Initialization (lines 614-618):**\n```python\n# Loop detection - track recent actions to detect stuck states\nrecent_actions = []  # List of (action_type, x, y) tuples\nLOOP_THRESHOLD = 5  # If 5 consecutive same actions, we're stuck\nloop_recovery_count = 0  # How many times we've tried to recover\nMAX_LOOP_RECOVERIES = 2  # Give up after this many recovery attempts\n```\n\n**Action tracking (lines 769-778):**\n```python\n# Track action for loop detection\naction_signature = action['action']\nif action['action'] == 'tap' and 'element_index' in action:\n    idx = action.get('element_index', 0)\n    if 0 <= idx < len(elements):\n        x, y = elements[idx]['center']\n        action_signature = f\"tap_{x}_{y}\"\nrecent_actions.append(action_signature)\nif len(recent_actions) > LOOP_THRESHOLD:\n    recent_actions.pop(0)\n```\n\n**Loop detection and recovery (lines 780-804):**\n```python\n# Check for loop - if last N actions are all identical, we're stuck\nif len(recent_actions) >= LOOP_THRESHOLD and len(set(recent_actions)) == 1:\n    loop_recovery_count += 1\n    print(f\"\\n  [LOOP DETECTED] Same action '{recent_actions[0]}' repeated {LOOP_THRESHOLD} times!\")\n    print(f\"  [RECOVERY] Attempt {loop_recovery_count}/{MAX_LOOP_RECOVERIES}\")\n\n    if loop_recovery_count > MAX_LOOP_RECOVERIES:\n        print(\"  [ABORT] Too many loop recoveries, giving up\")\n        return False\n\n    # Recovery: press back 5 times and restart Instagram\n    print(\"  Pressing BACK 5 times to escape stuck state...\")\n    for _ in range(5):\n        self.press_key('KEYCODE_BACK')\n        time.sleep(0.5)\n\n    print(\"  Reopening Instagram...\")\n    self.adb(\"am force-stop com.instagram.android\")\n    time.sleep(2)\n    self.adb(\"monkey -p com.instagram.android 1\")\n    time.sleep(5)\n\n    # Reset action tracking\n    recent_actions = []\n    print(\"  [RECOVERY] Restarted - continuing from step\", step + 1)\n```\n\n## Implementation Plan\n\n### Step 1: Define constants as class-level attributes (add after line 70)\n\n```python\n# Loop detection constants\nLOOP_THRESHOLD = 5  # If N consecutive same actions, we're stuck\nMAX_LOOP_RECOVERIES = 2  # Give up after this many recovery attempts\n```\n\n### Step 2: Create _build_action_signature() helper (add after cleanup() method, ~line 820)\n\n```python\ndef _build_action_signature(self, action, elements):\n    \"\"\"Build a unique signature for an action to detect loops.\n    \n    Args:\n        action: The action dict from Claude's analysis\n        elements: List of UI elements\n        \n    Returns:\n        str: Action signature for loop comparison\n    \"\"\"\n    action_signature = action['action']\n    if action['action'] == 'tap' and 'element_index' in action:\n        idx = action.get('element_index', 0)\n        if 0 <= idx < len(elements):\n            x, y = elements[idx]['center']\n            action_signature = f\"tap_{x}_{y}\"\n    return action_signature\n```\n\n### Step 3: Create _detect_and_recover_from_loop() helper (add after _build_action_signature)\n\n```python\ndef _detect_and_recover_from_loop(self, recent_actions, loop_recovery_count, step):\n    \"\"\"Detect if we're stuck in a loop and attempt recovery.\n    \n    Args:\n        recent_actions: List of recent action signatures\n        loop_recovery_count: Current number of recovery attempts\n        step: Current step number (for logging)\n        \n    Returns:\n        tuple: (should_abort: bool, new_recovery_count: int, reset_actions: bool)\n            - should_abort: True if we should abort the entire post operation\n            - new_recovery_count: Updated recovery count\n            - reset_actions: True if recent_actions should be cleared\n    \"\"\"\n    # Not enough actions to detect a loop yet\n    if len(recent_actions) < self.LOOP_THRESHOLD:\n        return (False, loop_recovery_count, False)\n    \n    # Check if all recent actions are identical (loop detected)\n    if len(set(recent_actions)) != 1:\n        return (False, loop_recovery_count, False)\n    \n    # Loop detected!\n    loop_recovery_count += 1\n    print(f\"\\n  [LOOP DETECTED] Same action '{recent_actions[0]}' repeated {self.LOOP_THRESHOLD} times!\")\n    print(f\"  [RECOVERY] Attempt {loop_recovery_count}/{self.MAX_LOOP_RECOVERIES}\")\n    \n    # Check if we've exceeded max recovery attempts\n    if loop_recovery_count > self.MAX_LOOP_RECOVERIES:\n        print(\"  [ABORT] Too many loop recoveries, giving up\")\n        return (True, loop_recovery_count, False)\n    \n    # Attempt recovery: press back 5 times and restart Instagram\n    print(\"  Pressing BACK 5 times to escape stuck state...\")\n    for _ in range(5):\n        self.press_key('KEYCODE_BACK')\n        time.sleep(0.5)\n    \n    print(\"  Reopening Instagram...\")\n    self.adb(\"am force-stop com.instagram.android\")\n    time.sleep(2)\n    self.adb(\"monkey -p com.instagram.android 1\")\n    time.sleep(5)\n    \n    print(f\"  [RECOVERY] Restarted - continuing from step {step + 1}\")\n    return (False, loop_recovery_count, True)\n```\n\n### Step 4: Refactor post() method to use the helpers\n\nReplace lines 614-618 (initialization):\n```python\n# Loop detection state\nrecent_actions = []\nloop_recovery_count = 0\n```\n\nReplace lines 769-804 with:\n```python\n# Track action for loop detection\naction_signature = self._build_action_signature(action, elements)\nrecent_actions.append(action_signature)\nif len(recent_actions) > self.LOOP_THRESHOLD:\n    recent_actions.pop(0)\n\n# Check for loop and attempt recovery if needed\nshould_abort, loop_recovery_count, reset_actions = self._detect_and_recover_from_loop(\n    recent_actions, loop_recovery_count, step\n)\nif should_abort:\n    return False\nif reset_actions:\n    recent_actions = []\n```\n\n## Key Design Decisions\n\n1. **Return tuple pattern**: The helper returns a tuple `(should_abort, new_recovery_count, reset_actions)` to communicate multiple outcomes without side effects on mutable arguments.\n\n2. **Class-level constants**: Moving `LOOP_THRESHOLD` and `MAX_LOOP_RECOVERIES` to class attributes allows easy configuration and testing.\n\n3. **Separate signature builder**: The `_build_action_signature()` helper is small but encapsulates the logic of creating comparable action signatures, improving testability.\n\n4. **Preserve logging**: All print statements are preserved in the helper to maintain the same debug output.\n\n5. **No behavior changes**: The extracted code must produce identical behavior to the current implementation.\n\n## Files Modified\n\n- `post_reel_smart.py`: Add class constants, add two helper methods, refactor post() loop detection section",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify the file has no syntax errors and imports correctly\npython -c \"from post_reel_smart import SmartInstagramPoster; print('Import successful')\"\n```\n\n### 2. Method Existence Verification\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)\n\n# Verify new methods exist\nassert hasattr(poster, '_build_action_signature'), 'Missing _build_action_signature'\nassert hasattr(poster, '_detect_and_recover_from_loop'), 'Missing _detect_and_recover_from_loop'\nassert callable(poster._build_action_signature), '_build_action_signature not callable'\nassert callable(poster._detect_and_recover_from_loop), '_detect_and_recover_from_loop not callable'\n\n# Verify class constants exist\nassert hasattr(SmartInstagramPoster, 'LOOP_THRESHOLD'), 'Missing LOOP_THRESHOLD constant'\nassert hasattr(SmartInstagramPoster, 'MAX_LOOP_RECOVERIES'), 'Missing MAX_LOOP_RECOVERIES constant'\nassert SmartInstagramPoster.LOOP_THRESHOLD == 5, f'LOOP_THRESHOLD should be 5, got {SmartInstagramPoster.LOOP_THRESHOLD}'\nassert SmartInstagramPoster.MAX_LOOP_RECOVERIES == 2, f'MAX_LOOP_RECOVERIES should be 2, got {SmartInstagramPoster.MAX_LOOP_RECOVERIES}'\n\nprint('Method and constant verification passed')\n\"\n```\n\n### 3. Unit Test - _build_action_signature()\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)\n\n# Test basic action signature\naction = {'action': 'scroll_down'}\nelements = []\nsig = poster._build_action_signature(action, elements)\nassert sig == 'scroll_down', f'Expected scroll_down, got {sig}'\n\n# Test tap action with element\naction = {'action': 'tap', 'element_index': 0}\nelements = [{'center': (100, 200)}]\nsig = poster._build_action_signature(action, elements)\nassert sig == 'tap_100_200', f'Expected tap_100_200, got {sig}'\n\n# Test tap action with invalid index\naction = {'action': 'tap', 'element_index': 99}\nelements = [{'center': (100, 200)}]\nsig = poster._build_action_signature(action, elements)\nassert sig == 'tap', f'Expected tap (invalid index), got {sig}'\n\n# Test tap action without element_index\naction = {'action': 'tap'}\nelements = [{'center': (100, 200)}]\nsig = poster._build_action_signature(action, elements)\nassert sig == 'tap', f'Expected tap (no index), got {sig}'\n\nprint('_build_action_signature tests passed')\n\"\n```\n\n### 4. Unit Test - _detect_and_recover_from_loop() (no loop case)\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nfrom unittest.mock import MagicMock\n\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)\nposter.LOOP_THRESHOLD = 5\nposter.MAX_LOOP_RECOVERIES = 2\n\n# Test with fewer than threshold actions (no loop)\nrecent_actions = ['tap_100_200', 'tap_150_300', 'scroll_down']\nshould_abort, new_count, reset = poster._detect_and_recover_from_loop(recent_actions, 0, 5)\nassert not should_abort, 'Should not abort with few actions'\nassert new_count == 0, 'Recovery count should remain 0'\nassert not reset, 'Should not reset actions'\n\n# Test with different actions (no loop)\nrecent_actions = ['tap_100_200', 'scroll_down', 'tap_150_300', 'back', 'tap_200_400']\nshould_abort, new_count, reset = poster._detect_and_recover_from_loop(recent_actions, 0, 5)\nassert not should_abort, 'Should not abort with varied actions'\nassert new_count == 0, 'Recovery count should remain 0'\nassert not reset, 'Should not reset actions'\n\nprint('No-loop detection tests passed')\n\"\n```\n\n### 5. Unit Test - _detect_and_recover_from_loop() (loop with recovery)\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nfrom unittest.mock import MagicMock\nimport time\n\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)\nposter.LOOP_THRESHOLD = 5\nposter.MAX_LOOP_RECOVERIES = 2\nposter.press_key = MagicMock()\nposter.adb = MagicMock()\n\n# Patch time.sleep to speed up test\noriginal_sleep = time.sleep\ntime.sleep = lambda x: None\n\ntry:\n    # Test loop detected - first recovery\n    recent_actions = ['tap_100_200'] * 5\n    should_abort, new_count, reset = poster._detect_and_recover_from_loop(recent_actions, 0, 10)\n    assert not should_abort, 'Should not abort on first recovery'\n    assert new_count == 1, f'Recovery count should be 1, got {new_count}'\n    assert reset, 'Should reset actions after recovery'\n    assert poster.press_key.call_count == 5, f'Should press BACK 5 times, called {poster.press_key.call_count}'\n    assert poster.adb.call_count >= 2, 'Should call adb for force-stop and monkey'\n    \n    print('Loop recovery test passed')\nfinally:\n    time.sleep = original_sleep\n\"\n```\n\n### 6. Unit Test - _detect_and_recover_from_loop() (max recoveries exceeded)\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nfrom unittest.mock import MagicMock\n\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)\nposter.LOOP_THRESHOLD = 5\nposter.MAX_LOOP_RECOVERIES = 2\n\n# Test max recoveries exceeded - should abort\nrecent_actions = ['tap_100_200'] * 5\nshould_abort, new_count, reset = poster._detect_and_recover_from_loop(recent_actions, 2, 10)\nassert should_abort, 'Should abort when max recoveries exceeded'\nassert new_count == 3, f'Recovery count should be 3, got {new_count}'\n\nprint('Max recovery abort test passed')\n\"\n```\n\n### 7. Integration Test - Full post() method still works\n```bash\n# Verify post() method still exists and has proper structure\npython -c \"\nimport inspect\nfrom post_reel_smart import SmartInstagramPoster\n\n# Check post method signature\nsig = inspect.signature(SmartInstagramPoster.post)\nparams = list(sig.parameters.keys())\nexpected = ['self', 'video_path', 'caption', 'max_steps', 'humanize']\nassert params == expected, f'post() params changed: {params} != {expected}'\n\n# Check that post() uses the helper methods (by inspecting source)\nsource = inspect.getsource(SmartInstagramPoster.post)\nassert '_build_action_signature' in source, 'post() should call _build_action_signature'\nassert '_detect_and_recover_from_loop' in source, 'post() should call _detect_and_recover_from_loop'\nassert 'recent_actions' in source, 'post() should still track recent_actions'\nassert 'loop_recovery_count' in source, 'post() should still track loop_recovery_count'\n\nprint('Integration check passed')\n\"\n```\n\n### 8. Line Count Verification\n```bash\n# Verify the post() method is shorter after extraction\npython -c \"\nimport inspect\nfrom post_reel_smart import SmartInstagramPoster\n\nsource = inspect.getsource(SmartInstagramPoster.post)\nlines = [l for l in source.split('\\n') if l.strip()]\nprint(f'post() method: {len(lines)} non-empty lines')\n\n# The inline loop detection was ~35 lines, now ~10 lines\n# post() should be noticeably shorter\nassert len(lines) < 250, f'post() should be shorter after extraction, got {len(lines)} lines'\nprint('Line count check passed')\n\"\n```\n\n### 9. Live Test - Run with actual posting (manual verification)\n```bash\n# This should be run manually to verify behavior is unchanged\n# python post_reel_smart.py test_phone test_video.mp4 \"Test caption\"\n# Verify loop detection still works by observing logs during stuck states\n```",
        "status": "done",
        "dependencies": [
          "39",
          "40",
          "41"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:25:35.704Z"
      },
      {
        "id": "43",
        "title": "Extract humanize action handlers from humanize_before_post()",
        "description": "Extract the 4 inline action handlers (scroll_feed, view_story, scroll_reels, check_notifications) from humanize_before_post() method (lines 151-243) into dedicated private helper methods, reducing the 93-line method to a clean ~25-line dispatch loop.",
        "details": "## Current State Analysis\n\nThe `humanize_before_post()` method in `post_reel_smart.py` (lines 151-243, ~93 lines) contains 4 inline action handlers with nested loops:\n\n### Current Structure:\n```python\ndef humanize_before_post(self):\n    print(\"\\n[HUMANIZE] Performing random actions before posting...\")\n    actions_done = 0\n    max_actions = random.randint(2, 4)\n\n    for _ in range(max_actions):\n        action = random.choice(['scroll_feed', 'view_story', 'scroll_reels', 'check_notifications'])\n\n        if action == 'scroll_feed':\n            # ~11 lines of inline scroll logic (lines 160-170)\n            ...\n        elif action == 'view_story':\n            # ~19 lines of inline story viewing logic (lines 172-190)\n            ...\n        elif action == 'scroll_reels':\n            # ~29 lines of inline reels browsing logic (lines 192-220)\n            ...\n        elif action == 'check_notifications':\n            # ~15 lines of inline notification checking logic (lines 222-236)\n            ...\n```\n\n## Implementation Plan\n\n### Step 1: Extract `_humanize_scroll_feed()` (~15 lines)\n\n**Location:** Add after `random_delay()` method (around line 150)\n\n```python\ndef _humanize_scroll_feed(self):\n    \"\"\"Scroll through Instagram feed randomly.\"\"\"\n    print(\"  - Scrolling feed...\")\n    scroll_count = random.randint(1, 3)\n    for _ in range(scroll_count):\n        self.swipe(360, 900, 360, 400, random.randint(200, 400))\n        self.random_delay(1.0, 3.0)\n    # Scroll back up sometimes\n    if random.random() < 0.3:\n        self.swipe(360, 400, 360, 900, 300)\n        self.random_delay(0.5, 1.5)\n    return True  # Action always succeeds\n```\n\n### Step 2: Extract `_humanize_view_story()` (~25 lines)\n\n```python\ndef _humanize_view_story(self):\n    \"\"\"View Instagram stories randomly.\n    \n    Returns True if a story was viewed, False if no unseen stories found.\n    \"\"\"\n    print(\"  - Viewing a story...\")\n    elements, _ = self.dump_ui()\n    story_elements = [e for e in elements \n                      if 'story' in e.get('desc', '').lower() \n                      and 'unseen' in e.get('desc', '').lower()]\n    if not story_elements:\n        return False\n    \n    story = random.choice(story_elements)\n    self.tap(story['center'][0], story['center'][1])\n    view_time = random.uniform(3, 8)\n    print(f\"    Watching for {view_time:.1f}s...\")\n    time.sleep(view_time)\n    \n    # Tap through a few more stories sometimes\n    if random.random() < 0.5:\n        for _ in range(random.randint(1, 3)):\n            self.tap(650, 640)  # Tap right side to skip to next story\n            time.sleep(random.uniform(2, 5))\n    \n    # Go back\n    self.press_key('KEYCODE_BACK')\n    self.random_delay(1.0, 2.0)\n    return True\n```\n\n### Step 3: Extract `_humanize_scroll_reels()` (~30 lines)\n\n```python\ndef _humanize_scroll_reels(self):\n    \"\"\"Browse Instagram Reels tab randomly.\n    \n    Returns True if reels were browsed, False if Reels tab not found.\n    \"\"\"\n    print(\"  - Browsing reels...\")\n    elements, _ = self.dump_ui()\n    reels_tab = [e for e in elements \n                 if 'reels' in e.get('desc', '').lower() and e['clickable']]\n    if not reels_tab:\n        return False\n    \n    self.tap(reels_tab[0]['center'][0], reels_tab[0]['center'][1])\n    self.random_delay(2.0, 4.0)\n    \n    # Watch a few reels\n    for _ in range(random.randint(1, 3)):\n        watch_time = random.uniform(3, 10)\n        print(f\"    Watching reel for {watch_time:.1f}s...\")\n        time.sleep(watch_time)\n        # Sometimes double-tap to like\n        if random.random() < 0.15:\n            print(\"    Double-tap like!\")\n            self.tap(360, 640)\n            time.sleep(0.1)\n            self.tap(360, 640)\n            self.random_delay(0.5, 1.0)\n        # Swipe to next reel\n        self.swipe(360, 1000, 360, 300, 200)\n        self.random_delay(0.5, 1.5)\n    \n    # Go back to home\n    elements, _ = self.dump_ui()\n    home_tab = [e for e in elements \n                if 'home' in e.get('desc', '').lower() and e['clickable']]\n    if home_tab:\n        self.tap(home_tab[0]['center'][0], home_tab[0]['center'][1])\n    self.random_delay(1.0, 2.0)\n    return True\n```\n\n### Step 4: Extract `_humanize_check_notifications()` (~20 lines)\n\n```python\ndef _humanize_check_notifications(self):\n    \"\"\"Check Instagram notifications/activity tab randomly.\n    \n    Returns True if notifications were checked, False if tab not found.\n    \"\"\"\n    print(\"  - Checking notifications...\")\n    elements, _ = self.dump_ui()\n    notif_btn = [e for e in elements \n                 if ('notification' in e.get('desc', '').lower() \n                     or 'activity' in e.get('desc', '').lower()) \n                 and e['clickable']]\n    if not notif_btn:\n        return False\n    \n    self.tap(notif_btn[0]['center'][0], notif_btn[0]['center'][1])\n    self.random_delay(2.0, 4.0)\n    \n    # Scroll through notifications sometimes\n    if random.random() < 0.5:\n        self.swipe(360, 800, 360, 400, 300)\n        self.random_delay(1.0, 2.0)\n    \n    # Go back\n    self.press_key('KEYCODE_BACK')\n    self.random_delay(1.0, 2.0)\n    return True\n```\n\n### Step 5: Refactor `humanize_before_post()` to Clean Dispatch Loop (~25 lines)\n\n```python\ndef humanize_before_post(self):\n    \"\"\"Perform random human-like actions before posting.\"\"\"\n    print(\"\\n[HUMANIZE] Performing random actions before posting...\")\n    \n    # Map action names to handler methods\n    action_handlers = {\n        'scroll_feed': self._humanize_scroll_feed,\n        'view_story': self._humanize_view_story,\n        'scroll_reels': self._humanize_scroll_reels,\n        'check_notifications': self._humanize_check_notifications,\n    }\n    \n    actions_done = 0\n    max_actions = random.randint(2, 4)\n\n    for _ in range(max_actions):\n        action = random.choice(list(action_handlers.keys()))\n        handler = action_handlers[action]\n        \n        if handler():\n            actions_done += 1\n        \n        if actions_done >= max_actions:\n            break\n\n    print(f\"[HUMANIZE] Completed {actions_done} random actions\")\n    # Small delay before proceeding\n    self.random_delay(1.0, 3.0)\n```\n\n## Key Design Decisions\n\n1. **Return values for success tracking**: Each helper returns `True` if the action was performed, `False` if UI elements weren't found. This preserves the original behavior where `actions_done` only increments on successful actions.\n\n2. **Naming convention**: Using `_humanize_*` prefix to:\n   - Indicate private methods (underscore prefix)\n   - Group them logically with the humanization feature\n   - Make them easy to find via search/autocomplete\n\n3. **No parameter passing**: All helpers use `self` to access `dump_ui()`, `tap()`, `swipe()`, `press_key()`, and `random_delay()`. This keeps signatures clean since all state is on the instance.\n\n4. **Preserve exact behavior**: The random delays, tap coordinates, and conditional logic are preserved exactly as-is to avoid changing humanization behavior.\n\n## File Changes Summary\n\n| Change | Lines Affected |\n|--------|----------------|\n| Add `_humanize_scroll_feed()` | Insert ~15 lines after line 149 |\n| Add `_humanize_view_story()` | Insert ~25 lines |\n| Add `_humanize_scroll_reels()` | Insert ~30 lines |\n| Add `_humanize_check_notifications()` | Insert ~20 lines |\n| Replace `humanize_before_post()` body | Lines 151-243 → ~25 lines |\n\n**Net effect**: From 93 lines to ~25 lines in main method, with 4 focused helper methods (~90 lines total). Total code grows slightly but complexity per method decreases significantly.",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify the file has no syntax errors and imports correctly\npython -c \"from post_reel_smart import SmartInstagramPoster; print('Import successful')\"\n```\n\n### 2. Method Existence Verification\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)\nmethods = ['_humanize_scroll_feed', '_humanize_view_story', '_humanize_scroll_reels', '_humanize_check_notifications', 'humanize_before_post']\nfor m in methods:\n    assert hasattr(poster, m), f'Missing method: {m}'\n    assert callable(getattr(poster, m)), f'Not callable: {m}'\nprint('All humanize methods exist and are callable')\n\"\n```\n\n### 3. Method Signature Verification\n```bash\npython -c \"\nimport inspect\nfrom post_reel_smart import SmartInstagramPoster\n\n# All humanize helpers should take only self (no extra params)\nfor name in ['_humanize_scroll_feed', '_humanize_view_story', '_humanize_scroll_reels', '_humanize_check_notifications']:\n    method = getattr(SmartInstagramPoster, name)\n    sig = inspect.signature(method)\n    params = list(sig.parameters.keys())\n    assert params == ['self'], f'{name} should only have self param, got: {params}'\nprint('All helper methods have correct (self-only) signature')\n\"\n```\n\n### 4. Return Type Verification (Static Analysis)\n```bash\n# Check that helpers return bool values\ngrep -A 2 \"def _humanize_\" post_reel_smart.py | grep \"return True\\|return False\"\n# Expected: Should see return True/False in each helper\n```\n\n### 5. Main Method Structure Verification\n```bash\npython -c \"\nimport inspect\nfrom post_reel_smart import SmartInstagramPoster\n\n# Get source of humanize_before_post\nsource = inspect.getsource(SmartInstagramPoster.humanize_before_post)\nlines = source.strip().split('\\n')\nprint(f'humanize_before_post() has {len(lines)} lines')\nassert len(lines) <= 30, f'Expected ~25 lines, got {len(lines)}'\n\n# Should contain dispatch logic, not inline handlers\nassert 'action_handlers' in source or 'handler()' in source, 'Should use dispatch pattern'\nassert 'for _ in range(scroll_count)' not in source, 'Should not have inline scroll loop'\nprint('Main method is properly refactored to dispatch pattern')\n\"\n```\n\n### 6. Live Behavior Test (Integration)\n```bash\n# Run with humanize flag on a test account to verify behavior unchanged\n# Note: This requires a real Geelark phone to be available\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nimport unittest.mock as mock\n\n# Create poster with mocked connection\nposter = SmartInstagramPoster('test_phone')\n\n# Mock the UI controller methods to avoid needing real device\nposter._ui_controller = mock.MagicMock()\nposter._conn.appium_driver = mock.MagicMock()\n\n# Mock dump_ui to return elements that will trigger actions\nposter.dump_ui = mock.MagicMock(return_value=([\n    {'desc': 'unseen story', 'text': '', 'center': (100, 100), 'clickable': True},\n    {'desc': 'reels', 'text': '', 'center': (200, 200), 'clickable': True},\n    {'desc': 'notification', 'text': '', 'center': (300, 300), 'clickable': True},\n    {'desc': 'home', 'text': '', 'center': (50, 50), 'clickable': True},\n], ''))\n\n# Run humanize - should call helper methods\nimport random\nrandom.seed(42)  # Deterministic for testing\nposter.humanize_before_post()\n\n# Verify swipe/tap/press_key were called (humanization happened)\nassert poster._ui_controller.swipe.called or poster._ui_controller.tap.called, 'Humanization should have done something'\nprint('Humanize behavior test passed')\n\"\n```\n\n### 7. Verify Original Behavior Preserved\n```bash\n# Check that random selection and max_actions limit are preserved\ngrep -A 5 \"def humanize_before_post\" post_reel_smart.py | grep -E \"random.choice|max_actions|random.randint\"\n# Expected: Should see random.choice for action selection and random.randint(2, 4) for max_actions\n```\n\n### 8. Full Integration Test (Optional - Requires Live Phone)\n```bash\n# Test with real phone to verify humanization still works\n# Use --humanize flag if posting_scheduler supports it, or test directly:\npython -c \"\n# Only run this with a real test account\n# python post_reel_smart.py test_account test_video.mp4 'test caption' --humanize\nprint('Skip live test - run manually with real phone')\n\"\n```",
        "status": "done",
        "dependencies": [
          "39",
          "40"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:26:39.314Z"
      },
      {
        "id": "44",
        "title": "Create PhoneConnector helper for setup scripts",
        "description": "Create a lightweight PhoneConnector class that encapsulates the find→start→enable ADB→connect flow for use by setup scripts, eliminating ~70 lines of duplicated setup_phone() logic in setup_adbkeyboard.py and setup_clipboard_helper.py.",
        "details": "## Current State Analysis\n\nBoth `setup_adbkeyboard.py` and `setup_clipboard_helper.py` contain nearly identical `setup_phone()` logic (lines 42-99 in each file):\n\n**Duplicated pattern in both scripts:**\n```python\n# 1. Find phone (lines 50-64)\nfor page in range(1, 10):\n    result = client.list_phones(page=page, page_size=100)\n    for p in result[\"items\"]:\n        if p[\"serialName\"] == phone_name:\n            phone = p\n            break\n\n# 2. Start phone if needed (lines 69-80)\nif phone[\"status\"] != 0:\n    client.start_phone(phone_id)\n    for i in range(60):\n        time.sleep(2)\n        status = client.get_phone_status([phone_id])\n        ...\n\n# 3. Enable ADB and connect (lines 82-99)\nclient.enable_adb(phone_id)\nadb_info = client.get_adb_info(phone_id)\ndevice = f\"{adb_info['ip']}:{adb_info['port']}\"\nsubprocess.run([ADB_PATH, \"connect\", device])\nadb(device, f\"glogin {password}\")\n```\n\n## Architecture Decision\n\n**Why not use DeviceConnectionManager?**\n- `DeviceConnectionManager` (device_connection.py) is designed for the full posting workflow with Appium\n- It has Appium-specific dependencies (`from appium import webdriver`)\n- Setup scripts don't need Appium - they only need ADB access\n- A lightweight helper avoids pulling in unnecessary dependencies\n\n**Two-tier architecture:**\n- **PhoneConnector** (new): Lightweight ADB-only flow for setup scripts\n- **DeviceConnectionManager** (existing): Full Appium workflow for posting\n\n## Implementation Plan\n\n### 1. Create `phone_connector.py`\n\n```python\n\"\"\"\nLightweight phone connector for setup scripts.\n\nThis provides the basic find→start→ADB enable→connect flow without Appium.\nFor full posting workflow with Appium, use DeviceConnectionManager instead.\n\"\"\"\nimport subprocess\nimport time\nfrom typing import Optional, Tuple\nfrom dataclasses import dataclass\n\nfrom config import Config\nfrom geelark_client import GeelarkClient\n\nADB_PATH = Config.ADB_PATH\n\n\n@dataclass\nclass PhoneConnection:\n    \"\"\"Result of a successful phone connection.\"\"\"\n    client: GeelarkClient\n    phone_id: str\n    phone_name: str\n    device_string: str  # \"ip:port\" format for ADB\n    password: str\n\n\nclass PhoneConnectorError(Exception):\n    \"\"\"Raised when phone connection fails.\"\"\"\n    pass\n\n\nclass PhoneConnector:\n    \"\"\"\n    Lightweight connector for Geelark phones - ADB only, no Appium.\n    \n    For setup scripts that need ADB access but not Appium.\n    For full posting workflow, use DeviceConnectionManager instead.\n    \"\"\"\n    \n    def __init__(self, geelark_client: GeelarkClient = None):\n        \"\"\"\n        Initialize the phone connector.\n        \n        Args:\n            geelark_client: Optional GeelarkClient instance for dependency injection.\n        \"\"\"\n        self.client = geelark_client or GeelarkClient()\n    \n    def find_phone(self, phone_name: str) -> Tuple[str, dict]:\n        \"\"\"\n        Find a phone by name in Geelark.\n        \n        Args:\n            phone_name: The serialName of the phone to find.\n            \n        Returns:\n            Tuple of (phone_id, phone_info_dict)\n            \n        Raises:\n            PhoneConnectorError: If phone not found.\n        \"\"\"\n        print(f\"Finding phone: {phone_name}\")\n        \n        for page in range(1, 10):\n            result = self.client.list_phones(page=page, page_size=100)\n            for p in result[\"items\"]:\n                if p[\"serialName\"] == phone_name:\n                    phone_id = p[\"id\"]\n                    print(f\"  Found: {p['serialName']} (Status: {p['status']})\")\n                    return phone_id, p\n            if len(result[\"items\"]) < 100:\n                break\n        \n        raise PhoneConnectorError(f\"Phone not found: {phone_name}\")\n    \n    def ensure_running(self, phone_id: str, phone_status: int) -> bool:\n        \"\"\"\n        Ensure the phone is running, starting it if necessary.\n        \n        Args:\n            phone_id: The Geelark phone ID.\n            phone_status: Current status (0=running, other=stopped).\n            \n        Returns:\n            True when phone is ready.\n        \"\"\"\n        if phone_status == 0:\n            return True  # Already running\n        \n        print(\"  Starting phone...\")\n        self.client.start_phone(phone_id)\n        \n        for i in range(60):\n            time.sleep(2)\n            status = self.client.get_phone_status([phone_id])\n            items = status.get(\"successDetails\", [])\n            if items and items[0].get(\"status\") == 0:\n                print(f\"    Ready after {(i+1)*2}s\")\n                time.sleep(5)  # Extra stabilization time\n                return True\n        \n        raise PhoneConnectorError(f\"Phone {phone_id} failed to start after 120s\")\n    \n    def connect_adb(self, phone_id: str) -> Tuple[str, str]:\n        \"\"\"\n        Enable ADB and establish connection.\n        \n        Args:\n            phone_id: The Geelark phone ID.\n            \n        Returns:\n            Tuple of (device_string, password) where device_string is \"ip:port\".\n        \"\"\"\n        print(\"  Enabling ADB...\")\n        self.client.enable_adb(phone_id)\n        time.sleep(5)\n        \n        adb_info = self.client.get_adb_info(phone_id)\n        device = f\"{adb_info['ip']}:{adb_info['port']}\"\n        password = adb_info['pwd']\n        \n        print(f\"  Connecting to {device}...\")\n        subprocess.run([ADB_PATH, \"connect\", device], capture_output=True)\n        time.sleep(1)\n        \n        # glogin authentication\n        result = subprocess.run(\n            [ADB_PATH, \"-s\", device, \"shell\", f\"glogin {password}\"],\n            capture_output=True, timeout=30,\n            encoding='utf-8', errors='replace'\n        )\n        login_result = result.stdout.strip() if result.stdout else \"\"\n        print(f\"  Login: {login_result or 'OK'}\")\n        \n        return device, password\n    \n    def setup_for_adb(self, phone_name: str) -> PhoneConnection:\n        \"\"\"\n        Complete setup flow: find → start → enable ADB → connect.\n        \n        This is the main entry point for setup scripts.\n        \n        Args:\n            phone_name: The serialName of the phone to connect.\n            \n        Returns:\n            PhoneConnection with all connection details.\n            \n        Raises:\n            PhoneConnectorError: On any failure.\n        \"\"\"\n        phone_id, phone_info = self.find_phone(phone_name)\n        self.ensure_running(phone_id, phone_info[\"status\"])\n        device, password = self.connect_adb(phone_id)\n        \n        return PhoneConnection(\n            client=self.client,\n            phone_id=phone_id,\n            phone_name=phone_name,\n            device_string=device,\n            password=password\n        )\n```\n\n### 2. Update `setup_adbkeyboard.py`\n\nReplace lines 42-99 with:\n\n```python\ndef setup_phone(phone_name):\n    \"\"\"Setup ADBKeyboard on a single phone\"\"\"\n    from phone_connector import PhoneConnector, PhoneConnectorError\n    \n    print(f\"\\n{'='*50}\")\n    print(f\"Setting up ADBKeyboard on: {phone_name}\")\n    print('='*50)\n    \n    try:\n        connector = PhoneConnector()\n        conn = connector.setup_for_adb(phone_name)\n        device = conn.device_string\n    except PhoneConnectorError as e:\n        print(f\"  ERROR: {e}\")\n        return False\n    \n    # Force uninstall first (clean slate)\n    print(\"  Uninstalling existing ADBKeyboard (if any)...\")\n    uninstall_result = adb(device, \"pm uninstall com.android.adbkeyboard\")\n    print(f\"    {uninstall_result or 'Not installed'}\")\n    time.sleep(1)\n    \n    # ... rest of ADBKeyboard-specific logic (lines 107-131)\n```\n\n### 3. Update `setup_clipboard_helper.py`\n\nReplace lines 42-99 with:\n\n```python\ndef setup_phone(phone_name):\n    \"\"\"Setup ClipboardHelper on a single phone\"\"\"\n    from phone_connector import PhoneConnector, PhoneConnectorError\n    \n    print(f\"\\n{'='*50}\")\n    print(f\"Setting up ClipboardHelper on: {phone_name}\")\n    print('='*50)\n    \n    try:\n        connector = PhoneConnector()\n        conn = connector.setup_for_adb(phone_name)\n        device = conn.device_string\n    except PhoneConnectorError as e:\n        print(f\"  ERROR: {e}\")\n        return False\n    \n    # Check if already installed\n    print(\"  Checking if ClipboardHelper is installed...\")\n    packages = adb(device, \"pm list packages | grep geelark.clipboard\")\n    # ... rest of ClipboardHelper-specific logic (lines 104-129)\n```\n\n## Key Design Decisions\n\n1. **Separate module, not in DeviceConnectionManager**: Keeps Appium dependency isolated\n2. **PhoneConnection dataclass**: Clean return type with all connection details\n3. **PhoneConnectorError exception**: Specific error handling without polluting DeviceConnectionError\n4. **Dependency injection**: Optional GeelarkClient parameter for testing\n5. **Idempotent**: Can be called multiple times safely (uses existing running phone)",
        "testStrategy": "## Test Strategy\n\n### 1. Unit Test - Module imports successfully\n```bash\npython -c \"from phone_connector import PhoneConnector, PhoneConnection, PhoneConnectorError; print('Import OK')\"\n```\n\n### 2. Unit Test - PhoneConnector instantiation\n```bash\npython -c \"\nfrom phone_connector import PhoneConnector\nconnector = PhoneConnector()\nprint(f'Client type: {type(connector.client).__name__}')\nprint('Instantiation OK')\n\"\n```\n\n### 3. Integration Test - Find phone (read-only, safe)\n```bash\npython -c \"\nfrom phone_connector import PhoneConnector\nconnector = PhoneConnector()\n\n# Use a known test phone name from accounts.txt\nphone_id, info = connector.find_phone('reelwisdompod_')\nprint(f'Found: {info[\\\"serialName\\\"]} (ID: {phone_id})')\n\"\n```\n\n### 4. Integration Test - Full setup_for_adb flow\n```bash\n# Test with a real phone (will start if needed - costs minutes)\npython -c \"\nfrom phone_connector import PhoneConnector\nconnector = PhoneConnector()\nconn = connector.setup_for_adb('reelwisdompod_')\nprint(f'Connected to: {conn.device_string}')\nprint(f'Phone ID: {conn.phone_id}')\n\"\n```\n\n### 5. End-to-End Test - setup_adbkeyboard.py still works\n```bash\n# Test that the refactored script behaves identically\npython setup_adbkeyboard.py reelwisdompod_\n\n# Verify ADBKeyboard is enabled\nadb -s <device> shell settings get secure default_input_method\n# Should show: com.android.adbkeyboard/.AdbIME\n```\n\n### 6. End-to-End Test - setup_clipboard_helper.py still works\n```bash\n# Test that the refactored script behaves identically\npython setup_clipboard_helper.py reelwisdompod_\n\n# Verify ClipboardHelper is installed\nadb -s <device> shell pm list packages | grep clipboard\n# Should show: package:com.geelark.clipboard\n```\n\n### 7. Verify Code Reduction\n```bash\n# Before: Count lines in setup_phone() functions\n# setup_adbkeyboard.py: lines 42-131 = ~90 lines\n# setup_clipboard_helper.py: lines 42-129 = ~88 lines\n\n# After: Each setup_phone() should be ~30-40 lines (APK-specific logic only)\n# phone_connector.py: ~120 lines (shared by all setup scripts)\n# Net reduction: ~60 lines duplicated code eliminated\n```\n\n### 8. Verify No Appium Dependency\n```bash\n# PhoneConnector should not import Appium\npython -c \"\nimport ast\nwith open('phone_connector.py', 'r') as f:\n    tree = ast.parse(f.read())\nimports = [node.names[0].name for node in ast.walk(tree) if isinstance(node, ast.Import)]\nfrom_imports = [node.module for node in ast.walk(tree) if isinstance(node, ast.ImportFrom)]\nall_imports = imports + [m for m in from_imports if m]\nassert 'appium' not in str(all_imports).lower(), 'PhoneConnector should not import Appium!'\nprint('No Appium dependency - OK')\n\"\n```\n\n### 9. Error Handling Test\n```bash\n# Test with non-existent phone\npython -c \"\nfrom phone_connector import PhoneConnector, PhoneConnectorError\nconnector = PhoneConnector()\ntry:\n    connector.find_phone('nonexistent_phone_12345')\n    print('ERROR: Should have raised PhoneConnectorError')\nexcept PhoneConnectorError as e:\n    print(f'Correctly raised PhoneConnectorError: {e}')\n\"\n```\n\n### 10. Stop phone after testing (CRITICAL)\n```bash\n# ALWAYS stop phones after testing to save billing minutes\npython -c \"\nfrom geelark_client import GeelarkClient\nclient = GeelarkClient()\nfor page in range(1, 20):\n    result = client.list_phones(page=page, page_size=100)\n    for phone in result['items']:\n        if phone['status'] == 1:\n            client.stop_phone(phone['id'])\n            print(f'STOPPED: {phone[\\\"serialName\\\"]}')\n    if len(result['items']) < 100:\n        break\n\"\n```",
        "status": "done",
        "dependencies": [
          "25",
          "31",
          "37"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:35:07.353Z"
      },
      {
        "id": "45",
        "title": "Consolidate ADB helper functions into DeviceConnectionManager",
        "description": "Move the standalone ADB helper functions (wait_for_adb, ensure_device_alive, reconnect_adb) from parallel_worker.py into DeviceConnectionManager as class methods, providing a single source for all ADB-related operations and eliminating ~105 lines of duplicated code.",
        "details": "## Current State Analysis\n\n### Duplicated Functions in parallel_worker.py (lines 69-173):\n```python\n# wait_for_adb(device_id, timeout=90, logger=None) -> bool (lines 69-107)\n# - Polls ADB devices list until device appears\n# - Returns True when device shows as \"device\" (not \"offline\")\n# - Used before Appium session creation\n\n# ensure_device_alive(device_id, logger=None) -> bool (lines 110-139)\n# - Single check if device is in ADB devices list\n# - Returns True if device is present and not offline\n# - Used for health checks during job execution\n\n# reconnect_adb(device_id, logger=None) -> bool (lines 142-173)\n# - Disconnects and reconnects ADB to device\n# - Returns True if reconnection successful\n# - Used for recovery from dropped connections\n```\n\n### Similar Methods Already in DeviceConnectionManager:\n- `_wait_for_device_ready()` (lines 198-218) - similar to wait_for_adb but instance-based\n- `verify_adb_connection()` (lines 238-246) - similar to ensure_device_alive\n- `reconnect_adb()` (lines 248-278) - instance-based, fetches password from Geelark\n\n## Implementation Plan\n\n### Step 1: Add Static/Class Methods to DeviceConnectionManager\n\nAdd these as **static methods** (don't require self) for device-agnostic operations:\n\n```python\n# device_connection.py - add after existing imports\n\n@staticmethod\ndef wait_for_device(device_id: str, timeout: int = 90, logger=None) -> bool:\n    \"\"\"\n    Wait for a device to appear in ADB devices list.\n    \n    This is the explicit ADB readiness gate - call AFTER starting phone\n    but BEFORE creating Appium session.\n    \n    Args:\n        device_id: Device identifier (e.g., \"192.168.1.100:5555\")\n        timeout: Maximum seconds to wait (default 90)\n        logger: Optional logger for status updates\n    \n    Returns:\n        True if device is ready, False on timeout\n    \"\"\"\n    deadline = time.time() + timeout\n    check_count = 0\n    \n    while time.time() < deadline:\n        check_count += 1\n        try:\n            result = subprocess.run(\n                [ADB_PATH, \"devices\"],\n                capture_output=True, text=True, timeout=10\n            )\n            for line in result.stdout.splitlines():\n                if device_id in line and \"device\" in line and \"offline\" not in line:\n                    if logger:\n                        logger.info(f\"ADB ready for {device_id} (took {check_count * 2}s)\")\n                    return True\n        except Exception as e:\n            if logger:\n                logger.debug(f\"ADB check error: {e}\")\n        \n        time.sleep(2)\n    \n    if logger:\n        logger.error(f\"ADB timeout ({timeout}s) waiting for {device_id}\")\n    return False\n\n@staticmethod\ndef is_device_alive(device_id: str, logger=None) -> bool:\n    \"\"\"\n    Check if a device is present in ADB devices list.\n    \n    Call periodically during job execution to detect device loss.\n    \n    Args:\n        device_id: Device identifier (e.g., \"192.168.1.100:5555\")\n        logger: Optional logger for status updates\n    \n    Returns:\n        True if device is alive, False if lost\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [ADB_PATH, \"devices\"],\n            capture_output=True, text=True, timeout=10\n        )\n        for line in result.stdout.splitlines():\n            if device_id in line and \"device\" in line and \"offline\" not in line:\n                return True\n        if logger:\n            logger.warning(f\"Device {device_id} not found in ADB devices\")\n        return False\n    except Exception as e:\n        if logger:\n            logger.warning(f\"ADB devices check failed: {e}\")\n        return False\n\n@staticmethod\ndef reconnect_device(device_id: str, logger=None) -> bool:\n    \"\"\"\n    Attempt to reconnect an ADB device (disconnect + connect).\n    \n    Args:\n        device_id: Device identifier (e.g., \"192.168.1.100:5555\")\n        logger: Optional logger for status updates\n    \n    Returns:\n        True if reconnect successful, False otherwise\n    \"\"\"\n    try:\n        # First disconnect\n        subprocess.run([ADB_PATH, \"disconnect\", device_id],\n                      capture_output=True, timeout=10)\n        \n        # Then reconnect\n        result = subprocess.run([ADB_PATH, \"connect\", device_id],\n                               capture_output=True, text=True, timeout=30)\n        \n        if \"connected\" in result.stdout.lower():\n            if logger:\n                logger.info(f\"Reconnected ADB to {device_id}\")\n            return True\n        else:\n            if logger:\n                logger.warning(f\"ADB reconnect failed: {result.stdout}\")\n            return False\n    except Exception as e:\n        if logger:\n            logger.warning(f\"ADB reconnect error: {e}\")\n        return False\n```\n\n### Step 2: Refactor Existing Instance Methods to Use Static Methods\n\nUpdate existing instance methods to delegate to the new static methods:\n\n```python\n# Update _wait_for_device_ready to use wait_for_device\ndef _wait_for_device_ready(self, max_attempts: int = 30) -> None:\n    \"\"\"Wait for device to appear in ADB devices list.\"\"\"\n    timeout = max_attempts * 2  # Each check is ~2 seconds\n    if not DeviceConnectionManager.wait_for_device(self.device, timeout):\n        raise Exception(f\"Device {self.device} never appeared in ADB devices list after {timeout}s\")\n\n# Update verify_adb_connection to use is_device_alive\ndef verify_adb_connection(self) -> bool:\n    \"\"\"Verify device is still connected via ADB.\"\"\"\n    return DeviceConnectionManager.is_device_alive(self.device)\n```\n\n### Step 3: Update parallel_worker.py to Import and Use DeviceConnectionManager\n\n```python\n# parallel_worker.py - change imports\nfrom device_connection import DeviceConnectionManager\n\n# Remove the three standalone functions (lines 69-173)\n# Replace all usages:\n\n# Old: wait_for_adb(device_id, timeout, logger)\n# New: DeviceConnectionManager.wait_for_device(device_id, timeout, logger)\n\n# Old: ensure_device_alive(device_id, logger)  \n# New: DeviceConnectionManager.is_device_alive(device_id, logger)\n\n# Old: reconnect_adb(device_id, logger)\n# New: DeviceConnectionManager.reconnect_device(device_id, logger)\n```\n\n### Step 4: Update Any Other Files Using These Functions\n\nSearch for other files importing these functions and update them similarly.\n\n## Key Design Decisions\n\n1. **Static methods vs instance methods**: Using static methods because these operations don't require instance state - they work on any device ID. This allows parallel_worker.py to call them without instantiating DeviceConnectionManager.\n\n2. **Naming conventions**:\n   - `wait_for_device()` - more general than `wait_for_adb()` \n   - `is_device_alive()` - clearer than `ensure_device_alive()`\n   - `reconnect_device()` - consistent with existing naming\n\n3. **Logger parameter**: Keep optional logger parameter for worker process logging integration.\n\n4. **Backward compatibility**: Existing instance methods (`verify_adb_connection`, `reconnect_adb`) continue to work but delegate to static methods internally.",
        "testStrategy": "## Test Strategy\n\n### 1. Verify Static Methods Import and Work Standalone\n```bash\npython -c \"\nfrom device_connection import DeviceConnectionManager\n\n# Test that static methods exist and are callable\nprint('wait_for_device:', callable(DeviceConnectionManager.wait_for_device))\nprint('is_device_alive:', callable(DeviceConnectionManager.is_device_alive))\nprint('reconnect_device:', callable(DeviceConnectionManager.reconnect_device))\n\n# Test with fake device (should return False, not crash)\nresult = DeviceConnectionManager.is_device_alive('192.168.99.99:5555')\nprint(f'is_device_alive for fake device: {result}')\nassert result == False, 'Should return False for non-existent device'\nprint('All static method tests passed!')\n\"\n```\n\n### 2. Verify parallel_worker.py Imports Successfully\n```bash\npython -c \"\nfrom parallel_worker import run_worker, setup_worker_logging\nfrom device_connection import DeviceConnectionManager\nprint('Import successful - no standalone ADB functions should exist')\n\n# Verify old functions don't exist at module level\nimport parallel_worker\nassert not hasattr(parallel_worker, 'wait_for_adb'), 'wait_for_adb should be removed'\nassert not hasattr(parallel_worker, 'ensure_device_alive'), 'ensure_device_alive should be removed'\nassert not hasattr(parallel_worker, 'reconnect_adb'), 'reconnect_adb should be removed'\nprint('Old functions properly removed!')\n\"\n```\n\n### 3. Verify Instance Methods Still Work\n```bash\npython -c \"\nfrom device_connection import DeviceConnectionManager\n\n# Create instance (won't connect, just verify method exists)\nmanager = DeviceConnectionManager('test_phone')\n\n# Verify instance methods exist and are callable\nassert callable(manager.verify_adb_connection), 'Instance method should exist'\nprint('Instance methods verified!')\n\"\n```\n\n### 4. Line Count Verification\n```bash\n# Before: Count lines in parallel_worker.py\nwc -l parallel_worker.py\n# Should be ~550 lines\n\n# After: Should be ~445 lines (105 lines removed)\n# The functions removed span lines 69-173 (105 lines)\n```\n\n### 5. Integration Test - Run Worker Startup\n```bash\n# Run parallel_worker.py in dry-run mode to verify imports work\npython parallel_worker.py --worker-id 0 --help\n# Should show help without import errors\n```\n\n### 6. Full Integration Test (with actual phones)\n```bash\n# Test full posting flow works with consolidated ADB operations\npython parallel_orchestrator.py --workers 1 --run\n\n# Monitor logs for:\n# - \"ADB ready for\" messages (from wait_for_device)\n# - No import errors\n# - Jobs complete successfully\n```\n\n### 7. Verify Code Deduplication\n```bash\n# Search for duplicate ADB patterns\ngrep -n \"ADB_PATH.*devices\" parallel_worker.py device_connection.py\n# Should only find matches in device_connection.py, not parallel_worker.py\n```",
        "status": "done",
        "dependencies": [
          "40",
          "25",
          "37"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:37:56.832Z"
      },
      {
        "id": "46",
        "title": "Convert _classify_error to dict-based pattern lookup table",
        "description": "Refactor the _classify_error() method in progress_tracker.py from a 5-condition if/elif chain to a Strategy pattern using an ERROR_PATTERNS dict that maps error types to lists of matching patterns, improving maintainability and extensibility.",
        "details": "## Current State Analysis\n\nThe `_classify_error()` method in `progress_tracker.py` (lines 541-560) uses an if/elif chain with 5 conditions:\n\n```python\ndef _classify_error(self, error: str) -> str:\n    error_lower = error.lower() if error else ''\n    \n    if 'suspended' in error_lower or 'account has been suspended' in error_lower:\n        return 'suspended'\n    elif 'captcha' in error_lower or 'verify' in error_lower:\n        return 'captcha'\n    elif 'log in' in error_lower or 'logged out' in error_lower or 'sign up' in error_lower:\n        return 'loggedout'\n    elif 'action blocked' in error_lower or 'try again later' in error_lower:\n        return 'actionblocked'\n    elif 'banned' in error_lower or 'disabled' in error_lower:\n        return 'banned'\n    else:\n        return ''  # Retryable\n```\n\n## Implementation Plan\n\n### Step 1: Define ERROR_PATTERNS class constant\n\nAdd a new class constant after `NON_RETRYABLE_ERRORS` (line 93):\n\n```python\n# Non-retryable error types - these failures should not be retried\nNON_RETRYABLE_ERRORS = {'suspended', 'captcha', 'loggedout', 'actionblocked', 'banned'}\n\n# Error classification patterns - maps error_type to list of substrings to match\n# Order matters: first matching error type wins\nERROR_PATTERNS = {\n    'suspended': ['suspended', 'account has been suspended'],\n    'captcha': ['captcha', 'verify'],\n    'loggedout': ['log in', 'logged out', 'sign up'],\n    'actionblocked': ['action blocked', 'try again later'],\n    'banned': ['banned', 'disabled'],\n}\n```\n\n### Step 2: Refactor _classify_error() method\n\nReplace the if/elif chain with a dict-based lookup:\n\n```python\ndef _classify_error(self, error: str) -> str:\n    \"\"\"\n    Classify an error message into an error type.\n\n    Uses ERROR_PATTERNS dict for pattern matching. Returns the first\n    matching error type from NON_RETRYABLE_ERRORS, or empty string\n    for retryable errors.\n    \"\"\"\n    if not error:\n        return ''\n    \n    error_lower = error.lower()\n    \n    for error_type, patterns in self.ERROR_PATTERNS.items():\n        if any(pattern in error_lower for pattern in patterns):\n            return error_type\n    \n    return ''  # Retryable\n```\n\n### Step 3: Ensure consistency between ERROR_PATTERNS and NON_RETRYABLE_ERRORS\n\nAdd a validation assertion in `__init__` (optional but recommended):\n\n```python\ndef __init__(self, progress_file: str, lock_timeout: float = 30.0):\n    # Validate ERROR_PATTERNS keys match NON_RETRYABLE_ERRORS\n    assert set(self.ERROR_PATTERNS.keys()) == self.NON_RETRYABLE_ERRORS, \\\n        f\"ERROR_PATTERNS keys must match NON_RETRYABLE_ERRORS\"\n    # ... rest of __init__\n```\n\n## Benefits\n\n1. **Easier to add new error types**: Add a single line to ERROR_PATTERNS dict\n2. **Self-documenting**: The dict clearly shows all patterns for each error type\n3. **Maintainable**: Patterns are grouped by error type, not scattered in elif branches\n4. **DRY**: Error types are defined once in ERROR_PATTERNS, used via iteration\n5. **Testable**: Can easily test individual patterns without mocking the whole method\n\n## Location\n\n- File: `progress_tracker.py`\n- Lines to modify: 93-97 (add ERROR_PATTERNS), 541-560 (refactor method)",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\npython -c \"from progress_tracker import ProgressTracker; print('Import successful')\"\n```\n\n### 2. Verify ERROR_PATTERNS Constant Exists\n```bash\npython -c \"\nfrom progress_tracker import ProgressTracker\nprint('ERROR_PATTERNS:', ProgressTracker.ERROR_PATTERNS)\nprint('Keys match NON_RETRYABLE_ERRORS:', set(ProgressTracker.ERROR_PATTERNS.keys()) == ProgressTracker.NON_RETRYABLE_ERRORS)\n\"\n```\n\n### 3. Unit Test All Error Classifications\n```bash\npython -c \"\nfrom progress_tracker import ProgressTracker\n\ntracker = ProgressTracker('test_progress.csv')\n\n# Test each error type with various patterns\ntest_cases = [\n    # Suspended\n    ('Your account has been suspended', 'suspended'),\n    ('Account suspended', 'suspended'),\n    \n    # Captcha\n    ('Please complete the captcha', 'captcha'),\n    ('Verify your identity', 'captcha'),\n    \n    # Logged out\n    ('Please log in to continue', 'loggedout'),\n    ('You have been logged out', 'loggedout'),\n    ('Sign up to continue', 'loggedout'),\n    \n    # Action blocked\n    ('Action blocked. Please try again later', 'actionblocked'),\n    ('Try again later', 'actionblocked'),\n    \n    # Banned\n    ('Your account has been banned', 'banned'),\n    ('Account disabled for violating terms', 'banned'),\n    \n    # Retryable (empty string)\n    ('Connection timeout', ''),\n    ('Network error', ''),\n    ('', ''),\n    (None, ''),\n]\n\nall_passed = True\nfor error_msg, expected in test_cases:\n    result = tracker._classify_error(error_msg)\n    status = '✓' if result == expected else '✗'\n    if result != expected:\n        all_passed = False\n    print(f'{status} \\\"{error_msg}\\\" -> \\\"{result}\\\" (expected \\\"{expected}\\\")')\n\nprint(f'\\nAll tests passed: {all_passed}')\n\n# Cleanup\nimport os\nif os.path.exists('test_progress.csv'):\n    os.remove('test_progress.csv')\nif os.path.exists('test_progress.csv.lock'):\n    os.remove('test_progress.csv.lock')\n\"\n```\n\n### 4. Integration Test with update_job_status()\n```bash\npython -c \"\nfrom progress_tracker import ProgressTracker\nimport os\n\ntracker = ProgressTracker('test_integration.csv')\n\n# Seed a test job\ntracker.seed_jobs([{\n    'job_id': 'test_job_1',\n    'account': 'test_account',\n    'video_path': '/fake/video.mp4',\n    'caption': 'Test caption'\n}])\n\n# Claim the job\njob = tracker.claim_next_job(worker_id=0)\nprint(f'Claimed job: {job[\\\"job_id\\\"]}')\n\n# Fail with a non-retryable error\ntracker.update_job_status('test_job_1', 'failed', worker_id=0, error='Account suspended')\n\n# Verify error_type was set correctly\njobs = tracker._read_all_jobs()\njob = next(j for j in jobs if j['job_id'] == 'test_job_1')\nprint(f'Status: {job[\\\"status\\\"]}')\nprint(f'Error type: {job[\\\"error_type\\\"]}')\nassert job['error_type'] == 'suspended', f'Expected suspended, got {job[\\\"error_type\\\"]}'\nprint('Integration test passed!')\n\n# Cleanup\nfor f in ['test_integration.csv', 'test_integration.csv.lock']:\n    if os.path.exists(f):\n        os.remove(f)\n\"\n```\n\n### 5. Verify No Regression in Live System\n```bash\n# Check current progress file still works\npython -c \"\nfrom progress_tracker import ProgressTracker\ntracker = ProgressTracker('parallel_progress.csv')\nstats = tracker.get_statistics()\nprint(f'Progress file loads correctly: {stats}')\n\"\n```",
        "status": "done",
        "dependencies": [
          "40"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:49:23.905Z"
      },
      {
        "id": "47",
        "title": "Convert action dispatch if/elif chain to ACTION_HANDLERS dispatch table",
        "description": "Refactor the 8-action if/elif chain in the post() method (lines 801-854) to use an ACTION_HANDLERS class constant dict mapping action names to handler methods, following the Command pattern established in Task 43's humanize dispatch table.",
        "details": "## Current State Analysis\n\nThe `post()` method in `post_reel_smart.py` (lines 801-854) contains an 8-condition if/elif chain for dispatching actions:\n\n```python\n# Execute action\nif action['action'] == 'done':\n    print(\"\\n[SUCCESS] Share initiated!\")\n    # ... 10 lines of success handling\n    return True\n\nelif action['action'] == 'home':\n    print(\"  [HOME] Going to home screen...\")\n    self.press_key('KEYCODE_HOME')\n    time.sleep(2)\n\nelif action['action'] == 'open_instagram':\n    print(\"  [OPEN] Opening Instagram...\")\n    self.adb(\"am force-stop com.instagram.android\")\n    time.sleep(1)\n    self.adb(\"monkey -p com.instagram.android 1\")\n    time.sleep(4)\n\nelif action['action'] == 'tap':\n    idx = action.get('element_index', 0)\n    if 0 <= idx < len(elements):\n        elem = elements[idx]\n        self.tap(elem['center'][0], elem['center'][1])\n    else:\n        print(f\"  Invalid element index: {idx}\")\n\nelif action['action'] == 'tap_and_type':\n    if self._handle_tap_and_type(action, elements, caption):\n        continue  # Helper handled it and wants to skip to next step\n\nelif action['action'] == 'back':\n    self.press_key('KEYCODE_BACK')\n\nelif action['action'] == 'scroll_down':\n    self.adb(\"input swipe 360 900 360 400 300\")\n\nelif action['action'] == 'scroll_up':\n    self.adb(\"input swipe 360 400 360 900 300\")\n```\n\n## Target Implementation Pattern\n\nFollow Task 43's pattern (lines 245-251 in `humanize_before_post()`):\n\n```python\n# Dispatch table for humanize actions\naction_handlers = {\n    'scroll_feed': self._humanize_scroll_feed,\n    'view_story': self._humanize_view_story,\n    'scroll_reels': self._humanize_scroll_reels,\n    'check_notifications': self._humanize_check_notifications,\n}\n```\n\n## Implementation Steps\n\n### Step 1: Create Handler Methods\n\nExtract each action into a private handler method. Handlers will receive context via a dataclass:\n\n```python\n@dataclass\nclass ActionContext:\n    \"\"\"Context passed to action handlers during post() execution.\"\"\"\n    action: Dict[str, Any]\n    elements: List[Dict]\n    caption: str\n    humanize: bool\n\nclass SmartInstagramPoster:\n    # ... existing code ...\n    \n    def _action_done(self, ctx: ActionContext) -> Optional[bool]:\n        \"\"\"Handle 'done' action - posting complete.\"\"\"\n        print(\"\\n[SUCCESS] Share initiated!\")\n        if self.wait_for_upload_complete(timeout=60):\n            print(\"[SUCCESS] Upload confirmed complete!\")\n        else:\n            print(\"[WARNING] Upload confirmation timeout - may still be processing\")\n        if ctx.humanize:\n            self.humanize_after_post()\n        return True  # Return value signals post() to return True\n    \n    def _action_home(self, ctx: ActionContext) -> None:\n        \"\"\"Handle 'home' action - go to home screen.\"\"\"\n        print(\"  [HOME] Going to home screen...\")\n        self.press_key('KEYCODE_HOME')\n        time.sleep(2)\n    \n    def _action_open_instagram(self, ctx: ActionContext) -> None:\n        \"\"\"Handle 'open_instagram' action - restart Instagram app.\"\"\"\n        print(\"  [OPEN] Opening Instagram...\")\n        self.adb(\"am force-stop com.instagram.android\")\n        time.sleep(1)\n        self.adb(\"monkey -p com.instagram.android 1\")\n        time.sleep(4)\n    \n    def _action_tap(self, ctx: ActionContext) -> None:\n        \"\"\"Handle 'tap' action - tap an element by index.\"\"\"\n        idx = ctx.action.get('element_index', 0)\n        if 0 <= idx < len(ctx.elements):\n            elem = ctx.elements[idx]\n            self.tap(elem['center'][0], elem['center'][1])\n        else:\n            print(f\"  Invalid element index: {idx}\")\n    \n    def _action_tap_and_type(self, ctx: ActionContext) -> Optional[str]:\n        \"\"\"Handle 'tap_and_type' action - tap field and type caption.\"\"\"\n        if self._handle_tap_and_type(ctx.action, ctx.elements, ctx.caption):\n            return 'continue'  # Signal to skip to next iteration\n        return None\n    \n    def _action_back(self, ctx: ActionContext) -> None:\n        \"\"\"Handle 'back' action - press back key.\"\"\"\n        self.press_key('KEYCODE_BACK')\n    \n    def _action_scroll_down(self, ctx: ActionContext) -> None:\n        \"\"\"Handle 'scroll_down' action - swipe up to scroll down.\"\"\"\n        self.adb(\"input swipe 360 900 360 400 300\")\n    \n    def _action_scroll_up(self, ctx: ActionContext) -> None:\n        \"\"\"Handle 'scroll_up' action - swipe down to scroll up.\"\"\"\n        self.adb(\"input swipe 360 400 360 900 300\")\n```\n\n### Step 2: Define ACTION_HANDLERS Dispatch Table\n\nCreate a class-level constant mapping action names to handler methods:\n\n```python\nclass SmartInstagramPoster:\n    # Class constant for action dispatch (Command pattern)\n    # Keys match action names from ClaudeUIAnalyzer (claude_analyzer.py:103)\n    ACTION_HANDLERS = {\n        'done': '_action_done',\n        'home': '_action_home', \n        'open_instagram': '_action_open_instagram',\n        'tap': '_action_tap',\n        'tap_and_type': '_action_tap_and_type',\n        'back': '_action_back',\n        'scroll_down': '_action_scroll_down',\n        'scroll_up': '_action_scroll_up',\n    }\n```\n\nNote: Use method name strings since we can't reference instance methods at class definition time.\n\n### Step 3: Refactor post() Method\n\nReplace the if/elif chain with dispatch table lookup:\n\n```python\ndef post(self, video_path, caption, max_steps=30, humanize=False):\n    # ... existing setup code (lines 722-800) ...\n    \n    # Create context for handlers\n    ctx = ActionContext(\n        action=action,\n        elements=elements,\n        caption=caption,\n        humanize=humanize\n    )\n    \n    # Dispatch action using handler table\n    action_name = action['action']\n    handler_name = self.ACTION_HANDLERS.get(action_name)\n    \n    if handler_name is None:\n        print(f\"  Unknown action: {action_name}\")\n        time.sleep(1)\n        continue\n    \n    # Get and call handler method\n    handler = getattr(self, handler_name)\n    result = handler(ctx)\n    \n    # Handle special return values\n    if result is True:\n        return True  # 'done' handler signals success\n    elif result is False:\n        return False  # Handler signals failure\n    elif result == 'continue':\n        continue  # Skip to next loop iteration\n    \n    # ... existing loop detection code (lines 846-854) ...\n```\n\n### Step 4: Handle ActionContext Import\n\nAdd the dataclass import and definition at the top of the file:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Any, Optional\n\n@dataclass\nclass ActionContext:\n    \"\"\"Context passed to action handlers during post() execution.\"\"\"\n    action: Dict[str, Any]\n    elements: List[Dict]\n    caption: str\n    humanize: bool\n```\n\n## Benefits\n\n1. **Consistency**: Matches the dispatch table pattern from Task 43 (`humanize_before_post()`)\n2. **Maintainability**: Adding new actions requires only: (1) add handler method, (2) add entry to dict\n3. **Testability**: Each handler method can be unit tested independently\n4. **Readability**: The `post()` method becomes shorter and clearer\n5. **Extensibility**: Easy to add new actions without modifying dispatch logic\n6. **Self-documenting**: The ACTION_HANDLERS dict serves as documentation of supported actions\n\n## Files Modified\n\n- `post_reel_smart.py`: Add ActionContext dataclass, 8 handler methods, ACTION_HANDLERS constant, refactor post() dispatch logic\n\n## Estimated Line Changes\n\n- Remove: ~53 lines (if/elif chain)\n- Add: ~70 lines (dataclass + 8 handlers + dict + dispatch logic)\n- Net: +17 lines, but much better organization",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify the file has no syntax errors and imports correctly\npython -c \"from post_reel_smart import SmartInstagramPoster; print('Import successful')\"\n```\n\n### 2. Verify ACTION_HANDLERS Constant Exists\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nprint('ACTION_HANDLERS:', SmartInstagramPoster.ACTION_HANDLERS)\nprint('Keys:', list(SmartInstagramPoster.ACTION_HANDLERS.keys()))\nexpected = ['done', 'home', 'open_instagram', 'tap', 'tap_and_type', 'back', 'scroll_down', 'scroll_up']\nassert set(SmartInstagramPoster.ACTION_HANDLERS.keys()) == set(expected), 'Missing handlers!'\nprint('All 8 handlers present')\n\"\n```\n\n### 3. Verify Handler Methods Exist\n```bash\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster.__new__(SmartInstagramPoster)  # Create without __init__\nhandlers = ['_action_done', '_action_home', '_action_open_instagram', '_action_tap', \n            '_action_tap_and_type', '_action_back', '_action_scroll_down', '_action_scroll_up']\nfor handler in handlers:\n    assert hasattr(poster, handler), f'Missing handler: {handler}'\n    assert callable(getattr(poster, handler)), f'Handler not callable: {handler}'\nprint('All 8 handler methods exist and are callable')\n\"\n```\n\n### 4. Verify ActionContext Dataclass\n```bash\npython -c \"\nfrom post_reel_smart import ActionContext\nctx = ActionContext(\n    action={'action': 'tap', 'element_index': 0},\n    elements=[{'center': (100, 200)}],\n    caption='Test caption',\n    humanize=False\n)\nprint('ActionContext created:', ctx)\nprint('action:', ctx.action)\nprint('elements:', ctx.elements)\nprint('caption:', ctx.caption)\nprint('humanize:', ctx.humanize)\n\"\n```\n\n### 5. Static Analysis - No if/elif Chain for Actions\n```bash\n# Verify the old if/elif chain is removed from post()\npython -c \"\nimport inspect\nfrom post_reel_smart import SmartInstagramPoster\nsource = inspect.getsource(SmartInstagramPoster.post)\n# Should NOT have the old pattern\nassert \\\"elif action['action'] == 'back'\\\" not in source, 'Old if/elif chain still present!'\nassert \\\"elif action['action'] == 'scroll_down'\\\" not in source, 'Old if/elif chain still present!'\n# SHOULD have new dispatch pattern\nassert 'ACTION_HANDLERS' in source or 'handler_name' in source, 'New dispatch pattern not found!'\nprint('Dispatch table pattern confirmed')\n\"\n```\n\n### 6. Integration Test - Full Posting Flow (Dry Run)\n```bash\n# Test with a mock scenario to verify dispatch works\n# This requires the phone infrastructure but verifies the refactor\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\n\n# Check that the class can be instantiated (basic sanity)\ntry:\n    poster = SmartInstagramPoster('test_phone')\n    # Verify ACTION_HANDLERS is accessible\n    assert hasattr(poster, 'ACTION_HANDLERS')\n    # Verify all handler methods resolve\n    for action_name, handler_name in poster.ACTION_HANDLERS.items():\n        handler = getattr(poster, handler_name)\n        print(f'{action_name} -> {handler_name} OK')\nexcept Exception as e:\n    # May fail due to missing credentials/phone, but dispatch should be configured\n    print(f'Expected init error (no phone): {type(e).__name__}')\n\"\n```\n\n### 7. Live Test (Full Integration)\n```bash\n# Run an actual post to verify behavior is identical\n# Use a test account and video\npython post_reel_smart.py <test_phone> <test_video.mp4> \"Test caption #test\"\n```\n\n### 8. Verify Parallel Orchestrator Still Works\n```bash\n# The orchestrator uses SmartInstagramPoster internally\npython parallel_orchestrator.py --status\n```\n\n### 9. Code Quality Checks\n```bash\n# Check for any remaining hardcoded action strings in dispatch area\ngrep -n \"action\\['action'\\] ==\" post_reel_smart.py | head -20\n# Should only show the handler return value checks, not the old dispatch\n```\n\n### Success Criteria\n1. All 8 actions in ACTION_HANDLERS constant\n2. All 8 handler methods (_action_*) exist and are callable\n3. ActionContext dataclass properly stores all fields\n4. No if/elif chain for action dispatch remains\n5. Same behavior: posting works identically before and after refactor\n6. Existing tests pass (parallel_orchestrator.py --status)\n7. Live post test succeeds with same output pattern",
        "status": "done",
        "dependencies": [
          "43",
          "3"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T11:51:53.525Z"
      },
      {
        "id": "48",
        "title": "Fix bare except clauses in core modules",
        "description": "Replace bare 'except:' clauses in device_connection.py and post_reel_smart.py with 'except Exception:' and add optional debug logging to improve error traceability without changing runtime behavior.",
        "details": "## Current State Analysis\n\nFound 4 bare except clauses across the two core modules:\n\n### device_connection.py (3 occurrences):\n\n**1. Line 448 - reconnect_appium() method:**\n```python\ntry:\n    if self.appium_driver:\n        self.appium_driver.quit()\nexcept:\n    pass\n```\nContext: Cleanup during Appium reconnection - silently ignores driver quit failures.\n\n**2. Line 482 - disconnect() method (Appium cleanup):**\n```python\ntry:\n    if self.appium_driver:\n        self.appium_driver.quit()\n        print(\"  Appium driver closed\")\nexcept:\n    pass\n```\nContext: Cleanup during disconnect - silently ignores driver quit failures.\n\n**3. Line 487 - disconnect() method (ADB cleanup):**\n```python\ntry:\n    self.client.disable_adb(self.phone_id)\nexcept:\n    pass\n```\nContext: Cleanup during disconnect - silently ignores ADB disable failures.\n\n### post_reel_smart.py (1 occurrence):\n\n**4. Line 897 - cleanup() method:**\n```python\ntry:\n    self.adb(\"rm -f /sdcard/Download/*.mp4\")\nexcept:\n    pass\n```\nContext: Cleanup after posting - silently ignores video deletion failures.\n\n## Implementation Steps\n\n### Step 1: Add optional logging infrastructure to device_connection.py\n\nSince device_connection.py doesn't currently import logging, add a minimal optional logger:\n\n```python\n# At top of file, after existing imports\nimport logging\n\n# Create module-level logger (only used when explicitly configured)\n_logger = logging.getLogger(__name__)\n```\n\n### Step 2: Fix bare except in reconnect_appium() (line 448)\n\n```python\n# Before\nexcept:\n    pass\n\n# After\nexcept Exception as e:\n    _logger.debug(\"Appium driver quit during reconnect failed: %s\", e)\n```\n\n### Step 3: Fix bare excepts in disconnect() (lines 482, 487)\n\n```python\n# Line 482 - Appium cleanup\nexcept Exception as e:\n    _logger.debug(\"Appium driver quit during disconnect failed: %s\", e)\n\n# Line 487 - ADB cleanup  \nexcept Exception as e:\n    _logger.debug(\"disable_adb during disconnect failed: %s\", e)\n```\n\n### Step 4: Add optional logging to post_reel_smart.py cleanup() (line 897)\n\nSince post_reel_smart.py also doesn't import logging at module level:\n\n```python\n# At top of file, after existing imports\nimport logging\n_logger = logging.getLogger(__name__)\n\n# Line 897 fix\nexcept Exception as e:\n    _logger.debug(\"Video cleanup rm command failed: %s\", e)\n```\n\n## Why 'except Exception:' Instead of More Specific Types\n\n1. **Preserves original behavior**: Catches the same errors (all exceptions except SystemExit, KeyboardInterrupt, GeneratorExit)\n2. **Best practice**: PEP 8 recommends avoiding bare except; `except Exception:` is the standard broad catch\n3. **Still catches everything needed**: Subprocess errors, Appium WebDriver exceptions, network errors, etc.\n4. **Doesn't catch control flow exceptions**: Allows KeyboardInterrupt to propagate (important for Ctrl+C handling during cleanup)\n\n## Why Optional Debug Logging\n\n1. **Zero overhead in production**: Debug logging is disabled by default\n2. **Helps debugging**: When issues occur, enabling debug logging reveals silently-swallowed errors\n3. **No behavior change**: The pass statement is effectively preserved (exception is caught, logged at debug level, then continues)\n4. **Consistent pattern**: Establishes a pattern for other cleanup code in the codebase",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify files have no syntax errors after changes\npython -c \"from device_connection import DeviceConnectionManager; print('device_connection.py OK')\"\npython -c \"from post_reel_smart import SmartInstagramPoster; print('post_reel_smart.py OK')\"\n```\n\n### 2. Verify No Bare Except Clauses Remain\n```bash\n# Search for bare except patterns - should return nothing\ngrep -n \"except:\" device_connection.py post_reel_smart.py | grep -v \"except Exception\"\n\n# Expected: No output (all bare excepts replaced)\n```\n\n### 3. Verify Logging Import Added\n```bash\npython -c \"\nimport ast\nwith open('device_connection.py', 'r') as f:\n    tree = ast.parse(f.read())\nimports = [node.names[0].name for node in ast.walk(tree) if isinstance(node, ast.Import)]\nassert 'logging' in imports, 'logging not imported in device_connection.py'\nprint('device_connection.py: logging import present')\n\"\n\npython -c \"\nimport ast\nwith open('post_reel_smart.py', 'r') as f:\n    tree = ast.parse(f.read())\nimports = [node.names[0].name for node in ast.walk(tree) if isinstance(node, ast.Import)]\nassert 'logging' in imports, 'logging not imported in post_reel_smart.py'\nprint('post_reel_smart.py: logging import present')\n\"\n```\n\n### 4. Functional Test - Disconnect Cleanup Works\n```bash\npython -c \"\nfrom device_connection import DeviceConnectionManager\n\n# Create manager with dummy phone name - will fail to connect but disconnect should work\nmgr = DeviceConnectionManager('nonexistent_test_phone')\nmgr.phone_id = 'fake_id'  # Set fake ID\nmgr.appium_driver = None  # No driver\n\n# Call disconnect - should not raise even though operations will fail\ntry:\n    mgr.disconnect()\n    print('SUCCESS: disconnect() completes without raising')\nexcept Exception as e:\n    print(f'FAILURE: disconnect() raised: {e}')\n\"\n```\n\n### 5. Verify Debug Logging Works When Enabled\n```bash\npython -c \"\nimport logging\n\n# Enable debug logging for device_connection module\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger('device_connection')\nlogger.setLevel(logging.DEBUG)\n\nfrom device_connection import DeviceConnectionManager\n\n# Create manager and trigger cleanup path\nmgr = DeviceConnectionManager('test_phone_for_logging')\nmgr.phone_id = 'fake'\nmgr.appium_driver = None\n\n# This should produce debug log output about cleanup failures\nprint('--- Debug output should appear below if logging works ---')\nmgr.disconnect()\nprint('--- End debug output ---')\n\"\n```\n\n### 6. Verify Original Behavior Preserved (Exceptions Still Swallowed)\n```bash\npython -c \"\nfrom device_connection import DeviceConnectionManager\n\n# Create a mock driver that raises on quit\nclass MockDriverThatRaises:\n    def quit(self):\n        raise RuntimeError('Simulated driver failure')\n\nmgr = DeviceConnectionManager('test_phone')\nmgr.phone_id = 'fake'\nmgr.appium_driver = MockDriverThatRaises()\n\n# disconnect should NOT raise despite the driver raising\ntry:\n    mgr.disconnect()\n    print('SUCCESS: Exceptions still properly swallowed in cleanup')\nexcept Exception as e:\n    print(f'FAILURE: Exception escaped cleanup: {e}')\n\"\n```",
        "status": "done",
        "dependencies": [
          "37",
          "38"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T12:02:16.484Z"
      },
      {
        "id": "49",
        "title": "Extract screen coordinate constants in post_reel_smart.py",
        "description": "Define named constants for magic numbers like SCREEN_CENTER_X=360, FEED_TOP_Y=400, FEED_BOTTOM_Y=900 used in swipe/tap operations. This makes the code self-documenting and easier to adjust for different screen sizes.",
        "details": "## Current State Analysis\n\nMagic numbers are scattered throughout `post_reel_smart.py` for screen coordinate operations. These numbers appear in swipe and tap calls but lack semantic meaning:\n\n### Magic Numbers Found (multi-use candidates):\n\n**Horizontal coordinates:**\n- `360` - Screen center X (12+ occurrences across swipes and taps)\n- `650` - Right side X (used for story skip tap at line 180)\n\n**Vertical coordinates:**\n- `400` - Feed top Y / scroll destination (used in scroll_down swipes)\n- `640` - Screen center Y (used for double-tap like at lines 205-207)\n- `800` - Notifications scroll Y\n- `900` - Feed bottom Y / scroll start (used in scroll_up swipes)\n- `1000` - Reels bottom Y (used in reels swipe at line 210)\n- `300` - Reels top Y (used in reels swipe at line 210)\n\n**Duration constants:**\n- `200, 300, 400` - Swipe durations in ms (some via `random.randint(200, 400)`)\n\n### Implementation Plan\n\n**Step 1: Define constants at class level or module level**\n\nAdd a new `ScreenCoordinates` dataclass or class-level constants in `post_reel_smart.py`:\n\n```python\n# Screen coordinate constants for 720x1280 resolution\n# These values are calibrated for Geelark cloud phones\nclass ScreenCoords:\n    \"\"\"Screen coordinate constants for UI interactions.\"\"\"\n    # Horizontal\n    SCREEN_CENTER_X = 360  # Center of 720px screen\n    STORY_SKIP_X = 650     # Right side for story skip tap\n    \n    # Vertical\n    FEED_TOP_Y = 400       # Top of scrollable feed area\n    SCREEN_CENTER_Y = 640  # Center of 1280px screen\n    NOTIFICATIONS_Y = 800  # Notifications scroll position\n    FEED_BOTTOM_Y = 900    # Bottom of scrollable feed area\n    REELS_TOP_Y = 300      # Top Y for reels swipe\n    REELS_BOTTOM_Y = 1000  # Bottom Y for reels swipe\n    \n    # Swipe durations (ms)\n    SWIPE_FAST_MS = 200\n    SWIPE_NORMAL_MS = 300\n    SWIPE_SLOW_MS = 400\n```\n\n**Step 2: Update usages in `post_reel_smart.py`**\n\nReplace magic numbers with constants:\n\n```python\n# Before (line 156):\nself.swipe(360, 900, 360, 400, random.randint(200, 400))\n\n# After:\nself.swipe(ScreenCoords.SCREEN_CENTER_X, ScreenCoords.FEED_BOTTOM_Y,\n           ScreenCoords.SCREEN_CENTER_X, ScreenCoords.FEED_TOP_Y,\n           random.randint(ScreenCoords.SWIPE_FAST_MS, ScreenCoords.SWIPE_SLOW_MS))\n```\n\n**Lines to update in `post_reel_smart.py`:**\n- Line 156: `_humanize_scroll_feed()` - scroll down swipe\n- Line 160: `_humanize_scroll_feed()` - scroll up swipe\n- Line 180: `_humanize_view_story()` - story skip tap (650, 640)\n- Lines 205-207: `_humanize_scroll_reels()` - double-tap like (360, 640)\n- Line 210: `_humanize_scroll_reels()` - reels swipe (360, 1000, 360, 300)\n- Line 232: `_humanize_check_notifications()` - notifications swipe\n- Line 283: `humanize_after_post()` - feed scroll\n- Line 564: `_action_scroll_down()` - ADB swipe command\n- Line 568: `_action_scroll_up()` - ADB swipe command\n\n**Step 3: Update `appium_ui_controller.py`**\n\nThe `scroll_down()` and `scroll_up()` methods (lines 221-227) also use these magic numbers. Either:\n1. Import `ScreenCoords` from `post_reel_smart.py` (creates import dependency)\n2. Define constants in a shared module (e.g., `config.py`)\n3. Define locally in `appium_ui_controller.py` (duplicate but isolated)\n\n**Recommended approach:** Add constants to `config.py` since it's already the centralized config:\n\n```python\n# In config.py, add:\nclass ScreenCoords:\n    \"\"\"Screen coordinate constants for 720x1280 Geelark phones.\"\"\"\n    SCREEN_CENTER_X = 360\n    FEED_TOP_Y = 400\n    SCREEN_CENTER_Y = 640\n    STORY_SKIP_X = 650\n    NOTIFICATIONS_Y = 800\n    FEED_BOTTOM_Y = 900\n    REELS_TOP_Y = 300\n    REELS_BOTTOM_Y = 1000\n    SWIPE_FAST_MS = 200\n    SWIPE_NORMAL_MS = 300\n    SWIPE_SLOW_MS = 400\n```\n\nThen import in both files:\n```python\nfrom config import Config, ScreenCoords, setup_environment\n```\n\n**Step 4: Exclude single-use magic numbers**\n\nOnly extract constants for values used in **multiple places**. Single-use coordinates like element centers from UI dumps should remain as-is since they're dynamically determined.\n\n### Files to Modify\n\n1. `config.py` - Add `ScreenCoords` class/dataclass\n2. `post_reel_smart.py` - Import and use `ScreenCoords` constants (9 locations)\n3. `appium_ui_controller.py` - Import and use `ScreenCoords` constants (2 locations)",
        "testStrategy": "## Test Strategy\n\n### 1. Syntax and Import Verification\n```bash\n# Verify all files have no syntax errors after changes\npython -c \"from config import Config, ScreenCoords; print('config.py OK')\"\npython -c \"from post_reel_smart import SmartInstagramPoster; print('post_reel_smart.py OK')\"\npython -c \"from appium_ui_controller import AppiumUIController; print('appium_ui_controller.py OK')\"\n```\n\n### 2. Verify ScreenCoords Constants Exist\n```bash\npython -c \"\nfrom config import ScreenCoords\nprint('SCREEN_CENTER_X:', ScreenCoords.SCREEN_CENTER_X)\nprint('FEED_TOP_Y:', ScreenCoords.FEED_TOP_Y)\nprint('FEED_BOTTOM_Y:', ScreenCoords.FEED_BOTTOM_Y)\nprint('All constants defined correctly')\n\"\n```\n\n### 3. Verify No Magic Numbers Remain in Multi-Use Locations\n```bash\n# Check that 360 is not used as a raw literal in swipe/tap calls\n# (should be replaced with ScreenCoords.SCREEN_CENTER_X)\ngrep -n \"swipe(360\" post_reel_smart.py\ngrep -n \"tap(360\" post_reel_smart.py\ngrep -n \"swipe(360\" appium_ui_controller.py\n# Expected: No matches (all replaced with constants)\n```\n\n### 4. Verify Constant Values Match Original\n```bash\npython -c \"\nfrom config import ScreenCoords\n# Verify the constants have the correct values\nassert ScreenCoords.SCREEN_CENTER_X == 360, 'SCREEN_CENTER_X wrong'\nassert ScreenCoords.FEED_TOP_Y == 400, 'FEED_TOP_Y wrong'\nassert ScreenCoords.FEED_BOTTOM_Y == 900, 'FEED_BOTTOM_Y wrong'\nassert ScreenCoords.SCREEN_CENTER_Y == 640, 'SCREEN_CENTER_Y wrong'\nassert ScreenCoords.REELS_BOTTOM_Y == 1000, 'REELS_BOTTOM_Y wrong'\nassert ScreenCoords.REELS_TOP_Y == 300, 'REELS_TOP_Y wrong'\nprint('All constant values verified')\n\"\n```\n\n### 5. Behavior Verification (No Code Breakage)\n```bash\n# Quick instantiation test to ensure the class still works\npython -c \"\nfrom post_reel_smart import SmartInstagramPoster\nposter = SmartInstagramPoster('test_phone')\nprint('SmartInstagramPoster instantiation OK')\n\"\n```\n\n### 6. Unit Test for Swipe Methods\n```bash\npython -c \"\nfrom config import ScreenCoords\nfrom appium_ui_controller import AppiumUIController\n\n# Verify scroll_down and scroll_up use correct values\n# (Check source code for ScreenCoords usage)\nimport inspect\nsource = inspect.getsource(AppiumUIController.scroll_down)\nassert 'ScreenCoords' in source or 'SCREEN_CENTER_X' in source, 'scroll_down should use constants'\nprint('AppiumUIController methods use constants')\n\"\n```\n\n### 7. Full Integration Test (Optional - requires running phone)\n```bash\n# Only run if a test phone is available\n# python post_reel_smart.py test_phone test_video.mp4 \"Test caption\"\n```\n\n### 8. Code Review Checklist\n- [ ] All multi-use magic numbers (360, 400, 640, 900, etc.) replaced with named constants\n- [ ] Constants defined in `config.py` ScreenCoords class\n- [ ] `post_reel_smart.py` imports and uses ScreenCoords\n- [ ] `appium_ui_controller.py` imports and uses ScreenCoords\n- [ ] Single-use numbers (from element bounds) NOT extracted\n- [ ] Code behavior unchanged (same coordinates used)",
        "status": "done",
        "dependencies": [
          "39",
          "43",
          "47"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2025-12-13T12:04:36.361Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-12-13T12:04:36.363Z",
      "taskCount": 49,
      "completedCount": 46,
      "tags": [
        "posting"
      ]
    }
  }
}
</file>

<file path=".taskmaster/templates/example_prd_rpg.txt">
<rpg-method>
# Repository Planning Graph (RPG) Method - PRD Template

This template teaches you (AI or human) how to create structured, dependency-aware PRDs using the RPG methodology from Microsoft Research. The key insight: separate WHAT (functional) from HOW (structural), then connect them with explicit dependencies.

## Core Principles

1. **Dual-Semantics**: Think functional (capabilities) AND structural (code organization) separately, then map them
2. **Explicit Dependencies**: Never assume - always state what depends on what
3. **Topological Order**: Build foundation first, then layers on top
4. **Progressive Refinement**: Start broad, refine iteratively

## How to Use This Template

- Follow the instructions in each `<instruction>` block
- Look at `<example>` blocks to see good vs bad patterns
- Fill in the content sections with your project details
- The AI reading this will learn the RPG method by following along
- Task Master will parse the resulting PRD into dependency-aware tasks

## Recommended Tools for Creating PRDs

When using this template to **create** a PRD (not parse it), use **code-context-aware AI assistants** for best results:

**Why?** The AI needs to understand your existing codebase to make good architectural decisions about modules, dependencies, and integration points.

**Recommended tools:**
- **Claude Code** (claude-code CLI) - Best for structured reasoning and large contexts
- **Cursor/Windsurf** - IDE integration with full codebase context
- **Gemini CLI** (gemini-cli) - Massive context window for large codebases
- **Codex/Grok CLI** - Strong code generation with context awareness

**Note:** Once your PRD is created, `task-master parse-prd` works with any configured AI model - it just needs to read the PRD text itself, not your codebase.
</rpg-method>

---

<overview>
<instruction>
Start with the problem, not the solution. Be specific about:
- What pain point exists?
- Who experiences it?
- Why existing solutions don't work?
- What success looks like (measurable outcomes)?

Keep this section focused - don't jump into implementation details yet.
</instruction>

## Problem Statement
[Describe the core problem. Be concrete about user pain points.]

## Target Users
[Define personas, their workflows, and what they're trying to achieve.]

## Success Metrics
[Quantifiable outcomes. Examples: "80% task completion via autopilot", "< 5% manual intervention rate"]

</overview>

---

<functional-decomposition>
<instruction>
Now think about CAPABILITIES (what the system DOES), not code structure yet.

Step 1: Identify high-level capability domains
- Think: "What major things does this system do?"
- Examples: Data Management, Core Processing, Presentation Layer

Step 2: For each capability, enumerate specific features
- Use explore-exploit strategy:
  * Exploit: What features are REQUIRED for core value?
  * Explore: What features make this domain COMPLETE?

Step 3: For each feature, define:
- Description: What it does in one sentence
- Inputs: What data/context it needs
- Outputs: What it produces/returns
- Behavior: Key logic or transformations

<example type="good">
Capability: Data Validation
  Feature: Schema validation
    - Description: Validate JSON payloads against defined schemas
    - Inputs: JSON object, schema definition
    - Outputs: Validation result (pass/fail) + error details
    - Behavior: Iterate fields, check types, enforce constraints

  Feature: Business rule validation
    - Description: Apply domain-specific validation rules
    - Inputs: Validated data object, rule set
    - Outputs: Boolean + list of violated rules
    - Behavior: Execute rules sequentially, short-circuit on failure
</example>

<example type="bad">
Capability: validation.js
  (Problem: This is a FILE, not a CAPABILITY. Mixing structure into functional thinking.)

Capability: Validation
  Feature: Make sure data is good
  (Problem: Too vague. No inputs/outputs. Not actionable.)
</example>
</instruction>

## Capability Tree

### Capability: [Name]
[Brief description of what this capability domain covers]

#### Feature: [Name]
- **Description**: [One sentence]
- **Inputs**: [What it needs]
- **Outputs**: [What it produces]
- **Behavior**: [Key logic]

#### Feature: [Name]
- **Description**:
- **Inputs**:
- **Outputs**:
- **Behavior**:

### Capability: [Name]
...

</functional-decomposition>

---

<structural-decomposition>
<instruction>
NOW think about code organization. Map capabilities to actual file/folder structure.

Rules:
1. Each capability maps to a module (folder or file)
2. Features within a capability map to functions/classes
3. Use clear module boundaries - each module has ONE responsibility
4. Define what each module exports (public interface)

The goal: Create a clear mapping between "what it does" (functional) and "where it lives" (structural).

<example type="good">
Capability: Data Validation
  → Maps to: src/validation/
    ├── schema-validator.js      (Schema validation feature)
    ├── rule-validator.js         (Business rule validation feature)
    └── index.js                  (Public exports)

Exports:
  - validateSchema(data, schema)
  - validateRules(data, rules)
</example>

<example type="bad">
Capability: Data Validation
  → Maps to: src/utils.js
  (Problem: "utils" is not a clear module boundary. Where do I find validation logic?)

Capability: Data Validation
  → Maps to: src/validation/everything.js
  (Problem: One giant file. Features should map to separate files for maintainability.)
</example>
</instruction>

## Repository Structure

```
project-root/
├── src/
│   ├── [module-name]/       # Maps to: [Capability Name]
│   │   ├── [file].js        # Maps to: [Feature Name]
│   │   └── index.js         # Public exports
│   └── [module-name]/
├── tests/
└── docs/
```

## Module Definitions

### Module: [Name]
- **Maps to capability**: [Capability from functional decomposition]
- **Responsibility**: [Single clear purpose]
- **File structure**:
  ```
  module-name/
  ├── feature1.js
  ├── feature2.js
  └── index.js
  ```
- **Exports**:
  - `functionName()` - [what it does]
  - `ClassName` - [what it does]

</structural-decomposition>

---

<dependency-graph>
<instruction>
This is THE CRITICAL SECTION for Task Master parsing.

Define explicit dependencies between modules. This creates the topological order for task execution.

Rules:
1. List modules in dependency order (foundation first)
2. For each module, state what it depends on
3. Foundation modules should have NO dependencies
4. Every non-foundation module should depend on at least one other module
5. Think: "What must EXIST before I can build this module?"

<example type="good">
Foundation Layer (no dependencies):
  - error-handling: No dependencies
  - config-manager: No dependencies
  - base-types: No dependencies

Data Layer:
  - schema-validator: Depends on [base-types, error-handling]
  - data-ingestion: Depends on [schema-validator, config-manager]

Core Layer:
  - algorithm-engine: Depends on [base-types, error-handling]
  - pipeline-orchestrator: Depends on [algorithm-engine, data-ingestion]
</example>

<example type="bad">
- validation: Depends on API
- API: Depends on validation
(Problem: Circular dependency. This will cause build/runtime issues.)

- user-auth: Depends on everything
(Problem: Too many dependencies. Should be more focused.)
</example>
</instruction>

## Dependency Chain

### Foundation Layer (Phase 0)
No dependencies - these are built first.

- **[Module Name]**: [What it provides]
- **[Module Name]**: [What it provides]

### [Layer Name] (Phase 1)
- **[Module Name]**: Depends on [[module-from-phase-0], [module-from-phase-0]]
- **[Module Name]**: Depends on [[module-from-phase-0]]

### [Layer Name] (Phase 2)
- **[Module Name]**: Depends on [[module-from-phase-1], [module-from-foundation]]

[Continue building up layers...]

</dependency-graph>

---

<implementation-roadmap>
<instruction>
Turn the dependency graph into concrete development phases.

Each phase should:
1. Have clear entry criteria (what must exist before starting)
2. Contain tasks that can be parallelized (no inter-dependencies within phase)
3. Have clear exit criteria (how do we know phase is complete?)
4. Build toward something USABLE (not just infrastructure)

Phase ordering follows topological sort of dependency graph.

<example type="good">
Phase 0: Foundation
  Entry: Clean repository
  Tasks:
    - Implement error handling utilities
    - Create base type definitions
    - Setup configuration system
  Exit: Other modules can import foundation without errors

Phase 1: Data Layer
  Entry: Phase 0 complete
  Tasks:
    - Implement schema validator (uses: base types, error handling)
    - Build data ingestion pipeline (uses: validator, config)
  Exit: End-to-end data flow from input to validated output
</example>

<example type="bad">
Phase 1: Build Everything
  Tasks:
    - API
    - Database
    - UI
    - Tests
  (Problem: No clear focus. Too broad. Dependencies not considered.)
</example>
</instruction>

## Development Phases

### Phase 0: [Foundation Name]
**Goal**: [What foundational capability this establishes]

**Entry Criteria**: [What must be true before starting]

**Tasks**:
- [ ] [Task name] (depends on: [none or list])
  - Acceptance criteria: [How we know it's done]
  - Test strategy: [What tests prove it works]

- [ ] [Task name] (depends on: [none or list])

**Exit Criteria**: [Observable outcome that proves phase complete]

**Delivers**: [What can users/developers do after this phase?]

---

### Phase 1: [Layer Name]
**Goal**:

**Entry Criteria**: Phase 0 complete

**Tasks**:
- [ ] [Task name] (depends on: [[tasks-from-phase-0]])
- [ ] [Task name] (depends on: [[tasks-from-phase-0]])

**Exit Criteria**:

**Delivers**:

---

[Continue with more phases...]

</implementation-roadmap>

---

<test-strategy>
<instruction>
Define how testing will be integrated throughout development (TDD approach).

Specify:
1. Test pyramid ratios (unit vs integration vs e2e)
2. Coverage requirements
3. Critical test scenarios
4. Test generation guidelines for Surgical Test Generator

This section guides the AI when generating tests during the RED phase of TDD.

<example type="good">
Critical Test Scenarios for Data Validation module:
  - Happy path: Valid data passes all checks
  - Edge cases: Empty strings, null values, boundary numbers
  - Error cases: Invalid types, missing required fields
  - Integration: Validator works with ingestion pipeline
</example>
</instruction>

## Test Pyramid

```
        /\
       /E2E\       ← [X]% (End-to-end, slow, comprehensive)
      /------\
     /Integration\ ← [Y]% (Module interactions)
    /------------\
   /  Unit Tests  \ ← [Z]% (Fast, isolated, deterministic)
  /----------------\
```

## Coverage Requirements
- Line coverage: [X]% minimum
- Branch coverage: [X]% minimum
- Function coverage: [X]% minimum
- Statement coverage: [X]% minimum

## Critical Test Scenarios

### [Module/Feature Name]
**Happy path**:
- [Scenario description]
- Expected: [What should happen]

**Edge cases**:
- [Scenario description]
- Expected: [What should happen]

**Error cases**:
- [Scenario description]
- Expected: [How system handles failure]

**Integration points**:
- [What interactions to test]
- Expected: [End-to-end behavior]

## Test Generation Guidelines
[Specific instructions for Surgical Test Generator about what to focus on, what patterns to follow, project-specific test conventions]

</test-strategy>

---

<architecture>
<instruction>
Describe technical architecture, data models, and key design decisions.

Keep this section AFTER functional/structural decomposition - implementation details come after understanding structure.
</instruction>

## System Components
[Major architectural pieces and their responsibilities]

## Data Models
[Core data structures, schemas, database design]

## Technology Stack
[Languages, frameworks, key libraries]

**Decision: [Technology/Pattern]**
- **Rationale**: [Why chosen]
- **Trade-offs**: [What we're giving up]
- **Alternatives considered**: [What else we looked at]

</architecture>

---

<risks>
<instruction>
Identify risks that could derail development and how to mitigate them.

Categories:
- Technical risks (complexity, unknowns)
- Dependency risks (blocking issues)
- Scope risks (creep, underestimation)
</instruction>

## Technical Risks
**Risk**: [Description]
- **Impact**: [High/Medium/Low - effect on project]
- **Likelihood**: [High/Medium/Low]
- **Mitigation**: [How to address]
- **Fallback**: [Plan B if mitigation fails]

## Dependency Risks
[External dependencies, blocking issues]

## Scope Risks
[Scope creep, underestimation, unclear requirements]

</risks>

---

<appendix>
## References
[Papers, documentation, similar systems]

## Glossary
[Domain-specific terms]

## Open Questions
[Things to resolve during development]
</appendix>

---

<task-master-integration>
# How Task Master Uses This PRD

When you run `task-master parse-prd <file>.txt`, the parser:

1. **Extracts capabilities** → Main tasks
   - Each `### Capability:` becomes a top-level task

2. **Extracts features** → Subtasks
   - Each `#### Feature:` becomes a subtask under its capability

3. **Parses dependencies** → Task dependencies
   - `Depends on: [X, Y]` sets task.dependencies = ["X", "Y"]

4. **Orders by phases** → Task priorities
   - Phase 0 tasks = highest priority
   - Phase N tasks = lower priority, properly sequenced

5. **Uses test strategy** → Test generation context
   - Feeds test scenarios to Surgical Test Generator during implementation

**Result**: A dependency-aware task graph that can be executed in topological order.

## Why RPG Structure Matters

Traditional flat PRDs lead to:
- ❌ Unclear task dependencies
- ❌ Arbitrary task ordering
- ❌ Circular dependencies discovered late
- ❌ Poorly scoped tasks

RPG-structured PRDs provide:
- ✅ Explicit dependency chains
- ✅ Topological execution order
- ✅ Clear module boundaries
- ✅ Validated task graph before implementation

## Tips for Best Results

1. **Spend time on dependency graph** - This is the most valuable section for Task Master
2. **Keep features atomic** - Each feature should be independently testable
3. **Progressive refinement** - Start broad, use `task-master expand` to break down complex tasks
4. **Use research mode** - `task-master parse-prd --research` leverages AI for better task generation
</task-master-integration>
</file>

<file path=".taskmaster/templates/example_prd.txt">
<context>
# Overview  
[Provide a high-level overview of your product here. Explain what problem it solves, who it's for, and why it's valuable.]

# Core Features  
[List and describe the main features of your product. For each feature, include:
- What it does
- Why it's important
- How it works at a high level]

# User Experience  
[Describe the user journey and experience. Include:
- User personas
- Key user flows
- UI/UX considerations]
</context>
<PRD>
# Technical Architecture  
[Outline the technical implementation details:
- System components
- Data models
- APIs and integrations
- Infrastructure requirements]

# Development Roadmap  
[Break down the development process into phases:
- MVP requirements
- Future enhancements
- Do not think about timelines whatsoever -- all that matters is scope and detailing exactly what needs to be build in each phase so it can later be cut up into tasks]

# Logical Dependency Chain
[Define the logical order of development:
- Which features need to be built first (foundation)
- Getting as quickly as possible to something usable/visible front end that works
- Properly pacing and scoping each feature so it is atomic but can also be built upon and improved as development approaches]

# Risks and Mitigations  
[Identify potential risks and how they'll be addressed:
- Technical challenges
- Figuring out the MVP that we can build upon
- Resource constraints]

# Appendix  
[Include any additional information:
- Research findings
- Technical specifications]
</PRD>
</file>

<file path=".taskmaster/CLAUDE.md">
# Task Master AI - Agent Integration Guide

## Essential Commands

### Core Workflow Commands

```bash
# Project Setup
task-master init                                    # Initialize Task Master in current project
task-master parse-prd .taskmaster/docs/prd.md       # Generate tasks from PRD document
task-master models --setup                        # Configure AI models interactively

# Daily Development Workflow
task-master list                                   # Show all tasks with status
task-master next                                   # Get next available task to work on
task-master show <id>                             # View detailed task information (e.g., task-master show 1.2)
task-master set-status --id=<id> --status=done    # Mark task complete

# Task Management
task-master add-task --prompt="description" --research        # Add new task with AI assistance
task-master expand --id=<id> --research --force              # Break task into subtasks
task-master update-task --id=<id> --prompt="changes"         # Update specific task
task-master update --from=<id> --prompt="changes"            # Update multiple tasks from ID onwards
task-master update-subtask --id=<id> --prompt="notes"        # Add implementation notes to subtask

# Analysis & Planning
task-master analyze-complexity --research          # Analyze task complexity
task-master complexity-report                      # View complexity analysis
task-master expand --all --research               # Expand all eligible tasks

# Dependencies & Organization
task-master add-dependency --id=<id> --depends-on=<id>       # Add task dependency
task-master move --from=<id> --to=<id>                       # Reorganize task hierarchy
task-master validate-dependencies                            # Check for dependency issues
task-master generate                                         # Update task markdown files (usually auto-called)
```

## Key Files & Project Structure

### Core Files

- `.taskmaster/tasks/tasks.json` - Main task data file (auto-managed)
- `.taskmaster/config.json` - AI model configuration (use `task-master models` to modify)
- `.taskmaster/docs/prd.md` - Product Requirements Document for parsing (`.md` extension recommended for better editor support)
- `.taskmaster/tasks/*.txt` - Individual task files (auto-generated from tasks.json)
- `.env` - API keys for CLI usage

**PRD File Format:** While both `.txt` and `.md` extensions work, **`.md` is recommended** because:
- Markdown syntax highlighting in editors improves readability
- Proper rendering when previewing in VS Code, GitHub, or other tools
- Better collaboration through formatted documentation

### Claude Code Integration Files

- `CLAUDE.md` - Auto-loaded context for Claude Code (this file)
- `.claude/settings.json` - Claude Code tool allowlist and preferences
- `.claude/commands/` - Custom slash commands for repeated workflows
- `.mcp.json` - MCP server configuration (project-specific)

### Directory Structure

```
project/
├── .taskmaster/
│   ├── tasks/              # Task files directory
│   │   ├── tasks.json      # Main task database
│   │   ├── task-1.md      # Individual task files
│   │   └── task-2.md
│   ├── docs/              # Documentation directory
│   │   ├── prd.md         # Product requirements (.md recommended)
│   ├── reports/           # Analysis reports directory
│   │   └── task-complexity-report.json
│   ├── templates/         # Template files
│   │   └── example_prd.md  # Example PRD template (.md recommended)
│   └── config.json        # AI models & settings
├── .claude/
│   ├── settings.json      # Claude Code configuration
│   └── commands/         # Custom slash commands
├── .env                  # API keys
├── .mcp.json            # MCP configuration
└── CLAUDE.md            # This file - auto-loaded by Claude Code
```

## MCP Integration

Task Master provides an MCP server that Claude Code can connect to. Configure in `.mcp.json`:

```json
{
  "mcpServers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "task-master-ai"],
      "env": {
        "ANTHROPIC_API_KEY": "your_key_here",
        "PERPLEXITY_API_KEY": "your_key_here",
        "OPENAI_API_KEY": "OPENAI_API_KEY_HERE",
        "GOOGLE_API_KEY": "GOOGLE_API_KEY_HERE",
        "XAI_API_KEY": "XAI_API_KEY_HERE",
        "OPENROUTER_API_KEY": "OPENROUTER_API_KEY_HERE",
        "MISTRAL_API_KEY": "MISTRAL_API_KEY_HERE",
        "AZURE_OPENAI_API_KEY": "AZURE_OPENAI_API_KEY_HERE",
        "OLLAMA_API_KEY": "OLLAMA_API_KEY_HERE"
      }
    }
  }
}
```

### Essential MCP Tools

```javascript
help; // = shows available taskmaster commands
// Project setup
initialize_project; // = task-master init
parse_prd; // = task-master parse-prd

// Daily workflow
get_tasks; // = task-master list
next_task; // = task-master next
get_task; // = task-master show <id>
set_task_status; // = task-master set-status

// Task management
add_task; // = task-master add-task
expand_task; // = task-master expand
update_task; // = task-master update-task
update_subtask; // = task-master update-subtask
update; // = task-master update

// Analysis
analyze_project_complexity; // = task-master analyze-complexity
complexity_report; // = task-master complexity-report
```

## Claude Code Workflow Integration

### Standard Development Workflow

#### 1. Project Initialization

```bash
# Initialize Task Master
task-master init

# Create or obtain PRD, then parse it (use .md extension for better editor support)
task-master parse-prd .taskmaster/docs/prd.md

# Analyze complexity and expand tasks
task-master analyze-complexity --research
task-master expand --all --research
```

If tasks already exist, another PRD can be parsed (with new information only!) using parse-prd with --append flag. This will add the generated tasks to the existing list of tasks..

#### 2. Daily Development Loop

```bash
# Start each session
task-master next                           # Find next available task
task-master show <id>                     # Review task details

# During implementation, check in code context into the tasks and subtasks
task-master update-subtask --id=<id> --prompt="implementation notes..."

# Complete tasks
task-master set-status --id=<id> --status=done
```

#### 3. Multi-Claude Workflows

For complex projects, use multiple Claude Code sessions:

```bash
# Terminal 1: Main implementation
cd project && claude

# Terminal 2: Testing and validation
cd project-test-worktree && claude

# Terminal 3: Documentation updates
cd project-docs-worktree && claude
```

### Custom Slash Commands

Create `.claude/commands/taskmaster-next.md`:

```markdown
Find the next available Task Master task and show its details.

Steps:

1. Run `task-master next` to get the next task
2. If a task is available, run `task-master show <id>` for full details
3. Provide a summary of what needs to be implemented
4. Suggest the first implementation step
```

Create `.claude/commands/taskmaster-complete.md`:

```markdown
Complete a Task Master task: $ARGUMENTS

Steps:

1. Review the current task with `task-master show $ARGUMENTS`
2. Verify all implementation is complete
3. Run any tests related to this task
4. Mark as complete: `task-master set-status --id=$ARGUMENTS --status=done`
5. Show the next available task with `task-master next`
```

## Tool Allowlist Recommendations

Add to `.claude/settings.json`:

```json
{
  "allowedTools": [
    "Edit",
    "Bash(task-master *)",
    "Bash(git commit:*)",
    "Bash(git add:*)",
    "Bash(npm run *)",
    "mcp__task_master_ai__*"
  ]
}
```

## Configuration & Setup

### API Keys Required

At least **one** of these API keys must be configured:

- `ANTHROPIC_API_KEY` (Claude models) - **Recommended**
- `PERPLEXITY_API_KEY` (Research features) - **Highly recommended**
- `OPENAI_API_KEY` (GPT models)
- `GOOGLE_API_KEY` (Gemini models)
- `MISTRAL_API_KEY` (Mistral models)
- `OPENROUTER_API_KEY` (Multiple models)
- `XAI_API_KEY` (Grok models)

An API key is required for any provider used across any of the 3 roles defined in the `models` command.

### Model Configuration

```bash
# Interactive setup (recommended)
task-master models --setup

# Set specific models
task-master models --set-main claude-3-5-sonnet-20241022
task-master models --set-research perplexity-llama-3.1-sonar-large-128k-online
task-master models --set-fallback gpt-4o-mini
```

## Task Structure & IDs

### Task ID Format

- Main tasks: `1`, `2`, `3`, etc.
- Subtasks: `1.1`, `1.2`, `2.1`, etc.
- Sub-subtasks: `1.1.1`, `1.1.2`, etc.

### Task Status Values

- `pending` - Ready to work on
- `in-progress` - Currently being worked on
- `done` - Completed and verified
- `deferred` - Postponed
- `cancelled` - No longer needed
- `blocked` - Waiting on external factors

### Task Fields

```json
{
  "id": "1.2",
  "title": "Implement user authentication",
  "description": "Set up JWT-based auth system",
  "status": "pending",
  "priority": "high",
  "dependencies": ["1.1"],
  "details": "Use bcrypt for hashing, JWT for tokens...",
  "testStrategy": "Unit tests for auth functions, integration tests for login flow",
  "subtasks": []
}
```

## Claude Code Best Practices with Task Master

### Context Management

- Use `/clear` between different tasks to maintain focus
- This CLAUDE.md file is automatically loaded for context
- Use `task-master show <id>` to pull specific task context when needed

### Iterative Implementation

1. `task-master show <subtask-id>` - Understand requirements
2. Explore codebase and plan implementation
3. `task-master update-subtask --id=<id> --prompt="detailed plan"` - Log plan
4. `task-master set-status --id=<id> --status=in-progress` - Start work
5. Implement code following logged plan
6. `task-master update-subtask --id=<id> --prompt="what worked/didn't work"` - Log progress
7. `task-master set-status --id=<id> --status=done` - Complete task

### Complex Workflows with Checklists

For large migrations or multi-step processes:

1. Create a markdown PRD file describing the new changes: `touch task-migration-checklist.md` (prds can be .txt or .md)
2. Use Taskmaster to parse the new prd with `task-master parse-prd --append` (also available in MCP)
3. Use Taskmaster to expand the newly generated tasks into subtasks. Consdier using `analyze-complexity` with the correct --to and --from IDs (the new ids) to identify the ideal subtask amounts for each task. Then expand them.
4. Work through items systematically, checking them off as completed
5. Use `task-master update-subtask` to log progress on each task/subtask and/or updating/researching them before/during implementation if getting stuck

### Git Integration

Task Master works well with `gh` CLI:

```bash
# Create PR for completed task
gh pr create --title "Complete task 1.2: User authentication" --body "Implements JWT auth system as specified in task 1.2"

# Reference task in commits
git commit -m "feat: implement JWT auth (task 1.2)"
```

### Parallel Development with Git Worktrees

```bash
# Create worktrees for parallel task development
git worktree add ../project-auth feature/auth-system
git worktree add ../project-api feature/api-refactor

# Run Claude Code in each worktree
cd ../project-auth && claude    # Terminal 1: Auth work
cd ../project-api && claude     # Terminal 2: API work
```

## Troubleshooting

### AI Commands Failing

```bash
# Check API keys are configured
cat .env                           # For CLI usage

# Verify model configuration
task-master models

# Test with different model
task-master models --set-fallback gpt-4o-mini
```

### MCP Connection Issues

- Check `.mcp.json` configuration
- Verify Node.js installation
- Use `--mcp-debug` flag when starting Claude Code
- Use CLI as fallback if MCP unavailable

### Task File Sync Issues

```bash
# Regenerate task files from tasks.json
task-master generate

# Fix dependency issues
task-master fix-dependencies
```

DO NOT RE-INITIALIZE. That will not do anything beyond re-adding the same Taskmaster core files.

## Important Notes

### AI-Powered Operations

These commands make AI calls and may take up to a minute:

- `parse_prd` / `task-master parse-prd`
- `analyze_project_complexity` / `task-master analyze-complexity`
- `expand_task` / `task-master expand`
- `expand_all` / `task-master expand --all`
- `add_task` / `task-master add-task`
- `update` / `task-master update`
- `update_task` / `task-master update-task`
- `update_subtask` / `task-master update-subtask`

### File Management

- Never manually edit `tasks.json` - use commands instead
- Never manually edit `.taskmaster/config.json` - use `task-master models`
- Task markdown files in `tasks/` are auto-generated
- Run `task-master generate` after manual changes to tasks.json

### Claude Code Session Management

- Use `/clear` frequently to maintain focused context
- Create custom slash commands for repeated Task Master workflows
- Configure tool allowlist to streamline permissions
- Use headless mode for automation: `claude -p "task-master next"`

### Multi-Task Updates

- Use `update --from=<id>` to update multiple future tasks
- Use `update-task --id=<id>` for single task updates
- Use `update-subtask --id=<id>` for implementation logging

### Research Mode

- Add `--research` flag for research-based AI enhancement
- Requires a research model API key like Perplexity (`PERPLEXITY_API_KEY`) in environment
- Provides more informed task creation and updates
- Recommended for complex technical tasks

---

_This guide ensures Claude Code has immediate access to Task Master's essential functionality for agentic development workflows._
</file>

<file path=".taskmaster/config.json">
{
  "models": {
    "main": {
      "provider": "claude-code",
      "modelId": "opus",
      "maxTokens": 32000,
      "temperature": 0.2
    },
    "research": {
      "provider": "perplexity",
      "modelId": "sonar-pro",
      "maxTokens": 8700,
      "temperature": 0.1
    },
    "fallback": {
      "provider": "claude-code",
      "modelId": "opus",
      "maxTokens": 32000,
      "temperature": 0.2
    }
  },
  "global": {
    "logLevel": "info",
    "debug": false,
    "defaultNumTasks": 10,
    "defaultSubtasks": 5,
    "defaultPriority": "medium",
    "projectName": "Taskmaster",
    "ollamaBaseURL": "http://localhost:11434/api",
    "bedrockBaseURL": "https://bedrock.us-east-1.amazonaws.com",
    "responseLanguage": "English",
    "enableCodebaseAnalysis": true,
    "enableProxy": false,
    "anonymousTelemetry": true,
    "defaultTag": "master",
    "azureOpenaiBaseURL": "https://your-endpoint.openai.azure.com/",
    "userId": "1234567890"
  },
  "claudeCode": {},
  "codexCli": {},
  "grokCli": {
    "timeout": 120000,
    "workingDirectory": null,
    "defaultModel": "grok-4-latest"
  }
}
</file>

<file path=".taskmaster/state.json">
{
  "currentTag": "posting",
  "lastSwitched": "2025-12-10T04:33:07.497Z",
  "branchTagMapping": {},
  "migrationNoticeShown": true
}
</file>

<file path="archived/batch_post_ARCHIVED.py">
"""
Batch post videos to Instagram Reels across multiple phones (round-robin).

Usage:
    python batch_post.py <chunk_folder> <phone1> <phone2> ... [--limit N]

Example:
    python batch_post.py va_chunk_05 miccliparchive reelwisdompod_ podmindstudio --limit 3
"""
import sys
import os

# Fix Windows console encoding for emojis BEFORE any other imports
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

import csv
import time
import glob
import argparse
from datetime import datetime
from post_reel_smart import SmartInstagramPoster


def get_already_posted():
    """Load all successfully posted shortcodes from batch_results_*.csv files"""
    posted = set()
    for filepath in glob.glob("batch_results_*.csv"):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if row.get('status') == 'success':
                        posted.add(row.get('shortcode'))
        except Exception as e:
            print(f"Warning: Could not read {filepath}: {e}")
    return posted


def load_posts_from_csv(chunk_folder, csv_name=None):
    """Load video/caption pairs from chunk CSV

    Supports multiple CSV formats:
    - Old format: 'Shortcode' column with video path, 'Text' for caption
    - New format: 'Image/Video link 1...' column with shortcode, 'Text' for caption
    """
    # Find CSV file
    if csv_name:
        csv_path = os.path.join(chunk_folder, csv_name)
    else:
        csv_files = [f for f in os.listdir(chunk_folder) if f.endswith('.csv')]
        if not csv_files:
            raise Exception(f"No CSV file found in {chunk_folder}")
        csv_path = os.path.join(chunk_folder, csv_files[0])

    print(f"Loading CSV: {csv_path}")

    # Build video map from subfolders
    videos = {}
    for item in os.listdir(chunk_folder):
        item_path = os.path.join(chunk_folder, item)
        if os.path.isdir(item_path):
            for f in os.listdir(item_path):
                if f.endswith('.mp4'):
                    shortcode = f.replace('.mp4', '')
                    videos[shortcode] = os.path.join(item_path, f)

    print(f"Found {len(videos)} videos in subfolders")

    posts = []
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        columns = reader.fieldnames

        # Detect video column (supports multiple formats)
        video_col = None
        for col in columns:
            if 'Video' in col or 'Image' in col:
                video_col = col
                break
            if col == 'Shortcode':
                video_col = col
                break

        if not video_col:
            raise Exception(f"No video column found. Columns: {columns}")

        for row in reader:
            caption = row.get('Text', '').strip()
            video_ref = row.get(video_col, '').strip()

            if not video_ref or not caption:
                continue

            # Handle different formats
            if video_ref in videos:
                # New format: shortcode directly maps to video
                video_path = videos[video_ref]
                shortcode = video_ref
            elif 'spoofed' in video_ref or 'chunk_01' in video_ref:
                # Old format: full path, replace spoofed with chunk folder
                video_path = video_ref.replace('spoofed', os.path.basename(chunk_folder))
                video_path = video_path.replace('chunk_01a', os.path.basename(chunk_folder))
                shortcode = os.path.basename(video_path).replace('.mp4', '')
            else:
                # Try as shortcode with .mp4 extension
                shortcode = video_ref
                if shortcode in videos:
                    video_path = videos[shortcode]
                else:
                    continue

            if os.path.exists(video_path):
                posts.append({
                    'shortcode': shortcode,
                    'video_path': video_path,
                    'caption': caption
                })

    return posts


def batch_post(chunk_folder, phones, limit=None, delay=10, humanize=False, csv_name=None):
    """Post videos round-robin across phones

    Args:
        chunk_folder: Folder containing CSV and video files
        phones: List of phone names to post to (round-robin)
        limit: Maximum number of posts
        delay: Delay between posts in seconds
        humanize: If True, perform random human-like actions before/after posting
        csv_name: Specific CSV filename to use (default: first .csv found)
    """

    # Load posts from CSV
    posts = load_posts_from_csv(chunk_folder, csv_name)
    print(f"Found {len(posts)} videos in {chunk_folder}")

    # Filter out already posted
    already_posted = get_already_posted()
    if already_posted:
        original_count = len(posts)
        posts = [p for p in posts if p['shortcode'] not in already_posted]
        skipped = original_count - len(posts)
        print(f"Skipping {skipped} already-posted videos ({len(already_posted)} total in history)")
        print(f"Remaining: {len(posts)} videos to post")

    if limit:
        posts = posts[:limit]
        print(f"Limited to {limit} posts")

    if not posts:
        print("No posts to process")
        return []

    print(f"Posting to {len(phones)} phones: {', '.join(phones)}")
    print("-" * 50)

    # Results log
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = f"batch_results_{timestamp}.csv"

    results = []

    for i, post in enumerate(posts):
        # Round-robin phone selection
        phone = phones[i % len(phones)]

        print(f"\n[{i+1}/{len(posts)}] {post['shortcode']} -> {phone}")
        print(f"  Caption: {post['caption'][:60]}...")

        try:
            poster = SmartInstagramPoster(phone)
            poster.connect()
            success = poster.post(post['video_path'], post['caption'], humanize=humanize)
            poster.cleanup()

            results.append({
                'shortcode': post['shortcode'],
                'phone': phone,
                'status': 'success' if success else 'failed',
                'timestamp': datetime.now().isoformat()
            })

            if success:
                print(f"  [OK] Posted successfully")
            else:
                print(f"  [FAIL] Post failed")

        except Exception as e:
            print(f"  [ERROR] {e}")
            results.append({
                'shortcode': post['shortcode'],
                'phone': phone,
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })

        # Save results after each post
        with open(log_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['shortcode', 'phone', 'status', 'error', 'timestamp'])
            writer.writeheader()
            writer.writerows(results)

        # Delay between posts
        if i < len(posts) - 1:
            print(f"  Waiting {delay}s before next post...")
            time.sleep(delay)

    # Summary
    print("\n" + "=" * 50)
    print("BATCH COMPLETE")
    print("=" * 50)

    success_count = sum(1 for r in results if r['status'] == 'success')
    print(f"Success: {success_count}/{len(results)}")
    print(f"Results saved to: {log_path}")

    if success_count < len(results):
        print("\nFailed posts:")
        for r in results:
            if r['status'] != 'success':
                print(f"  - {r['shortcode']} on {r['phone']}: {r.get('error', 'Unknown')}")

    return results


def main():
    parser = argparse.ArgumentParser(description='Batch post videos to Instagram')
    parser.add_argument('chunk_folder', help='Folder containing CSV and videos')
    parser.add_argument('phones', nargs='+', help='Phone names to post to (round-robin)')
    parser.add_argument('--limit', type=int, help='Limit number of posts')
    parser.add_argument('--delay', type=int, default=10, help='Delay between posts in seconds (default: 10)')
    parser.add_argument('--humanize', action='store_true', help='Perform random human-like actions before/after posting')
    parser.add_argument('--csv', type=str, help='Specific CSV filename to use (default: first .csv found)')

    args = parser.parse_args()

    if not os.path.isdir(args.chunk_folder):
        print(f"Folder not found: {args.chunk_folder}")
        sys.exit(1)

    batch_post(args.chunk_folder, args.phones, args.limit, args.delay, args.humanize, args.csv)


if __name__ == "__main__":
    main()
</file>

<file path="archived/batch_post_concurrent_ARCHIVED.py">
"""
Concurrent batch post videos to Instagram Reels across multiple phones.
Posts to multiple phones simultaneously using threading.

Usage:
    python batch_post_concurrent.py <chunk_folder> <phone1> <phone2> ... [--limit N] [--workers N]

Example:
    python batch_post_concurrent.py va_chunk_05 miccliparchive reelwisdompod_ podmindstudio --limit 6 --workers 3
"""
import sys
import os

# Fix Windows console encoding for emojis
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

import csv
import time
import argparse
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from post_reel_smart import SmartInstagramPoster


# Thread-safe print with phone prefix
print_lock = threading.Lock()

def safe_print(phone, message):
    """Thread-safe print with phone prefix"""
    with print_lock:
        print(f"[{phone}] {message}")


def load_posts_from_csv(chunk_folder):
    """Load video/caption pairs from chunk CSV"""
    csv_files = [f for f in os.listdir(chunk_folder) if f.endswith('.csv')]
    if not csv_files:
        raise Exception(f"No CSV file found in {chunk_folder}")

    csv_path = os.path.join(chunk_folder, csv_files[0])
    posts = []

    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            shortcode = row.get('Shortcode', '').strip()
            caption = row.get('Text', '').strip()

            if not shortcode or not caption:
                continue

            # Find the video file
            video_filename = f"{shortcode}-1.mp4"
            video_path = os.path.join(chunk_folder, video_filename)

            if os.path.exists(video_path):
                posts.append({
                    'shortcode': shortcode,
                    'video_path': video_path,
                    'caption': caption
                })
            else:
                print(f"Warning: Video not found: {video_filename}")

    return posts


def post_single(phone, post, humanize=False):
    """Post a single video to a phone. Returns result dict."""
    shortcode = post['shortcode']
    safe_print(phone, f"Starting: {shortcode}")
    safe_print(phone, f"Caption: {post['caption'][:50]}...")

    result = {
        'shortcode': shortcode,
        'phone': phone,
        'status': 'pending',
        'error': None,
        'timestamp': datetime.now().isoformat()
    }

    try:
        poster = SmartInstagramPoster(phone)
        poster.connect()
        success = poster.post(post['video_path'], post['caption'], humanize=humanize)
        poster.cleanup()

        result['status'] = 'success' if success else 'failed'
        if success:
            safe_print(phone, f"SUCCESS: {shortcode}")
        else:
            safe_print(phone, f"FAILED: {shortcode}")

    except Exception as e:
        result['status'] = 'error'
        result['error'] = str(e)
        safe_print(phone, f"ERROR on {shortcode}: {e}")

    result['timestamp'] = datetime.now().isoformat()
    return result


def batch_post_concurrent(chunk_folder, phones, limit=None, workers=2, humanize=False):
    """Post videos concurrently across phones

    Args:
        chunk_folder: Folder containing CSV and video files
        phones: List of phone names to post to (round-robin assignment)
        limit: Maximum number of posts
        workers: Number of concurrent workers (phones posting at once)
        humanize: If True, perform random human-like actions before/after posting
    """

    # Load posts from CSV
    posts = load_posts_from_csv(chunk_folder)
    print(f"Found {len(posts)} videos in {chunk_folder}")

    if limit:
        posts = posts[:limit]
        print(f"Limited to {limit} posts")

    if not posts:
        print("No posts to process")
        return []

    print(f"Posting to {len(phones)} phones: {', '.join(phones)}")
    print(f"Concurrent workers: {workers}")
    print("-" * 50)

    # Assign posts to phones (round-robin)
    phone_assignments = []
    for i, post in enumerate(posts):
        phone = phones[i % len(phones)]
        phone_assignments.append((phone, post))

    # Results log
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = f"batch_concurrent_results_{timestamp}.csv"

    results = []
    results_lock = threading.Lock()

    def save_results():
        """Save current results to CSV"""
        with results_lock:
            with open(log_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=['shortcode', 'phone', 'status', 'error', 'timestamp'])
                writer.writeheader()
                writer.writerows(results)

    start_time = time.time()

    # Run concurrent posts
    with ThreadPoolExecutor(max_workers=workers) as executor:
        # Submit all tasks
        future_to_assignment = {}
        for phone, post in phone_assignments:
            future = executor.submit(post_single, phone, post, humanize)
            future_to_assignment[future] = (phone, post)

        # Collect results as they complete
        for future in as_completed(future_to_assignment):
            phone, post = future_to_assignment[future]
            try:
                result = future.result()
                with results_lock:
                    results.append(result)
                save_results()
            except Exception as e:
                safe_print(phone, f"Unexpected error: {e}")
                with results_lock:
                    results.append({
                        'shortcode': post['shortcode'],
                        'phone': phone,
                        'status': 'error',
                        'error': str(e),
                        'timestamp': datetime.now().isoformat()
                    })
                save_results()

    elapsed = time.time() - start_time

    # Summary
    print("\n" + "=" * 50)
    print("CONCURRENT BATCH COMPLETE")
    print("=" * 50)

    success_count = sum(1 for r in results if r['status'] == 'success')
    print(f"Success: {success_count}/{len(results)}")
    print(f"Elapsed time: {elapsed:.1f}s")
    print(f"Results saved to: {log_path}")

    if success_count < len(results):
        print("\nFailed posts:")
        for r in results:
            if r['status'] != 'success':
                print(f"  - {r['shortcode']} on {r['phone']}: {r.get('error', 'Unknown')}")

    return results


def main():
    parser = argparse.ArgumentParser(description='Concurrent batch post videos to Instagram')
    parser.add_argument('chunk_folder', help='Folder containing CSV and videos')
    parser.add_argument('phones', nargs='+', help='Phone names to post to (round-robin assignment)')
    parser.add_argument('--limit', type=int, help='Limit number of posts')
    parser.add_argument('--workers', type=int, default=2, help='Number of concurrent workers (default: 2)')
    parser.add_argument('--humanize', action='store_true', help='Perform random human-like actions before/after posting')

    args = parser.parse_args()

    if not os.path.isdir(args.chunk_folder):
        print(f"Folder not found: {args.chunk_folder}")
        sys.exit(1)

    # Limit workers to number of phones
    workers = min(args.workers, len(args.phones))

    batch_post_concurrent(args.chunk_folder, args.phones, args.limit, workers, args.humanize)


if __name__ == "__main__":
    main()
</file>

<file path="archived/post_to_instagram.py">
"""
Post videos to Instagram via Geelark cloud phones.

Usage:
    python post_to_instagram.py <phone_name_or_id> <video_path> <caption>

Or import and use:
    from post_to_instagram import post_video
    post_video("cloudypenguinzip", "video.mp4", "Check this out! #funny")
"""
import sys
import os
import time
import tempfile
from geelark_client import GeelarkClient
from adb_controller import ADBController
from vision import analyze_for_instagram_post


def post_video(phone_identifier, video_path, caption, max_steps=50):
    """
    Post a video to Instagram on a Geelark cloud phone.

    Args:
        phone_identifier: Phone name or ID
        video_path: Local path to video file
        caption: Caption text to post
        max_steps: Maximum vision-action loops before giving up

    Returns:
        bool: True if post was successful
    """
    client = GeelarkClient()

    # Find phone
    print(f"Looking for phone: {phone_identifier}")
    result = client.list_phones(page_size=100)
    phone = None
    for p in result["items"]:
        if p["id"] == phone_identifier or p["serialName"] == phone_identifier:
            phone = p
            break

    if not phone:
        print(f"Phone not found: {phone_identifier}")
        return False

    phone_id = phone["id"]
    phone_name = phone["serialName"]
    print(f"Found phone: {phone_name} (ID: {phone_id})")

    # Start phone if not running
    if phone["status"] != 0:  # 0 = started
        print("Starting phone...")
        try:
            client.start_phone(phone_id)
            print("Phone starting, waiting 10 seconds...")
            time.sleep(10)
        except Exception as e:
            print(f"Failed to start phone: {e}")
            return False

    # Enable ADB
    print("Enabling ADB...")
    client.enable_adb(phone_id)
    print("Waiting 5 seconds for ADB to initialize...")
    time.sleep(5)

    # Get ADB connection info
    print("Getting ADB connection info...")
    adb_info = client.get_adb_info(phone_id)
    print(f"ADB: {adb_info['ip']}:{adb_info['port']}")

    # Connect via ADB
    adb = ADBController(adb_info["ip"], adb_info["port"], adb_info["pwd"])
    if not adb.connect():
        print("Failed to connect via ADB")
        return False

    try:
        # Upload video via Geelark API (not ADB - more reliable)
        print(f"Uploading video to Geelark cloud: {video_path}")
        resource_url = client.upload_file_to_geelark(video_path)
        print(f"Video uploaded to: {resource_url}")

        print("Pushing video to phone's Downloads folder...")
        upload_result = client.upload_file_to_phone(phone_id, resource_url)
        task_id = upload_result.get("taskId")
        print(f"Upload task started: {task_id}")

        print("Waiting for upload to complete...")
        client.wait_for_upload(task_id)
        print("Video uploaded to phone!")

        # Trigger media scan so video appears in gallery
        remote_video = "/sdcard/Download/" + os.path.basename(video_path)
        adb.shell(f"am broadcast -a android.intent.action.MEDIA_SCANNER_SCAN_FILE -d file://{remote_video}")
        time.sleep(3)

        # Launch Instagram
        print("Launching Instagram...")
        adb.launch_instagram()
        time.sleep(5)

        # Vision-action loop
        video_uploaded = False
        step = 0

        with tempfile.TemporaryDirectory() as tmpdir:
            while step < max_steps:
                step += 1
                print(f"\n--- Step {step} ---")

                # Take screenshot via Geelark API (more reliable than ADB)
                screenshot_path = os.path.join(tmpdir, f"screen_{step}.png")
                print("Taking screenshot...")

                try:
                    download_url = client.wait_for_screenshot(phone_id, timeout=30)
                    # Download the screenshot
                    import requests as req
                    resp = req.get(download_url)
                    with open(screenshot_path, "wb") as f:
                        f.write(resp.content)
                except Exception as e:
                    print(f"Failed to take screenshot: {e}")
                    time.sleep(2)
                    continue

                # Analyze with Claude Vision
                print("Analyzing screen...")
                try:
                    result = analyze_for_instagram_post(
                        screenshot_path,
                        caption,
                        video_uploaded=video_uploaded
                    )
                except Exception as e:
                    print(f"Vision error: {e}")
                    time.sleep(2)
                    continue

                print(f"Action: {result.get('action')} - {result.get('message')}")

                # Track if video was selected
                if result.get("video_selected"):
                    video_uploaded = True

                # Execute action
                action = result.get("action")

                if action == "done":
                    print("\n[SUCCESS] Post completed successfully!")
                    return True

                elif action == "error":
                    print(f"\n[ERROR] Error detected: {result.get('message')}")
                    return False

                elif action == "wait":
                    print("Waiting for loading...")
                    time.sleep(3)

                elif action == "tap":
                    x, y = result.get("x"), result.get("y")
                    print(f"Tapping ({x}, {y})")
                    adb.tap(x, y)
                    time.sleep(2)

                elif action == "type":
                    text = result.get("text", caption)
                    print(f"Typing: {text[:50]}...")
                    adb.type_text(text)
                    time.sleep(1)

                elif action == "swipe":
                    swipe = result.get("swipe", {})
                    print(f"Swiping from ({swipe['x1']},{swipe['y1']}) to ({swipe['x2']},{swipe['y2']})")
                    adb.swipe(swipe["x1"], swipe["y1"], swipe["x2"], swipe["y2"])
                    time.sleep(1)

                elif action == "back":
                    print("Pressing back")
                    adb.back()
                    time.sleep(1)

                else:
                    print(f"Unknown action: {action}")
                    time.sleep(2)

        print(f"\n[FAILED] Max steps ({max_steps}) reached without completing post")
        return False

    finally:
        # Cleanup
        print("\nCleaning up...")
        try:
            adb.shell(f"rm /sdcard/Download/{os.path.basename(video_path)}")
        except:
            pass
        adb.disconnect()
        client.disable_adb(phone_id)


if __name__ == "__main__":
    if len(sys.argv) < 4:
        print("Usage: python post_to_instagram.py <phone_name> <video_path> <caption>")
        print('Example: python post_to_instagram.py cloudypenguinzip video.mp4 "Check this out!"')
        sys.exit(1)

    phone = sys.argv[1]
    video = sys.argv[2]
    caption = sys.argv[3]

    success = post_video(phone, video, caption)
    sys.exit(0 if success else 1)
</file>

<file path="archived/setup_adbkeyboard.backup.py">
"""
Install and enable ADBKeyboard on Geelark cloud phones.
This keyboard allows typing special characters via ADB.

Usage:
    python setup_adbkeyboard.py <phone1> <phone2> ...

Example:
    python setup_adbkeyboard.py miccliparchive reelwisdompod_ podmindstudio
"""
import sys
import os
import time
import subprocess
from geelark_client import GeelarkClient

ADB_PATH = r"C:\Users\asus\Downloads\platform-tools-latest-windows\platform-tools\adb.exe"
APK_PATH = os.path.join(os.path.dirname(__file__), "ADBKeyboard.apk")


def adb(device, cmd, timeout=30):
    """Run ADB shell command"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def adb_install(device, apk_path):
    """Install APK via ADB"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "install", "-r", apk_path],
        capture_output=True, timeout=120,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def setup_phone(phone_name):
    """Setup ADBKeyboard on a single phone"""
    client = GeelarkClient()

    print(f"\n{'='*50}")
    print(f"Setting up ADBKeyboard on: {phone_name}")
    print('='*50)

    # Find phone
    print("Finding phone...")
    phone = None
    for page in range(1, 10):
        result = client.list_phones(page=page, page_size=100)
        for p in result["items"]:
            if p["serialName"] == phone_name:
                phone = p
                break
        if phone:
            break

    if not phone:
        print(f"  ERROR: Phone not found: {phone_name}")
        return False

    phone_id = phone["id"]
    print(f"  Found: {phone['serialName']} (Status: {phone['status']})")

    # Start phone if needed
    if phone["status"] != 0:
        print("  Starting phone...")
        client.start_phone(phone_id)
        for i in range(60):
            time.sleep(2)
            status = client.get_phone_status([phone_id])
            items = status.get("successDetails", [])
            if items and items[0].get("status") == 0:
                print(f"    Ready after {(i+1)*2}s")
                break
        time.sleep(5)

    # Enable ADB
    print("  Enabling ADB...")
    client.enable_adb(phone_id)
    time.sleep(5)

    # Get ADB info
    adb_info = client.get_adb_info(phone_id)
    device = f"{adb_info['ip']}:{adb_info['port']}"
    password = adb_info['pwd']

    # Connect
    print(f"  Connecting to {device}...")
    subprocess.run([ADB_PATH, "connect", device], capture_output=True)
    time.sleep(1)

    # Login
    login_result = adb(device, f"glogin {password}")
    print(f"  Login: {login_result or 'OK'}")

    # Check if already installed
    print("  Checking if ADBKeyboard is installed...")
    packages = adb(device, "pm list packages | grep adbkeyboard")
    if "com.android.adbkeyboard" in packages:
        print("  ADBKeyboard already installed!")
    else:
        # Install APK
        print(f"  Installing ADBKeyboard.apk...")
        install_result = adb_install(device, APK_PATH)
        print(f"    {install_result}")
        if "Success" not in install_result:
            print("  ERROR: Installation failed")
            return False

    # Enable ADBKeyboard as an input method
    print("  Enabling ADBKeyboard input method...")
    adb(device, "ime enable com.android.adbkeyboard/.AdbIME")

    # Set as default input method
    print("  Setting ADBKeyboard as default...")
    adb(device, "ime set com.android.adbkeyboard/.AdbIME")

    # Verify
    print("  Verifying...")
    current_ime = adb(device, "settings get secure default_input_method")
    if "adbkeyboard" in current_ime.lower():
        print(f"  SUCCESS: ADBKeyboard is now the default keyboard")
        return True
    else:
        print(f"  WARNING: Current IME is: {current_ime}")
        return False


def main():
    if len(sys.argv) < 2:
        print("Usage: python setup_adbkeyboard.py <phone1> <phone2> ...")
        print("Example: python setup_adbkeyboard.py miccliparchive reelwisdompod_ podmindstudio")
        sys.exit(1)

    if not os.path.exists(APK_PATH):
        print(f"ERROR: ADBKeyboard.apk not found at {APK_PATH}")
        sys.exit(1)

    phones = sys.argv[1:]
    results = {}

    for phone in phones:
        try:
            results[phone] = setup_phone(phone)
        except Exception as e:
            print(f"  ERROR: {e}")
            results[phone] = False

    # Summary
    print("\n" + "="*50)
    print("SETUP COMPLETE")
    print("="*50)
    for phone, success in results.items():
        status = "OK" if success else "FAILED"
        print(f"  {phone}: {status}")


if __name__ == "__main__":
    main()
</file>

<file path="archived/setup_clipboard_helper.backup.py">
"""
Install ClipboardHelper APK on Geelark cloud phones.
This app enables clipboard access via ADB for typing Unicode text, emojis, and newlines.

Usage:
    python setup_clipboard_helper.py <phone1> <phone2> ...

Example:
    python setup_clipboard_helper.py miccliparchive reelwisdompod_ podmindstudio
"""
import sys
import os
import time
import subprocess
from geelark_client import GeelarkClient

ADB_PATH = r"C:\Users\asus\Downloads\platform-tools-latest-windows\platform-tools\adb.exe"
APK_PATH = os.path.join(os.path.dirname(__file__), "ClipboardHelper.apk")


def adb(device, cmd, timeout=30):
    """Run ADB shell command"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def adb_install(device, apk_path):
    """Install APK via ADB"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "install", "-r", apk_path],
        capture_output=True, timeout=120,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def setup_phone(phone_name):
    """Setup ClipboardHelper on a single phone"""
    client = GeelarkClient()

    print(f"\n{'='*50}")
    print(f"Setting up ClipboardHelper on: {phone_name}")
    print('='*50)

    # Find phone
    print("Finding phone...")
    phone = None
    for page in range(1, 10):
        result = client.list_phones(page=page, page_size=100)
        for p in result["items"]:
            if p["serialName"] == phone_name:
                phone = p
                break
        if phone:
            break

    if not phone:
        print(f"  ERROR: Phone not found: {phone_name}")
        return False

    phone_id = phone["id"]
    print(f"  Found: {phone['serialName']} (Status: {phone['status']})")

    # Start phone if needed
    if phone["status"] != 0:
        print("  Starting phone...")
        client.start_phone(phone_id)
        for i in range(60):
            time.sleep(2)
            status = client.get_phone_status([phone_id])
            items = status.get("successDetails", [])
            if items and items[0].get("status") == 0:
                print(f"    Ready after {(i+1)*2}s")
                break
        time.sleep(5)

    # Enable ADB
    print("  Enabling ADB...")
    client.enable_adb(phone_id)
    time.sleep(5)

    # Get ADB info
    adb_info = client.get_adb_info(phone_id)
    device = f"{adb_info['ip']}:{adb_info['port']}"
    password = adb_info['pwd']

    # Connect
    print(f"  Connecting to {device}...")
    subprocess.run([ADB_PATH, "connect", device], capture_output=True)
    time.sleep(1)

    # Login
    login_result = adb(device, f"glogin {password}")
    print(f"  Login: {login_result or 'OK'}")

    # Check if already installed
    print("  Checking if ClipboardHelper is installed...")
    packages = adb(device, "pm list packages | grep geelark.clipboard")
    if "com.geelark.clipboard" in packages:
        print("  ClipboardHelper already installed!")
    else:
        # Install APK
        print(f"  Installing ClipboardHelper.apk...")
        install_result = adb_install(device, APK_PATH)
        print(f"    {install_result}")
        if "Success" not in install_result:
            print("  ERROR: Installation failed")
            return False

    # Test clipboard functionality
    print("  Testing clipboard...")
    import base64
    test_text = "Test with emoji 🔥 and newline\nSecond line!"
    text_b64 = base64.b64encode(test_text.encode('utf-8')).decode('ascii')
    result = adb(device, f"am start -a com.geelark.clipboard.COPY --es base64 {text_b64}")
    if "Starting" in result:
        print("  SUCCESS: ClipboardHelper is working!")
        return True
    else:
        print(f"  WARNING: Test may have failed: {result}")
        return True  # APK is installed, just test might not verify easily


def main():
    if len(sys.argv) < 2:
        print("Usage: python setup_clipboard_helper.py <phone1> <phone2> ...")
        print("Example: python setup_clipboard_helper.py miccliparchive reelwisdompod_ podmindstudio")
        sys.exit(1)

    if not os.path.exists(APK_PATH):
        print(f"ERROR: ClipboardHelper.apk not found at {APK_PATH}")
        print("Run the build script first: ClipboardHelper/build.ps1")
        sys.exit(1)

    phones = sys.argv[1:]
    results = {}

    for phone in phones:
        try:
            results[phone] = setup_phone(phone)
        except Exception as e:
            print(f"  ERROR: {e}")
            results[phone] = False

    # Summary
    print("\n" + "="*50)
    print("SETUP COMPLETE")
    print("="*50)
    for phone, success in results.items():
        status = "OK" if success else "FAILED"
        print(f"  {phone}: {status}")


if __name__ == "__main__":
    main()
</file>

<file path="reviews/architectural_layer_analysis.md">
# Architectural Layer Analysis Report
## Geelark Instagram Automation Codebase

**Analysis Date:** December 2024  
**Codebase:** YallaPapi/geelark-automation

---

## Executive Summary

The Geelark Instagram Automation codebase follows a **loosely-layered architecture** with recognizable but imperfectly separated concerns. While distinct functional areas exist, the codebase exhibits significant **layer violations** where business logic is embedded in presentation components, and infrastructure concerns leak into core domain logic.

### Architecture Pattern Assessment

| Pattern | Adherence | Notes |
|---------|-----------|-------|
| **Layered Architecture** | ⚠️ Partial | Layers exist but have unclear boundaries |
| **MVC/MVP** | ❌ Not Applied | UI components directly orchestrate business logic |
| **Clean Architecture** | ❌ Not Applied | Dependencies flow inward and outward chaotically |
| **Hexagonal/Ports & Adapters** | ❌ Not Applied | No clear port/adapter separation |

---

## Identified Architectural Layers

### Layer Diagram

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         PRESENTATION LAYER                                  │
│  ┌─────────────────┐ ┌──────────────────┐ ┌─────────────────────────────┐  │
│  │  dashboard.py   │ │ posting_dashboard│ │       post_gui.py           │  │
│  │  (Flask Web)    │ │     .py (Tkinter)│ │      (Tkinter)              │  │
│  └────────┬────────┘ └────────┬─────────┘ └──────────────┬──────────────┘  │
│           │                   │                          │                  │
│           │ ⚠️ DIRECT ACCESS  │ ⚠️ EMBEDS BUSINESS LOGIC │ ⚠️ SUBPROCESS   │
└───────────┼───────────────────┼──────────────────────────┼──────────────────┘
            │                   │                          │
            ▼                   ▼                          ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                      ORCHESTRATION / APPLICATION LAYER                      │
│  ┌─────────────────────┐ ┌────────────────────┐ ┌─────────────────────┐    │
│  │ parallel_orchestrator│ │  posting_scheduler │ │ scheduler_watchdog  │    │
│  │        .py          │ │        .py         │ │        .py          │    │
│  └──────────┬──────────┘ └──────────┬─────────┘ └──────────┬──────────┘    │
│             │                       │                      │                │
│             │ ⚠️ MIXED CONCERNS     │                      │                │
└─────────────┼───────────────────────┼──────────────────────┼────────────────┘
              │                       │                      │
              ▼                       ▼                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          CORE / DOMAIN LAYER                                │
│  ┌───────────────────────────────────────────────────────────────────────┐ │
│  │                     SmartInstagramPoster (post_reel_smart.py)         │ │
│  │  ┌─────────────┐ ┌──────────────┐ ┌─────────────┐ ┌───────────────┐  │ │
│  │  │ Connection  │ │ UI Analysis  │ │ AI Decision │ │ Posting Flow  │  │ │
│  │  │ Management  │ │   & Control  │ │   Making    │ │   (FSM)       │  │ │
│  │  └─────────────┘ └──────────────┘ └─────────────┘ └───────────────┘  │ │
│  │                    ⚠️ GOD CLASS - ALL MIXED TOGETHER                  │ │
│  └───────────────────────────────────────────────────────────────────────┘ │
│  ┌─────────────────────┐ ┌─────────────────────┐                           │
│  │   parallel_worker   │ │   progress_tracker  │                           │
│  │        .py          │ │        .py          │                           │
│  └──────────┬──────────┘ └──────────┬──────────┘                           │
└─────────────┼───────────────────────┼───────────────────────────────────────┘
              │                       │
              ▼                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                       INFRASTRUCTURE / DATA ACCESS LAYER                    │
│  ┌──────────────────┐ ┌────────────────────┐ ┌───────────────────────────┐ │
│  │  geelark_client  │ │appium_server_manager│ │     adb_controller        │ │
│  │  (REST API)      │ │   (Process Mgmt)   │ │     (Shell Commands)      │ │
│  └────────┬─────────┘ └─────────┬──────────┘ └─────────────┬─────────────┘ │
│           │                     │                          │                │
│           ▼                     ▼                          ▼                │
│  ┌──────────────────┐ ┌────────────────────┐ ┌───────────────────────────┐ │
│  │  Geelark Cloud   │ │   Appium Server    │ │        ADB / Shell        │ │
│  │      API         │ │   (localhost)      │ │                           │ │
│  └──────────────────┘ └────────────────────┘ └───────────────────────────┘ │
│                                                                             │
│  ┌──────────────────┐ ┌────────────────────┐                               │
│  │   File System    │ │   Anthropic API    │                               │
│  │  (CSV, JSON)     │ │   (Claude AI)      │                               │
│  └──────────────────┘ └────────────────────┘                               │
└─────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────┐
│                         CONFIGURATION LAYER                                 │
│  ┌──────────────────┐ ┌────────────────────┐ ┌───────────────────────────┐ │
│  │  parallel_config │ │      .env          │ │   Hardcoded Constants     │ │
│  │       .py        │ │   (credentials)    │ │   (scattered across files)│ │
│  └──────────────────┘ └────────────────────┘ └───────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Layer 1: Presentation Layer

### Purpose
Handle user interaction, display information, and capture user input.

### Components

| Component | Type | Framework | Responsibilities |
|-----------|------|-----------|------------------|
| `dashboard.py` | Web UI | Flask | Real-time status dashboard, log streaming |
| `posting_dashboard.py` | Desktop GUI | Tkinter | Full-featured posting control panel |
| `post_gui.py` | Desktop GUI | Tkinter | Simple single-post monitor |

### Code Analysis

#### `dashboard.py` - Flask Web Dashboard
```python
# dashboard.py - Lines 8633-8853
# Good: Clear presentation concern
app = Flask(__name__)
STATE_FILE = "scheduler_state.json"
LOG_FILE = "scheduler_live.log"

# HTML template embedded in Python (not ideal, but functional)
HTML = """
<!DOCTYPE html><html><head><meta charset="UTF-8"><title>Dashboard</title>
<style>
body{font-family:sans-serif;background:#1a1a2e;color:#fff...}
...
</style></head>
"""

# ⚠️ LAYER VIOLATION: Direct file system access for state
def load_state():
    if not os.path.exists(STATE_FILE): return {"jobs":[],"accounts":{}}
    try:
        with open(STATE_FILE,'r',encoding='utf-8') as f: return json.load(f)
    except: return {"jobs":[],"accounts":{}}

@app.route('/api/status')
def api_status():
    st=load_state()  # ← Direct data access, no service layer
    jobs=st.get('jobs',[])
    return jsonify({"stats":get_stats(jobs),...})
```

**Issues Identified:**
- ❌ Direct file I/O in presentation layer (should use a service/repository)
- ❌ Business logic (stats calculation) in presentation
- ⚠️ HTML template embedded in Python file

#### `posting_dashboard.py` - Tkinter Control Panel
```python
# posting_dashboard.py - Lines 15619-16137
class PostingDashboard:
    def __init__(self, root):
        self.root = root
        # ⚠️ LAYER VIOLATION: Direct instantiation of business logic
        self.scheduler = PostingScheduler()
        self.scheduler.on_status_update = self.log
        self.scheduler.on_job_complete = self.on_job_complete
        
        self.setup_ui()
        self.refresh_all()

    def start_scheduler(self):
        """Start the posting scheduler"""
        if not self.scheduler.accounts:
            messagebox.showerror("Error", "Add at least one account first")
            return
        if not self.scheduler.jobs:
            messagebox.showerror("Error", "Add video folders first")
            return
            
        # ⚠️ Directly calling business logic from UI
        self.scheduler.start()
        self.start_btn.config(state=tk.DISABLED)
        self.pause_btn.config(state=tk.NORMAL)
        self.stop_btn.config(state=tk.NORMAL)
```

**Issues Identified:**
- ❌ Direct instantiation of `PostingScheduler` (tight coupling)
- ❌ Business validation logic in UI layer
- ❌ UI directly controls scheduler state

#### `post_gui.py` - Single Post Monitor
```python
# post_gui.py - Lines 13881-14150
class PostingMonitor:
    def run_posting(self, phone, video_path, caption):
        """Run the posting script in a subprocess"""
        # ✓ GOOD: Uses subprocess to isolate concerns
        script_path = os.path.join(os.path.dirname(__file__), 'post_reel_smart.py')
        
        self.process = subprocess.Popen(
            [sys.executable, '-u', script_path, phone, video_path, caption],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            ...
        )
```

**Positive Pattern:**
- ✓ Uses subprocess isolation (loose coupling)
- ✓ Streams output without knowledge of posting internals

---

## Layer 2: Orchestration / Application Layer

### Purpose
Coordinate workflows, manage process lifecycle, and handle cross-cutting concerns.

### Components

| Component | Responsibilities |
|-----------|------------------|
| `parallel_orchestrator.py` | Multi-worker process management, job distribution |
| `posting_scheduler.py` | Job queue management, state persistence, retry logic |
| `scheduler_watchdog.py` | Health monitoring, automatic recovery |

### Code Analysis

#### `parallel_orchestrator.py` - Multi-Worker Coordination
```python
# parallel_orchestrator.py - Lines 12292-13326
def run_parallel_posting(num_workers, state_file, force_reseed, ...):
    """Main orchestration function"""
    config = get_config(num_workers=num_workers)
    
    # ⚠️ MIXED CONCERNS: Infrastructure + Business Logic
    # 1. Port availability checking (infrastructure)
    for worker_config in config.workers:
        port = worker_config.appium_port
        if is_port_in_use(port):
            if force_kill_ports:
                kill_process_on_port(port)  # Infrastructure concern
            else:
                raise Exception(f"Port {port} in use")

    # 2. Seed progress file (business logic)
    count = seed_progress_file(config, state_file, accounts)
    
    # 3. Start worker processes (process management)
    processes = []
    for worker_config in config.workers:
        proc = start_worker_process(worker_config, config)
        processes.append(proc)
    
    # 4. Monitor workers (orchestration)
    monitor_workers(processes, config)
```

**Issues Identified:**
- ⚠️ Mixes infrastructure (port checking) with business logic (job seeding)
- ⚠️ Direct subprocess management alongside business orchestration

#### `posting_scheduler.py` - Job Queue & State
```python
# posting_scheduler.py - Lines 16140-16900
class PostingScheduler:
    def __init__(self, state_file: str = "scheduler_state.json"):
        # ⚠️ MIXED CONCERNS: State, Config, Business Rules, Threading
        self.state_file = state_file
        self.jobs: Dict[str, PostJob] = {}
        self.accounts: Dict[str, AccountState] = {}
        
        # Settings (should be in config layer)
        self.max_retries = 3
        self.posts_per_account_per_day = 1
        
        # Runtime state (should be separate)
        self.running = False
        self.worker_thread: Optional[threading.Thread] = None
        
        # Callbacks (presentation layer concern)
        self.on_status_update: Optional[Callable] = None
        self.on_job_complete: Optional[Callable] = None
        
        self.load_state()

    def save_state(self):
        """⚠️ LAYER VIOLATION: Persistence mixed with business logic"""
        data = {
            'jobs': [job.to_dict() for job in self.jobs.values()],
            'accounts': [asdict(acc) for acc in self.accounts.values()],
            'settings': {
                'max_retries': self.max_retries,
                ...
            }
        }
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
```

**Issues Identified:**
- ❌ Combines job queue, state persistence, settings, threading, and callbacks
- ❌ File I/O directly in scheduler (should use repository pattern)
- ❌ Configuration mixed with runtime state

---

## Layer 3: Core / Domain Layer

### Purpose
Implement core business logic, domain entities, and automation workflows.

### Components

| Component | Responsibilities |
|-----------|------------------|
| `post_reel_smart.py` | Instagram posting automation (GOD CLASS) |
| `parallel_worker.py` | Individual worker job execution |
| `progress_tracker.py` | Job state tracking with file locking |
| `vision.py` | AI vision analysis (partially used) |
| `adb_controller.py` | ADB abstraction (partially used) |

### Code Analysis

#### `SmartInstagramPoster` - The God Class
```python
# post_reel_smart.py - Lines 14220-15398
class SmartInstagramPoster:
    """⚠️ GOD CLASS: 1200+ lines, 7+ responsibilities"""
    
    def __init__(self, phone_name, system_port=8200, appium_url=None):
        # ❌ Direct dependencies on infrastructure
        self.client = GeelarkClient()           # API client
        self.anthropic = anthropic.Anthropic()  # AI client
        
    # RESPONSIBILITY 1: Connection Management (Infrastructure)
    def connect(self):
        """Find phone and connect via ADB"""
        # 150+ lines of Geelark API + ADB + Appium setup
        for page in range(1, 10):
            result = self.client.list_phones(page=page, page_size=100)
            ...
        self.client.enable_adb(self.phone_id)
        subprocess.run([ADB_PATH, "connect", self.device], ...)
        self.connect_appium()
    
    # RESPONSIBILITY 2: UI Interaction (Device Control)
    def tap(self, x, y):
        self.appium_driver.tap([(x, y)])
    
    def swipe(self, x1, y1, x2, y2, duration_ms=300):
        self.appium_driver.swipe(x1, y1, x2, y2, duration_ms)
    
    # RESPONSIBILITY 3: UI Parsing (Technical)
    def dump_ui(self):
        """Dump UI hierarchy and return parsed elements"""
        xml_str = self.appium_driver.page_source
        for elem in root.iter():
            elements.append({
                'text': text, 'desc': desc, ...
            })
        return elements, xml_str
    
    # RESPONSIBILITY 4: AI Analysis (External Service)
    def analyze_ui(self, elements, caption):
        """Use Claude to analyze UI and decide next action"""
        prompt = f"""You are controlling an Android phone...
        Instagram posting flow:
        1. Find and tap Create/+ button...
        """
        response = self.anthropic.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=500,
            messages=[{"role": "user", "content": prompt}]
        )
        return json.loads(response.content[0].text)
    
    # RESPONSIBILITY 5: Business Logic (Posting Flow)
    def post(self, video_path, caption, max_steps=30, humanize=False):
        """Main posting flow with smart navigation"""
        self.upload_video(video_path)
        self.adb("am force-stop com.instagram.android")
        self.adb("monkey -p com.instagram.android 1")
        
        for step in range(max_steps):
            elements, raw_xml = self.dump_ui()
            action = self.analyze_ui(elements, caption)
            
            if action['action'] == 'tap':
                self.tap(x, y)
            elif action['action'] == 'done':
                return True
    
    # RESPONSIBILITY 6: Human Simulation (Domain)
    def humanize_before_post(self):
        """Perform random human-like actions"""
        # 100+ lines of random scrolling, story viewing, etc.
        
    # RESPONSIBILITY 7: Error Detection (Cross-cutting)
    def detect_error_state(self, elements):
        """Check for account/app errors"""
        error_keywords = {
            'suspended': ['your account has been suspended', ...],
            'captcha': ['confirm it\'s you', 'security check', ...],
            ...
        }
```

**Critical Issues:**
- ❌ **God Class**: 1200+ lines with 7+ distinct responsibilities
- ❌ **Hardcoded Infrastructure**: Direct `subprocess` calls, hardcoded paths
- ❌ **Mixed Abstraction Levels**: Low-level ADB commands mixed with high-level posting logic
- ❌ **Embedded AI Prompts**: 90+ lines of Instagram-specific prompts in the class
- ❌ **No Dependency Injection**: Direct instantiation of `GeelarkClient` and `anthropic.Anthropic`

#### `progress_tracker.py` - Job State Management
```python
# progress_tracker.py (not shown in detail, but analyzed)
@dataclass
class PostJob:
    """Domain entity - Good separation"""
    id: str
    video_path: str
    caption: str
    status: str = "pending"
    attempts: int = 0
    
class ProgressTracker:
    """⚠️ Mixes concerns: Domain + Persistence + File Locking"""
    def claim_next_job(self, worker_id: str) -> Optional[Dict]:
        # ✓ Good: Uses file locking for concurrency
        with portalocker.Lock(self.progress_file, 'r+', ...):
            # Read, modify, write atomically
            ...
```

---

## Layer 4: Infrastructure / Data Access Layer

### Purpose
Handle external system integration, data persistence, and technical concerns.

### Components

| Component | External System | Pattern |
|-----------|-----------------|---------|
| `geelark_client.py` | Geelark Cloud API | API Client |
| `appium_server_manager.py` | Appium Server | Process Manager |
| `adb_controller.py` | Android Debug Bridge | Command Wrapper |
| File I/O | CSV, JSON files | Direct Access |
| `anthropic` (inline) | Claude AI API | Direct SDK Use |

### Code Analysis

#### `geelark_client.py` - Well-Structured API Client
```python
# geelark_client.py - Lines 11551-11805
class GeelarkClient:
    """✓ GOOD: Clean API client with single responsibility"""
    
    def __init__(self):
        self.app_id = os.getenv("GEELARK_APP_ID")
        self.api_key = os.getenv("GEELARK_API_KEY")
        self.token = os.getenv("GEELARK_TOKEN")

    def _get_headers(self):
        """Generate headers for token-based authentication"""
        trace_id = str(uuid.uuid4()).upper().replace("-", "")
        return {
            "Content-Type": "application/json",
            "traceId": trace_id,
            "Authorization": f"Bearer {self.token}"
        }

    def _request(self, endpoint, data=None):
        """Make API request with full response logging"""
        url = f"{API_BASE}{endpoint}"
        headers = self._get_headers()
        resp = requests.post(url, json=data or {}, headers=headers)
        result = resp.json()
        if result.get("code") != 0:
            raise Exception(f"API error: {result.get('code')}")
        return result.get("data")

    # ✓ Clean, single-purpose methods
    def list_phones(self, page=1, page_size=100, group_name=None):
        return self._request("/open/v1/phone/list", {...})

    def start_phone(self, phone_id):
        return self._request("/open/v1/phone/start", {"ids": [phone_id]})
    
    def enable_adb(self, phone_id):
        return self._request("/open/v1/adb/setStatus", {...})
```

**Positive Patterns:**
- ✓ Single responsibility (Geelark API communication)
- ✓ Centralized error handling
- ✓ Clean method naming
- ✓ Environment-based configuration

#### `appium_server_manager.py` - Process Lifecycle Manager
```python
# appium_server_manager.py - Lines 2171-2500
class AppiumServerManager:
    """✓ GOOD: Focused on Appium server lifecycle"""
    
    def __init__(self, worker_config: WorkerConfig, parallel_config: ParallelConfig):
        self.worker_config = worker_config
        self.parallel_config = parallel_config
        self.process: Optional[subprocess.Popen] = None
    
    def start(self, timeout: float = 30.0) -> None:
        """Start the Appium server and wait for healthy"""
        if self.is_healthy():
            return  # Reuse existing
        
        cmd = self._build_command()
        self.process = subprocess.Popen(cmd, ...)
        
        if not self.wait_for_healthy(timeout=timeout):
            raise AppiumServerError("Appium didn't become healthy")
    
    def is_healthy(self, timeout: float = 5.0) -> bool:
        """Check if Appium server is running and healthy"""
        url = f"{self.appium_url}/status"
        response = urlopen(url, timeout=timeout)
        return data.get('value', {}).get('ready', False)
```

**Positive Patterns:**
- ✓ Context manager support (`__enter__`/`__exit__`)
- ✓ Health checking
- ✓ Graceful shutdown handling
- ✓ Clear separation from business logic

---

## Layer 5: Configuration Layer

### Purpose
Manage application settings, environment configuration, and runtime parameters.

### Components

| Component | Scope | Issues |
|-----------|-------|--------|
| `parallel_config.py` | Worker/port allocation | ✓ Well-structured |
| `.env` | API credentials | ✓ Standard practice |
| Hardcoded constants | Scattered | ❌ Duplicated, inconsistent |

### Code Analysis

#### `parallel_config.py` - Good Configuration Pattern
```python
# parallel_config.py - Lines 12086-12290
@dataclass
class WorkerConfig:
    """✓ GOOD: Clean, validated configuration"""
    worker_id: int
    appium_port: int
    system_port_start: int
    system_port_end: int
    
    @property
    def appium_url(self) -> str:
        return f"http://127.0.0.1:{self.appium_port}"
    
    def validate(self) -> None:
        if self.appium_port < 1024 or self.appium_port > 65535:
            raise ValueError(f"Invalid Appium port {self.appium_port}")

@dataclass
class ParallelConfig:
    """✓ GOOD: Centralized parallel execution config"""
    num_workers: int = 3
    progress_file: str = "parallel_progress.csv"
    job_timeout: int = 300
    # ⚠️ Hardcoded paths should be environment-based
    android_sdk_path: str = r"C:\Users\asus\Downloads\android-sdk"
    adb_path: str = r"C:\Users\asus\Downloads\android-sdk\platform-tools\adb.exe"
```

#### Hardcoded Constants - Anti-Pattern
```python
# ❌ SCATTERED ACROSS FILES:

# post_reel_smart.py - Line 14216
ADB_PATH = r"C:\Users\asus\Downloads\platform-tools-latest-windows\platform-tools\adb.exe"

# parallel_worker.py - Line 13375
ADB_PATH = r'C:\Users\asus\Downloads\android-sdk\platform-tools\adb.exe'
# ^^^ NOTE: DIFFERENT PATH!

# posting_scheduler.py - Lines 16158-16159
os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'

# parallel_orchestrator.py - Lines 12338-12339
os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'
```

**Critical Issue:** Same configuration value defined differently in multiple files!

---

## Architectural Pattern Violations

### Violation 1: Presentation → Domain Direct Coupling

```
┌─────────────────────────────────────┐
│     posting_dashboard.py            │
│  ┌─────────────────────────────────┐│
│  │ self.scheduler = PostingScheduler()  ← DIRECT INSTANTIATION
│  │ self.scheduler.start()          ││
│  │ self.scheduler.pause()          ││
│  └─────────────────────────────────┘│
└─────────────────────────────────────┘
```

**Problem:** UI directly controls business logic without abstraction.

**Correct Pattern:**
```python
# Should use dependency injection or service locator
class PostingDashboard:
    def __init__(self, scheduler_service: ISchedulerService):
        self.scheduler = scheduler_service
```

### Violation 2: Business Logic in Presentation

```python
# dashboard.py - Business logic in Flask route
def get_stats(jobs):
    s={"success":0,"in_progress":0,"pending":0,"failed":0}
    for j in jobs:
        st=j.get('status','pending')
        if st in s: s[st]+=1
    return s

@app.route('/api/status')
def api_status():
    st=load_state()  # ← Data access
    jobs=st.get('jobs',[])
    return jsonify({"stats":get_stats(jobs),...})  # ← Business logic
```

**Problem:** Stats calculation should be in a service layer.

### Violation 3: Infrastructure in Domain

```python
# SmartInstagramPoster.connect() - Infrastructure in domain class
def connect(self):
    # 150 lines mixing:
    # - Geelark API calls (infrastructure)
    # - ADB subprocess commands (infrastructure)
    # - Appium connection (infrastructure)
    # - Business validation (domain)
    
    subprocess.run([ADB_PATH, "connect", self.device], ...)
    self.adb(f"glogin {password}")
    self.connect_appium()
```

**Problem:** Domain class directly manages infrastructure concerns.

### Violation 4: Missing Repository Pattern

```python
# posting_scheduler.py - Direct file I/O in scheduler
def save_state(self):
    with open(self.state_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def load_state(self):
    with open(self.state_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
```

**Correct Pattern:**
```python
# Should use repository abstraction
class IStateRepository(Protocol):
    def save(self, state: SchedulerState) -> None: ...
    def load(self) -> SchedulerState: ...

class JsonFileStateRepository(IStateRepository):
    def save(self, state: SchedulerState) -> None:
        with open(self.path, 'w') as f:
            json.dump(state.to_dict(), f)
```

---

## Recommended Architecture

### Proposed Clean Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                      PRESENTATION LAYER                         │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐ │
│  │ Flask API   │  │ Tkinter GUI │  │    CLI Commands         │ │
│  └──────┬──────┘  └──────┬──────┘  └───────────┬─────────────┘ │
│         │                │                     │                │
│         └────────────────┼─────────────────────┘                │
│                          │                                      │
│                          ▼                                      │
│                   ┌─────────────┐                               │
│                   │ ViewModels  │  (DTOs, presentation logic)   │
│                   └──────┬──────┘                               │
└──────────────────────────┼──────────────────────────────────────┘
                           │ Depends on abstractions only
                           ▼
┌─────────────────────────────────────────────────────────────────┐
│                    APPLICATION LAYER                            │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                     Use Cases                            │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐  │   │
│  │  │ PostVideo   │  │ StartWorkers│  │ MonitorProgress │  │   │
│  │  │ UseCase     │  │ UseCase     │  │ UseCase         │  │   │
│  │  └─────────────┘  └─────────────┘  └─────────────────┘  │   │
│  └─────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                     Services                             │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐  │   │
│  │  │ Scheduler   │  │ Orchestrator│  │ ProgressTracker │  │   │
│  │  │ Service     │  │ Service     │  │ Service         │  │   │
│  │  └─────────────┘  └─────────────┘  └─────────────────┘  │   │
│  └─────────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────────┘
                           │ Depends on domain interfaces
                           ▼
┌─────────────────────────────────────────────────────────────────┐
│                      DOMAIN LAYER                               │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                     Entities                             │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐  │   │
│  │  │ PostJob     │  │ Account     │  │ WorkerState     │  │   │
│  │  └─────────────┘  └─────────────┘  └─────────────────┘  │   │
│  └─────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                   Domain Services                        │   │
│  │  ┌─────────────────┐  ┌───────────────────────────────┐ │   │
│  │  │ PostingStrategy │  │ HumanizationBehavior          │ │   │
│  │  └─────────────────┘  └───────────────────────────────┘ │   │
│  └─────────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                     Interfaces (Ports)                   │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐  │   │
│  │  │IPhoneClient │  │IUIController│  │ IAIAnalyzer     │  │   │
│  │  │IStateRepo   │  │IDeviceBridge│  │ IScreenCapture  │  │   │
│  │  └─────────────┘  └─────────────┘  └─────────────────┘  │   │
│  └─────────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────────┘
                           │ Implemented by adapters
                           ▼
┌─────────────────────────────────────────────────────────────────┐
│                   INFRASTRUCTURE LAYER                          │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                     Adapters                             │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐  │   │
│  │  │GeelarkClient│  │AppiumDriver │  │ ClaudeAnalyzer  │  │   │
│  │  │(IPhoneClient)│ │(IUIController)│ │ (IAIAnalyzer)   │  │   │
│  │  └─────────────┘  └─────────────┘  └─────────────────┘  │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐  │   │
│  │  │ADBBridge    │  │JsonStateRepo│  │ CSVProgressRepo │  │   │
│  │  │(IDeviceBridge)││(IStateRepo)  │ │ (IProgressRepo) │  │   │
│  │  └─────────────┘  └─────────────┘  └─────────────────┘  │   │
│  └─────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

---

## Summary of Findings

### Layers Identified

| Layer | Status | Key Issues |
|-------|--------|------------|
| **Presentation** | ⚠️ Exists but coupled | Direct business logic instantiation |
| **Application/Orchestration** | ⚠️ Partially separated | Mixed infrastructure concerns |
| **Domain/Core** | ❌ Poorly separated | God class, no clear boundaries |
| **Infrastructure** | ✓ Best structured | Clean API clients, but used directly |
| **Configuration** | ⚠️ Partial | Good dataclasses, bad constants |

### Critical Violations

1. **No Dependency Inversion**: Higher layers directly instantiate lower layers
2. **God Class**: `SmartInstagramPoster` has 7+ responsibilities in 1200+ lines
3. **Missing Abstractions**: No interfaces/protocols between layers
4. **Scattered Configuration**: Same values defined differently across files
5. **Presentation Logic Leakage**: Business rules in UI components

### Recommendations

| Priority | Action | Impact |
|----------|--------|--------|
| 🔴 High | Split `SmartInstagramPoster` into focused classes | Maintainability |
| 🔴 High | Introduce interface abstractions (Protocols) | Testability |
| 🟠 Medium | Centralize configuration in single module | Reliability |
| 🟠 Medium | Create repository pattern for state persistence | Separation |
| 🟢 Low | Add use case classes for orchestration | Clarity |

---

## Conclusion

The codebase has **emergent layers** that grew organically but lack **intentional architectural boundaries**. The infrastructure layer (`geelark_client.py`, `appium_server_manager.py`) shows the best separation, while the domain layer suffers from a monolithic God class. Implementing dependency injection and interface abstractions would significantly improve testability and maintainability.
</file>

<file path="reviews/coupling_cohesion_analysis.md">
# Coupling and Cohesion Analysis Report
## Geelark Instagram Automation Codebase

**Analysis Date:** December 2024  
**Codebase:** YallaPapi/geelark-automation

---

## Executive Summary

The Geelark Instagram Automation codebase exhibits several architectural patterns that impact maintainability and testability. While the system successfully accomplishes its goals, there are areas of **high coupling** (modules tightly dependent on each other) and **low cohesion** (modules handling multiple unrelated responsibilities) that could benefit from refactoring.

### Overall Assessment

| Metric | Rating | Notes |
|--------|--------|-------|
| **Coupling** | ⚠️ Moderate-High | Strong dependencies between core modules; hardcoded paths |
| **Cohesion** | ⚠️ Low-Moderate | Several "God classes" with mixed responsibilities |
| **Testability** | ❌ Low | Tightly coupled components make unit testing difficult |
| **Maintainability** | ⚠️ Moderate | Changes often require modifications in multiple files |

---

## Part 1: Coupling Analysis

### 1.1 Dependency Graph Overview

```
                          ┌─────────────────────────┐
                          │    External Services    │
                          │  (Geelark API, Claude)  │
                          └───────────┬─────────────┘
                                      │
    ┌─────────────────────────────────┼─────────────────────────────────┐
    │                                 │                                 │
    ▼                                 ▼                                 ▼
┌───────────────────┐   ┌───────────────────┐   ┌───────────────────────┐
│  geelark_client   │◄──│  post_reel_smart  │──►│    anthropic API      │
│      (API)        │   │    (CORE LOGIC)   │   │    (AI Vision)        │
└───────────────────┘   └─────────┬─────────┘   └───────────────────────┘
         ▲                        │
         │                        │
         │              ┌─────────┼──────────┐
         │              │         │          │
         │              ▼         ▼          ▼
         │    ┌─────────────┐ ┌──────────┐ ┌─────────┐
         │    │   Appium    │ │   ADB    │ │ vision  │
         │    │  (via SDK)  │ │ (shell)  │ │  .py    │
         │    └─────────────┘ └──────────┘ └─────────┘
         │
    ┌────┴───────────┬─────────────────┐
    │                │                 │
    ▼                ▼                 ▼
┌──────────┐  ┌───────────────┐  ┌─────────────────┐
│ parallel │  │    posting    │  │   scheduler     │
│ _worker  │  │   _scheduler  │  │   _watchdog     │
└──────────┘  └───────────────┘  └─────────────────┘
```

### 1.2 High Coupling Areas

#### 🔴 Issue #1: `SmartInstagramPoster` Class (post_reel_smart.py)

**Problem:** This class is a "God Object" with excessive dependencies on external systems.

```python
# post_reel_smart.py - Lines 14220-14237
class SmartInstagramPoster:
    def __init__(self, phone_name, system_port=8200, appium_url=None):
        self.client = GeelarkClient()           # ← Dependency 1: Geelark API
        self.anthropic = anthropic.Anthropic()  # ← Dependency 2: Claude AI
        self.phone_name = phone_name
        self.phone_id = None
        self.device = None
        # ... plus Appium WebDriver                # ← Dependency 3: Appium
        # ... plus ADB subprocess calls            # ← Dependency 4: ADB
```

**Coupling Count:** 4 major external dependencies + hardcoded paths

**Impact:**
- Cannot test posting logic without mocking 4 different external systems
- Changes to Geelark API require changes to posting logic
- Difficult to swap AI provider or device control mechanism

---

#### 🔴 Issue #2: Hardcoded Configuration (Global Constants)

**Problem:** Paths and configuration are hardcoded and duplicated across multiple files.

```python
# post_reel_smart.py - Line 14216-14217
ADB_PATH = r"C:\Users\asus\Downloads\platform-tools-latest-windows\platform-tools\adb.exe"
APPIUM_SERVER = "http://127.0.0.1:4723"

# parallel_worker.py - Line 13375
ADB_PATH = r'C:\Users\asus\Downloads\android-sdk\platform-tools\adb.exe'

# posting_scheduler.py - Lines 16158-16159
os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'
os.environ['ANDROID_SDK_ROOT'] = r'C:\Users\asus\Downloads\android-sdk'

# parallel_orchestrator.py - Lines 12338-12339
os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'
os.environ['ANDROID_SDK_ROOT'] = r'C:\Users\asus\Downloads\android-sdk'
```

**Impact:**
- Configuration scattered across 4+ files
- Deploying to different machine requires editing multiple files
- Inconsistent paths (note `platform-tools-latest-windows` vs `android-sdk`)
- Violates DRY (Don't Repeat Yourself) principle

---

#### 🔴 Issue #3: Circular/Tight Dependency Chain

**Problem:** `parallel_worker.py` → `post_reel_smart.py` → `geelark_client.py` creates a tight chain.

```python
# parallel_worker.py - Line 13613
from post_reel_smart import SmartInstagramPoster

# Then in execute_posting_job():
def execute_posting_job(job, worker_config, config, logger, tracker=None, worker_id=None):
    from post_reel_smart import SmartInstagramPoster  # ← Late import to avoid circular
    
    poster = SmartInstagramPoster(
        phone_name=account,
        system_port=worker_config.system_port,
        appium_url=worker_config.appium_url
    )
```

**Impact:**
- Late imports suggest circular dependency issues
- Worker is tightly coupled to specific poster implementation
- Cannot easily swap posting strategies

---

#### 🔴 Issue #4: Direct Subprocess Calls Throughout

**Problem:** ADB commands are called directly via `subprocess` in multiple classes without abstraction.

```python
# post_reel_smart.py - Line 14239-14246
def adb(self, cmd, timeout=30):
    result = subprocess.run(
        [ADB_PATH, "-s", self.device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""

# parallel_worker.py - Lines 13418-13426 (duplicate pattern)
result = subprocess.run(
    [ADB_PATH, "devices"],
    capture_output=True, text=True, timeout=10
)

# post_to_instagram.py uses ADBController class, but post_reel_smart.py doesn't
```

**Impact:**
- Same ADB execution logic duplicated
- Error handling inconsistent across files
- `adb_controller.py` exists but isn't used by the main poster class

---

### 1.3 Coupling Metrics Summary

| Module | Afferent Coupling (Ca) | Efferent Coupling (Ce) | Instability |
|--------|------------------------|------------------------|-------------|
| `geelark_client.py` | 6 (used by many) | 2 (few deps) | 0.25 (stable) |
| `post_reel_smart.py` | 4 | 6 | 0.60 (unstable) |
| `parallel_worker.py` | 1 | 5 | 0.83 (very unstable) |
| `progress_tracker.py` | 3 | 1 | 0.25 (stable) |
| `posting_scheduler.py` | 2 | 4 | 0.67 (unstable) |

*Instability = Ce / (Ca + Ce). Higher values indicate more fragile modules.*

---

## Part 2: Cohesion Analysis

### 2.1 Low Cohesion Areas

#### 🟠 Issue #1: `SmartInstagramPoster` - Mixed Responsibilities

**Problem:** This 1,200+ line class handles 7+ distinct responsibilities:

```python
class SmartInstagramPoster:
    # Responsibility 1: Device Connection Management
    def connect(self):           # 100+ lines of ADB/phone management
    def connect_appium(self):    # Appium session setup
    def reconnect_adb(self):     # Error recovery
    def verify_adb_connection(self):
    
    # Responsibility 2: UI Interaction (Low-level)
    def tap(self, x, y):
    def swipe(self, x1, y1, x2, y2, duration_ms=300):
    def press_key(self, keycode):
    def type_text_via_appium(self, text):
    
    # Responsibility 3: UI Analysis
    def dump_ui(self):           # Parse UI hierarchy
    def analyze_ui(self, elements, caption):  # Claude AI analysis
    
    # Responsibility 4: Instagram-specific Business Logic
    def upload_video(self, video_path):
    def post(self, video_path, caption, max_steps=30, humanize=False):
    def wait_for_upload_complete(self, timeout=60):
    
    # Responsibility 5: Error Detection & Recovery
    def detect_error_state(self, elements):
    def is_uiautomator2_crash(self, exception):
    def reconnect_appium(self):
    
    # Responsibility 6: Human-like Behavior Simulation
    def humanize_before_post(self):   # 100+ lines of random scrolling/viewing
    def random_delay(self, min_sec, max_sec):
    
    # Responsibility 7: Screenshot/Debugging
    def take_error_screenshot(self, phone_name, error_type):
```

**Cohesion Type:** **Logical Cohesion** (worst kind) - Functions grouped because they relate to "posting" but have different purposes.

**Impact:**
- Violates Single Responsibility Principle (SRP)
- Class is difficult to understand (1,200+ lines)
- Cannot reuse device control without bringing Instagram logic
- Testing requires mocking many unrelated subsystems

---

#### 🟠 Issue #2: `posting_scheduler.py` - Multiple Concerns

**Problem:** This module mixes job scheduling, state persistence, phone control, and UI callbacks.

```python
# posting_scheduler.py responsibilities:

# 1. Job queue management
class PostStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    # ...

@dataclass
class PostJob:
    id: str
    video_path: str
    # ...

# 2. State persistence (JSON file I/O)
def save_state(self):
    with open(self.state_file, 'w') as f:
        json.dump(state, f, indent=2)

def load_state(self):
    with open(self.state_file, 'r') as f:
        state = json.load(f)

# 3. Phone lifecycle management
def stop_all_phones(self):
    client = GeelarkClient()
    for page in range(1, 20):
        result = client.list_phones(...)
        for phone in result['items']:
            if phone['status'] == 1:
                client.stop_phone(phone['id'])

# 4. Threading/process control
def run(self):
    self.running = True
    self.runner_thread = threading.Thread(target=self._run_loop)
    self.runner_thread.start()

# 5. Callback/event handling (UI integration)
self.on_status_update = self.log
self.on_job_complete = self.on_job_complete
```

**Impact:**
- Hard to test scheduling logic in isolation
- State persistence is tightly bound to scheduling
- Phone control logic duplicated between scheduler and orchestrator

---

#### 🟠 Issue #3: Duplicate Implementations

**Problem:** Two different posting systems exist with overlapping functionality.

| Feature | `post_reel_smart.py` | `post_to_instagram.py` |
|---------|---------------------|------------------------|
| Device Connection | ✓ (inline) | ✓ (via ADBController) |
| Screenshot | ✗ (uses UI dump) | ✓ (via Geelark API) |
| AI Navigation | ✓ (inline Claude) | ✓ (via vision.py) |
| Status | **Active (main)** | **Deprecated but present** |

```python
# post_to_instagram.py - uses separate modules
from adb_controller import ADBController
from vision import analyze_for_instagram_post

# post_reel_smart.py - inline implementation
def dump_ui(self):  # Inline, doesn't use adb_controller
def analyze_ui(self, elements, caption):  # Inline, doesn't use vision.py
```

**Impact:**
- Code duplication
- Confusing for maintainers (which one to use?)
- `adb_controller.py` and `vision.py` are partially orphaned

---

### 2.2 Cohesion Metrics Summary

| Module | LCOM Score | Cohesion Type | Assessment |
|--------|------------|---------------|------------|
| `SmartInstagramPoster` | High (bad) | Logical | ❌ Very Low |
| `posting_scheduler.py` | Medium | Temporal | ⚠️ Low |
| `geelark_client.py` | Low (good) | Functional | ✅ High |
| `progress_tracker.py` | Low (good) | Functional | ✅ High |
| `parallel_config.py` | Low (good) | Informational | ✅ High |

*LCOM (Lack of Cohesion in Methods) - Lower is better*

---

## Part 3: Specific Code Examples

### Example 1: Tight Coupling - Device Connection in Poster

```python
# post_reel_smart.py - Lines 14844-14996
# This 150-line method handles:
# - Geelark API calls (list_phones, start_phone, enable_adb, get_adb_info)
# - ADB subprocess calls (connect, devices, glogin)
# - Appium connection
# - Error handling with retry loops

def connect(self):
    """Find phone and connect via ADB"""
    print(f"Looking for phone: {self.phone_name}")

    # Search across multiple pages - GEELARK API COUPLING
    phone = None
    for page in range(1, 10):
        result = self.client.list_phones(page=page, page_size=100)
        for p in result["items"]:
            if p["serialName"] == self.phone_name or p["id"] == self.phone_name:
                phone = p
                break
        # ...

    # Start phone if not running - GEELARK API COUPLING
    if phone["status"] != 0:
        self.client.start_phone(self.phone_id)
        # ... 20 lines of polling ...

    # Enable ADB with retry loop - GEELARK API COUPLING
    for enable_retry in range(max_enable_retries):
        self.client.enable_adb(self.phone_id)
        # ... 30 lines of verification ...

    # ADB connect - SUBPROCESS COUPLING
    subprocess.run([ADB_PATH, "disconnect", self.device], capture_output=True)
    connect_result = subprocess.run([ADB_PATH, "connect", self.device], ...)
    
    # Wait for device - SUBPROCESS COUPLING
    for attempt in range(max_attempts):
        result = subprocess.run([ADB_PATH, "devices"], ...)
        # ...

    # Appium connect - APPIUM COUPLING
    self.connect_appium()
```

**Refactoring Suggestion:** Extract into separate classes:
- `PhoneManager` - Geelark API interactions
- `ADBBridge` - ADB subprocess management  
- `AppiumSession` - Appium driver lifecycle

---

### Example 2: Low Cohesion - Mixed UI and Business Logic

```python
# post_reel_smart.py - Lines 14718-14791 (analyze_ui method)
# This method:
# 1. Formats UI elements as text
# 2. Constructs a Claude prompt with Instagram-specific knowledge
# 3. Makes API call to Claude
# 4. Parses JSON response

def analyze_ui(self, elements, caption):
    """Use Claude to analyze UI and decide next action"""

    # FORMATTING CONCERN
    ui_description = "Current UI elements:\n"
    for i, elem in enumerate(elements):
        # ... formatting logic ...

    # PROMPT ENGINEERING CONCERN (90 lines of Instagram-specific instructions)
    prompt = f"""You are controlling an Android phone to post a Reel to Instagram.
    
    Instagram posting flow:
    1. Find and tap Create/+ button...
    2. Select "Reel" option...
    # ... extensive Instagram knowledge ...
    
    CRITICAL RULES - NEVER GIVE UP:
    - NEVER return "error"...
    # ... more domain knowledge ...
    """

    # AI API CONCERN
    response = self.anthropic.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=500,
        messages=[{"role": "user", "content": prompt}]
    )

    # PARSING CONCERN
    text = response.content[0].text.strip()
    if text.startswith("```"):
        text = text.split("```")[1]
        # ...
    return json.loads(text)
```

**Refactoring Suggestion:** Separate into:
- `UIFormatter` - Convert UI elements to text
- `InstagramPromptBuilder` - Domain-specific prompt construction
- `ClaudeClient` - AI API wrapper with retry logic
- `ActionParser` - JSON response parsing

---

### Example 3: Duplicated Configuration

```python
# Configuration is scattered and duplicated:

# parallel_config.py - Line 12168-12169
android_sdk_path: str = r"C:\Users\asus\Downloads\android-sdk"
adb_path: str = r"C:\Users\asus\Downloads\android-sdk\platform-tools\adb.exe"

# post_reel_smart.py - Line 14216
ADB_PATH = r"C:\Users\asus\Downloads\platform-tools-latest-windows\platform-tools\adb.exe"
# ^ Note: DIFFERENT PATH!

# parallel_worker.py - Line 13375  
ADB_PATH = r'C:\Users\asus\Downloads\android-sdk\platform-tools\adb.exe'

# Multiple files set environment variables:
os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'
```

**Refactoring Suggestion:** Create a single `config.py`:
```python
# config.py
import os
from pathlib import Path

class Config:
    ANDROID_SDK = Path(os.getenv('ANDROID_SDK', r'C:\Users\asus\Downloads\android-sdk'))
    ADB_PATH = ANDROID_SDK / 'platform-tools' / 'adb.exe'
    APPIUM_BASE_PORT = 4723
    
    @classmethod
    def setup_environment(cls):
        os.environ['ANDROID_HOME'] = str(cls.ANDROID_SDK)
        os.environ['ANDROID_SDK_ROOT'] = str(cls.ANDROID_SDK)
```

---

## Part 4: Recommendations

### 4.1 Immediate Fixes (Low Effort, High Impact)

#### 1. Centralize Configuration
```python
# Create: config.py
from dataclasses import dataclass
from pathlib import Path
import os

@dataclass
class AppConfig:
    android_sdk: Path = Path(r'C:\Users\asus\Downloads\android-sdk')
    appium_base_port: int = 4723
    
    @property
    def adb_path(self) -> Path:
        return self.android_sdk / 'platform-tools' / 'adb.exe'
    
    def setup(self):
        os.environ['ANDROID_HOME'] = str(self.android_sdk)

# Usage everywhere:
from config import AppConfig
config = AppConfig()
```

#### 2. Remove Duplicate Posting System
- Delete `post_to_instagram.py` (deprecated)
- Consolidate `vision.py` functionality into main poster or create proper abstraction

#### 3. Extract ADB Operations
```python
# Create: adb_bridge.py
class ADBBridge:
    def __init__(self, adb_path: str, device_id: str):
        self.adb_path = adb_path
        self.device_id = device_id
    
    def shell(self, cmd: str, timeout: int = 30) -> str:
        """Execute ADB shell command"""
        result = subprocess.run(
            [self.adb_path, "-s", self.device_id, "shell", cmd],
            capture_output=True, timeout=timeout, encoding='utf-8'
        )
        return result.stdout.strip()
    
    def is_connected(self) -> bool:
        """Check if device is connected"""
        # ...
```

### 4.2 Medium-Term Refactoring (Moderate Effort)

#### 1. Split `SmartInstagramPoster` into Focused Classes

```
SmartInstagramPoster (1200 lines)
          │
          ▼ REFACTOR TO
          │
    ┌─────┴─────┬──────────┬─────────────┬────────────┐
    ▼           ▼          ▼             ▼            ▼
PhoneSession  UINavigator  AIAnalyzer  InstagramFlow  Humanizer
(connection)  (tap/swipe)  (Claude)    (posting FSM)  (random acts)
```

#### 2. Introduce Dependency Injection

```python
# Before: Tight coupling
class SmartInstagramPoster:
    def __init__(self, phone_name):
        self.client = GeelarkClient()  # Hard dependency
        self.anthropic = anthropic.Anthropic()  # Hard dependency

# After: Dependency injection
class SmartInstagramPoster:
    def __init__(
        self,
        phone_name: str,
        phone_client: PhoneClientProtocol,
        ai_analyzer: AIAnalyzerProtocol,
        ui_controller: UIControllerProtocol
    ):
        self.phone_name = phone_name
        self.phone_client = phone_client
        self.ai_analyzer = ai_analyzer
        self.ui_controller = ui_controller
```

#### 3. Create Interface Abstractions

```python
# protocols.py
from typing import Protocol, List, Dict, Any

class PhoneClientProtocol(Protocol):
    def list_phones(self, page: int, page_size: int) -> Dict[str, Any]: ...
    def start_phone(self, phone_id: str) -> None: ...
    def enable_adb(self, phone_id: str) -> None: ...

class AIAnalyzerProtocol(Protocol):
    def analyze_ui(self, elements: List[Dict], context: str) -> Dict[str, Any]: ...

class UIControllerProtocol(Protocol):
    def tap(self, x: int, y: int) -> None: ...
    def swipe(self, x1: int, y1: int, x2: int, y2: int) -> None: ...
    def dump_ui(self) -> List[Dict]: ...
```

### 4.3 Long-Term Architecture (Significant Effort)

#### Proposed Clean Architecture

```
┌────────────────────────────────────────────────────────────────┐
│                      Presentation Layer                        │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────┐ │
│  │     CLI      │  │  Dashboard   │  │    REST API (opt)    │ │
│  └──────────────┘  └──────────────┘  └──────────────────────┘ │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌────────────────────────────────────────────────────────────────┐
│                     Application Layer                          │
│  ┌──────────────────┐  ┌────────────────┐  ┌────────────────┐ │
│  │ PostingOrchest.  │  │ JobScheduler   │  │ ProgressTrack  │ │
│  └──────────────────┘  └────────────────┘  └────────────────┘ │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌────────────────────────────────────────────────────────────────┐
│                       Domain Layer                             │
│  ┌──────────────────┐  ┌────────────────┐  ┌────────────────┐ │
│  │  InstagramPost   │  │    PostJob     │  │   Account      │ │
│  │     (Entity)     │  │   (Entity)     │  │   (Entity)     │ │
│  └──────────────────┘  └────────────────┘  └────────────────┘ │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │              PostingService (Domain Logic)               │ │
│  └──────────────────────────────────────────────────────────┘ │
└────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌────────────────────────────────────────────────────────────────┐
│                   Infrastructure Layer                         │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────┐ │
│  │ GeelarkAPI   │  │  AppiumCtrl  │  │    ClaudeClient      │ │
│  │  (Adapter)   │  │  (Adapter)   │  │     (Adapter)        │ │
│  └──────────────┘  └──────────────┘  └──────────────────────┘ │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────┐ │
│  │  ADBBridge   │  │  FileStore   │  │    ConfigLoader      │ │
│  │  (Adapter)   │  │  (Adapter)   │  │     (Adapter)        │ │
│  └──────────────┘  └──────────────┘  └──────────────────────┘ │
└────────────────────────────────────────────────────────────────┘
```

---

## Part 5: Testing Implications

### Current State: Low Testability

```python
# Cannot unit test without:
# 1. Real Geelark account
# 2. Running Appium server
# 3. Real Android device
# 4. Valid Anthropic API key

def test_post_reel():
    # ❌ This requires all external systems
    poster = SmartInstagramPoster("test_phone")
    poster.connect()  # Calls Geelark, ADB, Appium
    result = poster.post("video.mp4", "caption")
```

### After Refactoring: High Testability

```python
# ✅ Unit test with mocks
def test_post_reel():
    mock_phone = MockPhoneClient()
    mock_ai = MockAIAnalyzer()
    mock_ui = MockUIController()
    
    poster = InstagramPoster(
        phone_client=mock_phone,
        ai_analyzer=mock_ai,
        ui_controller=mock_ui
    )
    
    mock_ai.set_response({"action": "tap", "element_index": 5})
    result = poster.execute_step()
    
    assert mock_ui.tap_called_with == (100, 200)
```

---

## Conclusion

The Geelark Instagram Automation codebase is functional but shows signs of organic growth that have led to coupling and cohesion issues. The primary concerns are:

1. **`SmartInstagramPoster`** is a God Class handling 7+ responsibilities
2. **Configuration is duplicated** across 4+ files with inconsistencies
3. **Tight coupling** between posting logic and external APIs
4. **Two parallel implementations** exist for posting (one deprecated but present)

### Priority Actions:
1. 🔴 **Urgent:** Centralize configuration to prevent deployment issues
2. 🟠 **Soon:** Extract ADB operations into reusable bridge class
3. 🟡 **Medium-term:** Split SmartInstagramPoster into focused classes
4. 🟢 **Long-term:** Introduce dependency injection for testability

Implementing these changes would significantly improve maintainability, testability, and make the codebase more resilient to changes in external dependencies.
</file>

<file path="reviews/design_patterns_analysis.md">
# Design Patterns Analysis Report
## Geelark Instagram Automation Codebase

**Analysis Date:** December 2024  
**Codebase:** YallaPapi/geelark-automation

---

## Executive Summary

This analysis identifies **12 design patterns** (both intentional and emergent) in the Geelark Instagram Automation codebase. The patterns range from well-implemented structural patterns to informal behavioral patterns. Some patterns are implemented cleanly while others emerge organically without explicit structure.

### Pattern Summary

| Category | Pattern | Implementation Quality | Location |
|----------|---------|----------------------|----------|
| **Creational** | Singleton (Lock-based) | ✓ Good | `posting_scheduler.py` |
| **Creational** | Builder | ✓ Good | `parallel_config.py` |
| **Creational** | Factory Method | ⚠️ Informal | `parallel_config.py` |
| **Structural** | Facade | ✓ Excellent | `geelark_client.py` |
| **Structural** | Proxy | ✓ Good | `appium_server_manager.py` |
| **Behavioral** | Observer | ⚠️ Informal | `posting_scheduler.py` |
| **Behavioral** | State | ⚠️ Partial | Job status system |
| **Behavioral** | Command | ⚠️ Informal | AI action system |
| **Behavioral** | Template Method | ⚠️ Informal | `execute_job()` |
| **Behavioral** | Strategy | ⚠️ Informal | Error classification |
| **Behavioral** | Iterator | ✓ Good | Progress tracking |
| **Concurrency** | Monitor Object | ✓ Good | File-locked operations |

---

## Creational Patterns

### 1. Singleton Pattern (Lock-Based Implementation)

**Description:**  
The Singleton pattern ensures a class has only one instance and provides a global point of access to it. This codebase implements a file-based lock mechanism to ensure only one scheduler runs at a time.

**Implementation Location:** `posting_scheduler.py`

```python
# posting_scheduler.py - Lines 16174-16200
LOCK_FILE = "scheduler.lock"

def is_process_running(pid: int) -> bool:
    """Check if a process with given PID is still running."""
    if sys.platform == 'win32':
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            PROCESS_QUERY_LIMITED_INFORMATION = 0x1000
            handle = kernel32.OpenProcess(PROCESS_QUERY_LIMITED_INFORMATION, False, pid)
            if handle:
                kernel32.CloseHandle(handle)
                return True
            return False
        except:
            import subprocess
            result = subprocess.run(['tasklist', '/FI', f'PID eq {pid}'],
                                   capture_output=True, text=True)
            return str(pid) in result.stdout
    else:
        # Unix/Linux/Mac
        try:
            os.kill(pid, 0)
            return True
        except OSError:
            return False

# Usage in PostingScheduler
class PostingScheduler:
    def start(self):
        """Start the scheduler with lock file protection"""
        # Check if another instance is running
        if os.path.exists(LOCK_FILE):
            with open(LOCK_FILE, 'r') as f:
                lock_data = json.load(f)
            existing_pid = lock_data.get('pid')
            if is_process_running(existing_pid):
                raise Exception(f"Another scheduler is already running (PID: {existing_pid})")
        
        # Create lock file
        with open(LOCK_FILE, 'w') as f:
            json.dump({'pid': os.getpid(), 'started_at': datetime.now().isoformat()}, f)
```

**UML Diagram:**
```
┌─────────────────────────────────────────────┐
│           PostingScheduler                   │
├─────────────────────────────────────────────┤
│ - LOCK_FILE: str = "scheduler.lock"         │
│ - _instance_pid: int                        │
├─────────────────────────────────────────────┤
│ + start(): void                             │
│ + stop(): void                              │
│ - _acquire_lock(): bool                     │
│ - _release_lock(): void                     │
│ - _is_stale_lock(): bool                    │
└─────────────────────────────────────────────┘
         │
         │ creates/manages
         ▼
┌─────────────────────────────────────────────┐
│            scheduler.lock                    │
│  (File-based lock with PID + heartbeat)     │
├─────────────────────────────────────────────┤
│ { "pid": 12345,                             │
│   "started_at": "2024-12-01T10:00:00",      │
│   "last_heartbeat": "2024-12-01T10:05:00" } │
└─────────────────────────────────────────────┘
```

**Reasoning & Benefits:**
- ✓ Prevents multiple scheduler instances that could cause duplicate posts
- ✓ Cross-platform implementation (Windows + Unix)
- ✓ Heartbeat mechanism detects truly stale locks from crashed processes
- ✓ No external dependencies (uses OS primitives + file system)

---

### 2. Builder Pattern

**Description:**  
The Builder pattern separates the construction of a complex object from its representation, allowing the same construction process to create different representations.

**Implementation Location:** `parallel_config.py`

```python
# parallel_config.py - Lines 12141-12262
@dataclass
class ParallelConfig:
    """Configuration built step-by-step with validation"""
    num_workers: int = 3
    workers: List[WorkerConfig] = field(default_factory=list)
    progress_file: str = "parallel_progress.csv"
    logs_dir: str = "logs"
    shutdown_timeout: int = 60
    job_timeout: int = 300
    delay_between_jobs: int = 10
    max_posts_per_account_per_day: int = 1
    
    def __post_init__(self):
        """Build worker configs if not provided."""
        if not self.workers:
            self.workers = self._generate_worker_configs(self.num_workers)
        self._validate()

    def _generate_worker_configs(self, n: int) -> List[WorkerConfig]:
        """
        Builder method: Generate N worker configurations with non-overlapping resources.

        Port allocation:
            - Appium: 4723, 4725, 4727, ... (odd ports starting from 4723)
            - systemPort: 8200-8209, 8210-8219, 8220-8229, ...
        """
        configs = []
        base_appium_port = 4723
        base_system_port = 8200
        system_port_range = 10

        for i in range(n):
            worker = WorkerConfig(
                worker_id=i,
                appium_port=base_appium_port + (i * 2),
                system_port_start=base_system_port + (i * system_port_range),
                system_port_end=base_system_port + (i * system_port_range) + system_port_range - 1,
                log_file=os.path.join(self.logs_dir, f"worker_{i}.log"),
                appium_log_file=os.path.join(self.logs_dir, f"appium_{i}.log"),
            )
            configs.append(worker)
        return configs

    def _validate(self) -> None:
        """Validate the configuration after building."""
        # Check for port conflicts
        appium_ports = [w.appium_port for w in self.workers]
        if len(appium_ports) != len(set(appium_ports)):
            raise ValueError("Duplicate Appium ports detected!")
        # ... more validation

# Factory function that uses the builder
def get_config(num_workers: int = 3) -> ParallelConfig:
    """Get a parallel configuration with the specified number of workers."""
    return ParallelConfig(num_workers=num_workers)
```

**UML Diagram:**
```
┌──────────────────────────────────┐
│         ParallelConfig           │
│           (Builder)              │
├──────────────────────────────────┤
│ + num_workers: int               │
│ + workers: List[WorkerConfig]    │
│ + progress_file: str             │
├──────────────────────────────────┤
│ + __post_init__()                │
│ - _generate_worker_configs(n)    │
│ - _validate()                    │
│ + get_worker(id): WorkerConfig   │
│ + get_env_vars(): dict           │
└──────────────────────────────────┘
         │ builds
         ▼
┌──────────────────────────────────┐
│         WorkerConfig             │
│          (Product)               │
├──────────────────────────────────┤
│ + worker_id: int                 │
│ + appium_port: int               │
│ + system_port_start: int         │
│ + system_port_end: int           │
│ + log_file: str                  │
├──────────────────────────────────┤
│ + appium_url: str (property)     │
│ + validate(): void               │
└──────────────────────────────────┘
```

**Reasoning & Benefits:**
- ✓ Automatically generates consistent worker configurations
- ✓ Ensures port allocation never conflicts
- ✓ Validation happens after construction (fail-fast)
- ✓ Easy to create configs for different worker counts

---

## Structural Patterns

### 3. Facade Pattern

**Description:**  
The Facade pattern provides a unified interface to a set of interfaces in a subsystem, making the subsystem easier to use.

**Implementation Location:** `geelark_client.py`

```python
# geelark_client.py - Lines 11551-11805
class GeelarkClient:
    """
    FACADE: Unified interface to Geelark Cloud API subsystem.
    
    Hides complexity of:
    - Authentication (token generation, headers)
    - Request formatting (JSON, proper endpoints)
    - Error handling (HTTP errors, API error codes)
    - Response parsing (extracting data from response structure)
    """
    
    def __init__(self):
        self.app_id = os.getenv("GEELARK_APP_ID")
        self.api_key = os.getenv("GEELARK_API_KEY")
        self.token = os.getenv("GEELARK_TOKEN")

    def _get_headers(self):
        """Hidden complexity: Authentication header generation"""
        trace_id = str(uuid.uuid4()).upper().replace("-", "")
        return {
            "Content-Type": "application/json",
            "traceId": trace_id,
            "Authorization": f"Bearer {self.token}"
        }

    def _request(self, endpoint, data=None):
        """Hidden complexity: Request/response handling"""
        url = f"{API_BASE}{endpoint}"
        headers = self._get_headers()
        
        resp = requests.post(url, json=data or {}, headers=headers)
        
        # Hidden: HTTP error handling
        if resp.status_code != 200:
            raise Exception(f"API error: {resp.status_code}")
        
        # Hidden: API-level error handling
        result = resp.json()
        if result.get("code") != 0:
            raise Exception(f"API error: {result.get('code')} - {result.get('msg')}")
        
        return result.get("data")

    # SIMPLIFIED PUBLIC INTERFACE
    def list_phones(self, page=1, page_size=100):
        """Simple: List cloud phones"""
        return self._request("/open/v1/phone/list", {"page": page, "pageSize": page_size})

    def start_phone(self, phone_id):
        """Simple: Start a phone"""
        result = self._request("/open/v1/phone/start", {"ids": [phone_id]})
        if result.get("successAmount", 0) > 0:
            return result["successDetails"][0]
        raise Exception(f"Failed to start phone")

    def upload_file_to_geelark(self, local_path):
        """
        FACADE: Single method hides multi-step upload process:
        1. Get upload URL from API
        2. Upload file via PUT to cloud storage
        3. Return resource URL for later use
        """
        ext = os.path.splitext(local_path)[1].lstrip(".").lower()
        result = self.get_upload_url(ext)
        upload_url = result.get("uploadUrl")
        resource_url = result.get("resourceUrl")
        
        with open(local_path, "rb") as f:
            resp = requests.put(upload_url, data=f)
        
        if resp.status_code not in [200, 201]:
            raise Exception(f"Upload failed: {resp.status_code}")
        
        return resource_url

    def wait_for_screenshot(self, phone_id, timeout=30):
        """
        FACADE: Hides polling complexity:
        1. Request screenshot
        2. Poll for completion
        3. Return download URL
        """
        result = self.screenshot(phone_id)
        task_id = result.get("taskId")
        
        start = time.time()
        while time.time() - start < timeout:
            result = self.get_screenshot_result(task_id)
            if result.get("status") == 2:  # Success
                return result.get("downloadLink")
            elif result.get("status") == 3:  # Failed
                raise Exception("Screenshot failed")
            time.sleep(1)
        
        raise Exception("Screenshot timeout")
```

**UML Diagram:**
```
┌─────────────────────────────────────────────────────────────────┐
│                        CLIENT CODE                               │
│   (SmartInstagramPoster, PostingScheduler, parallel_worker)     │
└───────────────────────────────┬─────────────────────────────────┘
                                │ uses simple interface
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                     GeelarkClient (FACADE)                       │
├─────────────────────────────────────────────────────────────────┤
│ + list_phones(page, page_size): dict                            │
│ + start_phone(phone_id): dict                                   │
│ + stop_phone(phone_id): dict                                    │
│ + enable_adb(phone_id): dict                                    │
│ + upload_file_to_geelark(path): str                             │
│ + wait_for_screenshot(phone_id): str                            │
├─────────────────────────────────────────────────────────────────┤
│ - _get_headers(): dict                                          │
│ - _request(endpoint, data): dict                                │
└───────────────────────────────┬─────────────────────────────────┘
                                │ encapsulates
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    GEELARK API SUBSYSTEM                         │
├─────────────────────────────────────────────────────────────────┤
│ POST /open/v1/phone/list     │ Authentication Headers           │
│ POST /open/v1/phone/start    │ Token Generation                 │
│ POST /open/v1/adb/setStatus  │ Response Parsing                 │
│ POST /open/v1/upload/getUrl  │ Error Code Handling              │
│ PUT  {cloudStorageUrl}       │ Polling Logic                    │
└─────────────────────────────────────────────────────────────────┘
```

**Reasoning & Benefits:**
- ✓ **Simplicity**: Client code calls `start_phone(id)` instead of managing auth, headers, error codes
- ✓ **Encapsulation**: API changes only affect the facade, not client code
- ✓ **Reduced coupling**: Clients don't depend on `requests` library directly
- ✓ **Centralized logging**: All API calls logged in one place

---

### 4. Proxy Pattern

**Description:**  
The Proxy pattern provides a surrogate or placeholder for another object to control access to it.

**Implementation Location:** `appium_server_manager.py`

```python
# appium_server_manager.py - Lines 2205-2468
class AppiumServerManager:
    """
    PROXY: Controls access to the Appium server process.
    
    Proxy responsibilities:
    - Lifecycle management (start, stop, restart)
    - Health monitoring (is_healthy, wait_for_healthy)
    - Resource protection (port management, cleanup)
    - Virtual proxy: lazy initialization (reuse existing if healthy)
    """
    
    def __init__(self, worker_config: WorkerConfig, parallel_config: ParallelConfig):
        self.worker_config = worker_config
        self.parallel_config = parallel_config
        self.process: Optional[subprocess.Popen] = None
        self._started = False

    @property
    def appium_url(self) -> str:
        """Proxy provides URL to the real Appium server."""
        return self.worker_config.appium_url

    def is_healthy(self, timeout: float = 5.0) -> bool:
        """
        PROXY: Check if real server is available.
        Clients don't need to know HTTP health check details.
        """
        try:
            url = f"{self.appium_url}/status"
            req = Request(url, method='GET')
            with urlopen(req, timeout=timeout) as response:
                data = json.loads(response.read().decode())
                return data.get('value', {}).get('ready', False)
        except:
            return False

    def start(self, timeout: float = 30.0) -> None:
        """
        PROXY: Virtual proxy with lazy/smart initialization.
        Reuses existing healthy server instead of always restarting.
        """
        # Smart proxy: reuse if already running and healthy
        if self.is_healthy():
            logger.info(f"Reusing existing healthy Appium on port {self.port}")
            self._started = True
            self.process = None  # We didn't start it
            return

        # Kill anything blocking our port
        self._kill_existing_on_port()

        # Start the real Appium server
        cmd = self._build_command()
        self.process = subprocess.Popen(cmd, ...)
        
        # Wait for it to become available
        if not self.wait_for_healthy(timeout=timeout):
            raise AppiumServerError("Appium didn't become healthy")
        
        self._started = True

    def ensure_healthy(self, restart_timeout: float = 60.0) -> bool:
        """
        PROTECTION PROXY: Ensure server is healthy before use.
        Auto-recovers if server has crashed.
        """
        if self.is_healthy():
            return True
        
        logger.warning(f"Appium unhealthy, attempting restart...")
        self._kill_existing_on_port()
        time.sleep(2)
        
        self.start(timeout=restart_timeout)
        return True

    def __enter__(self):
        """Context manager support for clean resource management."""
        self.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Ensure cleanup on exit."""
        self.stop()
        return False
```

**UML Diagram:**
```
┌────────────────────────────────┐
│        parallel_worker         │
│           (Client)             │
└───────────────┬────────────────┘
                │ uses
                ▼
┌────────────────────────────────┐        ┌─────────────────────────┐
│    AppiumServerManager         │        │    Appium Server        │
│          (Proxy)               │───────▶│   (Real Subject)        │
├────────────────────────────────┤        ├─────────────────────────┤
│ + appium_url: str (property)   │        │ Running on localhost    │
│ + start(): void                │        │ Port: 4723/4725/4727    │
│ + stop(): void                 │        │ /status endpoint        │
│ + is_healthy(): bool           │        │ /session endpoint       │
│ + ensure_healthy(): bool       │        └─────────────────────────┘
│ + __enter__()                  │
│ + __exit__()                   │
├────────────────────────────────┤
│ - _build_command(): list       │
│ - _kill_existing_on_port()     │
│ - wait_for_healthy(): bool     │
└────────────────────────────────┘
```

**Reasoning & Benefits:**
- ✓ **Virtual Proxy**: Reuses existing healthy server (performance optimization)
- ✓ **Protection Proxy**: `ensure_healthy()` validates server before each job
- ✓ **Smart Proxy**: Auto-recovery when server crashes
- ✓ **Resource Management**: Context manager ensures cleanup

---

## Behavioral Patterns

### 5. Observer Pattern (Informal Implementation)

**Description:**  
The Observer pattern defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified automatically.

**Implementation Location:** `posting_scheduler.py`

```python
# posting_scheduler.py - Lines 16692-16720 & 17003-17061
class PostingScheduler:
    def __init__(self, state_file: str = "scheduler_state.json"):
        # ...
        # OBSERVER: Callback functions (informal implementation)
        self.on_status_update: Optional[Callable] = None  # GUI notification
        self.on_job_complete: Optional[Callable] = None   # Job completion notification

    def _log(self, message: str):
        """NOTIFY: Send status update to observers"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        full_msg = f"[{timestamp}] {message}"
        print(full_msg)
        
        # Notify GUI observer if attached
        if self.on_status_update:
            self.on_status_update(full_msg)

    def execute_job(self, job: PostJob) -> bool:
        # ... job execution ...
        
        if success:
            job.status = PostStatus.SUCCESS.value
            self._log(f"[OK] {job.id} posted successfully")
            
            # NOTIFY: Job complete observer
            if self.on_job_complete:
                self.on_job_complete(job, True)
        else:
            # NOTIFY: Job failed observer
            if self.on_job_complete:
                self.on_job_complete(job, False)

# OBSERVER ATTACHMENT in posting_dashboard.py
class PostingDashboard:
    def __init__(self, root):
        self.scheduler = PostingScheduler()
        
        # Attach observers
        self.scheduler.on_status_update = self.log          # Log messages to GUI
        self.scheduler.on_job_complete = self.on_job_complete  # Refresh UI on completion

    def log(self, message: str):
        """Observer callback: Handle status updates"""
        self.log_text.insert(tk.END, message + '\n')
        self.log_text.see(tk.END)

    def on_job_complete(self, job, success):
        """Observer callback: Handle job completion"""
        self.root.after(100, self.refresh_jobs)
        self.root.after(100, self.refresh_stats)
```

**UML Diagram:**
```
┌─────────────────────────────────────────────┐
│           PostingScheduler                   │
│              (Subject)                       │
├─────────────────────────────────────────────┤
│ + on_status_update: Callable                │
│ + on_job_complete: Callable                 │
├─────────────────────────────────────────────┤
│ + _log(message): void                       │
│ + execute_job(job): bool                    │
│   └─ calls on_status_update(msg)            │
│   └─ calls on_job_complete(job, success)    │
└──────────────────┬──────────────────────────┘
                   │ notifies
        ┌──────────┴──────────┐
        ▼                     ▼
┌───────────────────┐ ┌───────────────────────┐
│ PostingDashboard  │ │   Other Observers     │
│   (Observer)      │ │   (Future: Webhook)   │
├───────────────────┤ ├───────────────────────┤
│ + log(msg)        │ │ + notify(msg)         │
│ + on_job_complete │ │ + on_complete(job)    │
└───────────────────┘ └───────────────────────┘
```

**Reasoning & Benefits:**
- ✓ **Decoupling**: Scheduler doesn't know about GUI implementation
- ✓ **Extensibility**: Easy to add more observers (webhooks, Slack notifications)
- ⚠️ **Informal**: Uses simple callbacks instead of formal Observer interface
- ⚠️ **Limitation**: Single observer per event (not a list of observers)

---

### 6. State Pattern (Partial Implementation)

**Description:**  
The State pattern allows an object to alter its behavior when its internal state changes. The object will appear to change its class.

**Implementation Location:** `progress_tracker.py`, `parallel_worker.py`

```python
# progress_tracker.py - Job state constants
class ProgressTracker:
    # STATE DEFINITIONS
    STATUS_PENDING = 'pending'
    STATUS_CLAIMED = 'claimed'
    STATUS_SUCCESS = 'success'
    STATUS_FAILED = 'failed'
    STATUS_RETRYING = 'retrying'
    STATUS_SKIPPED = 'skipped'
    
    # NON-RETRYABLE ERROR STATES
    NON_RETRYABLE_ERRORS = {'suspended', 'captcha', 'loggedout', 'actionblocked', 'banned'}

# State transitions in update_job_status
def update_job_status(self, job_id, status, worker_id, error=''):
    """State machine for job status transitions"""
    
    if status == self.STATUS_SUCCESS:
        # TRANSITION: any → SUCCESS (terminal state)
        job['status'] = self.STATUS_SUCCESS
    
    elif status == self.STATUS_FAILED:
        attempts = int(job.get('attempts', 0)) + 1
        error_type = self._classify_error(error)
        
        if error_type in self.NON_RETRYABLE_ERRORS:
            # TRANSITION: any → FAILED (terminal, non-retryable)
            job['status'] = self.STATUS_FAILED
        
        elif attempts >= max_attempts:
            # TRANSITION: any → FAILED (terminal, max attempts)
            job['status'] = self.STATUS_FAILED
        
        else:
            # TRANSITION: any → RETRYING (will be processed again)
            job['status'] = self.STATUS_RETRYING
            retry_at = datetime.now() + timedelta(minutes=retry_delay)
            job['retry_at'] = retry_at.isoformat()

# parallel_worker.py - Worker lifecycle states
class WorkerState:
    """
    Worker lifecycle states for the state machine approach.
    
    State transitions:
        STARTING -> ADB_PENDING -> ADB_READY -> APPIUM_READY -> JOB_RUNNING
        Any state -> ERROR_RECOVERY -> STARTING
        Any state -> SHUTDOWN
    """
    STARTING = 'starting'         # Worker initializing
    ADB_PENDING = 'adb_pending'   # Waiting for ADB device
    ADB_READY = 'adb_ready'       # ADB device connected
    APPIUM_READY = 'appium_ready' # Appium session ready
    JOB_RUNNING = 'job_running'   # Executing a posting job
    ERROR_RECOVERY = 'error_recovery'  # Handling errors
    SHUTDOWN = 'shutdown'         # Clean shutdown requested
```

**State Diagram:**
```
                 ┌─────────────────────────────────────────────────────────┐
                 │                     JOB STATES                          │
                 │                                                         │
                 │    ┌─────────┐    claim     ┌─────────┐                │
                 │    │ PENDING │──────────────▶│ CLAIMED │                │
                 │    └─────────┘               └────┬────┘                │
                 │                                   │                     │
                 │                          execute_job()                  │
                 │                                   │                     │
                 │                    ┌──────────────┼──────────────┐      │
                 │                    ▼              ▼              ▼      │
                 │             ┌─────────┐    ┌──────────┐    ┌────────┐  │
                 │             │ SUCCESS │    │ RETRYING │    │ FAILED │  │
                 │             │(terminal)│    └────┬─────┘    │(terminal)│ │
                 │             └─────────┘         │          └────────┘  │
                 │                                 │                      │
                 │                    retry_at reached                    │
                 │                                 │                      │
                 │                                 ▼                      │
                 │                           ┌─────────┐                  │
                 │                           │ PENDING │ (re-queue)       │
                 │                           └─────────┘                  │
                 └─────────────────────────────────────────────────────────┘
```

**Reasoning & Benefits:**
- ✓ Clear state transitions documented
- ✓ Error classification determines state transitions
- ⚠️ **Not true State Pattern**: Uses strings, not State objects
- ⚠️ **Missing**: State-specific behavior methods

**Improvement Suggestion:**
```python
# True State Pattern implementation would look like:
class JobState(ABC):
    @abstractmethod
    def process(self, job: PostJob, context: JobContext) -> 'JobState': ...

class PendingState(JobState):
    def process(self, job, context):
        if context.worker_available:
            job.claimed_by = context.worker_id
            return ClaimedState()
        return self

class ClaimedState(JobState):
    def process(self, job, context):
        result = context.execute()
        if result.success:
            return SuccessState()
        elif result.retryable and job.attempts < job.max_attempts:
            return RetryingState(retry_at=result.retry_at)
        else:
            return FailedState(error=result.error)
```

---

### 7. Command Pattern (Informal - AI Action System)

**Description:**  
The Command pattern encapsulates a request as an object, allowing parameterization of clients with different requests.

**Implementation Location:** `post_reel_smart.py` (AI-driven action system)

```python
# post_reel_smart.py - Lines 14735-14791 (Claude AI prompt)
# Claude returns "commands" as JSON objects

# COMMAND: Action dictionary returned by Claude AI
# Example commands:
{
    "action": "tap",
    "element_index": 5,
    "reason": "Tap the Create button"
}

{
    "action": "tap_and_type",
    "element_index": 3,
    "text": "Check out this video! #viral",
    "reason": "Enter caption"
}

{
    "action": "back",
    "reason": "Dismiss unexpected dialog"
}

{
    "action": "done",
    "reason": "Post completed successfully"
}

# COMMAND EXECUTOR: post() method
def post(self, video_path, caption, max_steps=30):
    """Execute commands from AI"""
    
    for step in range(max_steps):
        # Get UI state
        elements, raw_xml = self.dump_ui()
        
        # AI generates command
        action = self.analyze_ui(elements, caption)
        
        # COMMAND DISPATCH: Execute based on action type
        if action['action'] == 'done':
            return True
        
        elif action['action'] == 'tap':
            idx = action.get('element_index', 0)
            elem = elements[idx]
            self.tap(elem['center'][0], elem['center'][1])
        
        elif action['action'] == 'tap_and_type':
            idx = action.get('element_index', 0)
            text = action.get('text', caption)
            # ... tap then type
        
        elif action['action'] == 'back':
            self.press_key('KEYCODE_BACK')
        
        elif action['action'] == 'scroll_down':
            self.adb("input swipe 360 900 360 400 300")
        
        elif action['action'] == 'home':
            self.press_key('KEYCODE_HOME')
        
        elif action['action'] == 'open_instagram':
            self.adb("am force-stop com.instagram.android")
            self.adb("monkey -p com.instagram.android 1")
```

**UML Diagram:**
```
┌─────────────────────────────────────────────────────────────────┐
│                    Claude AI (Invoker)                          │
│  analyze_ui() → returns action dict                             │
└───────────────────────────────┬─────────────────────────────────┘
                                │ generates
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                  Action Dictionary (Command)                     │
├─────────────────────────────────────────────────────────────────┤
│  {"action": "tap", "element_index": 5, "reason": "..."}         │
│  {"action": "tap_and_type", "text": "...", "reason": "..."}     │
│  {"action": "back", "reason": "..."}                            │
│  {"action": "done", "reason": "..."}                            │
└───────────────────────────────┬─────────────────────────────────┘
                                │ processed by
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│              SmartInstagramPoster (Receiver)                     │
├─────────────────────────────────────────────────────────────────┤
│  + tap(x, y)                                                    │
│  + swipe(x1, y1, x2, y2)                                        │
│  + press_key(keycode)                                           │
│  + type_text(text)                                              │
│  + adb(command)                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Reasoning & Benefits:**
- ✓ **Decoupling**: AI doesn't know how actions are executed
- ✓ **Extensibility**: Easy to add new action types
- ✓ **Logging**: Each action can be logged with its reason
- ⚠️ **Informal**: Uses dict instead of Command classes
- ⚠️ **No undo**: Actions cannot be reversed

---

### 8. Template Method Pattern (Informal)

**Description:**  
The Template Method pattern defines the skeleton of an algorithm in a method, deferring some steps to subclasses.

**Implementation Location:** `posting_scheduler.py` - `execute_job()`

```python
# posting_scheduler.py - Lines 16949-17080
def execute_job(self, job: PostJob) -> bool:
    """
    TEMPLATE METHOD: Fixed algorithm structure with customizable phases.
    
    Template structure:
    1. INIT phase (template step)
    2. CONNECT phase (customizable)
    3. POST phase (customizable)
    4. CLEANUP phase (template step - always runs)
    """
    from post_reel_smart import SmartInstagramPoster
    
    job.status = PostStatus.IN_PROGRESS.value
    job.attempts += 1
    self.save_state()
    
    phase = "init"
    start_time = time.time()
    poster = None
    
    try:
        # PHASE 1: Init (template step)
        if self.test_retry_mode and job.attempts == 1:
            raise Exception("TEST MODE: Simulated failure")
        
        # PHASE 2: Connect (hook - could be overridden)
        phase = "connect"
        phase_start = time.time()
        poster = SmartInstagramPoster(job.account)
        poster.connect()
        logger.info(f"phase={phase} completed in {time.time()-phase_start:.1f}s")
        
        # Check overall timeout
        if time.time() - start_time > 120:
            raise TimeoutError(f"Job exceeded total timeout after {phase}")
        
        # PHASE 3: Post (hook - could be overridden)
        phase = "instagram_post"
        phase_start = time.time()
        success = poster.post(job.video_path, job.caption, humanize=self.humanize)
        logger.info(f"phase={phase} completed in {time.time()-phase_start:.1f}s")
        
        # PHASE 4: Process result (template step)
        phase = "cleanup"
        
        if success:
            job.status = PostStatus.SUCCESS.value
            self._handle_success(job)  # Template step
            return True
        else:
            raise Exception("Post returned False")
    
    except Exception as e:
        self._handle_failure(job, phase, e)  # Template step
        return False
    
    finally:
        # PHASE 5: Cleanup (template step - ALWAYS runs)
        try:
            if poster:
                poster.cleanup()
        except Exception as cleanup_err:
            logger.warning(f"Cleanup error: {cleanup_err}")
        
        # Double-check: stop phone
        close_all_running_phones({job.account})
```

**Reasoning & Benefits:**
- ✓ **Consistent structure**: All jobs follow same phase sequence
- ✓ **Timeout handling**: Built into template
- ✓ **Cleanup guarantee**: `finally` block always runs
- ⚠️ **Not true Template Method**: No inheritance/overriding
- ⚠️ **Improvement**: Could extract phases as overridable methods

---

### 9. Strategy Pattern (Informal - Error Classification)

**Description:**  
The Strategy pattern defines a family of algorithms, encapsulates each one, and makes them interchangeable.

**Implementation Location:** `progress_tracker.py`

```python
# progress_tracker.py - Lines 18005-18024
def _classify_error(self, error: str) -> str:
    """
    STRATEGY: Classify errors into categories.
    Each error type determines the retry strategy.
    
    Returns one of the NON_RETRYABLE_ERRORS or empty string for retryable.
    """
    error_lower = error.lower() if error else ''
    
    # Strategy 1: Account suspended
    if 'suspended' in error_lower or 'account has been suspended' in error_lower:
        return 'suspended'
    
    # Strategy 2: Captcha required
    elif 'captcha' in error_lower or 'verify' in error_lower:
        return 'captcha'
    
    # Strategy 3: Logged out
    elif 'log in' in error_lower or 'logged out' in error_lower:
        return 'loggedout'
    
    # Strategy 4: Action blocked
    elif 'action blocked' in error_lower or 'try again later' in error_lower:
        return 'actionblocked'
    
    # Strategy 5: Banned
    elif 'banned' in error_lower or 'disabled' in error_lower:
        return 'banned'
    
    # Strategy 6: Retryable (default)
    else:
        return ''

# Strategy determines behavior:
if error_type in self.NON_RETRYABLE_ERRORS:
    job['status'] = self.STATUS_FAILED  # No retry
else:
    job['status'] = self.STATUS_RETRYING  # Will retry
```

**Reasoning & Benefits:**
- ✓ **Encapsulated rules**: Error classification logic in one place
- ✓ **Extensible**: Easy to add new error types
- ⚠️ **Informal**: Not using Strategy interface/classes
- ⚠️ **Improvement**: Could use Strategy classes for different retry policies

---

### 10. Iterator Pattern (File-Locked Job Queue)

**Description:**  
The Iterator pattern provides a way to access elements of an aggregate object sequentially without exposing its underlying representation.

**Implementation Location:** `progress_tracker.py`

```python
# progress_tracker.py - claim_next_job and _locked_operation
class ProgressTracker:
    """
    ITERATOR: Thread-safe iteration over job queue.
    Uses file locking to ensure atomic access across processes.
    """
    
    def _locked_operation(self, operation: Callable) -> Any:
        """
        Execute an operation with exclusive file lock.
        This enables safe iteration across multiple processes.
        """
        with portalocker.Lock(self.progress_file, 'r+', 
                              flags=portalocker.LOCK_EX,
                              timeout=30) as f:
            # Read all jobs (aggregate)
            f.seek(0)
            reader = csv.DictReader(f)
            jobs = list(reader)
            
            # Execute operation (iteration logic)
            modified_jobs, result = operation(jobs)
            
            # Write back if modified
            if modified_jobs is not None:
                f.seek(0)
                f.truncate()
                writer = csv.DictWriter(f, fieldnames=self.FIELDNAMES)
                writer.writeheader()
                writer.writerows(modified_jobs)
            
            return result
    
    def claim_next_job(self, worker_id: int, max_posts_per_account_per_day: int = 1):
        """
        ITERATOR: Get next available job from queue.
        
        Iterates through jobs to find one that:
        1. Has status PENDING
        2. Has assigned account
        3. Account not currently in use by another worker
        4. Account not at daily limit
        """
        def _claim_operation(jobs):
            # Build set of accounts currently in use
            accounts_in_use = {
                j.get('account') for j in jobs
                if j.get('status') == self.STATUS_CLAIMED
            }
            
            # ITERATE: Find first available job
            for job in jobs:
                if job.get('status') == self.STATUS_PENDING:
                    account = job.get('account', '')
                    
                    # Skip if no account
                    if not account:
                        continue
                    
                    # Skip if account in use
                    if account in accounts_in_use:
                        continue
                    
                    # Skip if at daily limit
                    if account in accounts_at_limit:
                        continue
                    
                    # Claim this job
                    job['status'] = self.STATUS_CLAIMED
                    job['worker_id'] = str(worker_id)
                    job['claimed_at'] = datetime.now().isoformat()
                    return jobs, dict(job)
            
            return jobs, None  # No job available
        
        return self._locked_operation(_claim_operation)
```

**Reasoning & Benefits:**
- ✓ **Thread-safe**: File locking prevents race conditions
- ✓ **Process-safe**: Works across multiple worker processes
- ✓ **Encapsulated**: Iteration logic hidden from callers
- ✓ **Atomic**: Read-modify-write in single locked operation

---

## Concurrency Patterns

### 11. Monitor Object Pattern

**Description:**  
The Monitor Object pattern synchronizes concurrent method execution to ensure only one method at a time runs within an object.

**Implementation Location:** `progress_tracker.py`

```python
# progress_tracker.py - File-locked critical sections
class ProgressTracker:
    """
    MONITOR: Uses file locking to ensure exclusive access.
    All state-modifying operations go through _locked_operation().
    """
    
    def _locked_operation(self, operation: Callable) -> Any:
        """
        MONITOR: Mutual exclusion for file operations.
        
        Uses portalocker for cross-process synchronization.
        Only one process can hold the lock at a time.
        """
        with portalocker.Lock(
            self.progress_file, 
            'r+',
            flags=portalocker.LOCK_EX,  # Exclusive lock
            timeout=30  # Wait up to 30s for lock
        ) as f:
            # CRITICAL SECTION START
            f.seek(0)
            reader = csv.DictReader(f)
            jobs = list(reader)
            
            # Execute the operation
            modified_jobs, result = operation(jobs)
            
            # Write back atomically
            if modified_jobs is not None:
                f.seek(0)
                f.truncate()
                writer = csv.DictWriter(f, fieldnames=self.FIELDNAMES)
                writer.writeheader()
                writer.writerows(modified_jobs)
            
            # CRITICAL SECTION END
            return result
    
    def claim_next_job(self, worker_id: int, ...):
        """All workers call this - monitor ensures serialization."""
        return self._locked_operation(_claim_operation)
    
    def update_job_status(self, job_id: str, status: str, ...):
        """All workers call this - monitor ensures serialization."""
        return self._locked_operation(_update_operation)
```

**Diagram:**
```
┌─────────────────────────────────────────────────────────────────┐
│                    parallel_progress.csv                         │
│                     (Shared Resource)                            │
└───────────────────────────────┬─────────────────────────────────┘
                                │
                    ┌───────────┴───────────┐
                    │   MONITOR (file lock) │
                    │  portalocker.LOCK_EX  │
                    └───────────┬───────────┘
                                │
        ┌───────────────────────┼───────────────────────┐
        ▼                       ▼                       ▼
┌───────────────┐       ┌───────────────┐       ┌───────────────┐
│   Worker 0    │       │   Worker 1    │       │   Worker 2    │
│ claim_next()  │       │ claim_next()  │       │ claim_next()  │
│ update_status │       │ update_status │       │ update_status │
└───────────────┘       └───────────────┘       └───────────────┘
        │                       │                       │
        └───────────────────────┴───────────────────────┘
                                │
                         Only ONE worker
                         can hold lock
                          at a time
```

**Reasoning & Benefits:**
- ✓ **Cross-process safety**: File locks work across Python processes
- ✓ **Atomic operations**: Read-modify-write is indivisible
- ✓ **No race conditions**: Prevents duplicate job claims
- ✓ **Timeout handling**: Doesn't block forever if lock unavailable

---

## Summary Table

| Pattern | Category | Quality | Implementation |
|---------|----------|---------|----------------|
| **Singleton (Lock-based)** | Creational | ✓ Good | File-based lock with heartbeat |
| **Builder** | Creational | ✓ Good | WorkerConfig generation |
| **Facade** | Structural | ✓ Excellent | GeelarkClient API wrapper |
| **Proxy** | Structural | ✓ Good | AppiumServerManager |
| **Observer** | Behavioral | ⚠️ Informal | Callback functions |
| **State** | Behavioral | ⚠️ Partial | String-based job states |
| **Command** | Behavioral | ⚠️ Informal | AI action dictionaries |
| **Template Method** | Behavioral | ⚠️ Informal | execute_job() phases |
| **Strategy** | Behavioral | ⚠️ Informal | Error classification |
| **Iterator** | Behavioral | ✓ Good | File-locked job queue |
| **Monitor Object** | Concurrency | ✓ Good | portalocker file locking |

---

## Recommendations for Improvement

### 1. Formalize Observer Pattern
```python
class ISchedulerObserver(Protocol):
    def on_status_update(self, message: str) -> None: ...
    def on_job_complete(self, job: PostJob, success: bool) -> None: ...

class PostingScheduler:
    def __init__(self):
        self._observers: List[ISchedulerObserver] = []
    
    def add_observer(self, observer: ISchedulerObserver) -> None:
        self._observers.append(observer)
    
    def _notify_status(self, message: str) -> None:
        for observer in self._observers:
            observer.on_status_update(message)
```

### 2. Implement True State Pattern
```python
class JobState(ABC):
    @abstractmethod
    def handle(self, job: Job, context: JobContext) -> 'JobState': ...

class PendingState(JobState):
    def handle(self, job, context):
        if context.claim(job):
            return ClaimedState()
        return self
```

### 3. Formalize Command Pattern
```python
class Action(ABC):
    @abstractmethod
    def execute(self, poster: InstagramPoster) -> bool: ...
    @abstractmethod
    def undo(self, poster: InstagramPoster) -> None: ...

class TapAction(Action):
    def __init__(self, x: int, y: int):
        self.x, self.y = x, y
    
    def execute(self, poster):
        poster.tap(self.x, self.y)
        return True
```

These improvements would make the patterns more explicit, testable, and maintainable.
</file>

<file path="reviews/review1.txt">
There are 2 parts to this review, first part is short and it is only for the retry logic. Second part is for the project as a whole. Please implement these changes using taskmaster systematically and then test again with 5 workers. 

Retry logic review part:

There is already an automatic retry system in the older `PostingScheduler`, but the new parallel orchestrator/worker path does **not** yet have an equivalent built-in retry loop.

## What exists today

### PostingScheduler (single-run, non-parallel path)

`posting_scheduler.py` implements a robust auto-retry mechanism around `PostJob` objects:

- Each job has `attempts`, `max_attempts` (default 3), `status` (`PENDING`, `INPROGRESS`, `RETRYING`, `FAILED`, `SUCCESS`), `last_attempt`, `error_type`, etc.[1]
- On failure in `execute_job`, it decides:
  - If `error_type` is in `["suspended", "captcha", "loggedout", "actionblocked"]`, it is treated as non-retryable and marked `FAILED` immediately.[1]
  - Else, if `attempts < max_attempts`, the job is put into `RETRYING` with `retry_delay_minutes` (default 0.25 = 15s), and will be picked up later.[1]
  - Else, it is marked permanently `FAILED`.[1]
- `get_retry_jobs()` returns jobs with `status == RETRYING`, and the main loop waits until the next `retry_at` time (`last_attempt + retry_delay_minutes`) before re-running them.[1]
- There are convenience methods:
  - `retry_failed_job(job_id)` and `retry_all_failed()` to reset failed jobs back to `RETRYING` from the dashboard.[1]
- Account-level state (`AccountState`) tracks:
  - `consecutive_failures`, `cooldown_until`, and applies cooldown (up to 60 minutes) after repeated infra failures (`is_infra_error=True`).[1]
  - This ensures “good” accounts keep getting retried, while problematic ones back off.

So: in the **scheduler-only** mode, jobs that fail for retryable reasons will be automatically retried up to `max_attempts`, and you can also bulk “retry all failed” from the dashboard to cycle through remaining failures again.[1]

### Parallel orchestrator / worker path

The newer parallel path is:

- `parallel_orchestrator.py` seeds jobs into `parallel_progress.csv` and then spawns N `parallel_worker.py` processes.[1]
- `progress_tracker.py` manages job claiming and status transitions in the CSV, but:
  - It does **not** have the same `PostStatus.RETRYING` concept or `max_attempts` field per job.
  - It tracks `status` (pending/claimed/success/failed), worker IDs, timestamps, etc., but there is no built-in “retry queue” or retry delay.[1]

In `parallel_worker.py`:

- Jobs are processed once per claim:
  - On success, status is set to success in `parallel_progress.csv`.
  - On failure, status is set to failed; there is no automatic re-claim logic, no `max_attempts`, and no transition to a retrying state.[1]
- There is **no equivalent** of `PostingScheduler`’s `max_retries`, `retry_delay_minutes`, or `get_retry_jobs()` in the parallel worker loop.[1]

So for the **parallel system you care about**:

- A job that fails once will remain failed in `parallel_progress.csv` and will not be automatically retried by the current code.
- The only way to cycle failures again today would be via an external script or manual massaging of the CSV (e.g., resetting failed rows back to pending), which is not implemented in this repo.

## What this means for your “cycle until posted” requirement

- In the old scheduler flow, there is a clear auto-retry up to `max_attempts`, and tools to bulk-reset failed jobs for another pass.[1]
- In the new parallel orchestrator/worker architecture, **automatic retries are not in place yet**, so:
  - You will get roughly “1 attempt per job per run”.
  - Failures are permanent until you add retry logic or manually reset their status in the progress CSV.

To get the “keep cycling failed-but-active accounts until they succeed” behavior in the parallel system, you will need to:

- Add `attempts`, `max_attempts`, and `status` values analogous to `PostingScheduler.PostJob` into `parallel_progress.csv`.
- Extend `ProgressTracker` with `RETRYING` and `get_retry_jobs` logic and a retry delay knob.
- Teach `parallel_worker` to:
  - Increment attempts.
  - Move failed-but-retryable jobs into `RETRYING`.
  - Periodically re-claim `RETRYING` jobs once their delay has elapsed.
- Reuse the `AccountState.record_post(success, is_infra_error)` pattern to add cooldown per account in the parallel context.

Those patterns already exist and are well-tested in `posting_scheduler.py`; they just haven’t been ported into the parallel orchestrator path yet.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/59369057/cd8fe9d2-93bb-496c-953f-6bfd157b2d29/repomix-output-https_-github.com-YallaPapi-geelark-automation.xml)

***

Full review:

The project already has most of the pieces you need (per-account limits, a daily ledger, per-worker Appium configs, staggered startup), but there are several broken or partial invariants that explain duplicates, collisions, and ADB instability.[1]

## Architecture summary

- **Core scheduler / single-phone path (older but “known good”)**  
  - `postingscheduler.py` is the main non-parallel scheduler: maintains `schedulerstate.json` as the canonical state (accounts, jobs, per-account history) and logs to `batchresults.csv` plus logs.[1]
  - It enforces per-account limits, retries, and logging, but is architected around a single posting loop rather than parallel workers.[1]

- **Parallel orchestrator path (the system you care about)**  
  - `parallel_config.py` (`ParallelConfig`, `WorkerConfig`) defines per-worker Appium port and systemPort slices, plus global settings like `max_posts_per_account_per_day`, timeouts, and `parallel_progress.csv` as the shared ledger.[1]
  - `parallel_orchestrator.py` is the main entry point:  
    - Checks for other orchestrators via `check_for_running_orchestrators` (process name scan) and refuses to run if another is active.[1]
    - `full_cleanup(config)` stops all phones, kills processes on Appium ports, disconnects ADB, validates/repairs the progress file, and optionally releases stale claims.[1]
    - `seed_progress_file(config, statefile, accounts_filter)` seeds `parallel_progress.csv` from `schedulerstate.json` via `ProgressTracker.seed_from_scheduler_state`, respecting `config.max_posts_per_account_per_day`.[1]
    - `start_all_workers(config)` launches `parallel_worker.py` as separate processes with per-worker environment and staggers them by `time.sleep(60)` between starts.[1]
    - `monitor_workers` polls workers and prints status, driven entirely off `ProgressTracker.get_stats()`.[1]

- **Progress tracking / daily ledger**  
  - `parallel_progress_tracker.py` or `progress_tracker.py` (the exact filename in the XML is `ProgressTracker` class) manages `parallel_progress.csv` with:  
    - Columns `job_id, account, video_path, caption, status, worker_id, claimed_at, completed_at, error` (names inferred from comments; actual constants are in `ProgressTracker.COLUMNS`).[1]
    - Cross-platform file locking using `portalocker` when available, with a Windows `msvcrt` fallback and a `.lock` sidecar file.[1]
    - Methods:
      - `read_all_jobs`, `write_all_jobs` with atomic temp-file rename.[1]
      - `load_success_counts()` which computes `success_count_today(account)` from the current CSV, used for seeding and claim-time enforcement.[1]
      - `seed_from_scheduler_state(statefile, account_list, redistribute, max_posts_per_account_per_day)` which reads `schedulerstate.json` and writes initial jobs, enforcing per-account daily caps at seeding time and ensuring only one job per account per seeding pass.[1]
      - `update_job_status(job_id, status, worker_id, error)` and claim helpers (not fully visible in snippet) to transition status from `pending → claimed → success/failed/skipped`.[1]
      - `release_stale_claims(max_age_seconds)` to turn `claimed` jobs back to `pending` after crashes.[1]
  - The orchestrator uses `reset_day(progressfile)` (seen in the instructions) to archive `parallel_progress.csv` to `parallel_progress_YYYYMMDD.csv` and create a fresh daily ledger.[1]

- **Parallel worker / per-phone posting**  
  - `parallel_worker.py` is a worker process that:  
    - Accepts `--worker-id`, `--num-workers`, `--progress-file`, `--delay` from the orchestrator.[1]
    - Uses `ParallelConfig` to pick its own Appium port and systemPort range (via `WorkerConfig`), and logs to a per-worker logfile.[1]
    - Uses `ProgressTracker` to claim jobs and update status, and `SmartInstagramPoster` / `postreel_smart.py` for the actual IG post via Appium.[1]
    - Handles graceful shutdown via signals and reports per-worker stats via `get_worker_stats()` in the tracker.[1]

- **ADB/Appium helpers**  
  - `postreel_smart.py` (the “THE WORKING ONE”) encapsulates the UI automation: starting Instagram, navigating UI via periodic UI dumps and actions, with ADB path configurable via `ADB_PATH = r"C:\...adb.exe"`.[1]
  - Geelark API wrapper `geelark_client.py` (mentioned) manages phone start/stop, ADB enable/tunnels, etc., but the parallel code mostly treats it as a black box and relies on higher-level functions like `start_phone`, `stop_phone`, and ADB commands executed through `adb` and Appium.[1]

## Violations and root causes

### 1. Per-account daily cap not fully enforced

**Where it is enforced now**

- `ParallelConfig.max_posts_per_account_per_day` exists and defaults to 1.[1]
- `ProgressTracker.seed_from_scheduler_state(..., max_posts_per_account_per_day=config.max_posts_per_account_per_day)` calculates per-account success counts from the existing `parallel_progress.csv` and only seeds new jobs for accounts with `success_count < max_posts_per_account_per_day`.[1]
- The seeding implementation explicitly states it:
  - Builds `success_count_by_account` from `load_success_counts()`.
  - Avoids assigning more than `max_posts_per_account_per_day` jobs per account in this seeding pass (so no intra-batch reuse during seeding).[1]

**Violations**

1. **No explicit cap at claim-time**  
   - There is no evidence in the snippets that `ProgressTracker.claim_next_job` (or equivalent) re-checks `success_count_today(account)` at claim time. The comments say “defense in depth – enforced at seeding and claim time,” but the claim-time check is not clearly implemented in the visible code.[1]
   - If the progress file is modified mid-day (e.g., manually deleted, reset incorrectly, or multiple orchestrators run), the seeding-time invariants are no longer sufficient.

2. **Reusing accounts within the same batch when reseeding**  
   - Seeding ensures one job per account per *seeding pass*, but if the user runs `--force-reseed` or `--seed-only` + `--run` repeatedly during the same day without a reset, the per-account one-job-per-batch invariant can be broken (because the code only looks at *success* counts, not “already assigned pending jobs today”).[1]
   - There is no explicit “per-day per-account assignment ledger” beyond successes; pending/failed jobs from earlier runs are not considered when deciding whether to assign another job for the same account in the same day.

3. **Progress file deletion / recreation during the day**  
   - `validate_progress_file(progressfile)` deletes an empty or “corrupt” `parallel_progress.csv` as a “fix,” then treats “file missing” as valid.[1]
   - `full_cleanup(config)` calls `validate_progress_file(config.progressfile)` unconditionally and may thus remove the daily ledger mid-day if it is temporarily empty or appears corrupt (for example, if the user killed the process at a bad moment).[1]
   - User instructions explicitly say “NEVER DELETE THE PROGRESS FILE MANUALLY,” but the code *programmatically* deletes the file in these cases and then allows reseeding with `--force-reseed`, effectively wiping daily history.[1]

**Root cause:** daily limit enforcement relies heavily on the presence of an intact `parallel_progress.csv` and successes-only counts; when the file is deleted/reseeded mid-day or multiple orchestrators are run, the system loses awareness of prior posts and can assign multiple jobs to the same account in one day or even in one batch.

***

### 2. Daily ledger as single source of truth is compromised

**What should be true**

- `parallel_progress.csv` must be the canonical, append-only daily ledger; `schedulerstate.json` is long-term state but not the day’s posting record.[1]

**What the code actually does**

1. **Multiple writers with whole-file rewrite**  
   - `ProgressTracker` uses `locked_operation` with a separate `.lock` file and portalocker/msvcrt to serialize access.[1]
   - Each update (`update_job_status`, `claim_next_job`, `release_stale_claims`, seeding) reads **all jobs** into memory and rewrites the entire CSV via `write_all_jobs()` with a temp file rename.[1]
   - While locking should prevent concurrent corruption, the pattern is high-risk under heavy multi-process write load; any failure between read and write can leave the file empty or partially written, triggering `validate_progress_file` to classify it as corrupt and delete it.[1]

2. **Returning “claimed” jobs to pending in `full_cleanup`**  
   - `full_cleanup(config, release_claims=True)` calls `ProgressTracker.release_stale_claims(max_age_seconds=0)`, which immediately sets all `claimed` jobs back to `pending` regardless of whether they were in progress only briefly.[1]
   - This is appropriate for crash recovery but dangerous if `full_cleanup` is run mid-batch deliberately: jobs that were actually in progress or already successfully posted (but not yet marked `success` because the worker crashed after posting) can be re-executed.  

3. **Day reset mechanism vs ad-hoc manual resets**  
   - `--reset-day` archives the progress file and creates a fresh ledger – this is correct.[1]
   - But `--force-reseed` on the orchestrator, combined with `validate_progress_file` deleting “empty/corrupt” files, provides an accidental “hidden reset” that bypasses the explicit day boundary and can duplicate posts within the same day.[1]

**Root cause:** the progress tracker is designed as the single source of truth, but its robustness is undermined by aggressive file “repair” behaviors and a whole-file rewrite pattern that makes corruption more likely when processes are killed.

***

### 3. ADB/Appium lifecycle lacks a strict readiness gate and robust recovery

**Where phones and Appium are controlled**

- Per-worker Appium configuration is clean: `ParallelConfig.generate_worker_configs` assigns each `WorkerConfig` a unique Appium port (4723, 4725, …) and a distinct `systemPort` slice (8200–8209, 8210–8219, etc.).[1]
- Orchestrator `start_all_workers` simply spawns `parallel_worker.py` with the right environment; each worker then starts its own Appium server and Phone/ADB connection using Geelark API and ADB commands (implementation is in the worker and `postreel_smart.py`, not fully visible in the snippet).[1]

**Violations**

1. **No explicit “ADB ready” gate before Appium session creation**  
   - In the provided snippets, there is no dedicated helper like `wait_for_adb(device_id, timeout)` that polls `adb devices` until the device is present before starting/invoking Appium.[1]
   - Geelark phones can show `status == RUNNING` while ADB is not yet reachable; the current code appears to rely on that status and an implicit delay (60s between worker starts) rather than a device-level readiness check.[1]

2. **Missing detection of ADB disappearance mid-run**  
   - The comments mention “device not in list of connected devices / glogin returning empty list,” but there is no visible logic in the worker to:
     - Periodically verify that the device is still in `adb devices`, and  
     - On failure, stop the Appium server and phone, then restart both and resume processing on that worker only.[1]
   - Error handling for ADB flakiness is mainly in `postreel_smart.py` as retries around `am instrument`, but not as a full state machine that restarts phones.[1]

3. **Implicit assumption that staggered worker start is enough**  
   - `start_all_workers` uses `time.sleep(60)` between workers to prevent hammering Geelark; this helps but is not a correctness guarantee.[1]
   - There is no feedback loop: if ADB readiness takes longer on a given phone, the worker may still fail with “device not found” rather than waiting gracefully.

**Root cause:** the worker/Appium lifecycle is missing explicit ADB readiness checks and recovery branches; intermittent ADB/tunnel issues turn into failures or stuck states rather than being handled as a restart-and-continue state machine.

***

### 4. Worker ↔ phone ↔ Appium binding is only partially enforced

**Where binding is defined**

- `ParallelConfig` ensures unique Appium port and non-overlapping systemPort ranges per worker; no two workers use the same Appium URL or systemPort if they share the same config. This satisfies the Appium side of the invariant.[1]

**Violations**

1. **No explicit phone assignment per worker**  
   - In the repo, there is no clear mapping `worker_id → phone_id` defined in configuration (e.g., a `worker_phone_map`), nor a central phone allocator that marks phones as reserved per worker.[1]
   - `parallel_orchestrator.py` and `parallel_worker.py` accept an `--accounts` list but do not appear to accept or enforce a corresponding `--phones` mapping; workers can end up selecting “any available phone” from Geelark when starting, increasing the risk of two workers using the same device if the underlying phone pool is small.[1]

2. **No guard against multiple workers targeting the same phone**  
   - There is no cross-process lock or reservation file per phone (e.g., `phone_<id>.lock`).  
   - The only global coordination is around progress/jobs, not around phones; the Geelark API might prevent double-starting the same phone, but the local code does not ensure “one worker ↔ one phone” logically.[1]

3. **Port allocation is safe only if everyone uses `ParallelConfig`**  
   - If any other legacy script (e.g., `batchpost.py`, `batchpost_concurrent.py`, or direct `postreel_smart.py` invocations) is run concurrently, it may start its own Appium server on overlapping ports or reuse the same phone, violating the one-worker-per-phone invariant. The code does not detect or prevent this.[1]

**Root cause:** ports are isolated by configuration, but phone allocation is not; workers implicitly “grab phones” rather than being bound to a pre-assigned phone identity, making phone-level collisions possible.

***

## Proposed fix plan

### 1. Strengthen per-account caps and daily ledger behavior

#### 1.1 ProgressTracker: enforce caps at claim-time

**File:** `parallel_progress_tracker.py` (or `progress_tracker.py`)  
**Functions to change / add:**

- Add a helper:
  ```python
  def get_daily_success_counts(self) -> Dict[str, int]:
      return self.load_success_counts()
  ```
  This is mostly a semantic wrapper, but clarifies intent.[1]

- Modify `claim_next_job` (or equivalent) to enforce account success caps defensively:

  ```python
  def claim_next_job(self, worker_id: int, max_posts_per_account_per_day: int) -> Optional[Dict[str, Any]]:
      def op(jobs):
          success_by_account = self.load_success_counts()
          # Build current in-memory assigned counts, including jobs already claimed but not yet success
          assigned_by_account = {}
          for j in jobs:
              acc = j.get("account")
              if not acc:
                  continue
              if j.get("status") in (self.STATUSSUCCESS, self.STATUSCLAIMED):
                  assigned_by_account[acc] = assigned_by_account.get(acc, 0) + 1

          now = datetime.utcnow().isoformat()
          for job in jobs:
              if job.get("status") != self.STATUSPENDING:
                  continue
              acc = job.get("account")
              total_for_acc = success_by_account.get(acc, 0) + assigned_by_account.get(acc, 0)
              if total_for_acc >= max_posts_per_account_per_day:
                  continue  # skip this job; account hit limit
              # claim this job
              job["status"] = self.STATUSCLAIMED
              job["worker_id"] = str(worker_id)
              job["claimed_at"] = now
              return jobs, job  # return updated jobs and the claimed job

          return jobs, None

      return self.locked_operation(op)
  ```

- Ensure every worker call to `claim_next_job` passes `config.max_posts_per_account_per_day` so that both seeding and claim-time enforce the cap.[1]

This ensures that even if the ledger was seeded incorrectly or partially, workers will never claim jobs that would cause an account to exceed `N` total posts (including claimed-but-not-yet-success jobs) in that day.

#### 1.2 Prevent same-account reuse within a batch

**File:** `parallel_progress_tracker.py`  

Add a per-day “assigned” notion that uses both `STATUSSUCCESS` and `STATUSCLAIMED` in the counts (as above). The key rule: **for any given day’s ledger file, only allow one job per account to ever be in `claimed` or `success` status** when `max_posts_per_account_per_day=1`.

Implementation notes:

- In `seed_from_scheduler_state`, when building `success_count_by_account`, also include already pending jobs for the day:

  ```python
  existing_jobs = self.read_all_jobs() if os.path.exists(self.progress_file) else []
  assigned_accounts_today = set()
  for job in existing_jobs:
      if job.get("status") in (self.STATUSPENDING, self.STATUSCLAIMED, self.STATUSSUCCESS):
          assigned_accounts_today.add(job.get("account"))
  ```

  Then, when deciding to add new jobs, skip any account already in `assigned_accounts_today` for today, regardless of success count.[1]

- This ensures that within one daily ledger, each account can appear in “scheduled/claimed/success” at most `max_posts_per_account_per_day` times, and reseeding cannot “reuse” the account.

#### 1.3 Make ledger deletion explicit and safe

**File:** `parallel_orchestrator.py`

- Tighten `validate_progress_file(progressfile)` so that it **never silently deletes** a non-empty file. Only delete when:
  - The file exists but read as zero rows *and* zero bytes (true empty), or
  - The user explicitly requested a reset (`--reset-day`) and you are archiving it first.[1]

- Remove the behavior of deleting “corrupt” files on read errors. Instead:
  - Log a loud error and abort the orchestrator run.
  - Require the operator to manually archive and reset via `--reset-day`.  

Example change:

```python
def validate_progress_file(progress_file: str) -> bool:
    if not os.path.exists(progress_file):
        return True
    try:
        with open(progress_file, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
        if len(rows) == 0:
            logger.error("Progress file exists but is empty; refusing to auto-delete. Run with --reset-day after manual inspection.")
            return False
        return True
    except Exception as e:
        logger.error("Progress file appears corrupt; refusing to auto-delete. Run with --reset-day after manual inspection. %s", e)
        return False
```

- In `full_cleanup(config)`, **remove** the call to `validate_progress_file` or only call it when you are about to start a **new day** (e.g., under `--reset-day` flow). For mid-day cleanup, do not touch the ledger.[1]

#### 1.4 Make `--force-reseed` strictly an offline operation

**File:** `parallel_orchestrator.py`

- Change behavior so `--force-reseed`:
  - Only works when there are **no active workers** and the orchestrator is not in `--run` mode.
  - Requires explicit `--reset-day` or a special `--force-reset-progress` flag with confirmation to archive the old progress file.  

This ensures you cannot accidentally wipe intra-day history while the day is still active.

***

### 2. Robust ADB/Appium lifecycle with explicit state machine

#### 2.1 Add explicit ADB readiness gate

**File:** `parallel_worker.py` or a new helper `adb_utils.py`

**New helper:**

```python
def wait_for_adb(device_id: str, adb_path: str, timeout: int = 90) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        try:
            out = subprocess.check_output([adb_path, "devices"], encoding="utf-8")
            for line in out.splitlines():
                if device_id in line and "device" in line:
                    return True
        except Exception:
            pass
        time.sleep(2)
    return False
```

- Use this after starting the phone / enabling ADB but **before** starting Appium or creating a session.

**Integration:**

- In the worker’s startup flow:

  ```python
  phone_id = ... # from assigned phone mapping
  start_geelark_phone(phone_id)
  if not wait_for_adb(phone_id, adb_path=config.adb_path, timeout=90):
      logger.error("ADB failed to become ready for phone %s", phone_id)
      # clean up and retry / mark worker as unhealthy
      return
  start_appium_server(worker_config.appium_port, ...)
  wait_for_appium_ready(...)
  ```

#### 2.2 Detect ADB/device loss mid-run and recover

**File:** `parallel_worker.py`

- Add periodic checks during job execution:

  ```python
  def ensure_device_alive(device_id: str, adb_path: str) -> bool:
      try:
          out = subprocess.check_output([adb_path, "devices"], encoding="utf-8")
          for line in out.splitlines():
              if device_id in line and "device" in line:
                  return True
      except Exception:
          pass
      return False
  ```

- Wrap the main job loop:

  ```python
  while not shutdown_requested:
      if not ensure_device_alive(phone_id, config.adb_path):
          logger.warning("Device %s lost; restarting phone+Appium", phone_id)
          stop_appium_server(worker_config.appium_port)
          stop_geelark_phone(phone_id)
          start_geelark_phone(phone_id)
          if not wait_for_adb(phone_id, config.adb_path, timeout=90):
              # optionally backoff and retry, or mark worker as degraded
              continue
          start_appium_server(...)
      job = tracker.claim_next_job(worker_id, config.max_posts_per_account_per_day)
      ...
  ```

This ensures mid-run ADB loss leads to a controlled restart on that worker only, rather than cascading errors.

#### 2.3 Minimal state machine

You can conceptualize each worker’s phone lifecycle as:

- `PHONE_STARTING`  
  - Action: Geelark `start_phone`.  
  - Transition to `ADB_PENDING`.

- `ADB_PENDING`  
  - Action: `wait_for_adb(device_id, timeout)`.  
  - On success → `ADB_READY`, on timeout → `ERROR_RECOVERY`.

- `ADB_READY`  
  - Action: start Appium server on worker-specific port; `wait_for_appium_ready`.  
  - On success → `APPIUM_READY`, on failure → `ERROR_RECOVERY`.

- `APPIUM_READY`  
  - Action: run job loop (`JOB_RUNNING`); `claim_next_job`, run `postreel_smart`.  
  - If `ensure_device_alive` fails → `ERROR_RECOVERY`.

- `JOB_RUNNING`  
  - On job completion → back to `APPIUM_READY` to claim next job.  
  - On IG/app crash with recoverable error → retry logic; on repeated failures → mark job failed and continue.

- `ERROR_RECOVERY`  
  - Action: stop Appium, stop phone if running, backoff, then go to `PHONE_STARTING`.  
  - If repeated failures beyond threshold → worker exits with error.

Implement this as an explicit enum or just structured `while` with a `state` variable so behavior is predictable.

***

### 3. Enforce strict worker ↔ phone ↔ Appium bindings

#### 3.1 Add explicit phone assignment in config

**File:** `parallel_config.py`

- Extend `WorkerConfig` with a `phone_id: Optional[str]` field:

  ```python
  @dataclass
  class WorkerConfig:
      worker_id: int
      appium_port: int
      system_port_start: int
      system_port_end: int
      log_file: str
      appium_log_file: str
      phone_id: Optional[str] = None
  ```

- Add a new configuration file or CLI argument for `--phones phone1,phone2,phone3`; in `get_config(num_workers, phones=None)`:

  ```python
  def get_config(num_workers: int, phones: Optional[List[str]] = None) -> ParallelConfig:
      cfg = ParallelConfig(num_workers=num_workers)
      if phones:
          if len(phones) != num_workers:
              raise ValueError("Number of phones must match number of workers")
          for w, phone in zip(cfg.workers, phones):
              w.phone_id = phone
      return cfg
  ```

#### 3.2 Use phone_id in workers and prevent sharing

**File:** `parallel_orchestrator.py`

- Parse `--phones` CLI argument and pass it to `get_config`.  
- Before starting workers, validate that all `phone_id` values are unique and match actual Geelark phones (via a simple `list_phones` check). If not, abort.

**File:** `parallel_worker.py`

- On startup, read the `phone_id` from env or as an argument and require it to be present:

  ```python
  parser.add_argument("--phone-id", required=True)
  ...
  phone_id = args.phone_id
  ```

- Use that phone exclusively in the worker’s lifecycle (start/stop, ADB checks, Appium session creation).  
- Do **not** scan for “any available phone”; always use the bound one.

This enforces “one worker → one phone → one Appium instance + systemPort slice” at the code level, not by hope.

***

### 4. File-level change checklist

**`parallel_config.py`**

- Add `phone_id` to `WorkerConfig`.  
- Extend `get_config` to accept phones and assign them.  
- No change needed for port allocations, which already avoid collisions.[1]

**`parallel_orchestrator.py`**

- Arguments:
  - Add `--phones` CLI option (comma-separated IDs) and feed into `get_config`.[1]
- Orchestration:
  - Validate unique `phone_id` and Geelark existence before `start_all_workers`.  
  - In `start_worker_process`, pass `--phone-id` for each worker.  
  - Keep `time.sleep(60)` stagger but now rely on readiness gates inside workers as well.[1]
- Cleanup:
  - Harden `validate_progress_file` to avoid deleting or altering the ledger mid-day.  
  - Restrict `--force-reseed` and call to `validate_progress_file` to “new day” flows only.  
  - Keep `full_cleanup` for phones/ports/ADB, but do not touch `parallel_progress.csv` unless in reset mode.[1]

**`parallel_progress_tracker.py` / `progress_tracker.py`**

- Implement `get_daily_success_counts()` and integrate success + claimed job counting for both seeding and claim-time.  
- Modify `seed_from_scheduler_state` to consider existing pending/claimed jobs per account for the current day, preventing per-batch reuse.[1]
- Modify `claim_next_job` to enforce `max_posts_per_account_per_day` using combined success+claimed counts.  
- Ensure all operations use `locked_operation` and atomic writes, but stop auto-deleting “corrupt” files in helper functions.[1]

**`parallel_worker.py`**

- Accept `--phone-id` and use it exclusively to start/stop the Geelark phone.  
- Add `wait_for_adb`, `ensure_device_alive`, and a simple state machine around phone/Appium lifecycle.  
- On ADB loss, perform per-worker recovery (stop Appium, stop phone, restart both, then continue).  
- Ensure claims use `tracker.claim_next_job(worker_id, config.max_posts_per_account_per_day)`.

**`postreel_smart.py` / ADB helpers**

- Ensure `ADB_PATH` is correctly set (there is already a comment about editing `ADB_PATH`).[1]
- Where possible, funnel calls through the new `wait_for_adb`/`ensure_device_alive` helpers instead of assuming the device is always present.

***

These changes will:

- Make `parallel_progress.csv` a robust, non-ephemeral daily ledger that truly limits posts per account to `N` per day and prevents intra-batch reuse.  
- Make worker behavior deterministic and self-healing with respect to ADB flakiness and tunnel instability.  
- Enforce strict one-to-one mappings between workers, phones, and Appium instances, removing phone/port collisions as a class of bugs.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/59369057/38d0fbf2-bfb6-4062-b0d4-7270976f8cdf/repomix-output-https_-github.com-YallaPapi-geelark-automation-1.xml)
</file>

<file path=".env.example">
# API Keys (Required to enable respective provider)
ANTHROPIC_API_KEY="your_anthropic_api_key_here"       # Required: Format: sk-ant-api03-...
PERPLEXITY_API_KEY="your_perplexity_api_key_here"     # Optional: Format: pplx-...
OPENAI_API_KEY="your_openai_api_key_here"             # Optional, for OpenAI models. Format: sk-proj-...
GOOGLE_API_KEY="your_google_api_key_here"             # Optional, for Google Gemini models.
MISTRAL_API_KEY="your_mistral_key_here"               # Optional, for Mistral AI models.
XAI_API_KEY="YOUR_XAI_KEY_HERE"                       # Optional, for xAI AI models.
GROQ_API_KEY="YOUR_GROQ_KEY_HERE"                     # Optional, for Groq models.
OPENROUTER_API_KEY="YOUR_OPENROUTER_KEY_HERE"         # Optional, for OpenRouter models.
AZURE_OPENAI_API_KEY="your_azure_key_here"            # Optional, for Azure OpenAI models (requires endpoint in .taskmaster/config.json).
OLLAMA_API_KEY="your_ollama_api_key_here"             # Optional: For remote Ollama servers that require authentication.
GITHUB_API_KEY="your_github_api_key_here"             # Optional: For GitHub import/export features. Format: ghp_... or github_pat_...
</file>

<file path=".gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
dev-debug.log

# Dependency directories
node_modules/
__pycache__/
*.pyc

# Environment variables
.env

# Editor directories and files
.idea
.vscode
.cursor/
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

# OS specific
.DS_Store
nul

# Videos and large files
*.mp4
*.zip
*.apk
*.tgz

# Video/content folders
chunk_*/
va_chunk_*/
package/
ClipboardHelper/

# Screenshots and images (except for docs)
*.png
error_screenshots/

# Batch results and state files
batch_results_*.csv
scheduler_state.json

# XML dumps
ui_dump*.xml

# Docs that shouldn't be in repo
*.docx
</file>

<file path=".mcp.json">
{
	"mcpServers": {
		"task-master-ai": {
			"type": "stdio",
			"command": "npx",
			"args": [
				"-y",
				"task-master-ai"
			],
			"env": {
				"ANTHROPIC_API_KEY": "YOUR_ANTHROPIC_API_KEY_HERE",
				"PERPLEXITY_API_KEY": "YOUR_PERPLEXITY_API_KEY_HERE",
				"OPENAI_API_KEY": "YOUR_OPENAI_KEY_HERE",
				"GOOGLE_API_KEY": "YOUR_GOOGLE_KEY_HERE",
				"XAI_API_KEY": "YOUR_XAI_KEY_HERE",
				"OPENROUTER_API_KEY": "YOUR_OPENROUTER_KEY_HERE",
				"MISTRAL_API_KEY": "YOUR_MISTRAL_KEY_HERE",
				"AZURE_OPENAI_API_KEY": "YOUR_AZURE_KEY_HERE",
				"OLLAMA_API_KEY": "YOUR_OLLAMA_API_KEY_HERE"
			}
		}
	}
}
</file>

<file path="accounts.txt">
quickcutspod
podsnipline
podreelsector
podpunchdaily
podpeakstudio
podcutstories
podclipcrafters
mindsetmiccuts
micwisdomdaily
micnotesarchive
micmindvault
castcoremedia
bitepodmedia
bitecastclips
clipsonairwave
archipelago_one
warlordregent
thequietbaron
thefieldsketcher
thebaysideduke
thebackroadman
stone_mason_live
sovereignclaw
silverscribewindow
seegloryvault
primejuggernaut
orbmasterstrike
kingmakerpulse
itsunpluggedlife
ironwillascendant
inreallifemaxx
empirestrongofmind
crimsonlegionshort
bentzenithruler
tjmexicosfinest
sammycakes4me
rustywatermeal
RoughConcreteShifter
reddyplayerwonton
pinkmanmcpink
lucysplainyoself
LoomedTwillHook
LockedVaultDuster
HollowedBoneVessels
FrozenGearSmoker
filbertthesmasher
FallenBarkSwitch
EmptyFuelMatrix
daisochunks
contibonit
ClosedCircuitMute
bondsgoldengun
blackietheblackest
basilthymeoregano
AgedWalnutThrones
speckles_is_here
rushhourresponse
redcarelesscrocs
ogtylerguy
milkyjersey.trainer
markatetwobananas
marblebasecase
lupethelooper
FusedMercurySpike
DarkLichenCoded
choice.jonestown
chance_of_rain_tomorrow
BrokenRockPace
ApexStratagem
clipsonpodcast
podsnipworks
talkgembytes
miccliparchive
castreelworks
viraltalkfeed
reelpodsector
apodwavecentral
micdropchannel
viralmicstudio
quickpodsnaps
podmindstudio
talktrackhub
</file>

<file path="adb_controller.py">
"""
ADB Controller - connects to Geelark devices and runs commands
"""
import subprocess
import time
import os

from config import Config

# ADB executable path - use centralized config for consistency
ADB_PATH = Config.ADB_PATH


class ADBController:
    def __init__(self, ip, port, password):
        self.ip = ip
        self.port = port
        self.password = password
        self.device = f"{ip}:{port}"
        self.connected = False

    def connect(self, retries=3):
        """Connect to device via ADB"""
        for attempt in range(retries):
            try:
                # Disconnect first to clean state
                subprocess.run(
                    [ADB_PATH, "disconnect", self.device],
                    capture_output=True, timeout=5
                )

                # Connect with password
                # Geelark uses adb connect with auth
                result = subprocess.run(
                    [ADB_PATH, "connect", self.device],
                    capture_output=True, text=True, timeout=10
                )

                if "connected" in result.stdout.lower():
                    self.connected = True
                    print(f"Connected to {self.device}")
                    # Geelark requires glogin with password
                    login_result = subprocess.run(
                        [ADB_PATH, "-s", self.device, "shell", f"glogin {self.password}"],
                        capture_output=True, text=True, timeout=10
                    )
                    if "success" in login_result.stdout.lower():
                        print("Geelark login successful")
                    else:
                        print(f"Geelark login: {login_result.stdout}")
                    return True

                # May need to pair first
                if "authenticate" in result.stdout.lower() or "pair" in result.stdout.lower():
                    # Try pairing
                    pair_result = subprocess.run(
                        [ADB_PATH, "pair", self.device, self.password],
                        capture_output=True, text=True, timeout=10
                    )
                    print(f"Pair result: {pair_result.stdout}")

                    # Try connect again
                    result = subprocess.run(
                        [ADB_PATH, "connect", self.device],
                        capture_output=True, text=True, timeout=10
                    )

                    if "connected" in result.stdout.lower():
                        self.connected = True
                        print(f"Connected to {self.device}")
                        return True

                print(f"Connect attempt {attempt + 1} failed: {result.stdout} {result.stderr}")
                time.sleep(2)

            except subprocess.TimeoutExpired:
                print(f"Connect attempt {attempt + 1} timed out")
                time.sleep(2)

        return False

    def disconnect(self):
        """Disconnect from device"""
        subprocess.run([ADB_PATH, "disconnect", self.device], capture_output=True)
        self.connected = False

    def shell(self, command, timeout=30):
        """Run shell command on device"""
        if not self.connected:
            raise Exception("Not connected to device")

        result = subprocess.run(
            [ADB_PATH, "-s", self.device, "shell", command],
            capture_output=True, text=True, timeout=timeout
        )
        return result.stdout.strip()

    def tap(self, x, y):
        """Tap at coordinates"""
        return self.shell(f"input tap {x} {y}")

    def swipe(self, x1, y1, x2, y2, duration_ms=300):
        """Swipe from (x1,y1) to (x2,y2)"""
        return self.shell(f"input swipe {x1} {y1} {x2} {y2} {duration_ms}")

    def type_text(self, text):
        """Type text (spaces become %s)"""
        # Escape special characters for shell
        escaped = text.replace(" ", "%s").replace("'", "\\'").replace('"', '\\"')
        return self.shell(f"input text '{escaped}'")

    def key_event(self, keycode):
        """Send key event (e.g., KEYCODE_BACK=4, KEYCODE_HOME=3)"""
        return self.shell(f"input keyevent {keycode}")

    def back(self):
        """Press back button"""
        return self.key_event(4)

    def home(self):
        """Press home button"""
        return self.key_event(3)

    def screenshot_to_file(self, local_path):
        """Take screenshot and pull to local file"""
        remote_path = "/sdcard/screenshot.png"

        # Take screenshot
        self.shell(f"screencap -p {remote_path}")

        # Pull to local
        result = subprocess.run(
            [ADB_PATH, "-s", self.device, "pull", remote_path, local_path],
            capture_output=True, text=True, timeout=30
        )

        # Clean up remote
        self.shell(f"rm {remote_path}")

        return os.path.exists(local_path)

    def push_file(self, local_path, remote_path):
        """Push file to device"""
        result = subprocess.run(
            [ADB_PATH, "-s", self.device, "push", local_path, remote_path],
            capture_output=True, text=True, timeout=300
        )
        print(f"Push stdout: {result.stdout}")
        print(f"Push stderr: {result.stderr}")
        print(f"Push returncode: {result.returncode}")
        return "pushed" in result.stdout.lower() or result.returncode == 0

    def launch_app(self, package_name):
        """Launch an app by package name"""
        return self.shell(
            f"monkey -p {package_name} -c android.intent.category.LAUNCHER 1"
        )

    def launch_instagram(self):
        """Launch Instagram"""
        return self.launch_app("com.instagram.android")

    def get_current_activity(self):
        """Get current foreground activity"""
        result = self.shell("dumpsys activity activities | grep mResumedActivity")
        return result


if __name__ == "__main__":
    # Test with dummy values
    print("ADB Controller module loaded successfully")
    print("Usage: adb = ADBController(ip, port, password)")
    print("       adb.connect()")
    print("       adb.tap(500, 500)")
</file>

<file path="appium_server_manager.py">
"""
Appium Server Manager for Multi-Process Workers.

This module handles the lifecycle of Appium server instances:
- Start an Appium server on a specific port with proper Android SDK environment
- Wait for server to become healthy (HTTP /status check)
- Stop server gracefully (SIGTERM then SIGKILL if needed)
- Clean up orphaned UiAutomator2 processes

Each worker process uses this to manage its own dedicated Appium instance.
"""

import os
import sys
import time
import signal
import subprocess
import json
import logging
from typing import Optional
from urllib.request import urlopen, Request
from urllib.error import URLError

from parallel_config import WorkerConfig, ParallelConfig

logger = logging.getLogger(__name__)


class AppiumServerError(Exception):
    """Raised when Appium server fails to start or becomes unhealthy."""
    pass


class AppiumServerManager:
    """
    Manages the lifecycle of a single Appium server instance.

    Usage:
        manager = AppiumServerManager(worker_config, parallel_config)
        try:
            manager.start()
            # ... use Appium ...
        finally:
            manager.stop()

    Or as context manager:
        with AppiumServerManager(worker_config, parallel_config) as manager:
            # ... use Appium at manager.appium_url ...
    """

    def __init__(self, worker_config: WorkerConfig, parallel_config: ParallelConfig):
        self.worker_config = worker_config
        self.parallel_config = parallel_config
        self.process: Optional[subprocess.Popen] = None
        self._started = False

    @property
    def appium_url(self) -> str:
        """Get the Appium server URL."""
        return self.worker_config.appium_url

    @property
    def port(self) -> int:
        """Get the Appium server port."""
        return self.worker_config.appium_port

    @property
    def worker_id(self) -> int:
        """Get the worker ID."""
        return self.worker_config.worker_id

    def __enter__(self):
        self.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.stop()
        return False  # Don't suppress exceptions

    def _get_env(self) -> dict:
        """Get environment variables with Android SDK paths."""
        env = os.environ.copy()
        env.update(self.parallel_config.get_env_vars())
        return env

    def _build_command(self) -> list:
        """Build the Appium server command."""
        # Use full path on Windows to avoid PATH issues in subprocess
        if sys.platform == 'win32':
            npm_path = os.path.join(os.environ.get('APPDATA', ''), 'npm')
            appium_cmd = os.path.join(npm_path, 'appium.cmd')
        else:
            appium_cmd = 'appium'

        return [
            appium_cmd,
            '--address', '127.0.0.1',
            '--port', str(self.port),
            '--log-timestamp',
            '--local-timezone',
            '--allow-insecure', 'uiautomator2:adb_shell',  # Appium v3 format: driver:feature
        ]

    def is_healthy(self, timeout: float = 5.0) -> bool:
        """
        Check if Appium server is running and healthy.

        Args:
            timeout: HTTP request timeout in seconds

        Returns:
            True if server responds with ready=True
        """
        try:
            url = f"{self.appium_url}/status"
            req = Request(url, method='GET')
            with urlopen(req, timeout=timeout) as response:
                data = json.loads(response.read().decode())
                return data.get('value', {}).get('ready', False)
        except (URLError, TimeoutError, json.JSONDecodeError, Exception) as e:
            logger.debug(f"Worker {self.worker_id}: Health check failed: {e}")
            return False

    def wait_for_healthy(self, timeout: float = 30.0, poll_interval: float = 1.0) -> bool:
        """
        Wait for Appium server to become healthy.

        Args:
            timeout: Maximum time to wait in seconds
            poll_interval: Time between health checks

        Returns:
            True if server became healthy, False if timeout
        """
        start_time = time.time()
        while time.time() - start_time < timeout:
            if self.is_healthy():
                return True
            time.sleep(poll_interval)
        return False

    def start(self, timeout: float = 30.0) -> None:
        """
        Start the Appium server and wait for it to become healthy.

        If a healthy Appium server is already running on our port, we reuse it
        instead of killing and restarting. This allows efficient handoff between
        runs and workers.

        Args:
            timeout: Maximum time to wait for server to start

        Raises:
            AppiumServerError: If server fails to start or become healthy
        """
        # Check if Appium is already running and healthy on our port
        if self.is_healthy():
            logger.info(f"Worker {self.worker_id}: Reusing existing healthy Appium on port {self.port}")
            self._started = True
            self.process = None  # We didn't start it, so we won't stop it
            return

        # Ensure logs directory exists
        self.parallel_config.ensure_logs_dir()

        # Port is in use but not healthy Appium - kill whatever is there
        self._kill_existing_on_port()

        # Start Appium server
        cmd = self._build_command()
        env = self._get_env()

        logger.info(f"Worker {self.worker_id}: Starting Appium on port {self.port}")
        logger.debug(f"Worker {self.worker_id}: Command: {' '.join(cmd)}")

        try:
            # Open log file for Appium output
            log_file = open(self.worker_config.appium_log_file, 'w', encoding='utf-8')

            if sys.platform == 'win32':
                # Windows: use CREATE_NEW_PROCESS_GROUP for clean shutdown
                self.process = subprocess.Popen(
                    cmd,
                    stdout=log_file,
                    stderr=subprocess.STDOUT,
                    env=env,
                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP
                )
            else:
                # Unix: use start_new_session for process group isolation
                self.process = subprocess.Popen(
                    cmd,
                    stdout=log_file,
                    stderr=subprocess.STDOUT,
                    env=env,
                    start_new_session=True
                )

            logger.info(f"Worker {self.worker_id}: Appium started with PID {self.process.pid}")

        except FileNotFoundError:
            raise AppiumServerError(
                f"Worker {self.worker_id}: 'appium' command not found. "
                "Install with: npm install -g appium"
            )
        except Exception as e:
            raise AppiumServerError(f"Worker {self.worker_id}: Failed to start Appium: {e}")

        # Wait for server to become healthy
        if not self.wait_for_healthy(timeout=timeout):
            # Server didn't start - check if process died
            if self.process.poll() is not None:
                raise AppiumServerError(
                    f"Worker {self.worker_id}: Appium process died immediately. "
                    f"Check log: {self.worker_config.appium_log_file}"
                )
            else:
                self.stop()
                raise AppiumServerError(
                    f"Worker {self.worker_id}: Appium didn't become healthy within {timeout}s"
                )

        self._started = True
        logger.info(f"Worker {self.worker_id}: Appium ready on {self.appium_url}")

    def stop(self, timeout: float = 10.0) -> None:
        """
        Stop the Appium server gracefully.

        Args:
            timeout: Maximum time to wait for graceful shutdown before force kill
        """
        if self.process is None:
            return

        logger.info(f"Worker {self.worker_id}: Stopping Appium server (PID {self.process.pid})")

        try:
            # First try graceful shutdown
            if sys.platform == 'win32':
                # Windows: send CTRL_BREAK_EVENT to process group
                self.process.send_signal(signal.CTRL_BREAK_EVENT)
            else:
                # Unix: send SIGTERM
                self.process.terminate()

            # Wait for graceful shutdown
            try:
                self.process.wait(timeout=timeout)
                logger.info(f"Worker {self.worker_id}: Appium stopped gracefully")
            except subprocess.TimeoutExpired:
                # Force kill if graceful shutdown failed
                logger.warning(f"Worker {self.worker_id}: Appium didn't stop gracefully, force killing")
                self.process.kill()
                self.process.wait(timeout=5)

        except Exception as e:
            logger.error(f"Worker {self.worker_id}: Error stopping Appium: {e}")

        finally:
            self.process = None
            self._started = False

    def ensure_healthy(self, restart_timeout: float = 60.0) -> bool:
        """
        Ensure Appium is healthy before processing a job.

        Call this before each job to verify Appium is still responding.
        If unhealthy, attempts to restart automatically.

        Args:
            restart_timeout: Timeout for restart attempt if needed

        Returns:
            True if Appium is healthy (or was restarted successfully)

        Raises:
            AppiumServerError: If Appium cannot be made healthy
        """
        if self.is_healthy():
            return True

        logger.warning(f"Worker {self.worker_id}: Appium unhealthy, attempting restart...")

        # Kill whatever is there (might be hung)
        self._kill_existing_on_port()
        time.sleep(2)

        # Try to restart
        try:
            self.start(timeout=restart_timeout)
            logger.info(f"Worker {self.worker_id}: Appium restarted successfully")
            return True
        except AppiumServerError as e:
            logger.error(f"Worker {self.worker_id}: Failed to restart Appium: {e}")
            raise

    def _kill_existing_on_port(self) -> None:
        """Kill any existing process using our Appium port."""
        if sys.platform == 'win32':
            try:
                # Find process using the port
                result = subprocess.run(
                    ['netstat', '-ano'],
                    capture_output=True, text=True, timeout=10
                )
                for line in result.stdout.split('\n'):
                    if f':{self.port}' in line and 'LISTENING' in line:
                        parts = line.split()
                        if parts:
                            pid = parts[-1]
                            if pid.isdigit():
                                subprocess.run(['taskkill', '/F', '/PID', pid],
                                             capture_output=True, timeout=10)
                                logger.info(f"Worker {self.worker_id}: Killed existing process on port {self.port}")
                                time.sleep(1)
            except Exception as e:
                logger.debug(f"Worker {self.worker_id}: Error killing existing process: {e}")
        else:
            try:
                # Unix: use lsof to find and kill
                result = subprocess.run(
                    ['lsof', '-ti', f':{self.port}'],
                    capture_output=True, text=True, timeout=10
                )
                if result.stdout.strip():
                    for pid in result.stdout.strip().split('\n'):
                        if pid.isdigit():
                            subprocess.run(['kill', '-9', pid], capture_output=True, timeout=5)
                            logger.info(f"Worker {self.worker_id}: Killed existing process on port {self.port}")
                            time.sleep(1)
            except Exception as e:
                logger.debug(f"Worker {self.worker_id}: Error killing existing process: {e}")


def cleanup_all_appium_servers(config: ParallelConfig) -> int:
    """
    Kill all Appium servers for all configured workers.

    Args:
        config: Parallel configuration

    Returns:
        Number of servers killed
    """
    killed = 0
    for worker in config.workers:
        manager = AppiumServerManager(worker, config)
        if manager.is_healthy(timeout=2):
            logger.info(f"Found running Appium on port {worker.appium_port}, killing...")
            manager._kill_existing_on_port()
            killed += 1
    return killed


def check_all_appium_servers(config: ParallelConfig) -> dict:
    """
    Check health status of all configured Appium servers.

    Args:
        config: Parallel configuration

    Returns:
        Dict mapping worker_id to health status
    """
    status = {}
    for worker in config.workers:
        manager = AppiumServerManager(worker, config)
        status[worker.worker_id] = {
            'port': worker.appium_port,
            'healthy': manager.is_healthy(timeout=2),
            'url': worker.appium_url
        }
    return status


if __name__ == "__main__":
    # Demo/test: start and stop an Appium server
    import sys

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s'
    )

    from parallel_config import get_config

    config = get_config(num_workers=1)
    worker = config.workers[0]

    print(f"\nTesting AppiumServerManager for worker {worker.worker_id}")
    print(f"  Port: {worker.appium_port}")
    print(f"  systemPort: {worker.system_port_start}-{worker.system_port_end}")

    manager = AppiumServerManager(worker, config)

    print("\n1. Checking if Appium already running...")
    if manager.is_healthy():
        print("   Appium is already running!")
    else:
        print("   Appium not running, starting...")
        try:
            manager.start(timeout=30)
            print(f"   Appium started successfully at {manager.appium_url}")
        except AppiumServerError as e:
            print(f"   Failed to start: {e}")
            sys.exit(1)

    print("\n2. Health check...")
    print(f"   Healthy: {manager.is_healthy()}")

    print("\n3. Stopping Appium...")
    manager.stop()
    print("   Stopped.")

    print("\n4. Verifying stopped...")
    print(f"   Healthy: {manager.is_healthy()}")
</file>

<file path="appium_ui_controller.py">
"""
Appium UI Controller - encapsulates all Appium-based UI interactions.

This module provides a clean interface for interacting with Android
UI elements through Appium WebDriver.

Extracted from SmartInstagramPoster to improve separation of concerns.
"""
import re
import time
import xml.etree.ElementTree as ET
from typing import List, Dict, Tuple, Optional, Any

from appium import webdriver
from appium.webdriver.common.appiumby import AppiumBy

from config import Config


class AppiumUIController:
    """Controls Android UI through Appium WebDriver."""

    def __init__(self, driver: webdriver.Remote):
        """
        Initialize the controller.

        Args:
            driver: Appium WebDriver instance (must already be connected).
        """
        self._driver = driver

    @property
    def driver(self) -> webdriver.Remote:
        """Get the underlying Appium driver."""
        return self._driver

    def tap(self, x: int, y: int, delay: float = 1.5) -> None:
        """Tap at coordinates.

        Args:
            x: X coordinate.
            y: Y coordinate.
            delay: Delay after tap in seconds.
        """
        print(f"  [TAP] ({x}, {y})")
        if not self._driver:
            raise Exception("Appium driver not connected - cannot tap")
        self._driver.tap([(x, y)])
        time.sleep(delay)

    def swipe(self, x1: int, y1: int, x2: int, y2: int, duration_ms: int = 300) -> None:
        """Swipe from one point to another.

        Args:
            x1: Start X coordinate.
            y1: Start Y coordinate.
            x2: End X coordinate.
            y2: End Y coordinate.
            duration_ms: Duration of swipe in milliseconds.
        """
        if not self._driver:
            raise Exception("Appium driver not connected - cannot swipe")
        self._driver.swipe(x1, y1, x2, y2, duration_ms)

    def press_key(self, keycode) -> None:
        """Press a key.

        Args:
            keycode: Key code (int) or string like 'KEYCODE_BACK'.
        """
        if not self._driver:
            raise Exception("Appium driver not connected - cannot press key")

        key_map = {
            'KEYCODE_BACK': 4,
            'KEYCODE_HOME': 3,
            'KEYCODE_ENTER': 66,
        }

        if isinstance(keycode, str):
            keycode = key_map.get(keycode, 4)  # Default to BACK

        self._driver.press_keycode(keycode)

    def type_text(self, text: str) -> bool:
        """Type text into the currently focused field.

        Args:
            text: Text to type (supports Unicode/emojis).

        Returns:
            True if text was typed successfully.
        """
        if not self._driver:
            print("    ERROR: Appium driver not connected!")
            return False

        print(f"    Typing via Appium ({len(text)} chars)...")
        try:
            # Find the currently focused EditText element
            edit_texts = self._driver.find_elements(AppiumBy.CLASS_NAME, "android.widget.EditText")
            if edit_texts:
                for et in edit_texts:
                    if et.is_displayed():
                        et.send_keys(text)
                        print("    Appium: text sent successfully")
                        time.sleep(0.8)
                        return True

            # Fallback: try to type using the active element
            active = self._driver.switch_to.active_element
            if active:
                active.send_keys(text)
                print("    Appium: text sent to active element")
                time.sleep(0.8)
                return True

            print("    ERROR: No text field found to type into")
            return False

        except Exception as e:
            print(f"    Appium typing error: {e}")
            return False

    def dump_ui(self) -> Tuple[List[Dict], str]:
        """Dump UI hierarchy and return parsed elements.

        Returns:
            Tuple of (elements list, raw XML string).
            Elements have: text, desc, id, bounds, center, clickable.

        Raises:
            Exception: If driver not connected or dump fails.
        """
        elements = []
        xml_str = ""

        if not self._driver:
            raise Exception("Appium driver not connected - cannot dump UI")

        xml_str = self._driver.page_source

        if '<?xml' not in xml_str:
            return elements, xml_str

        xml_clean = xml_str[xml_str.find('<?xml'):]
        try:
            root = ET.fromstring(xml_clean)
            # Appium uses class names as tags, iterate over ALL elements
            for elem in root.iter():
                text = elem.get('text', '')
                desc = elem.get('content-desc', '')
                res_id = elem.get('resource-id', '')
                bounds = elem.get('bounds', '')
                clickable = elem.get('clickable', 'false')

                if bounds and (text or desc or clickable == 'true'):
                    # Parse bounds [x1,y1][x2,y2]
                    m = re.match(r'\[(\d+),(\d+)\]\[(\d+),(\d+)\]', bounds)
                    if m:
                        x1, y1, x2, y2 = map(int, m.groups())
                        cx, cy = (x1+x2)//2, (y1+y2)//2
                        elements.append({
                            'text': text,
                            'desc': desc,
                            'id': res_id.split('/')[-1] if '/' in res_id else res_id,
                            'bounds': bounds,
                            'center': (cx, cy),
                            'clickable': clickable == 'true'
                        })
        except ET.ParseError as e:
            print(f"  XML parse error: {e}")

        return elements, xml_str

    def is_keyboard_visible(self, adb_shell_func=None) -> bool:
        """Check if the keyboard is currently visible.

        Args:
            adb_shell_func: Optional function to run ADB shell commands.
                           If not provided, returns False.

        Returns:
            True if keyboard is visible.
        """
        if not adb_shell_func:
            return False

        # Method 1: Check dumpsys for keyboard visibility
        result = adb_shell_func("dumpsys input_method | grep mInputShown")
        if "mInputShown=true" in result:
            return True

        # Method 2: Check window visibility
        result = adb_shell_func("dumpsys window | grep -i keyboard")
        if "isVisible=true" in result.lower() or "mhasfocus=true" in result.lower():
            return True

        # Method 3: Check if InputMethod window is visible
        result = adb_shell_func("dumpsys window windows | grep -E 'mCurrentFocus|mFocusedApp'")
        if "InputMethod" in result:
            return True

        return False

    def save_screenshot(self, filepath: str) -> bool:
        """Save a screenshot to file.

        Args:
            filepath: Path to save screenshot.

        Returns:
            True if screenshot was saved.
        """
        try:
            if self._driver:
                self._driver.save_screenshot(filepath)
                return True
        except Exception as e:
            print(f"    Failed to save screenshot: {e}")
        return False

    def scroll_down(self) -> None:
        """Scroll down on the screen."""
        self.swipe(
            Config.SCREEN_CENTER_X, Config.FEED_BOTTOM_Y,
            Config.SCREEN_CENTER_X, Config.FEED_TOP_Y,
            Config.SWIPE_DURATION_FAST
        )

    def scroll_up(self) -> None:
        """Scroll up on the screen."""
        self.swipe(
            Config.SCREEN_CENTER_X, Config.FEED_TOP_Y,
            Config.SCREEN_CENTER_X, Config.FEED_BOTTOM_Y,
            Config.SWIPE_DURATION_FAST
        )

    def go_back(self) -> None:
        """Press the back button."""
        self.press_key('KEYCODE_BACK')

    def go_home(self) -> None:
        """Press the home button."""
        self.press_key('KEYCODE_HOME')
</file>

<file path="chunk_01c.csv">
Text,Pinterest Source Url,LinkedIn Group Title,CatalogId(optional),ProductIdsSeparatedByComma(optional),Source,Image/Video link 1 (file path or URL(works only for images))
"The airport security theater gets dissected by Sean Evans on @2bears.1cave and honestly, we're all living this nightmare. #2Bears1Cave #seanevans #comedy #airportlife #airportsecurity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DM6m1Econ4x-2.mp4
"Tom Segura knows exactly how loyal Bert is when it comes to his marriage – there's absolutely zero question about his dedication. 🐻 @2bears.1cave

#2Bears1Cave #marriedlife #happywife #comedy #tomsegura",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DMbMMftoiDC-2.mp4
Tom's favorite hobby? Making his mom regret every parenting decision she's ever made 😂 Classic moment from @2bears.1cave that hits different when you know the family dynamic. #2Bears1Cave 212 #helicopterride #funnymoments,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DOCMmXuCLCs-2.mp4
The universal truth nobody warns you about: little boys and wives operate on an energy source science hasn't discovered yet. @2bears.1cave breaks down the reality. #2Bears1Cave 297 #sons #comedy #little,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DNtL2c3UF6K-2.mp4
Two NFL veterans break down the defensive beasts that gave them nightmares on the field 💀 Beau Allen and Jason Kelce recall their most challenging opponents throughout their careers over on @2bears.1cave 🏈 Ep. 288 #2Bears1Cave #2bears1cavepodcast #NFL #football #podcast #JasonKelce #Eagles #footballpodcast #nflpodcast,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DJ32YBcIFF4-1.mp4
Tom Segura's transformation has the internet doing double takes 👀 The side-by-side from @2bears.1cave shows what dedication really looks like over 24 months. #2Bears1Cave #bertkreischer #tomsegura #2bears #fitness #fit,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DMNmeE-oIXY-1.mp4
"Tom Segura and the crew can't help but roast this street interview moment 😂 The chaos continues over at @2bears.1cave where nothing is off limits

#2Bears1Cave #2bears #tomsegura #streetinterview #comedy #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DLQnA_Koit--1.mp4
"When Blort Krishna crossed paths with Black Twitter, the internet had opinions. @2bears.1cave breaks down the cultural collision that had everyone picking sides.

#2Bears1Cave #YMH #YourMomsHouse #BadFriends #Podcast #Comedy #StandUp #Comedian #TomSegura #BertKreischer #AndrewSantino #BobbyLee #Comedy #TigerBelly #Flagrant #Funny",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DLTFJyGo0Wn-2.mp4
"Joey Diaz has met his match, and it's not what you'd expect – it's walking. @2bears.1cave captures the hilarious moment. Ep. 282 #2Bears1Cave",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DH5x_AkIHee-2.mp4
"The motorcycle era begins for Bart 🏍️ @2bears.1cave drops this gem in episode 279 where life just got a whole lot more interesting

#2Bears1Cave #2bears1cavepodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DHMbE9rI-TP-1.mp4
"The secret weapon elite athletes don't talk about? It's hiding in plain sight on your face. @2bears.1cave reveals how a simple Nasal Dilator Kit is transforming workout performance for thousands across the country—better oxygen flow means pushing past old limits and bouncing back quicker than ever. Link in bio to level up. 📌

#nasalbreathing #nasaldialator #trending",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DI6mE7PtOhc-1.mp4
"The kind of dad wisdom that actually sticks 💯 @2bears.1cave serving up life lessons in Ep. 15

#2bears1cave #2bears1cavepodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DF_VttIyX2q-1.mp4
Jim Norton joins the podcast and the crew gets deep into what makes an H Man summer truly unforgettable. @2bears.1cave sits down with @jimnortonofficial for episode 294 where Tom Segura and the gang break down Tim's latest declaration. #2Bears1Cave #2bears #2B1C #TomSegura,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DLbC0dqoT2V-1.mp4
"The Kreischer and Segura children were clearly born without a fear gene, as @2bears.1cave can confirm 😂

#2bears1cave #comedians #podcastersofinstagram",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DFqpKI_z4rk-1.mp4
"Tom Segura puts the viral breathing device to the test while Bert watches in typical fashion 😂 Via @2bears.1cave

#trending #tiktokmademebuyit #nasalbreathing #breathwork #podcast #comedy #2bears1cave",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DJxE_WltdUR-1.mp4
"Tom Segura's reaction to these gifts from Bart Kreischer hits different when you realize the thought that went into each one 🎁 Over on @2bears.1cave, these two prove friendship isn't about the price tag – it's about actually knowing what makes your buddy light up. Episode 200 energy right here. #2Bears1Cave",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DK3REr1oC0r-1.mp4
"Two comedy legends debate the ultimate question: whose influence runs deeper, Taylor Swift or Joe Rogan? @2bears.1cave tackles the conversation everyone's been thinking about but nobody's answering. #2Bears1Cave #taylorswift #joerogan #comedy #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DPCbKmCiLQS-1.mp4
@realfunnymarco and the crew break down Ice Cube's permanent scowl energy on @2bears.1cave – turns out the man's range goes from angry to... angrier 😤 #2Bears1Cave #icecube #movie #waroftheworlds,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DP-cjyLCB3z-1.mp4
"Tom Segura and Bert Kreischer remind us why the tough moments matter most in this clip from @2bears.1cave 🐻🐻

#2Bears1Cave #2bears1cavepodcast #comedypodcast #comedians",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\2bears.1cave\DLNBCypIVmB-2.mp4
"According to Alex Jones and Elijah Schaffer, Candace Owens exposed how Zionist donors attempted to manipulate Charlie Kirk. @alexjones.tv breaks down this explosive revelation.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DPp9eJBkbay-2.mp4
"A chilling prediction from October 2025 that demands attention. @alexjones.tv breaks down alleged NATO operations and the potential escalation toward global conflict. What really happened behind closed doors? The pieces are coming together.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DP16sTWEZa9-1.mp4
Behind the scenes of a media empire's final chapter—Ed Martin's rescue attempt for INFOWARS hit a wall when Todd Blanche pulled the plug. The full story from @alexjones.tv breaks down what really happened. #infowars #trumpwon #maganews,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DPzZGHOEY7S-2.mp4
"Behind closed doors at the Pentagon, preparations are underway for something most Americans aren't talking about yet. @alexjones.tv breaks down Trump's directive on potential welfare riots and civil unrest in this October 30th, 2025 emergency broadcast.

#infowars #trumpwon #maganews #ebt",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQckPhJkQpL-2.mp4
"A chilling prophecy from the medical establishment: Dr. Anthony Fauci and Dr. Peter Hotez have issued warnings about a coming pandemic under Trump's watch—but this time, resistance could mean arrest. @alexjones.tv breaks down what they're calling ""Disease X"" and why 2025 has officials sounding the alarm on enforcement measures that would make previous mandates look tame.

#AlexJones #DiseaseX #AnthonyFauci #PeterHotez #Pandemic2025 #Trump #MedicalTyranny #Freedom #WakeUp #Resistance #PublicHealth #EmergencyReport #InfoWars #StayAlert",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQ2XdLzgCze-1.mp4
"Venezuela might be next on the radar according to this breakdown from @alexjones.tv. Alex Jones discusses Trump's potential military move that could shift everything. Drop your thoughts below. 10/31/25

#infowars #trumpwon #maganews #ebt",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQe9wrYEUcp-1.mp4
"The declaration that's got everyone talking: Alex Jones delivers a powerful message about Team Humanity's inevitable victory over the New World Order. @alexjones.tv isn't holding back in this one. 🔥

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQNCEydkSxQ-1.mp4
"The timing couldn't be more suspicious. As Trump's recovery gains momentum, certain forces seem determined to derail it – and @alexjones.tv isn't holding back on calling it out. He breaks down exactly what's happening behind the scenes and why Democrats are scrambling. October 20th, 2025.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQCvFGkkfVk-1.mp4
"The establishment's worst nightmare? A voice they can't silence. While they scheme to lock him up, @alexjones.tv continues breaking down the replacement migration agenda they desperately want buried. November 5th, 2025 - the truth hits different when they're trying to cage the messenger.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQsKWlokQDQ-2.mp4
"Political analyst Alex Jones examines the escalating tensions between Democratic leadership and the MAGA movement in this compelling breakdown. According to Jones, desperate tactics are being deployed that could push the nation toward unprecedented internal conflict. @alexjones.tv delivers his unfiltered perspective on where this dangerous path might lead.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DP6-JuwEd2O-1.mp4
"A chilling forecast from the front lines of information warfare – while others debate economic policy, Alex Jones (@alexjones.tv) is sounding the alarm on something far more sinister. His latest warning connects the dots between financial collapse and digital tyranny, revealing how globalist architects might exploit the next depression as cover for implementing an AI-powered surveillance grid. This isn't just about market crashes – it's about the infrastructure of control being built in plain sight.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQuphmpEYLv-1.mp4
"The battle for America's major cities is heating up, and Alex Jones (@alexjones.tv) isn't holding back on what he's witnessing unfold in places like New York. This November 4th commentary cuts straight to the point about radical Islamist movements and their growing influence across urban America.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DQpjRUZkX2Z-1.mp4
"The Deep State's days are numbered according to @alexjones.tv, who breaks down why Trump and America have reached their breaking point with John Brennan - 11/26/25

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DRiU7wwkfHO-1.mp4
"The deep state's civil war blueprint just got exposed by Alex Jones, and he's calling on Trump to take immediate action against the architects. @alexjones.tv breaks down the Podesta plan that has everyone talking this November 25th. 

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DRfqnSCkYeG-2.mp4
"The CIA's loyalty to Maduro just got called out in brutal fashion by @alexjones.tv – and the timing couldn't be more suspect as Trump ramps up pressure on the Venezuelan regime.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DRQMs_YETf9-2.mp4
"The investigation into Democratic calls for rebellion is underway, with Trump's military courts and Hegseth leading the charge according to @alexjones.tv's latest breakdown from 11/21/25. He's connecting dots that mainstream media won't touch.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DRVP8nGEUxg-1.mp4
"Bill Gates could be planning round two, and Alex Jones from @alexjones.tv says Trump needs to shut it down before it launches. The warning comes as concerns grow about what's next on the global agenda.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DRlqUvpkfUt-2.mp4
"A powerful defense of free speech from Charlie Kirk as he breaks down how Alex Jones faced censorship after calling out mainstream media dishonesty. @alexjones.tv continues to stand firm on exposing the truth, no matter the cost. December 17th, 2023 - a moment worth remembering.

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DRq5OjXEWxN-1.mp4
"Alex Jones backs Trump's statement on how traitors have historically faced capital punishment under U.S. law - November 20th, 2025

Via @alexjones.tv

#infowars #trumpwon #maganews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\alexjones.tv\DRSvXffEU3i-2.mp4
"The secret weapon most people overlook in conversation? The pause. @askvinh demonstrates why eliminating ""umm"" and ""ahh"" fillers instantly upgrades your communication game. That moment of silence isn't awkward—it's powerful. It gives your words weight and your audience time to actually absorb what you're saying. Master the strategic pause and transform how people receive your message.

#communicationskills #publicspeaking #confidence #communicationtips #personaldevelopment #selfimprovement #speakingtips #effectivecommunication #socialskills #charisma",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DGlvMcHT0HD-2.mp4
"When someone dominates the conversation with stories about themselves, they're actually pushing people away. @askvinh breaks down why flipping the script—leading with genuine questions and curiosity—is what actually makes you magnetic in conversations. The trap? Thinking you need to impress people by talking more about yourself.

#communication #communicationskills #socialskills #confidence #selfimprovement #personaldevelopment #selfdevelopment #conversationskills #charisma",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DGA40Lev0Rs-2.mp4
"Want to level up how you communicate? @askvinh breaks down the essential moves that separate great speakers from everyone else.

His blueprint covers the fundamentals most people overlook: filming yourself to catch what you're actually projecting, syncing your vibe with whoever you're talking to, and mastering the art of strategic silence (yes, pauses are powerful when you know how to use them).

He also shares the FORD method for keeping conversations flowing naturally and reveals why dropping your pitch at the end of sentences instantly makes you sound more confident and commanding.

These aren't complex theories—just practical adjustments that actually work. Ready to transform how you show up in conversations? Drop MASTERCLASS in the comments to join his free training kicking off tomorrow.

#communicationskills #publicspeaking #socialskills #confidence #personaldevelopment #selfimprovement #communication #speakingtips #charisma",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DF-UDC9NBGZ-1.mp4
"Creating real change in how people think? It demands everything you've got. @askvinh breaks down why influence requires maximum energy output, not minimal effort. Most quit because they expect it to flow naturally—but greatness lives on the other side of exhaustion, not convenience. The ones who transform minds are the ones who refuse to coast.

What's your take?

#influence #leadership #mindset #personaldevelopment #growthmindset #successmindset #motivation #influencer #thoughtleadership #impact",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DHvm_o6MWqp-1.mp4
"When most people assume English is someone's first language, they'd never guess it's actually their third 👀

@askvinh shares how Teochew came first, Vietnamese second, and English third - a journey that meant spending school days barely speaking and constantly thinking in Vietnamese instead.

His breakthrough? Immersion became everything. To gain clarity and speed in any new language, you have to surround yourself with it even more than your mother tongue.

Practice isn't just helpful - it's the only way forward 💪

Tag someone learning English right now 🌍

#englishlearning #languagelearning #learnenglish #englishteacher #studyenglish #englishvocabulary #englishspeaking #speakenglish #polyglot #vietnamese #bilingualproblems #languagetips #esl #englishfluency",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DG5icHTJU4m-1.mp4
"The vibration you create when you speak literally travels through the air and shifts the emotional state of everyone around you 🌊

Wild to think about, right? But here's the part most people miss: those good vibes have to pass through YOU before reaching anyone else.

Which means every time you uplift someone with your words, you're actually benefiting twice.

Smart insight from @askvinh

#communication #personaldevelopment #socialskills #selfimprovement #mindset #energy #vibes #positivethinking #communicationskills #emotionalintelligence #personalgrowth #lifelessons #psychology #socialskillstips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DJmIQQ0RpqG-2.mp4
"Communication happens whether you're aware of it or not—and @askvinh breaks down exactly how to master it. Every interaction is an opportunity to influence, connect, or persuade. He's offering a free training packed with frameworks that actually work. Drop 🍆 or eggplant in the comments to get access.

#communication #communicationskills #communicationtips #salestips #salestraining #influence #persuasion #charisma #selfimprovement #personaldevelopment #businesstips #entrepreneurship #socialskills #confidence",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DJ_8G5XymVs-2.mp4
"The secret to why your words aren't landing the way you think they should 👀

Most people blame their message when communication fails, but @askvinh reveals the real issue isn't what you're saying—it's how your brain processes the exchange. He breaks down the psychological barrier that keeps you from truly connecting, even when you think you're being crystal clear.

Understanding this changes everything about how you show up in conversations 💯

#communication #communicationskills #socialskills #confidence #selfimprovement #personaldevelopment #psychology #mindset #growthmindset #selfdevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DKwu4hQSfkl-2.mp4
"The secret to content that actually connects? It's all about ditching the ""written voice"" and embracing how you naturally speak. @askvinh breaks down why so many creators struggle to sound authentic—they're typing in essay format instead of conversation format. When you write the way you actually talk, rehearsing becomes effortless and your delivery feels genuine instead of robotic. This applies beyond content creation too—meetings, presentations, anywhere you need people to actually listen instead of zone out. The moment you sound like you're reading a script is the moment you lose your audience.

#contentcreation #contenttips #contentcreator #socialmediatips #videocontent #contentmarketing #creatoreconomy #digitalmarketing #socialmedia #contentstrategist",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DHTSO2qPvL4-2.mp4
"@askvinh wrapped up his Melbourne STAGE workshop with this incredible energy ❤️

When you watch someone truly passionate about teaching communication, it shows in every moment. The final day always hits different.

#communicationskills #stageworkshop #publicspeaking #presentationskills #communicationcoach #leadershipdevelopment #professionaldevelopment #melbourne",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DNNvWXnRJ5E-1.mp4
"The difference between standing alone at a networking event and making valuable connections? It's all about preparation, says @askvinh. Having a concise self-intro ready means you're not scrambling when someone asks about you. But here's what most people get wrong: they think talking more = networking better. Actually, the real skill is active listening and knowing when to contribute versus when to let the conversation breathe. Courage gets you in the door, but strategic listening keeps you in the room.

#networking #networkingevents #networkingskills #professionaldevelopment #careerdevelopment #careeradvice #communication #communicationskills #socialskills #professionalgrowth #businessnetworking #networkingtips #careergoals #personaldevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DKyNHOZxMj2-2.mp4
"Looking at this wholesome moment, it's clear that @askvinh has discovered something most parents overlook: the untapped power of simply humming.

While everyone's searching for the perfect lullaby playlist or white noise machine, he's mastered a 5-minute sleep technique using nothing but his voice — no words, no technology, just pure human connection.

What makes this work isn't perfection. It's presence. It's the willingness to use the one instrument we're all born with but rarely learn to play.

His baby girl doesn't need Grammy-level vocals. She needs the comfort that comes from her dad's sound, delivered with what he calls ""delusional level of vocal confidence.""

That's the real superpower — showing up fully, voice and all, in those quiet moments that matter most.

#DadLife #Parenting #Fatherhood #GirlDad #ParentingTips #DadTok #FatherDaughter #BabyGirl #ParentHack #Humming #VoiceHealing #MindfulParenting #ConnectionOverPerfection #NewDad #ParentingWin",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DK1-ho6vCyh-2.mp4
"Most people want the extraordinary life but bail the moment they realize they have to suck first. @askvinh breaks down why being terrible at the beginning isn't a setback—it's literally the cost of admission. The winners? They pay that price upfront and take messy action anyway 👊

#success #motivation #mindset #entrepreneurship #personaldevelopment #growthmindset #successmindset #motivationalquotes #entrepreneur #selfimprovement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DOBWH5Skb4b-2.mp4
"Speaking faster isn't always better—and @askvinh breaks down exactly why that matters.

Want people to actually absorb what you're saying? It's all about controlling your pace. Important points deserve slower delivery. Everything else can move quicker. That contrast is what creates vocal variety and helps your audience know what deserves their attention.

DM or comment DOAC for the full podcast conversation with @steven

#communicationskills #publicspeaking #speakingtips #communication #clarity #podcastclips #selfimprovement #personaldevelopment #speakingskills #effectivecommunication",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DMc-Yp3tY8r-1.mp4
"Knowledge without action is just entertainment. @askvinh breaks down why so many people stay stuck in learning mode instead of execution mode—and how to finally make the switch that changes everything.

#knowledge #learning #personaldevelopment #selfimprovement #productivity #motivation #mindset #success #growth #action #execution #personalgrowth #lifelessons #inspiration #motivational",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DOFTKR7kvGv-1.mp4
"Some people need to hear this: you're still figuring it out, and that's exactly where you should be. @askvinh reminds us why self-judgment kills progress before it even starts 💯

Tag someone who's being too hard on themselves 👇

#motivation #mindset #selflove #personalgrowth #growthmindset #selfimprovement #mentality #successmindset #motivationalquotes #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DPgamn0AUWQ-1.mp4
"@askvinh drops wisdom: master communication, master negotiation. Your words shape your reality – sharpen them and watch opportunities multiply. The better you express yourself, the more doors swing open.

#communication #communicationskills #negotiation #negotiationskills #personaldevelopment #selfdevelopment #selfimprovement #growthmindset #successmindset #lifeskills #leadership #leadershipdevelopment #professionaldevelopment #careergrowth #personalgrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DQ4GUGvjIeA-2.mp4
"@askvinh reveals his top 3 communication frameworks in his free training — comment 'FRAMEWORK' below to get access 💬

#communicationskills #communicationtips #socialskills #conversationskills #confidencetips #confidence #framework #training #freetips #socialanxiety #improveconfidence",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DRXBFCAkSAr-2.mp4
"The future won't belong to those who master AI—it'll belong to those who master people. @askvinh breaks down why communication and genuine connection are becoming the ultimate competitive advantage in an increasingly automated world. As machines handle more tasks, the human touch becomes rare, and rarity creates value. What's your take? Will we crave authentic human interaction more as technology advances, or will we retreat further into digital isolation?

#AI #HumanSkills #Communication #FutureOfWork #PeopleSkills #EmotionalIntelligence #Leadership #SocialSkills #Technology #CareerAdvice #PersonalDevelopment #HumanConnection #SoftSkills #Networking #ProfessionalGrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\askvinh\DQoq580lUNi-1.mp4
"Bobby's holding nothing back when it comes to Shane 👀 @badfriendspod drops the full unfiltered convo on Patreon today, then hits all platforms Monday.

#BadFriends #BobbyLee #AndrewSantino #PodcastClips #Comedy #Funny #StandUpComedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DHL4n_nJMYf-1.mp4
"Bobby Lee's got Hollywood gold with this pitch: a revenge thriller about tracking down his stepdad who happens to be part Bigfoot, part vampire 🎬 The Bad Friends duo strikes again with another unhinged movie concept that somehow makes perfect sense | 📍 @badfriendspod

#badfriends #bobbytaesoo #bobbylee #andrewsantino #podcast #comedy #moviepitch #funny #standup #comedypodcast #podcastclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DG3fNL5SfUl-2.mp4
"Bobby Lee shares why Filipinos flock to Italy in this hilarious take from @badfriendspod that'll have you reconsidering every vacation stereotype you've ever heard 😂

#badfriends #bobbyleeandrewsantino #standup #standupcomedy #standup #comedy #funny #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DHWMJQpyTlf-1.mp4
"The Bad Friends podcast just hit a massive milestone – 2 million subscribers strong! 🎉 @badfriendspod continues to dominate with their unfiltered comedy and chaotic energy that keeps fans coming back for more.

#badfriends #badfriendspod #andrewsantino #bobbyleee #podcast #comedy #funny #standup #comedian #podcasting #podcastclips #comedypodcast #2million #milestone #celebration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DJcFxw5J9I3-2.mp4
"Bobby Lee discovers his Muay Thai instructor has been holding back—turns out those ""sharp"" elbows were about as dangerous as pool noodles. @badfriendspod brings the training montage nobody asked for but everyone needed.

#badfriends #bobbyleeandrewsantino #andrewsantino #bobbylee #standup #standupcomedy #standupcmedian #funny #funnyvideos #funnyvideo #badfriendspod #podcast #podcastclips #comedy #comedyvideo #comedyvideos #comedypodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DIjYKV5xQUg-2.mp4
"The squad gets an international update as Dax calls in straight from Japan 🇯🇵 via @badfriendspod

#badfriendspod #comedypodcast #andrewsantino #bobbyjlee #funnyclips #podcastclips #standupcomedy #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DJjzRdrprPc-2.mp4
"A wild story straight from Francis Ford Coppola's set featuring Shia that @badfriendspod had to share with the world 🎬

#badfriends #badfriendspod #comedy #standup #podcast #funny #comedypodcast #viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DKcckA_xJH3-1.mp4
"The crew unleashed their latest chaos and @badfriendspod fans can catch all the unfiltered action exclusively on Patreon right now 🎭

#badfriends #podcast #comedy #standup #standupcomedy #comedypodcast #andrewsantino #bobbyleе #patreon",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DKSKEjvRVGc-1.mp4
"The legend of the mysterious intern continues at Los Tito's 👀 @badfriendspod drops this one on Patreon today, everyone else waits till Monday 🔥

#badfriends #podcast #comedy #standupcomedy #andrewsantino #bobbyleee #funny #podcastclips #comedypodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DK2NBfOR5N--2.mp4
"Bobby Lee and Andrew Santino from @badfriendspod keep pushing boundaries with their comedy – and yes, they promise this bit is all about getting the laughs. Pride month energy at its finest. 🌈😂

#loveislove #happypride #badfriendspod #comedy #podcast #standupcomedy #comedyreels #funny #humor #lgbtq #pridecomedy #comedians",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DKm6fESS8_G-2.mp4
"The group discovers Rudy might have some snitch tendencies 👀 

Via @badfriendspod

#badfriends #badfriendspod #podcastclips #comedypodcast #andrewsantino #bobbylee #funnyclips #podcast #comedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DMsrOH9xYQT-2.mp4
"Bobby Lee and Andrew Santino from @badfriendspod are on the hunt for their next Fancy to bring the zombie movie to life! Think you've got what it takes? Better check those boxes first: LA resident ✓ Born in Spain with that authentic accent ✓ Ready to shoot your shot at carlosinthebooth@gmail.com – but seriously, if you don't fit the criteria, keep scrolling 👀

#badfriends #badfriendspod #bobbyleeandrewsantino #fancyb #comedypodcast #podcastclips #standup #standupcomedy #tigerbelly #andrewsantino #bobbylee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DLVbVEiyTaf-1.mp4
"The crew headed to mini golf and absolute chaos followed 🏌️‍♂️ @badfriendspod takes London by storm in Episode 3 of their 5-part series, with new episodes dropping weekly at patreon.com/badfriends

🎥 @mckonecorkery

#BadFriends #BadFriendsLondon #MiniGolf #Comedy #Podcast #ComedyPodcast #AndrewSantino #BobbyLee #London #Patreon",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DNqyQv6x0aR-1.mp4
"The basketball legend gets a vehicular makeover 🏀🚗

@badfriendspod delivers the nickname nobody knew they needed – Michael Jeep Jordan has entered the chat.

#badfriends #andrewsantino #bobbyleee #standup #standupcomedy #comedy #funny #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DNyKvdiYnjM-1.mp4
"The community college hustle finally coming through for Harland 📚💡

When those random night courses actually become relevant in conversation... @badfriendspod captures the moment perfectly.

#badfriends #comedy #podcast #standup #funny #comedian #comedypodcast #podcastclips #andrewsantino #bobbyleee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DOGw2mckQp5-2.mp4
"Bobby landed a Braveheart reference that caught everyone off guard 😂 The timing was absolutely perfect and the delivery had the whole room dying

via @badfriendspod

#badfriends #bobbyleelive #andrewsantino #standup #podcast #comedypodcast #comedy #funny",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DQ7MOnLkmzc-1.mp4
"Bobby Lee and Andrew Santino aren't letting parenthood slow them down – fresh content just dropped on Patreon from @badfriendspod 🎯

#badfriends #podcast #comedy #standup #standupcomedy #funny #comedypodcast #bobbyleeandrewsantino #tigerbelly #andrewsantino #bobbylee #whiskeyginger",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DPEkgb6EdZH-1.mp4
"Bobby Lee throws out a question that stops everyone in their tracks on @badfriendspod – Henderson as a last name belongs to which race? The crew's answers had the whole room divided.

#badfriends #bobbyleeandrewsantino #standup #standupcomedy #standupcomedian #funny #funnyvideos #funnyvideo #funnymoments #funnyreels #andrewsantino #bobbylee #podcast #podcastclips #podcasts #comedy #comedypodcast #comedyreels #reels",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DQKH0OEESDg-1.mp4
"The crew can't stop roasting each other's features and honestly it's peak comedy 💀

🎙️ @badfriendspod

#badfriends #fatskinnyeyes #podcastclips #comedypodcast #andrewsantino #bobbyleee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\badfriendspod\DRxLIlZiXOW-2.mp4
"Tom's reaction says it all 😬

According to @candaceshow, this dating trend needs to end ASAP. When women start acting like this, it's a red flag nobody's talking about.

Watch Tom's face when she drops that line 💀

#candaceowens #datingadvice #dating #relationshipadvice #relationships #modernwomen #moderndating #datingtips #redflags #datingstandards",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\C12ynVPuYwy-2.mp4
"Candace Owen (@candaceshow) couldn't believe what she was seeing. 👀

#candaceowens #candace #politics #conservative #news #viral #trending #fyp #foryou #foryoupage",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\C3V_AEYun1y-2.mp4
"A powerful message from @candaceshow that's resonating across communities: the silencing needs to stop. When faith becomes controversial simply for existing, we've lost our way as a society. She's calling out the double standard—and people are listening.

#Faith #Christianity #FreeSpeech #ReligiousFreedom #SpeakUp #ChristianLife #StandStrong #BelieverLife #FaithOverFear #ChristianCommunity #TruthMatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\C2gA7IEu1fK-1.mp4
"@candaceshow breaks down one of the wildest spending stories you'll hear today 💸

$11,000. Gone. And wait until you hear what it was for.

#CandaceOwens #Candace #PoliticalCommentary #ConservativeValues #CulturalCommentary #PodcastClips #ViralMoment #PoliticalDiscussion",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CkJMweCsjsg-1.mp4
"@candaceshow pulled no punches in this one 🎯 When keeping it real goes right 💯

#CandaceOwens #Candace #Conservative #Politics #Truth #Viral #FYP #Conservative #Republican #Trump #MAGA #America #News #CandaceShow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CmFfrfzrOpF-1.mp4
"Candace isn't holding back on this one. When @candaceshow speaks, people listen—and this message hits different. 🎯

#candaceowens #candace #conservative #conservatives #trump #donaldtrump #maga #makeamericagreatagain #republican #republicans #gop #america #usa #politics #political #politicalnews #news #latestnews #currentevents #debate #viral #trending",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CnheULJKQe8-1.mp4
"Candace isn't holding back on this one 😬 @candaceshow calls it exactly what it is.

#candaceowens #candace #podcast #podcasts #podcastclips #interview",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\Cpdi8FQOPOM-2.mp4
"The fashion icon energy is unmatched 👏 @candaceshow never misses when it comes to style

#CandaceOwens #Fashion #Style #Conservative #PoliticalCommentary #OOTD #FashionInspo #StyleIcon",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CqqcMF_usxf-1.mp4
"The chicken feed controversy everyone's talking about – Purina under fire as suspicious patterns emerge. @candaceshow investigates what's really happening with our food supply.

Streaming exclusively on @dailywireplus.

#CandaceOwens #DailyWire #Purina #FoodSupply #Conspiracy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CoN9fbYrmoV-2.mp4
"The clip everyone's talking about – and for good reason.

📹 @candaceshow

#CandaceOwens #Candace #TheCandaceOwensShow #Conservative #Politics #PoliticalNews #Breaking #BreakingNews #News #DailyWire #Republican #GOP #Trump #MAGA #America #USA #Truth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CrmQcFqLD-D-2.mp4
"Basketball star Brittney Griner has had a change of heart about standing during the national anthem, according to @candaceshow 👀

#BrittneyGriner #NationalAnthem #WNBA #Sports #Basketball #Patriotism #America #Conservative #Politics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CsuLODIgLb9-1.mp4
"Looking for straight talk? @candaceshow breaks down the issues everyone's thinking about but afraid to say out loud in today's episode. Link in bio to watch the full conversation.

#CandaceShow #CommonSense #PodcastClips #Candace #Politics #News #Conservative #Viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CrMPFsAgB0C-2.mp4
"Candace (@candaceshow) isn't holding back on this one 😬

#candaceowens #candace #politics #conservative #news #viral #fyp #foryou #foryoupage",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\Ctwa94qv1_b-2.mp4
"Mia Khalifa's track record speaks for itself—maybe skip her guidance. 🎯

via @candaceshow

#MiaKhalifa #BadAdvice #Candace #CandaceOwens #TheCandaceOwensShow #Conservative #Politics #DailyWire #Commentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CviMBa0rIgv-1.mp4
"The evidence that could change everything about the Steven Avery case: Teresa Halbach's car on the Avery Salvage Lot. @candaceshow investigates whether this was a setup or if the truth runs deeper.

Episode 4 of #ConvictingAMurderer is streaming now on @dailywireplus.

#StevenAvery #TeresaHalbach #TrueCrime #MakingAMurderer #CrimeDocumentary #DailyWire",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CxRNppDpSl8-2.mp4
"Looking at how the concept of ""equality"" gets twisted in modern discourse 🎯

@realcandaceowens breaks down this reality with @theofficertatum on the Candace Owens Podcast. Full episode at @candaceshow - link in bio!

#CandaceOwens #OfficerTatum #Equality #PodcastClips #PoliticalDiscussion #HonestConversation #TruthMatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\Cu2tG3PR-NL-1.mp4
"A fascinating contradiction: Maren Morris claims country music is ""burning itself down"" while the genre literally dominates America's charts with the biggest songs in the nation. Plot twist? She wasn't part of that success story.

📍 Via @candaceshow

#MarenMorris #CountryMusic #MusicIndustry #CandaceOwens #CountryCharts #MusicNews #PopCulture #Entertainment #ChartToppers #CountryArtists",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\Cx8mnJNAzkr-1.mp4
"The tragic reality of a generation lost to ideology. When parents, schools, and society all abandon their responsibilities, this is what we get. @candaceshow breaks down the cultural collapse in real time.

#CandaceOwens #Culture #America #Education #Parenting #Truth #Conservative #Politics #Society #CulturalDecay #WakeUp #Reality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CzMpK-Vr2Qf-2.mp4
"A friendly reminder that Mia Khalifa probably isn't the best source for life guidance. @candaceshow breaks it down.

#CandaceOwens #MiaKhalifa #BadAdvice #SocialMedia #Commentary #Politics #Conservative #TruthBomb #KeepItReal #CancelCulture #Influencers #CandaceShow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\candaceshow\CviMBa0rIgv-2.mp4
"@charliekirk1776 breaks down what the iconic red hat truly represents to millions of Americans who believe in restoring greatness to their nation.

#MAGA #MakeAmericaGreatAgain #Trump #Conservative #PatriotsUnite #RedWave #AmericaFirst #TPUSA #TurningPointUSA #Politics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DJxAhiDysKw-1.mp4
"Charlie Kirk (@charliekirk1776) was just as surprised as everyone else 👀

#Surprise #Unexpected #PlotTwist #Reaction #Viral #Trending #TPUSA #Conservative #Politics #News #Breaking #MustWatch #Shocking #DidNotExpect #Wow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DJaJ7MLhffY-2.mp4
"The mind over matter debate just got real 🧠 @charliekirk1776 breaks down why developing intellect should come before everything else. Sometimes the most controversial take is simply getting priorities straight.

#conservative #america #liberal #republican #politics #trump #maga #news #democrat #usa #freedom #minecraft #biden #socialism #capitalism #god #christian",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DKc_NF0hE6w-1.mp4
"The perfect balance exists in Christ—love that never compromises truth, and truth that's always rooted in love. @charliekirk1776 reminds us why both matter equally.

#Jesus #Faith #Truth #Love #Christian #Christianity #God #Bible #Gospel #ChristianFaith #BibleTruth #JesusChrist #FaithOverFear #ChristianLife #TruthMatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DKFnhL1S1un-1.mp4
"The policy position couldn't be more straightforward, according to @charliekirk1776 — illegal entry should result in deportation, period. No exceptions, no loopholes. Just enforcement of the law as written.

#IllegalImmigration #BorderSecurity #Immigration #DeportIllegals #EnforceTheLaw #BorderCrisis #IllegalAliens #AmericaFirst #SecureTheBorder #ImmigrationReform",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DJXQexhSgkB-2.mp4
"When the TV remote becomes a dealbreaker—@charliekirk1776 isn't wrong about this one. Shared values start with something as simple as which news you're consuming together. If you can't align on basic media choices, imagine the bigger conversations down the road.

#Relationships #DatingAdvice #ModernDating #RelationshipGoals #DatingTips #RealTalk #Conservative #ValuesFirst #CompatibilityMatters #RelationshipAdvice #Dating101 #MediaBias #SharedValues #MarriageAdvice #CoupleGoals",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DKaNohNSTwy-2.mp4
"Charlie Kirk breaks down why moral objectivity requires belief in a higher power. Without God as the ultimate standard, right and wrong become merely subjective opinions that shift with culture and time. @charliekirk1776 explains the logical foundation that connects divine authority to universal moral truth.

#CharlieKirk #Faith #MoralTruth #Christianity #God #Philosophy #Ethics #Conservative #Truth #Morality #ChristianFaith #BiblicalTruth #WorldView",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DL-1orjS_EJ-2.mp4
,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DPkBN2GAQAz-1.mp4
,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DPwk3jpkqLN-2.mp4
,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DQprggAkppe-1.mp4
,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DRfLYj7CUdr-1.mp4
"The feminist agenda found its complete opposite in Donald Trump, as @charliekirk1776 points out.

#Trump #DonaldTrump #Trump2024 #MAGA #Conservative #Feminism #Politics #America",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DNEW_Y8BzNN-2.mp4
"Charlie Kirk (@charliekirk1776) points out the glaring double standard in how justice is applied in America today. When conservatives face legal action, it's swift and severe. When liberals do the same or worse, they walk free. This clip highlights exactly why millions of Americans have lost faith in our institutions.

#CharlieKirk #DoubleStandards #JusticeSystem #Conservative #Politics #TwoTierJustice #LegalSystem #PoliticalBias #AmericaFirst #TPUSA #TurningPointUSA #ConservativeValues #Corruption",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DMLuI32hkQ3-1.mp4
"The audacity is real 😤 When they tried it but @charliekirk1776 wasn't having ANY of it. That's what we call standing firm when the enemy comes knocking 💪🔥

#NotToday #StandFirm #Truth #Faith #Conservative #America #TPUSA #TurningPointUSA #CharlieKirk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DNl2UpbyqjS-2.mp4
"The age-old philosophical truth: evil only has meaning when measured against good. @charliekirk1776 reminds us that moral relativism crumbles under this simple logic—without an objective standard, the very concept of evil becomes meaningless.

#Truth #Philosophy #MoralClarity #Conservative #Values #GoodVsEvil #ObjectiveTruth #ChristianValues #Faith #Wisdom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DM_OocKBjWp-2.mp4
"The moment you realize someone's speaking nothing but facts 💯 @charliekirk1776 breaks it down in a way that just hits different. Worth the watch 👀

❤️🇺🇸

#charliekirk #turningpointusa #conservative #politics #truth #america #patriot #maga #republican #freedom #usa",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DO37nBZj9HC-1.mp4
"The question that shouldn't be controversial yet somehow stumps people every time 🎯 @charliekirk1776 highlights how basic biology has become a debate topic in 2024

#CharlieKirk #TurningPointUSA #TPUSA #CommonSense #Biology #Reality #Truth #ConservativeValues #CriticalThinking #BasicQuestions",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DNoalZ2ynd5-2.mp4
"Following the unimaginable tragedy, Mrs. Erika Kirk steps forward with a message for America. Her composure and grace in this devastating moment speak volumes about her character and the legacy her husband leaves behind.

Via @charliekirk1776

#ErikaKirk #AmericanLeadership #NationalAddress #Strength #Legacy #Unity #CourageousWoman #America #LeadershipMatters #StandStrong",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DOhk5yXiYJ_-2.mp4
"Charlie Kirk (@charliekirk1776) knows the drill—February brings Valentine's Day, and with it, the predictable parade of articles trying to convince single women they're better off alone. The pattern repeats every year, he points out, where mainstream publications essentially tell women that relationships aren't worth pursuing. According to Charlie, this messaging isn't just about celebrating independence—it's actively discouraging women from seeking meaningful connections. Check out his full breakdown on why these annual think-pieces might be doing more harm than good.

#CharlieKirk #DatingCulture #ValentinesDay #Relationships #ModernDating #MediaBias #SingleLife #DatingAdvice #CulturalCommentary #SocialTrends",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\charliekirk1776\DP4mey0kuJH-2.mp4
"Every 999 episodes doesn't just happen—it earns you some serious perspective on what actually works in relationships. @chriswillx breaks down the patterns he's observed after countless conversations with the world's sharpest minds, and the takeaway is clear: fitness compatibility might be the most underrated filter for finding your person. When your values around health align, almost everything else clicks into place naturally.

#relationshipadvice #datingadvice #relationshiptips #datingtips #relationship #dating #moderndating #datingcoach #relationships #relationshipcoach",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DP2CxwnkifF-2.mp4
"Matthew McConaughey breaks down a truth most people avoid: choosing integrity over convenience isn't getting any easier. @chriswillx captures this powerful moment on what it really takes to live courageously.

The Art of Living a Courageous Life - Matthew McConaughey (4K)

#MatthewMcConaughey #Courage #Integrity #Motivation #Mindset #PersonalGrowth #SelfImprovement #LifeLessons #Inspiration #Wisdom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DPfEWdJDno0-1.mp4
"Every relationship decision reveals who you truly are. Dr. John Delony breaks down why being all-in isn't just about commitment—it's about choosing yourself too. @chriswillx explores what it really means to show up fully without losing yourself in the process.

#relationship #relationshipadvice #dating #datingadvice #love #marriage #chriswilliamson #modernwisdom #podcast #clips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DPWfFTXjrb4-2.mp4
"@chriswillx is hitting the road and bringing the show straight to your city 🇺🇸🇨🇦

Stage lights go up next week 💜

#comedy #standupcomedy #tour #liveshow #comedian #livetour #comedytour #standup #livecomedy #tourlife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DPy_OvIDiSp-1.mp4
"The measurement of courage isn't found in tomorrow's outcomes—it exists in today's choices. Matthew McConaughey breaks down what it truly means to live boldly, straight from his philosophy on taking action despite uncertainty. @chriswillx captures this masterclass moment in crystal clarity.

#MatthewMcConaughey #Courage #Motivation #SelfDevelopment #PersonalGrowth #Mindset #LifeAdvice #Philosophy #Inspiration #SelfImprovement #SuccessMindset #Wisdom #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DPzPP4ADutt-2.mp4
"The real flex isn't how many candles are on your cake—it's whether you actually showed up for the life you were living. @chriswillx breaks down why chasing extra years without chasing meaning is just existence with a longer timer. Quality over quantity isn't just a motto, it's the whole point. Stop counting decades and start making them count.

#livebetter #qualityoflife #longevity #lifelessons #mindsetshift #personalgrowth #selfimprovement #motivation #lifeadvice #modernwisdom #depthovertime #meaningfullife #purposefulliving",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DPRWDl3iOxh-1.mp4
"Looking back at 999 episodes, @chriswillx has learned that the sweet spot between ambition and peace isn't found—it's actively built. Work doesn't have to destroy you to define you. The real flex? Creating something meaningful without sacrificing everything else that matters.

#ModernWisdom #Podcast #WorkLifeBalance #PersonalGrowth #Productivity #SelfImprovement #Entrepreneurship #Mindset #Success #LifeLessons #PodcastClips #Motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DQjlGE1jvHS-2.mp4
"The bodybuilding legend opens up about what success really costs when the cameras aren't rolling. Chris Bumstead reveals the unfiltered reality of building an empire while staying human.

Full conversation with @chriswillx

#ChrisBumstead #Bodybuilding #FitnessMotivation #ClassicPhysique #MrOlympia #TRT #Fatherhood #Purpose #LifeAdvice #Relationships #SuccessMindset #FitnessJourney #GymMotivation #AthleteLife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DQAOJzHDL8q-2.mp4
"When becoming a parent shifts everything you thought you knew about purpose and meaning, @chriswillx sits down with Jimmy Carr to explore how kids rewire your entire worldview. The unexpected truths about parenthood's transformation.

#JimmyCarr #ChrisWilliamson #Parenthood #Parenting #MeaningfulLife #LifeLessons #ParentingJourney #ModernWisdom #Podcast #DeepConversations #LifeAdvice #ParentingTruths",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DQeH9S4jgxk-1.mp4
"When Bugzy Malone breaks down how to win by being irreplaceable instead of just being the best, you listen. The game changes when you realize nobody can compete with your authenticity. 

Via @chriswillx

#BugzyMalone #Authenticity #SelfMastery #LifeLessons #Mindset #PersonalDevelopment #SelfImprovement #Motivation #Success #WisdomWednesday #RealTalk #BeYourself #OriginalityWins #UnorthodoxStrategy #4K",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DQmRlVSjswc-2.mp4
"The price tag on American life keeps climbing, but who's really pulling the strings behind those numbers? @chriswillx sits down with Bernie Sanders to unpack the truth about government power and the cost of living crisis hitting everyday Americans.

#BernieSanders #USPolitics #CostOfLiving #PoliticalDiscussion #GovernmentTransparency #AmericanEconomy #PoliticalPodcast #EconomicJustice #WhoRunsAmerica #PoliticsExplained",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DQj11M6Drnz-1.mp4
"The uncomfortable truth about Britain's immigration crisis isn't what most people think, according to Konstantin Kisin's analysis shared by @chriswillx. He breaks down the complex forces driving the nation's transformation and questions whether the immigration debate will shift from political strategy to moral imperative. Kisin's perspective challenges conventional narratives about what's really happening behind the scenes.

#KonstantinKisin #Immigration #BritishPolitics #UKPolitics #Politics #PoliticalDebate #Immigration #Society #Culture #Podcast #PodcastClips #ChrisWilliamson",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DQovoXjDme6-1.mp4
"The difference between showing up and showing out—@chriswillx sits down with WHOOP founder Will Ahmed to break down what elite performance actually requires

#performance #athlete #athletes #fitness #whoop #sports #motivation #training #mindset #success #winning #excellence #podcast #podcastclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DRpYLiGDuXd-1.mp4
"Chris Williamson (@chriswillx) breaks down why most people never escape the procrastination cycle. If you're ready to shift from stuck to unstoppable, drop ""Beat"" below for a free guide on building laser focus and real momentum. Just make sure you're following so the DM comes through - and don't forget to check your Request folder.

#TheFearlessMotivation #inspirational #inspiration #mindset #motivation #motivational #inspire #selfimprovement #positivity #selfrespect",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DRp5jBMDOlj-2.mp4
"America's food system mystery: why is eating clean such an uphill battle? @chriswillx spent 6 intense days in London noticing the stark differences in food accessibility across the pond.

#health #wellness #nutrition #foodquality #americanfood #healthyfood #cleaneating #foodindustry #diet #healthylifestyle #fitness #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DRFGuL6jnVN-1.mp4
"The street-smart philosophy that challenges conventional wisdom about finding balance. Bugzy Malone breaks down why the traditional approach might be keeping you stuck, in this thought-provoking exchange with @chriswillx

#BugzyMalone #ChrisWilliamson #ModernWisdom #LifeBalance #StreetPhilosophy #UnorthodoxThinking #SuccessMindset #RealTalk #SelfImprovement #Motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DRN5ebNjwBO-1.mp4
"The cycle of delay ends when action becomes non-negotiable. @chriswillx breaks down why waiting for the ""perfect moment"" keeps you trapped in the same patterns. Drop ""Beat"" below for a free guide on building unwavering focus and momentum that actually sticks. Follow first so the DM reaches you - and don't forget to check your Request folder.

#TheFearlessMotivation #inspirational #inspiration #mindset #motivation #motivational #inspire #selfimprovement #positivity #selfrespect",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DRp5jBMDOlj-1.mp4
"The marriage question that challenges everything modern culture tells you about happiness.

@chriswillx breaks down why the feminist narrative around partnership might be completely backwards – and what actually leads to fulfillment.

Stop believing the lies. Start understanding what truly matters.

#ChrisWilliamson #ModernWisdom #RelationshipAdvice #DatingAdvice #Masculinity #SelfImprovement #Marriage #Happiness #RedPill #MentalHealth #SelfDevelopment #PersonalGrowth #LifeAdvice #Podcast #Motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\chriswillx\DRZ6d7MDhjR-1.mp4
"@codiesanchez breaks down the psychology behind why wealthy people make decisions at lightning speed while others hesitate. The pattern? Fast decisions, more zeros. Slow decisions, struggling to grow. It's not about being reckless—it's about training yourself to assess, commit, and move. Hesitation is expensive.

#businessmindset #wealthmindset #entrepreneurship #decisionmaking #moneymindset #businesstips #millionairemindset #successmindset #entrepreneurlife #businessgrowth #wealthbuilding",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DN8K7UZEUq2-1.mp4
"@codiesanchez breaks down the shocking truth behind Starbucks' $40 billion CEO mistake. The hiring lesson? 17 months was all it took to prove they got it spectacularly wrong.

#ceomindset #businessstrategy #leadershiplessons #entrepreneurship #businessgrowth #corporatestrategy #hiringmistakes #executiveleadership #businessinsights",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DOqn98cjTbY-2.mp4
"The grind nobody sees? That's exactly where champions are made. @codiesanchez breaks down why there's no substitute for the unglamorous work that happens when no one's watching. Success isn't about viral moments—it's about the daily discipline that builds empires from the ground up. Who in your circle is living this truth right now? Give them their flowers below. 👇

#success #entrepreneurship #businessmindset #hardwork #grinding #entrepreneur #businessowner #hustle #motivation #mindset #workethic #grind #smallbusiness #businesstips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DO3zTwAFHfe-2.mp4
"@codiesanchez breaks down the real money-maker at car dealerships (hint: it's not the cars). Episode 4 of her ""Economics Of"" Series reveals why these businesses are secretly finance operations in disguise. Drop OWN IT below for your weekend event invite—3 days left to claim your spot.

#BusinessStrategy #Economics #Entrepreneurship #Finance #CarDealership #BusinessEducation #WealthBuilding #PassiveIncome #SmallBusiness #BusinessOwner",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DOoZ65PiSVC-1.mp4
"The boring business revolution has a leader, and her name is @codiesanchez.

She runs Contrarian Thinking—an investment and advisory firm proving that laundromats, car washes, gyms, manufacturing shops, and landscaping companies are where real wealth is built. No hype. No cash burns. Just businesses that actually make money.

Here's the stat that matters: 79% of all U.S. millionaires built their wealth this way.

Her firm has trained over 9,000 operators, investors, and dealmakers who are now outperforming major private equity shops. The secret? Buying unsexy, profitable businesses and scaling them into cash-flowing empires.

She's opening up her once-a-year virtual intensive where she'll reveal:
🔑 Her proprietary deal-finding system
🔑 The exact playbook for buying small businesses today
🔑 Her step-by-step roadmap to cash-flow through acquisitions

Comment ""OWN IT"" for access. Learn the Contrarian way to buy, build, and scale.

#BusinessAcquisition #SmallBusiness #Entrepreneurship #WealthBuilding #BusinessOwner #PassiveIncome #FinancialFreedom #BusinessStrategy #Investing #CashFlow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DN_JWcBCcrn-2.mp4
"The people around you either fuel your obsession with growth or drain it. @codiesanchez breaks down why your inner circle determines your ceiling. Who in your life is pushing you to level up? Drop their name below 👇

#entrepreneur #businessmindset #success #motivation #growthmindset #businessowner #entrepreneurship #mindset #successmindset #millionairemindset #entrepreneurlife #businesstips #motivationmonday #hustlehard #businessgrowth #personaldevelopment #selfimprovement #goalsetting #ambition #winningmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DP9EwEhlNc2-1.mp4
"The real test of a relationship? What you say when they can't hear you. @codiesanchez reminds us that integrity in love means keeping the same energy behind closed doors as you do face-to-face.

#relationships #relationshipadvice #marriage #love #partnership #respect #integrity #datingadvice #healthyrelationships #relationshiptips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DPtqSIBlL-u-1.mp4
"Looking at @codiesanchez's track record, one thing becomes crystal clear: your current situation is just a chapter, not the whole story.

Debt? She's been there. Lost millions? Check. Divorce, company exits that didn't go her way, failed ventures? All part of the journey. Now she's built tens of millions back, remarried and thriving, with debt only on the assets that serve her.

Codie Sanchez runs Contrarian Thinking — an investment and advisory firm teaching a different path to wealth. Forget the flashy startups. She's talking laundromats, car washes, gyms, manufacturing shops, landscaping companies. The businesses everyone overlooks but that actually print money.

Over 9,000 operators, investors, and dealmakers have learned her system. These students are now outperforming seasoned private equity firms.

She's opening up her once-a-year virtual intensive covering:
🔑 Her proprietary deal-finding search methods
🔑 The exact playbook for acquiring small businesses
🔑 Step-by-step roadmap to cash-flow through acquisitions

Drop ""OWN IT"" below to secure your spot and learn the Contrarian approach to buying, building, and scaling real businesses.

#BusinessAcquisition #Entrepreneurship #SmallBusiness #ContrairianThinking #BuyingBusinesses #WealthBuilding #BusinessOwner",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DN-utmricIi-2.mp4
"Most people are unknowingly feeding 40 cents of every dollar they spend straight into the pockets of venture-backed giants. @codiesanchez isn't about that life.

She's Codie Sanchez, founder of Contrarian Thinking—an investment and advisory firm proving that the real money isn't in Silicon Valley unicorns, it's in the businesses everyone else ignores.

Laundromats. Car washes. Gyms. Manufacturing shops. Landscaping companies. The unsexy businesses that actually make money instead of burning through it.

Her firm has trained over 9,000 operators, investors, and dealmakers in the art of acquiring boring, profitable businesses. Her students are now outperforming traditional private equity shops.

She's opening up her once-a-year virtual intensive where she breaks down:
🔑 Her proprietary deal-finding system
🔑 The exact playbook for buying small businesses
🔑 Her step-by-step acquisition roadmap for building real cash flow

Comment ""DEALS"" to secure your spot and learn the Contrarian approach to buying, building, and scaling companies.

#BusinessAcquisition #Entrepreneurship #SmallBusiness #Contrarian #WealthBuilding #PrivateEquity #BusinessStrategy #Investing #CashFlow #DealMaking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DOMDEvFCbSS-2.mp4
"What keeps successful people up at night? The answer isn't what you'd expect.

@codiesanchez sits down to uncover the hidden cost of achievement that nobody talks about—and why the world's advice might be leading you in the wrong direction.

Comment MSOWS to save your spot and join Arthur Brooks at the event.

#success #entrepreneur #business #motivation #entrepreneurship #businessowner #smallbusiness #marketing #mindset #leadership",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DQMmEFRkQXe-2.mp4
"@codiesanchez just dropped the perfect excuse for your next gym session 💪

Turns out there's an actual psychological term for working out your feelings: somatic regulation. It's when you use physical movement to process emotions. So next time someone asks why you're hitting the gym again, hit them with ""just doing some somatic regulation"" and watch their confused face 😂

#gym #gymmotivation #mentalhealthmatters #workoutmotivation #fitnessmotivation #psychology #selfcare #mentalhealth #fitnesstips #gymlife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DQ7Ou8WgQjs-2.mp4
"@codiesanchez dropped a mindset shift that changes everything: your ideas deserve the same protection as your equity. She's showing why the size of your circle doesn't matter—it's the quality of people in it. There's a massive difference between someone who's watching your back and someone who's just watching you move. If you're serious about building, this is your reminder to audit your inner circle and protect your energy like the asset it is.

#entrepreneur #businessmindset #entrepreneurship #mindset #businesstips #entrepreneurlife #success #wealth #businessowner #smallbusiness #motivation #hustlehard #businessgrowth #millionairemindset #successmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DQheyH5j901-1.mp4
"Most people think willpower is about strength, but @codiesanchez breaks down why being busy actually destroys your ability to make good decisions. The more decisions you make throughout the day, the worse your willpower gets—it's science, not weakness. That's why successful people automate everything they can and protect their decision-making energy like it's gold.

#willpower #productivity #decisionfatigue #success #entrepreneurmindset #businesstips #mindsetshift #codiesanchez #personalgrowth #selfimprovement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DQXTjqBEovv-1.mp4
"The third obstacle hits different – that's when most people quit. But the real ones? They've got someone in their corner demanding more.

@codiesanchez breaking down what separates those who make it from those who don't 💯

Drop BORING below and she'll send you 130+ unsexy businesses worth your investment money right now.

#businessowner #entrepreneur #investing #wealthbuilding #businessmindset #investingtips #entrepreneurmindset #smallbusiness #makemoney #financialfreedom #businessgrowth #mindsetmatters #successmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DQCyJF5CYrk-1.mp4
"@codiesanchez shares a powerful reflection on isolation and focus. When critics mock and odds stack against you, she sees it differently—the universe confirming you're measuring what matters. Trading comfort for financial freedom isn't easy, but that resistance? It's just proof you're on the right path. The real question: do you want it bad enough to push through? Drop your guesses on the poem and author below 👇

#entrepreneur #businessowner #smallbusiness #entrepreneurship #motivation #success #mindset #businessmindset #wealth #financialfreedom #millionairemindset #businessgrowth #hustle #ambition #entrepreneurlife #businesstips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DQPBrhPlFY1-2.mp4
"The ultimate power move? Walking away whenever you want. That's the flex money should actually buy you—not another luxury purchase. @codiesanchez breaks down why investing in your freedom beats collecting things every single time. Want more unfiltered business truth? Drop BIG DEAL in the comments for the podcast link.

#entrepreneurship #financialfreedom #businessmindset #wealthbuilding #entrepreneurmindset #businesstips #moneymanagement #financialindependence #businessowner #entrepreneur #wealth #freedom #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DRcQYRHjuC2-2.mp4
"@codiesanchez breaks down why the wealthiest woman in America got there by mastering something completely ordinary—a product sitting in your house right now.

The takeaway? Unglamorous industries print money while everyone chases the next shiny thing.

#boringbusinesses #wealthbuilding #businessstrategy #entrepreneurmindset #makemoney #businessowner #smallbusiness #sidehustle #businesstips #millionairemindset #passiveincome #financialfreedom #entrepreneur",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DRSnmU8khFR-2.mp4
"The people around you either fuel your ambition or drain it—there's no middle ground. @codiesanchez breaks down why successful people protect their circle fiercely: builders celebrate builders, while those who've never created anything will project their limitations onto your dreams. You can transform yourself completely, but trying to change others is a losing battle.

#entrepreneurmindset #businessowner #smallbusinessowner #entrepreneur #mindsetmatters #successmindset #businesstips #motivation #growthmindset #entrepreneurlife #businessgrowth #millionairemindset #wealthbuilding #businessmotivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DQZTszqlG3a-1.mp4
"The difference between someone who reads about business and someone who builds one? They've survived the boss from hell and the team that made them want to quit. @codiesanchez reminds us that those brutal work experiences aren't setbacks—they're training grounds. Every terrible manager, every dysfunctional team, every moment you wanted to walk out? That's what builds the resilience you'll need when real money is on the line. The grit you're earning today becomes the advantage you'll have tomorrow.

#business #entrepreneur #entrepreneurship #smallbusiness #businessowner #entrepreneurmindset #success #mindset #motivation #businesstips #womeninbusiness #hustleculture #workethic #businessgrowth #leadership",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\codiesanchez\DRAHHD_FI04-1.mp4
"The collagen dosage debate finally gets clarity from @dave.asprey—turns out, most people aren't taking nearly enough to see real results 💊

#collagen #biohacking #antiaging #supplements #wellness #healthtips #longevity #biohacker #skinhealth #healthyliving",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DO1mfVjEW4O-2.mp4
"Dave Asprey (@dave.asprey) sat down with Dr. Phil and dropped some serious wisdom about meditation practices that actually work. The biohacking pioneer breaks down why traditional approaches miss the mark and what high-performers do differently. This conversation challenges everything you thought you knew about mental training.

#drphil #podcast #daveasprey #heavilymeditated #biohacking #meditation #mentalhealth #selfimprovement #mindset #wellness #performance #podcasting",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DOfxA-hkfM_-1.mp4
"Dave Asprey reveals his top pick for the cleanest carb source that delivers maximum benefits with minimal toxins. 👆🏼

Mochi stands out as @dave.asprey's go-to starch for sustained energy without the downsides. Here's what makes it different.

#cleaneating #carbs #mochi #biohacking #healthycarbs #cleanccarbs #nutrition #energyboost #healthyfood #wellness #guthealth #antiinflammatory #foodscience #OptimalHealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DOzB4NiD_0j-1.mp4
"The dairy industry won't tell you this: humans are the only species drinking milk from other animals, and our bodies aren't built for it. @dave.asprey breaks down why most dairy (except grass-fed butter) didn't make the cut for the Bulletproof Diet – the proteins are actually major inflammation and allergen triggers in Western eating patterns. Sometimes evolution gives us the answers we've been ignoring.

#bulletproofdiet #dairyfree #antiinflammatory #gutHealth #foodallergies #functionalnutrition #biohacking #grassfedbutter #healthylifestyle #nutritionscience #inflammationfree #daveasprey",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DOQ7HflEVuS-2.mp4
"The real secrets to making it past 100? @dave.asprey breaks down exactly what matters most when it comes to extreme longevity. 💯

Drop a number (1, 2, or 3) for the one you're already doing!

#daveasprey #biohacking #biohacker #healthydiet #wellness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DP4bXqYkZwO-1.mp4
"The invisible forces attacking your body 24/7 have finally met their match. @dave.asprey reveals how @quantumupgrade.io delivers instant system recharges through natural quantum energy—accessible from literally anywhere on the planet. His listeners score 15 Days FREE to test this revolutionary service. Claim yours at quantumupgrade.io/DAVE.

#Sponsored #QuantumUpgrade #DaveAsprey #biohacking #biohacker #biohacked #energy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DPASwnpERRf-2.mp4
"Coffee lovers, listen up! 🎉 @dave.asprey is celebrating International Coffee Day with an epic giveaway that'll fuel your mornings for an entire month. The prize? Mold-free coffee from @dangercoffeeofficial that'll change your caffeine game ☕️

Here's how to enter: Drop your daily coffee cup count in the comments, tag your most caffeinated friend, and share this post!

#InternationalCoffeeDay #CoffeeGiveaway #MoldFreeCoffee #CoffeeLover #CaffeineAddict #CoffeeTime #GiveawayAlert #HealthyCoffee #CoffeeChallenge #WinCoffee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DPSh65CEcgw-1.mp4
"A CDC whistleblower's confession that changes everything about vaccine safety data. Dr. William Thompson came forward claiming he and four colleagues were directed by their supervisor Frank DiStefano to literally destroy evidence from an internal MMR vaccine study—one showing Black boys vaccinated on schedule had 260% higher autism diagnosis rates compared to those who delayed. The study was then published with that critical finding erased. @dave.asprey breaks down why this matters and why institutional deception at health agencies needs to end now.

What's your take on this? 👇🏼

(via IG/maha_pac)

#publichealth #transparency #CDC #vaccines #MMRvaccine #parentalrights #informedconsent #healthfreedom #vaccinesafety #whistleblower #autism #blackhealth #healthequity #medicaltransparency #bigpharma #childrenshealth #healthcarereform #parentingchoices",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DOWQHr9kXXu-2.mp4
"The science behind facial paralysis injections might surprise you. @dave.asprey breaks down how the neurotoxin doesn't just stay put—it migrates to surrounding areas and research suggests it could be rewiring your emotional responses. When you stop your face from moving, you're actually disrupting the feedback loop between your physical expressions and mental state. Worth knowing what you're really signing up for. Drop a 👇 if this changed your perspective.

#BotoxTruth #BiohackingBeauty #LongevityFirst #CellularHealth #AntiAgingReality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DQ2uYMMkp6M-1.mp4
"The human body isn't just flesh and bone—it's programmable. @dave.asprey breaks down his ""Meat Operating System"" concept with Dr. Matt Cook, explaining how we can upgrade our biology like software through strategic inputs. From AI-powered diagnostics to nature-based protocols that actually move the needle beyond symptom management, this conversation maps out where healthcare is headed. Health enthusiasts, practitioners, and innovators need to hear this. Catch the full discussion or meet them live at the Business of Biohacking conference in Austin, TX | October 20-23, 2025 | businessofbiohacking.com

#biohacking #healthoptimization #longevity #functionalhealth #regenerativemedicine #wellness #healthtech #biotechnology #antiaging #humanperformance #healthcare #austintexas #biohackingconference",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DPwmUKwibr_-2.mp4
"Joint pain doesn't have to be your new normal. @dave.asprey breaks down the clinical data behind a supplement that's actually delivering measurable results.

Cartigenix HP by @calroyhealthsciences isn't just another joint supplement making empty promises. Real participants in three human trials experienced 67% average pain reduction, walked 50% farther, and showed improved cartilage biomarkers – all tracked over 90 days*†.

Whether it's your knees, hips, or shoulders holding you back, there's science-backed relief available. Every Calroy product comes with a 45-day money back guarantee, so there's zero risk in trying.

Grab your discount at calroy.com/dave

†As shown in two placebo-controlled, randomized, controlled human research studies (Vaidya 2025; Desai 2024). A prospective study (n=1,236) similarly demonstrated significant improvements in pain scores, along with quality of life measures (Desai 2022).

#jointpain #jointpainrelief #kneepain #hippain #shoulderpain #jointhealth #supplements #healthoptimization #biohacking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DPRz2yYEQXk-2.mp4
"Dave Asprey (@dave.asprey) just revealed what billion-dollar wellness companies don't want you to know: your nervous system controls aging faster than any pill ever could 🧠⚡

The biohacking pioneer breaks down why shifting your internal state matters more than your supplement stack when it comes to longevity.

#antiaging #biohacking #longevity #nervousystem #wellness #healthspan #biohacker #aging #mindset #daveasprey #optimization #longevitytips #healthoptimization #wellnessjourney",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DQopfwSAAtz-1.mp4
"The secret to faster recovery and better sleep might be sitting in @dave.asprey's closet right now. He swears by the @boncharge_ Infrared Sauna Blanket for a reason—it delivers full-body benefits without the hassle of traditional saunas. Ready in just 5 minutes, portable enough to travel with, and easy to maintain, it's the ultimate shortcut to feeling recharged. Grab yours at boncharge.com with code DAVE for 15% off.

#InfraredSauna #BiohackingGear #MuscleRecovery #BonCharge #LongevityTools",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DQrd213ER2f-2.mp4
"From battle to freedom—@dave.asprey shares a powerful moment that captures his philosophy on life and respect. The struggle was real, but so was the release.

Teaching children to value every creature, no matter how small, plants seeds of consciousness that extend far beyond insects. It's about recognizing the sacred in all forms—even the animals that become our sustenance.

True honor lives in the details: how we treat them, the quality of their existence, and the appreciation we carry when they fuel our bodies. This is what intentional living actually means.

When everyone's obsessed with accumulation, genuine thankfulness becomes revolutionary.

#GratitudeInAction #RespectAllLife #ThankfulLiving #KindnessMatters #BiohackingHumanity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DQjoB0tkUd8-1.mp4
"The difference between guessing and knowing could add decades to your life. @dave.asprey built Inside Track for people tired of wellness trends that lead nowhere—this is where cutting-edge longevity science meets practical application. Real data on performance optimization, nutrition strategies, and recovery protocols that actually work. No fluff, no recycled advice, just the tools high performers use to take control of their biology. New subscribers get instant access to the Beginner's Guide to Biohacking. Head to daveasprey.com or hit the link in bio to join Inside Track.

#biohacking #biohackinginformation #biohacker #Longevity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DQbvW7nCdZl-2.mp4
"When @dave.asprey talks about digestive enzymes, people listen. His go-to? MassZymes—packed with 18 different enzymes designed to tackle proteins, fats, and carbs so nothing goes to waste. The result: food actually converts to usable energy instead of sitting like a brick in your system. He takes them with meals for optimal digestion, or solo between eating windows to support recovery. Grab yours at bioptimizers.com/dave with code DAVE15 for a discount.

#digestion #digestiveenzymes #guthealth #bioptimizers #enzymes #healthylifestyle #wellness #nutrition #supplements #energyboost #recovery #fitness #healthtips #naturalsupplements #gutbrain",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DRevf45EY4k-1.mp4
"The holiday drinking trap isn't about willpower—it's about what's happening inside your cells. @dave.asprey breaks down why that festive drink comes with a hidden price tag: compromised mitochondria, spiked stress hormones, and a next-day system struggling under toxic load and inflammation. Instead of the usual cycle of temporary buzz followed by energy drain and poor sleep, he points to Trukava as the smarter swap—delivering calm and mental lift while keeping your biology functioning at full capacity. Real presence at holiday gatherings doesn't require sacrificing how you'll feel the next morning.

#biohacking #alcoholfree #holidayhealth #kava #trukava",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DRj_-m9ASPC-2.mp4
"The moment he recognizes a pattern is the moment everything shifts. @dave.asprey explains how becoming conscious of automatic reactions transforms mental health from the inside out. It's not theory—it's daily practice. Spotting the thought before it spirals. Recognizing the trigger before the reaction. Choosing differently because awareness creates space between stimulus and response. His book Heavily Meditated breaks down how to build this skill without the mystical fluff—just practical steps anyone can use.

#MentalHealthAwareness #MindfulnessMatters #SelfAwareness #MentalWellness #ConsciousLiving",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DRXIBF9kdSd-1.mp4
"The reason belly fat won't budge has nothing to do with your workout routine, according to @dave.asprey.

He explains that testosterone and thyroid function are the actual drivers behind how your body processes fuel and stores fat. When these hormone systems decline, your metabolism shifts into conservation mode—holding onto belly fat as a protective mechanism rather than burning it off.

Optimizing testosterone helps maintain lean tissue, stable glucose levels, and cognitive sharpness. A functioning thyroid ensures your cells use energy efficiently instead of stockpiling it. When both operate in sync, your body finally gets the signal to release stubborn fat.

Hormones run the show. Fix the signals, and the physical changes catch up.

Tag someone who's been fighting this battle without knowing the real cause.

#bellyfat #hormonehealth #testosterone #thyroidhealth #biohacking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\dave.asprey\DRvaEzjkdqi-2.mp4
"When couples shift from ""mine"" to ""ours,"" everything changes. @daveramsey breaks down why true partnership in marriage means viewing income as shared, not separate—regardless of who earns what. This mindset shift creates unity, forces communication, and turns financial goals into joint victories. Because real love isn't keeping score at 50/50—it's both partners going all in at 100/100.

#Marriage #MoneyTips #FinancialFreedom #RelationshipGoals #DebtFree #MoneyAndMarriage #FinancialPeace #CoupleGoals #MarriageTips #DaveRamsey",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DJMb-l2K8hq-2.mp4
"Tom and his wife carried a staggering $1 million debt load when they called into @daveramsey's show looking for answers.

#DebtFreeJourney #FinancialFreedom #DaveRamsey #DebtFreeScream #MoneyTok #PersonalFinance #DebtPayoff #FinanceTok #MillionDollarDebt",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DKmi7rkSdT8-1.mp4
"A $1.3M net worth, zero debt, and 40-year-old Jim is second-guessing himself over his trusty 25-year-old truck. @daveramsey had to set him straight on what actually matters when it comes to dating and building wealth.

#DaveRamsey #MoneyTok #FinancialFreedom #DebtFree #MillionaireMindset #WealthBuilding #FinanceTips #MoneyAdvice #NetWorth #DebtFreeJourney #FinancialIndependence #SmartMoney",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DJjrI0zOJzb-2.mp4
"There's a direct correlation between wealth building and caring less about others' opinions, according to @daveramsey. The distinction is clear: those struggling financially often project their insecurities through unsolicited advice, worried others might surpass them. Meanwhile, people who've built substantial wealth—that $1–10 million net worth range—got there precisely because they stopped performing for an audience. They made financial decisions based on their own goals, not external validation. The result? A completely transformed approach to spending and lifestyle choices that serves their family's actual needs instead of impressing strangers.

#money #finance #wealth #financialfreedom #investing #personalfinance #moneytips #financialindependence #millionaire #wealthbuilding #moneymindset #financialliteracy #debtfree #investing101 #moneymoves",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DJzFC91NcP2-1.mp4
"The real test isn't understanding the plan—it's sticking to it when no one's watching. @daveramsey breaks down why living below your means isn't just about cutting expenses; it's about refusing to go back to old habits. The choice to sacrifice now instead of filing for bankruptcy later comes down to one decision: are you actually going to follow through? Because knowing what to do and doing it are completely different battles. Drawing that line in the sand means your money finally starts working for you instead of controlling every move you make.

#DaveRamsey #DebtFreeCommunity #FinancialFreedom #BudgetingTips #MoneyMindset #DebtFreeJourney #PersonalFinance #FinancialPeace #MoneyGoals #WealthBuilding",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DK4ly75pMeQ-1.mp4
"Every vacation has a return date, but credit card debt doesn't. @daveramsey breaks down why the smartest travelers save first and spend later. Planning ahead means your only souvenir is relaxation—not monthly payments and interest charges haunting your bank account. The memories stay golden when they're fully paid for before you even pack your bags.

#DebtFree #VacationMode #BudgetingTips #FinancialFreedom #SaveMoney #DebtFreeJourney #PersonalFinance #MoneyTips #FinancialPeace #SmartMoney",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DLpkHkpiENT-1.mp4
"Money fights or money peace? @daveramsey says the choice starts with one decision: combining finances. When couples ditch the ""yours and mine"" mentality and go all-in together, they're not just managing accounts—they're building unshakeable trust and creating a shared vision for their future. Because real partnership means both people giving everything, not splitting it down the middle. Marriage isn't 50/50. It's 100/100.

#Marriage #RelationshipGoals #MoneyTips #FinancialFreedom #MarriageAdvice #Teamwork #CoupleGoals #HealthyRelationships #MoneyAndMarriage #RelationshipAdvice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DL5irVKN42V-2.mp4
"The out-of-state college trap is financially devastating, and @daveramsey isn't sugarcoating it. Parents who truly care about their teenagers' futures will guide them toward debt-free education options close to home. The reality? Student loans destroy lives, but they're exponentially worse when kids pay quadruple the cost just to cross state lines for a school they can't afford. Choosing an out-of-state university without the cash to back it up isn't just a mistake—it's financial self-destruction. Smart families pick affordable paths over prestigious zip codes.

#studentloans #college #collegedebt #debtfree #money #personalfinance #financialfreedom #daveramsey",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DLVUuW9Kse--2.mp4
"The real wealth killer? Handing your paycheck over to banks and lenders before you even see it. @daveramsey breaks down why most people stay stuck in the paycheck-to-paycheck trap—it's not about how much you earn, it's about who controls your money. Every debt payment is cash flowing OUT instead of building YOUR future. His solution is straightforward: zero-based budgeting, debt snowball method, and ditching the financing habit. When you redirect that money toward investing instead of interest payments, everything changes. Take back control of your income and watch your wealth actually grow.

#DaveRamsey #DebtFree #DebtSnowball #BudgetingTips #FinancialFreedom #WealthBuilding #MoneyTips #PersonalFinance #FinancialPeace #DebtFreeJourney #ZeroBasedBudget #PaycheckToPaycheck #MoneyManagement #FinancialAdvice #BuildWealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DMsl6TzKGli-1.mp4
"Financial wisdom that never gets old: don't invest in what you don't understand. @daveramsey breaks down why clarity beats FOMO every single time when it comes to your hard-earned money.

#Money #Investing #PersonalFinance #FinancialFreedom #MoneyTips #WealthBuilding #SmartMoney #FinancialAdvice #InvestingTips #MoneyMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DOQ72c8CTyS-2.mp4
"The wisdom @maxlucado shared with Dave Ramsey hits different: some thoughts don't deserve space in your head. When you kick out the lies and fill your mind with truth instead, transformation is inevitable.

#MentalHealth #Mindset #Truth #WisdomWednesday #PersonalGrowth #SelfDevelopment #MindsetShift #DaveRamsey #MaxLucado #PositiveThinking #MentalWellness #LifeAdvice #Wisdom #MindsetMatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DNYSIHJOFev-2.mp4
"The Bible says a good man leaves an inheritance to his children's children (Proverbs 13:22), but @daveramsey wants parents to understand something crucial: wealth doesn't corrupt character—it reveals it. Whether money brings out someone's best or worst qualities depends entirely on who they already are. Parents have zero obligation to leave anything behind, but they shouldn't avoid it out of fear either. The real work isn't protecting kids from inheritance—it's raising adults with the morals and wisdom to handle it. Do that job right, and passing down wealth becomes the blessing it was meant to be, not fuel for poor choices.

#DaveRamsey #MoneyTips #Inheritance #FinancialFreedom #PersonalFinance #WealthBuilding #MoneyManagement #FinancialWisdom #Parenting #Legacy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DNIuuSqNmMB-2.mp4
"The difference between broke and building wealth? One simple habit that takes 20 minutes a month. According to @daveramsey, most people skip this step and spend their entire lives reacting to their bank account instead of controlling it. A budget isn't restrictive—it's actually what gives you permission to spend guilt-free because you've already decided where every dollar belongs. Stop letting your paycheck disappear into thin air. His free app EveryDollar (link in his bio) walks you through creating your first budget so you can finally take charge instead of playing catch-up.

#budget #budgeting #moneytips #daveramsey #everydollar #financialfreedom #debtfree #personalfinance #moneymindset #financialliteracy #smartmoney #moneymanagement #wealthbuilding",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DMvRa8_py4H-1.mp4
"Dave Ramsey's framework isn't complicated—7 Steps, straightforward execution. The challenge? It demands unwavering commitment. Most people know what to do; they just won't stay consistent long enough to see results. He emphasizes that crossing the finish line requires eliminating excuses and reversing the money dynamic so your finances serve you instead of controlling you. The methodology succeeds every time when people actually follow through without backtracking. @daveramsey

#BabySteps #DebtFreeJourney #FinancialFreedom #MoneyGoals #DebtFreeCommunity #FinancialPeace #BudgetingTips #DebtFree #PersonalFinance #FinancialPlanning",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DOLx2rNjuCD-2.mp4
"The real flex isn't counting down to Friday—it's building a Monday through Thursday you don't need to escape from. @daveramsey reminds us that when you're obsessed with the weekend, your weekdays might be the problem. Design a life you actually enjoy living every single day.

#DaveRamsey #CareerAdvice #WorkLifeBalance #MondayMotivation #FinancialFreedom #PersonalGrowth #SuccessMindset #LifeAdvice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DQb2TfpkcdV-1.mp4
"The math on this one is absolutely insane – $1.8 million in the hole. @daveramsey breaks down exactly how deep this couple is buried and what it's going to take to dig out.

#debt #debtfree #money #finance #financialfreedom #personalfinance #budget #investing #wealth #financialliteracy #moneymanagement #daveramsey #debtfreejourney #financetips #moneytips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DQEqUQ-DYDr-2.mp4
"The farmer's paradox that @daveramsey highlights: You can till the soil, plant every seed perfectly, and put in endless hours—but without rain, there's nothing. According to him, faithful farmers understand this deeply. They show up and do the work, yet they know their effort alone doesn't guarantee the harvest. It's the ultimate lesson in humility and faith—working hard while recognizing who truly provides. 🌾

#Faith #HardWork #FarmersKnowBest #TrustGod #Humility #WorkAndPray #HarvestSeason #FaithAndWork #DaveRamsey #Wisdom #FaithJourney #ChristianLiving #GodsProvision",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DPg8OA3gvEY-2.mp4
".
.
.
When @daveramsey drops truth bombs, he doesn't mince words. Being vague with people? That's not compassion—it's cruelty disguised as politeness.

#DaveRamsey #MoneyTok #FinancialFreedom #DebtFreeJourney #Leadership #PersonalFinance #BabySteeps #FinanceTok #MoneyAdvice #Communication #Leadership101 #RealTalk #HardTruths",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DRw-LopgVTO-1.mp4
"The vacation hangover hits different when it's just memories and not credit card bills 💳✈️

@daveramsey breaks down why delayed gratification actually wins: that beach sunset feels even better when you're not mentally calculating interest rates. Planning ahead means the relaxation doesn't end the second you land back home. Debt-free travel isn't just smarter, it's actually MORE enjoyable because you're fully present instead of dreading what's waiting in your inbox.

Save first, travel later, stress never.

#DebtFree #DebtFreeTravel #BudgetTravel #PersonalFinance #MoneyTips #FinancialFreedom #SmartMoney #VacationMode #TravelSmart #DebtFreeCommunity #FinancialPeace #MoneyMindset #SaveMoney",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\daveramsey\DQCYtmuDULG-1.mp4
"When you push hard enough, even the strongest man alive feels the burn 💪 @drmikeclips breaks down what happened when elite training meets raw power in this unforgettable moment with @thorbjornsson. The full breakdown is live on the @rpstrength YouTube channel under ""Exercise Scientist Critiques Strongman THOR Bjornsson"" — and if you thought that was intense, the actual training session drops 9/1. Mark your calendars 📅

#strongman #thor #thorbjornsson #fitness #bodybuilding #gym #workout #training #exercisescience #strength #fitnessmotivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DN10YPdwtJQ-2.mp4
"When an exercise scientist gets the chance to train alongside a living legend 💪 @drmikeclips captures the moment Dr. Mike heads to Iceland to work with none other than @thorbjornsson himself. The full breakdown is waiting on the @rpstrength YouTube channel - search for ""Exercise Scientist Critiques Strongman THOR Bjornsson"" to see how world-class strength training really works 🇮🇸

Hit that follow button to catch more incredible athlete collaborations ⁠

#strongman #thor #thorbjornsson #exercisescience #strength #training #iceland #worldsstrongestman #fitness #athlete #rpstrength #drmike",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DNrSUCVXveJ-2.mp4
"Quality sleep trumps early wake-up times—the science is clear. @drmikeclips breaks down why prioritizing rest matters more than alarm clock gymnastics. ⏰💤

Want the HYPERTROPHY TRAINING eBook? Drop TRAIN1 below for FREE access to:

💯 Evidence-based volume calculations
💯 Complete training strategies 
💯 Dr. Mike's expert breakdown on maximizing gains

📹️ Full Video: Exercise Scientist Critiques @chrisheria on the @rpstrength YouTube!

#sleepscience #hypertrophy #trainingvolume #evidencebased #fitnesstips #musclegrowth #sciencebackedfitness #sleepmatters #workoutscience #gains #fitnesseducation #strengthtraining",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DN3IYLAXHVO-1.mp4
"The arms that need their own zip code have entered the chat. 💪 @thorbjornsson and @drmikeisraetel linked up at the LEGENDARY @thorspowergym for a session that'll make your screen crack from pure mass.

Full training breakdown courtesy of @drmikeclips – catch the complete video on the @rpstrength YouTube channel and prepare for involuntary bicep pump while watching. 🚀🔥

#biceps #armday #bodybuilding #gym #fitness #strengthtraining #hafthor #thorbjornsson #drmike #rpstrength #powergym #training #workout #muscle #gains",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DOMJyQHj2gY-2.mp4
"@drmikeclips weighs in on the 10-minute backwards walking protocol and wants to hear YOUR take. Are you brave enough to give this one a shot?

Full breakdown available on the @rpstrength YouTube channel
📹️ Exercise Scientist Critiques Knees Over Toes Guy

#backwardswalking #exercisescience #kneesovertoesrpstrength #fitnessreview #workoutanalysis #strengthtraining #exercisephysiology #trainingtips #fitnesstips #sciencebasedfitness #workoutroutine #fitnessexpert #exerciseanalysis #rpstrength",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DPAQjbrkR42-2.mp4
"The protein aisle doesn't have to be a battlefield of confusion anymore. @drmikeclips breaks down exactly what works, what's worth your money, and what's just fancy marketing. From understanding different protein sources to calculating your actual needs for muscle growth and recovery, this free resource cuts through the industry noise. Want the complete breakdown? Drop PROTEIN1 below and stop second-guessing every supplement decision 💪

#protein #proteinpowder #supplements #fitness #nutrition #muscle #musclegrowth #fitnesstips #gym #workout #healthylifestyle #fatloss #recovery #gains",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DPbTds0Ccpp-1.mp4
"Looking to dial in your training volume without the guesswork? @drmikeclips breaks down the exact calculations you need. This is the science-backed approach that cuts through all the noise and gets straight to what actually works for hypertrophy. Drop TRAIN1 in the comments and grab the FREE HYPERTROPHY TRAINING eBook sent directly to your DMs! 

#trainingvolume #hypertrophy #sciencebasedtraining #musclegrowth #fitnesstips #workoutscience #gainz #gymknowledge #evidencebased #fitnessadvice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DPL_WgEDpVl-1.mp4
"During his appearance on the Bryan Johnson Podcast, Dr. Mike Israetel weighs in on a fascinating question: if you could turn back the clock to 22, would you? @drmikclips breaks down this thought-provoking moment from an episode packed with insights on AI's role in fitness, the reality of steroids, and handling online critics. The conversation goes deep into what truly matters when it comes to longevity and peak performance.

#DrMikeIsraetel #BryanJohnson #FitnessScience #AIFitness #Longevity #BodyOptimization #FitnessPodcast #HealthSpan #AntiAging #SteroidTruth #FitnessAI #OptimalHealth #PodcastClips #FitnessDiscussion #OnlineFitness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DP48VkhDmb3-1.mp4
"Looking at @drmikeclips demonstrate exactly when to bail on a rep shows the discipline most people skip in their training. That eighth attempt? He stops mid-pull because form was about to break—this is the maturity that builds real strength. His approach to weighted pullups flips conventional thinking: body weight progression during bulks, strategic eccentric control for growth, and micro-loading that prioritizes back development over ego. The @versagripps keep his grip solid while his principles keep gains coming. Train with his methods through the @rpstrength RP Hypertrophy App.

#pullups #pullupsfordays #backworkout #backtraining #lats #latworkout #pullupworkout #weightedpullups #fitnesstips #trainingtips #workouttips #formcheck #properform #musclegrowth #hypertrophy #gymtips #bodybuilding #naturalbodybuilding #rpstrength #sciencebasedtraining",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DOQqeBgiCbs-2.mp4
"The secret to sustainable fat loss isn't complicated—@drmikeclips breaks down exactly what works and what doesn't. No gimmicks, just proven strategies that actually deliver lasting results.

Drop FATLOSS1 in the comments for the complete mini-guide sent directly to your DMs 📲

Inside: science-backed methods, practical tips to maximize progress, and how to avoid the mistakes that keep most people stuck. Everything needed to start seeing real change.

#fatloss #weightloss #fatlosstips #caloriedeficit #weightlosstips #losingweight #fatlossjourney #sustainablefatloss #evidencebased #sciencebacked #fitnesstips #nutrition #healthylifestyle #getlean #bodytransformation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DQ9aQ5nDJFA-1.mp4
"Locked up but not skipping leg day – @drmikeclips breaks down how inmates build serious muscle behind bars. Exercise science meets prison ingenuity in this eye-opening breakdown.

Full analysis drops on the @rpstrength YouTube channel.

#prisonworkout #legday #exercisescience #prisontraining #prisonworkouts #workoutscience #legworkout #fitnesseducation #trainingtips #workoutanalysis #strengthtraining #fitnessbreakdown",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DP_Zcpojc_v-1.mp4
"The science behind building mental and physical toughness might surprise you – @drmikeclips breaks down why pushing boundaries actually transforms your capacity to handle stress. His approach connects directly to how strength training rewires both body and mind.

Ready to transform your training with a proven system? Drop 'STRONG1' in the comments for instant access to the FREE Strength Training Made Simple guide that covers:

🎯 Precise set and rep schemes designed for maximum strength
💯 Muscle-building techniques backed by real results
📊 Customized protocols whether you're just starting or already advanced

Stop guessing and start growing. Comment 'STRONG1' now! 💪

#strengthtraining #buildmuscle #fitness #workout #gym #muscle #training #fitnesstips #gymmotivation #strengthandconditioning #fitnessmotivation #workoutmotivation #musclegrowth #trainingtips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DPQ7tFoD9Um-1.mp4
"Looking to unlock serious lat development? @drmikeclips breaks down the science behind what actually works for back growth in this exercise scientist's critique of Lee Priest's training methods.

Comment TRAIN1 below for a FREE Hypertrophy Training eBook sent straight to your DMs 💪

#fitness #gym #workout #bodybuilding #fitnessmotivation #gymmotivation #fitfam #training #muscle #fit #motivation #personaltrainer #fitnessmodel #health #instafit #gains #strong #fitnessaddict #gymlife #exercise #healthylifestyle #leepriest #lats #backworkout #backtraining",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DQNmHB1kYgA-2.mp4
Most lifters are leaving gains on the table with their hack squat setup—@drmikeclips breaks down the three critical adjustments that transform this movement from basic to brutal. Foot positioning isn't one-size-fits-all: find the sweet spot between maximum knee flexion and heel-driven power. The descent matters more than you think—actively drive knees forward and out while fighting the urge to speed through that bottom half where leverage wants to cheat you. Ready to level up your training? The @rpstrength RP Hypertrophy App has everything you need (link in his bio). #hacksquat #legday #hypertrophy #rpstrength #lifting #quads #bodybuilding #gymtips #fitnesstips #trainingtips,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DQPElMxAElC-2.mp4
"Want real results without the guesswork? @drmikeclips has the blueprint. Their FREE Strength Training Made Simple guide eliminates the confusion—showing you the precise sets, reps, and techniques that actually work for building lasting muscle and serious strength gains. No fluff, just proven methods tailored to your level. 💪

COMMENT 'STRONG1' to transform your training! 🚀

#StrengthTraining #MuscleBuilding #FitnessGuide #WorkoutTips #GymMotivation #BuildMuscle #StrengthGains #FitnessJourney #TrainingProgram #GymLife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DRHnuRpicAK-2.mp4
"The three substances sabotaging your rest more than you realize 😴

Dr. Mike breaks down how caffeine, alcohol, and marijuana mess with your sleep cycles in ways most people don't understand. Even when you think they're helping you wind down, they could be doing the opposite.

Worth the watch if you value your recovery 💤

Via @drmikeclips

#sleep #sleeptips #caffeine #alcohol #marijuana #sleepquality #health #wellness #healthtips #drmike #sleepscience #recovery #insomnia #sleepbetter #healthylifestyle",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DRGLopmkXPG-2.mp4
"Dr. Mike breaks down the incomplete protein debate and explains what you really need to focus on for muscle growth 💪 via @drmikeclips

#protein #incompleteprotein #completeprotein #proteinmyths #musclegrowth #muscleretention #fitnessfacts #nutritiontips #proteintips #bodybuilding #fittok #gymmotivation #fitnesstips #nutritioncoach #evidencebasedfitness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DRVsefPCBZE-1.mp4
"Dr. Mike breaks down the pendulum squat mechanics that most lifters completely miss, according to @drmikeclips. His approach? Drop your ego at the door—he's moving 220lbs with a 500lb high bar squat capability, proving that full range of motion beats heavy loads every time. The key adjustments: feet positioned lower on the platform than expected, controlled descent without the slow-mo theatrics, and stance width tailored to individual quad activation. That rounded lower back everyone's worried about? It's a positioning problem, not a depth problem. The bonus insight challenges conventional gym wisdom about knee lockout. Drop GAINS10 in the comments to access his training program ⬇️

#pendulumsquat #squattips #legday #quadworkout #gymtips #fitnesstips #trainingtips #resistancetraining #strengthtraining #hypertrophy #musclegrowth #legworkout #squatform",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DReypI6DCA9-1.mp4
"The equation is brutally simple according to @drmikclips: skip the sleep, skip the gains. Recovery happens in bed, not in the gym. Want stronger lifts and faster fat loss? The pillow is just as important as the plates.

#sleep #sleepbetter #muscle #musclegrowth #gains #fitness #fitnessmotivation #gym #gymmotivation #workout #workoutmotivation #bodybuilding #training #trainingmotivation #recovery #rest",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\drmikeclips\DRYLbuODUQe-1.mp4
"The people asking questions are gathering intelligence while everyone else is protecting their ego.

@edmylett breaks down why curiosity beats credentials every single time.

#edmylett #motivation #mindset #success #personaldevelopment #growthmindset #selfimprovement #inspiration #leadership #successmindset #motivationalquotes #wisdom #knowledge #learning",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\C22aXnbu3vs-1.mp4
"The hardest chains to break aren't external—they're the ones we forge in our own minds. @edmylett reminds us that discomfort isn't a warning sign to retreat, it's an invitation to evolve. Every bold decision carries weight, and that weight is what builds strength. Choose the path that scares you a little. That's exactly where transformation lives.

#EdMylett #Motivation #Mindset #PersonalGrowth #GrowthMindset #OvercomeFear #BreakFree #TakeRisks #SelfImprovement #SuccessMindset #Inspiration #DailyMotivation #MindsetMatters #FearlessLiving #PushYourLimits",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\C1w4-A9I0H5-2.mp4
"The real work begins after you say ""I do"" 💍

@edmylett reminds us that while weddings last a day, marriages require daily effort. Love and respect aren't automatic—they're choices you make every morning when you wake up next to your partner.

Are you putting in the work for the relationship that matters most?

May this couple live a long, healthy, and peaceful life together ❤️

Source: @ceciarmy

#marriage #relationships #love #respect #weddingday #marriagegoals #relationshipadvice #motivation #mindset #couplegoals #commitment #dailywork #weddinginspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\C2U8GVau3Ij-1.mp4
"Understanding trumps being right—that's the relationship wisdom @edmylett lives by. He points to 1 Corinthians 13:4-7 as the blueprint: ""Love is patient, love is kind. It does not envy, it does not boast, it is not proud. It does not dishonor others, it is not self-seeking, it is not easily angered, it keeps no record of wrongs. Love does not delight in evil but rejoices with the truth. It always protects, always trusts, always hopes, always perseveres."" When you prioritize love over ego in every disagreement, you stay young at heart. Tag someone who needs this reminder today. ❤️

#love #relationships #marriage #faith #scripture #corinthians #chooselove #relationshipgoals #couple #edmylett #mindset #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\C3dCXqkuYBE-2.mp4
"The moment that speaks louder than words 🤍

@edmylett captures the power of family connection in its purest form.

#family #motivation #inspiration #love #fatherhood #parenthood #fatherandson #familyfirst #blessed #grateful #parentingtips #lifecoach #mindset #motivationalquotes #inspirationalquotes #familytime #fathersontime #dadlife #familygoals #emotionalintelligence #wholesome",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\Ct4GVS6AKFO-1.mp4
"When Tony Robbins sits down with @edmylett for their fourth conversation, the insights get deeper, the strategies get bolder, and the blueprint for total life transformation becomes crystal clear.

This isn't your typical success talk – it's a full-scale immersion into how the ultra-wealthy think about money AND how high performers master every season of their lives.

From freedom funds to asymmetrical risk rewards, from Ray Dalio's investing fundamentals to private equity allocation strategies that actually work for everyday investors – Tony breaks down what the top 1% know that most people don't.

But here's what makes this episode different: it goes beyond the bank account. Tony and Ed dig into the mental, emotional, and physical alignment required to become the hero of your own story.

🚨 FREE seat waiting: Tony's Time to Rise Summit (January 25-27) – visit jointony100.com to claim yours and design your 2024 results plan in just 3 days.

The conversation covers defining life seasons, conquering modern selfishness, building diversified portfolios regardless of your starting point, and synchronizing mind-body-emotion-action for unstoppable momentum.

Link in bio to watch the full episode with @tonyrobbins now.

#TonyRobbins #EdMylett #LifeMastery #MoneyMastery #WealthBuilding #InvestingStrategies #PersonalDevelopment #FinancialFreedom #SuccessMindset #TimeToRiseSummit #RayDalio #PrivateEquity #AssetAllocation #Entrepreneurship #Philanthropy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\C2Kos8XOhmG-1.mp4
"The ""average tax"" might be costing you more than any deduction on your paycheck 💭

@edmyett breaks down why mediocrity drains your life in ways money can't measure. When you're just going through the motions, you're paying a price that affects how you show up everywhere—and how the world sees you.

His solution? Stop settling. Whether you're raising kids, building businesses, or mastering your craft, greatness requires focused thought, intensity, consistency, and a standard you refuse to compromise on.

Wrong environment? Wrong people? That's usually why the fire's gone. Find where your brilliance belongs and protect that standard like your life depends on it—because it does.

#Motivation #Mindset #PersonalDevelopment #SelfImprovement #Success #GrowthMindset #Inspiration #SuccessMindset #Greatness #LevelUp #Goals #MotivationalQuotes #LifeAdvice #Entrepreneur #PersonalGrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\C3QKZiwupui-1.mp4
"What if the path to inner peace has been hiding in plain sight all along? @edmylett sits down with GURUDEV SRI SRI RAVI SHANKAR—a humanitarian giant who's impacted 500 MILLION lives across 180 countries—to uncover the ancient wisdom we desperately need today.

This isn't your typical self-help conversation. Gurudev brings real-world experience from negotiating global peace conflicts and shares how simple practices like BREATHING and MEDITATION can radically shift your entire reality.

Inside this episode, they explore everything from releasing what no longer serves you to understanding DOUBT's true role in your life. Plus, you'll hear Gurudev's perspective on discovering hidden potential, finding CLARITY, embracing more JOY, and even the controversial topic of PSYCHEDELICS.

Whether you're drowning in stress or simply searching for deeper meaning, this conversation delivers the compass you need right now.

LINK IN BIO to watch/listen!

#EdMylett #SriSriRaviShankar #InnerPeace #Meditation #Spirituality #PersonalGrowth #Mindfulness #Peace #SelfImprovement #Podcast #Inspiration #Wisdom #Consciousness #MentalHealth #Wellness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CtJv6EQAUpw-2.mp4
"The ripple effect of personal transformation starts with a single choice, and @edmylett breaks down exactly why investing in yourself isn't selfish—it's strategic.

He challenges the idea that self-improvement is self-centered, flipping the script entirely: your growth directly determines how much you can give to others. When you stop evolving, you stop serving at your highest level.

The questions he poses cut deep: Is your mind renewing? Your spirit? And the big one—are you putting yourself first or dead last?

Most people sacrifice their own development thinking it makes them more generous, but it actually limits their capacity to make a real difference. Shedding old versions of yourself isn't optional if you want to create lasting impact.

The newest, most evolved version of you unlocks the ability to elevate everyone in your circle. That's not theory—that's how transformation works.

#personalgrowth #mindsetreset #selfimprovement #growthmindset #levelup #motivation #inspiration #mindsetshift #personaldevelopment #bettereveryday #growyourself #transformyourlife #evolveyourself",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\C4dTCqTOGgA-2.mp4
"The blueprint is simple, yet most people overlook it. @edmylett breaks down what separates those who win from those who wonder why they didn't: integrity in action, consistency in effort, and humanity in everything. No excuses, no shortcuts—just the fundamentals that actually matter.

#edmylett #motivation #mindset #success #personaldevelopment #growth #inspiration #entrepreneur #selfimprovement #goals #hustle #grind #successmindset #motivationalquotes #lifelessons #keepgoing",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\Cwfe_c8sswJ-2.mp4
"Your brain operates like a search engine—whatever question you type in, it'll find an answer for. @edmylett breaks down why the quality of your questions literally determines the quality of your life.

Most people trap themselves by asking ""What went wrong?"" and wonder why they stay stuck. The secret? Your thoughts are just questions and answers on repeat. Upgrade the questions, and you'll upgrade everything.

Instead of ""What went wrong?""—try ""What can I learn from this?""

That simple shift tells your brain to search for solutions instead of problems. Right questions = brain in overdrive mode. Wrong questions = dead-end results.

The transformation starts with better questions.

Tag someone who needs this perspective shift.

@garrain.jones

#mindset #personaldevelopment #selfimprovement #motivation #growthmindset #successmindset #mindsetmatters #personalgrowth #selfgrowth #motivationalquotes #successquotes #mindsetcoach #inspiration #lifecoach #positivevibes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CupSHxkAgYA-1.mp4
"Ed Mylett (@edmylett) breaks his 24 hours into three separate 6-hour mini days—giving himself 21 days every week instead of just 7.

His reasoning? In a world where AI and technology deliver instant results, operating on the old 24-hour framework puts you behind. Shorter, more urgent time blocks trigger your brain to generate higher energy, sharper focus, and faster problem-solving.

He still prioritizes exercise, prayer, family and rest—but operates with significantly more efficiency than most people ever will.

Want his full breakdown on maximizing your week?

Comment ""#OneMore"" below and he'll send you The Power of One More Day Guide showing exactly how he gets 21 days a week.

#OneMore #MaxOut #EdMylett #Productivity #TimeManagement #Success #Motivation #SelfImprovement #PersonalDevelopment #Mindset #ProductivityHacks #SuccessMindset #GoalSetting #HighPerformance #Efficiency",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CwknaTdM0ez-1.mp4
"High achievers are holding their own happiness hostage, and @edmylett is calling them out on it.

He breaks down why so many driven individuals operate under a dangerous myth: that being happy now will somehow dim their ambition. They're literally rationing joy like it's a limited resource, convinced that staying unhappy keeps them hungry.

But here's the framework that changes everything—""Blissful Dissatisfaction."" It's the ability to be genuinely happy in this moment while simultaneously being unsatisfied with where you are. These aren't opposing forces; they're meant to coexist.

The reality? Happiness is your default setting. You weren't born stressed and striving—you learned that. Which means you can unlearn it too.

Stop postponing joy until the next promotion, relationship, or milestone. You're worthy of happiness right now, and it won't cost you your edge.

Want the complete training on living in blissful dissatisfaction? Drop ""#happy"" below for free access.

#BlissfulDissatisfaction #HighAchiever #MindsetShift #PersonalGrowth #SelfDevelopment #SuccessMindset #HappinessIsAChoice #MaxOut #EdMylett #MotivationDaily #GrowthMindset #InnerPeace #AmbitionAndJoy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CuHi65Rg2Uq-2.mp4
"Magic happens when dads show up with pure love ✨

@edmyslettshares this powerful reminder that the greatest gift we can give is creating unforgettable moments for those who matter most. Real love is action, not just words.

Drop a tag for the dads who make life magical 👇

source: @dadsaysjokes

#DadLife #Fatherhood #ParentingWin #FamilyFirst #DadGoals #MotivationMonday #Inspiration #LoveInAction #QualityTime #ParentingTips #FamilyLove #DadMode",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CvkP92mAMag-1.mp4
"The ""Sampling Your Dreams"" strategy that @edmylett breaks down here flips the script on how most people chase their goals. Instead of waiting to feel worthy after achieving something, he teaches the power of touching your dreams first—visiting that house, test driving that car, walking through that business space—to eliminate imposter syndrome before success even arrives. Your brain needs to recognize the dream as familiar territory, not foreign ground. When you physically interact with what you're building toward, you're programming your mind to see it as inevitable rather than impossible.

#dreams #mindset #success #motivation #personaldevelopment #goalsetting #entrepreneur #growthmindset #believeinyourself #manifestation #successmindset #dreambig",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\Cxdh2N_uv7q-2.mp4
"The difference between self-acceptance and complacency? Growth doesn't require you to believe you're broken first. @edmylett breaks down why understanding your inherent worth is actually the foundation for real transformation—not the enemy of it. Your value isn't determined by how others show up for you, and their pain shouldn't write your story. You came into this world blessed and extraordinary. Period. Now go build from that truth. 💪

#SelfWorth #PersonalGrowth #MindsetShift #SelfDevelopment #Motivation #YouAreEnough #InnerStrength #GrowthMindset #SelfLove #Inspiration #MotivationalQuotes #BelieveInYourself #KnowYourWorth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\Cy59YMJu1jT-2.mp4
"Who you think you are becomes who you actually are—and @edmylett breaks down exactly how to use that power in his latest solo episode.

He's cutting straight to the core: your identity is the foundation controlling your finances, relationships, mental strength, and physical health. If any of those areas aren't where you want them, it traces back to your internal thermostat and what you believe you deserve.

Ed walks through using faith, intention, and association to rewire how you see yourself. This isn't about motivation—it's about fundamentally shifting the truth you've accepted about who you are.

The wake-up call? You're responsible for changing it, and this episode gives you the roadmap.

#identity #personaldevelopment #selfimprovement #mindset #growthmindset #motivation #success #podcast #edmylett #maxout #selflove #mentality #believeinyourself #goals #transformation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CyBUVyuL6u--1.mp4
"Want to know the real formula behind every incredible achievement you've ever witnessed? @edmylett breaks down the unglamorous reality: there's zero magic involved. Just raw hours of grinding when nobody's watching, repeated until mastery becomes second nature. The people dominating their fields—whether they're nailing trick shots, scaling businesses, or raising amazing families—all share the same DNA: relentless passion mixed with ironclad discipline. They bring intensity and consistency to the table every single day, not just when motivation strikes. That's the non-negotiable standard for anything worth accomplishing. Stop hunting for shortcuts and start stacking those unseen repetitions.

@tirosperfectos

#EdMylett #Motivation #Discipline #Success #Mindset #Consistency #NoShortcuts #GreatnessMindset #WorkEthic #Goals #PersonalGrowth #SelfImprovement #HustleHard #DedicationToExcellence #ChampionMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CzglS28Io9b-1.mp4
"Looking to completely transform where you're headed? @edmylett breaks down the exact framework for redesigning everything—from the relationships you keep to the experiences you chase.

This solo Q&A episode delivers straight answers about living with intention while actually enjoying the present moment. He's diving into follower questions and explaining why treating life design like body maintenance changes the game.

The reality check? Time isn't unlimited. Recent losses have reinforced this truth for him, which is why he's pushing the urgency factor hard.

Drop YOUR question in the comments—he's personally reviewing submissions for future episodes!

Full breakdown available at the link in his bio.

#maxout #edmylett #motivation #inspirationalquotes #inspiration #motivationalquotes #quotes #success #mindset #motivational #goals #inspired #inspirational #inspire #personaldevelopment #entrepreneur #successquotes #positivity #personalgrowth #entrepreneurship #successful #motivationalspeaker #life #dreambig #entrepreneurlife #nevergiveup #businessowner #growth #transformyourlife #changeagent",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\edmylett\CzbixjmIRMc-1.mp4
"Think you know how alcohol affects your body? @foundmyfitness drops a comprehensive breakdown covering everything from cancer risks to fertility impacts, hangover science to workout recovery. This deep dive explores zinc and magnesium's protective role for regular drinkers, reveals which cocktails trigger the worst hangovers, examines why fructose might save your morning, and uncovers why NSAIDs could be making things worse. The episode also tackles alcohol's link to brain volume loss, thiamine deficiency, neuroinflammation, sleep disruption, and whether those drinks are actually killing your gains. Plus: why prospective parents should consider a 3-month abstinence period and how 5 weekly drinks for women equates to smoking 10 cigarettes. Find ""The Truth About Alcohol: Risks, Benefits, and Everything In-Between"" on the FoundMyFitness podcast via Spotify, Apple Podcasts, and YouTube.

#alcohol #health #wellness #nutrition #podcast #science #fertility #fitness #hangover #sleep #brainhealth #cancer #vitamins #minerals #foundmyfitness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\C89xuUTuqry-2.mp4
"@foundmyfitness breaks down three game-changing lifestyle interventions that work synergistically to optimize your metabolic health. Her keynote from the American Academy of Anti-Aging Medicine conference tackles the science behind HIIT's superiority for glucose regulation, the metabolic consequences of eating too close to bedtime, and how sleep directly impacts insulin signaling. The detailed timestamps make it easy to jump to specific topics—from lactate's role as a signaling molecule to exercise snacks that rival 45-minute walks, plus practical sleep hygiene strategies and why eating earlier in the day matters more than you think. Available across all platforms with slides that complement the discussion.

#metabolichealth #hiit #sleephygiene",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DA9F8auSMxQ-1.mp4
"Your heart's flexibility is under attack—and elevated blood sugar is the culprit. @foundmyfitness breaks down how poor glucose regulation triggers a cascade that literally stiffens cardiac tissue through AGE formation. These advanced glycation end products don't just damage DNA and increase cancer risk; they cross-link collagen and elastin in the heart and blood vessels, reducing flexibility and driving up blood pressure. The result? Accelerated cardiovascular aging that compromises your heart's ability to meet daily demands. She outlines actionable solutions including vigorous exercise, sleep optimization, and meal timing strategies in episode 96—now streaming on YouTube, Spotify, and Apple Podcasts.

#metabolichealth #hearthealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DBJ-g3PyNaj-2.mp4
"A five-day experiment with canned soup revealed urinary BPA levels skyrocketing to 20.8 µg/L—among the highest recorded outside factory workers, according to @foundmyfitness. The same plastic lining found in soup cans exists in most aluminum beverage and food containers, from sodas to sparkling water. Research shows drinking from BPA-lined cans can spike blood pressure 16-fold versus glass bottles, with urinary concentrations at these levels correlating to hormonal disruptions. The solution isn't complicated: swapping canned products for alternatives in glass, cartons, or fresh options significantly cuts BPA exposure and its associated long-term health risks.

#microplastics #bpa #endocrinedisruptors #bloodpressure #hormones",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DBb_zDzSebb-2.mp4
"The supplement world is full of hype, but creatine continues to prove itself through rigorous scientific scrutiny. @foundmyfitness breaks down why this compound deserves attention beyond the gym—from powering cellular energy through ATP production to emerging data suggesting cognitive enhancement during periods of mental strain and exhaustion.

One persistent concern? The hair loss myth. Dr. Layne Norton (@biolayne) addresses this head-on in his recent podcast appearance, clarifying that while one small study showed elevated DHT levels, no actual link to hair loss has been established in the research.

Daily dosing recommendations hover between 5-10 grams, and the old-school loading protocol is now considered unnecessary by most experts. Experiencing digestive issues? Split your dose into smaller servings throughout the day.

For the complete deep-dive into Layne's supplement recommendations, episode 94 of the FoundMyFitness podcast delivers three and a half hours of evidence-based insights. Stream it on Apple Podcasts, Spotify, or YouTube, with detailed show notes at foundmyfitness.com/episodes/layne-norton

#creatine #supplements #fitness #brain",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\C_OXZniS5GT-1.mp4
"Every sperm sample tested. Every single one. That's the alarming reality @foundmyfitness breaks down about microplastic contamination and male fertility.

The damage goes beyond just presence—these particles are reshaping sperm and hindering movement, directly threatening reproductive capacity. Polystyrene from food containers accounts for 31% of what's being found, while PVC from water pipes leaches straight into what we drink daily.

The BPA connection makes it worse: this estrogen-mimicking chemical hitchhikes on microplastics, tanking testosterone levels and crushing sperm quality in men with higher exposure.

But there's a path forward. Skip heating plastic. Switch to stainless steel and glass. Install reverse osmosis filtration. Small shifts, significant impact.

Episode 95 of the FoundMyFitness Podcast delivers the full breakdown on how microplastics are affecting reproduction, brain function, cardiovascular health, and hormones. Available now on YouTube, Spotify, and Apple Podcasts.

#microplastics #xenoestrogens #fertility #endocrinedisruptors #bpa",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DAY63yNy6oR-1.mp4
"Movement could be the difference between thriving and merely surviving in our later years—and the current guidelines might be missing the mark. Dr. Rhonda Patrick breaks down the exercise paradox facing America's seniors and what actually supports healthy aging over at @foundmyfitness

#longevity #healthspan #exercisescience #aging #seniorfitness #healthyaging #movementismedicine #wellness #nutrition #science",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DGD1Ok8x9Jl-2.mp4
"Dr. Rhonda Patrick's supplement routine has stayed remarkably consistent over time, built around five core essentials she considers non-negotiable: Omega-3 fatty acids (minimum 1.5-2 g daily), Vitamin D (dosed to maintain blood levels of 40-60 ng/mL), a multivitamin for nutritional gaps, Sulforaphane to boost glutathione and support BPA detoxification, and Magnesium for its critical role in DNA repair enzymes.

__

Clip via @foundmyfitness Members-only AMA

Visit foundmyfitness.com/ask-me-anything for upcoming sessions

#supplements #omega3 #vitaminD #magnesium #sulforaphane #healthspan #longevity #nutrition #wellness #healthyaging",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DHHBIbwOa6C-1.mp4
"What if the best medicine during cancer treatment comes from moving your body? @foundmyfitness explores groundbreaking research with Dr. Kerry Courneya revealing that physical activity alongside chemotherapy delivers remarkable results—from slashing fatigue and anxiety to extending survival rates up to 8 years post-treatment. Patients saw enhanced sleep, better chemo tolerance, and improved body composition through aerobic and resistance training. While exercise isn't a cure-all and some studies show mixed results, working with an oncologist to customize workout intensity can tip the scales toward powerful benefits. Dive into the full conversation on the latest FoundMyFitness podcast episode.

#cancer #exercise #chemotherapy #fitness #health #wellness #oncology #cancerresearch #cancerprevention",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DG8xkL6yie8-2.mp4
"Looking to control blood sugar without adding extra cardio to your routine? @foundmyfitness reveals a game-changing discovery: breaking up 8.5 hours of sitting with brief bodyweight squats every 45 minutes outperforms a traditional 30-minute walk for glucose regulation.

The mechanism? Lactate acts as a signaling molecule that triggers GLUT4 transporters to migrate to cell surfaces, actively clearing glucose from blood into muscle tissue. This metabolic boost persists for 48 hours.

Rhonda breaks down the science of lactate's impact on metabolic health and brain function in her latest conversation with Rich Roll on The Rich Roll Podcast.

Their discussion covers:

• An exercise protocol proven to reverse two decades of cardiac aging
• Evidence-based strategies to reduce microplastic exposure
• How air pollution accelerates Alzheimer's risk

Plus additional insights on optimizing longevity

#metabolichealth #bloodsugar #glucosecontrol #lactate #exercise #longevity #healthspan #brainhealth #microplastics #airpollution #alzheimers #heartdisease #foundmyfitness #rhondapatrick #richroll",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DFVWiYWuApB-1.mp4
"Curious what keeps @foundmyfitness balanced when summer heat turns up? She's asking her community to share their go-to stress relief rituals for the season. Drop your answer below! ☀️

#SummerVibes #StressRelief #WellnessJourney #HealthyLiving #SelfCare #MindfulLiving #SummerWellness #MentalHealth #HealthTips #Wellness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DLkdevKuAXo-1.mp4
"Your brain has a gatekeeper that usually blocks creatine—until stress forces it open.

@foundmyfitness breaks down how cognitive pressure from sleep loss, aging, or mental exhaustion actually makes the blood-brain barrier more permeable, creating a window where supplemental creatine can slip through and boost function.

The protocols that work:
• 20g daily for 5 days during sleep deprivation = 10-20% better working memory
• 5g daily for weeks in older adults = sharper recall and mental clarity
• Ongoing research suggests benefits for mood stability, reduced cognitive fatigue, and potential TBI protection

This isn't about everyday supplementation—it's about timing creatine for periods of elevated brain demand when it can actually make a difference.

Full breakdown in FMF episode 100 with @dr.darrencandow

#creatine #creatinesupplement #brainfog #cognitivehealth #brainhealth #sleepscience #neuroprotection #biohacking #longevity #aging #functionalmedicine #sciencebacked #mentalperformance #mitochondria",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DImOoXSu-X9-2.mp4
"Looking to hack your sleep naturally? The answer might be colder than you think.

While conventional wisdom suggests warming up before bed, @foundmyfitness explains how strategic cold exposure triggers a powerful rebound effect. The initial sympathetic spike gives way to a dramatic parasympathetic shift in the hours that follow—potentially boosting HRV by 20–60%. Her husband has made it his go-to protocol for better sleep quality.

The key? Timing the cold plunge several hours before bed, not right before. She and @DrAndyGalpin dive deeper into sleep optimization tactics in their latest FoundMyFitness podcast conversation.

Episode available at FoundMyFitness.com/episodes/andy-galpin

#sleep #sleepquality #coldplunge #coldtherapy #hrv #parasympathetic #sleephack #biohacking #recovery #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DJXOmb7yiJ2-2.mp4
"# The Hidden Petroleum Product You're Putting in Your Mouth Daily

Most people don't realize they're chewing plastic. @foundmyfitness explains how conventional chewing gum releases thousands of microplastic particles into saliva with every piece—thanks to petroleum-derived polymers hiding behind the vague ingredient ""gum base.""

She was a regular Xylitol gum user for dental health until this discovery changed everything. The solution? Plant-based alternatives like Simply Gum and True Gum, which use natural tree sap instead of synthetic polymers.

For chronic gum chewers, the annual microplastic exposure adds up to tens of thousands of particles—but unlike many sources of plastic contamination, this one's completely within your control.

_

Via her conversation on The Tim Ferriss Show (@timferriss)

#microplastics #toxins #plasticfree #healthtips #wellnessjourney #holistichealth #nontoxicliving #healthylifestyle #functionalhealth #cleanliving #wellness #healthychoices #naturalhealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DM8dyWZyiNK-2.mp4
"Looking to level up your nutrition game? @foundmyfitness breaks down her essential three: dark leafy greens for that crucial magnesium, folate, and vitamin K most of us are missing; blueberries packed with brain-boosting polyphenols that sharpen cognition with just one cup daily; and wild salmon 2-3 times weekly to hit your omega-3 targets for better cardiovascular health. Simple staples, powerful results.

#superfoods #nutrition #healthyeating #omega3 #brainhealth #hearthealth #magnesium #polyphenols #salmon #blueberries #leafygreens #wellness #healthtips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DNl89MvRvRk-1.mp4
"The immune system's ability to fight cancer can increase 6-fold from just minutes of exercise, according to research shared by @foundmyfitness. Natural killer T cell activity surges during physical activity, improving the body's capacity to detect and destroy cancerous cells. Beyond immediate immune enhancement, consistent exercise correlates with lower cancer recurrence rates, decreased mortality, and improved survival outcomes in patients with cancer history. Studies highlight vigorous-intensity workouts as particularly beneficial. While not a replacement for medical treatment, exercise functions as a powerful adjunct therapy and preventative measure across most cancer types.

#exercise #cancer #immunity #naturalkillerTcells #cancerprevention #immunesystem #healthspan #longevity #vigorous #workout",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DQsFxswElOE-1.mp4
"The connection between broccoli sprouts and brain protection runs deeper than most realize. @foundmyfitness explains how sulforaphane's activation of the Nrf2 pathway mirrors the cellular benefits of exercise and fasting—ramping up the body's stress response genes and flooding cells with glutathione, our most powerful internal antioxidant. This mechanism reaches the brain too, which is why she has her parents supplementing with it daily as a defense against neurodegeneration. From traumatic brain injury to Alzheimer's, conditions rooted in oxidative stress may be countered by this compound. While supplements work, broccoli sprouts pack 100 times more sulforaphane precursor than fully grown broccoli, making them an incredibly concentrated whole-food option.

#sulforaphane #nrf2 #glutathione #broccoli #broccolisprouts #brainhealth #neuroscience #antiaging #longevity #oxidativestress #alzheimers #traumaticbraininjury #neurodegeneration #antioxidants #nutrition #healthspan #biohacking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DNqssZrO4Jd-2.mp4
"Looking to upgrade your sleep game? Dr. Rhonda Patrick breaks down her personal supplement stack over at @foundmyfitness, sharing exactly what she takes and the science-backed reasoning behind each choice.

Her go-to list includes melatonin (reserved for jet lag emergencies), magnesium glycinate for stress-related nervous system support, L-theanine to quiet an anxious mind, glycine for better subjective sleep quality, and myo-inositol to silence that relentless mental chatter at night.

These insights come from a Premium Member Q&A episode—but the first 30 minutes just dropped on the main FoundMyFitness podcast feed. The full episode is titled ""Exogenous ketones, my coffee protocol, and supplements for blood sugar regulation (Premium Member Q&A July 2025)"" and it's available now on all podcast platforms.

#sleep #sleepsupplements #melatonin #magnesium #ltheanine #glycine #inositol #sleepquality #biohacking #supplements #foundmyfitness #podcast #rhondapatrick",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundmyfitness\DOHaE-Ckf_K-1.mp4
"The best entrepreneurs don't wait for flawless conditions—they move forward and adjust as they go.

via @foundr

#entrepreneur #entrepreneurship #business #success #motivation #businessowner #mindset #startup #entrepreneurlife #successmindset #businessmindset #hustlehard #startuplife #entrepreneurmindset #businesstips #growthmindset #motivationalquotes #businessgrowth #hustler",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DEj_3rXiSaQ-2.mp4
"Tom Bilyeu spent years grinding behind the scenes before making his mark. That relentless drive? It's what separates dreamers from doers. @foundr breaks down how staying in the game long enough changes everything.

#entrepreneur #entrepreneurship #success #motivation #business #inspiration #mindset #goals #motivationalquotes #successquotes #entrepreneurlife #businessmindset #hustlehard #foundrmag",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DFCjmuGqhFW-1.mp4
"Most people think they need permission to start—but the real entrepreneurs? They just build.

This founder didn't wait for the perfect moment. Didn't overthink it. Just took action and figured it out along the way.

That's the startup mindset in action.

Via @foundr

#startup #startups #entrepreneurship #entrepreneur #startuptips #entrepreneurmindset #startuplife #businessmindset #entrepreneurlife #founderstories #businessgrowth #startupadvice #entrepreneurship101 #businessowner #hustlemode",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DEWyAKSvV9i-2.mp4
"Looking to validate your business idea without burning cash? Noah Kagan from AppSumo breaks down why customer confirmation beats gut instinct every time.

Watch the full conversation on the #foundrpodcast from @foundr

#noahkagan #appsumo #businessvalidation #startuptips #entrepreneurship #businessstrategy #marketresearch #customervalidation #startupadvice #businessgrowth #entrepreneurmindset #founderpodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DGU88mRPp1v-1.mp4
"Money talks, but purpose screams louder. When you chase the mission instead of the dollar signs, success finds you anyway. That's the real secret nobody wants to admit.

📹 via @foundr

#entrepreneur #entrepreneurship #business #motivation #success #mindset #businessowner #entrepreneurlife #hustler #millionaire #businessmindset #motivationalquotes #successquotes #entrepreneurmindset #businessmotivation #hustle #businesstips #wealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DFXJ3myBmEP-1.mp4
"Looking to launch? Hold up—tweaking just 1-2 of these elements could be the difference between crickets and conversions when you finally hit that sell button.

@foundr breaks down the pre-launch essentials that actually move the needle.

#entrepreneurship #businesstips #startupadvice #productlaunch #foundr #businessstrategy #entrepreneurlife #startuplife #businessgrowth #marketingtips #smallbusinesstips #entrepreneurmindset #businessowner #digitalbusiness #onlinebusiness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DGAkUwnPRP--1.mp4
"Looking back at interview moments that sparked the most debate, this conversation definitely takes the crown for @foundr 🔥

The audacity to ask about bank account balances during a first meeting? Wild move. But sometimes the uncomfortable questions lead to the realest answers.

Drop your take below 👇

#entrepreneur #business #interview #podcast #contentcreator #entrepreneurship #businesspodcast #entrepreneurmindset #startuplife #businesstips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DHsktGWJ8Y1-2.mp4
"The difference between those who make it and those who don't? One group lets fear paralyze them, the other uses it as data. This perspective shift changes everything.

via @foundr

#entrepreneur #entrepreneurship #business #motivation #success #mindset #businessowner #entrepreneurlife #startup #marketing #inspiration #smallbusiness #goals #hustle #motivationalquotes #businessmindset #successmindset #entrepreneurmindset #startuplife #businesstips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DIrDMD-NSIw-1.mp4
"Tom Bilyeu didn't let fear paralyze him—he used it as fuel. While most people freeze when doubt creeps in, he learned to move forward anyway. That shift in perspective changed everything.

The difference between those who succeed and those who don't? It's not fearlessness. It's deciding that fear won't make the decision for you.

Via @foundr

#entrepreneur #entrepreneurship #business #mindset #success #motivation #entrepreneurlife #businessowner #startup #hustle #businessmindset #goals #inspiration #motivationalquotes #successmindset #entrepreneurmindset #businesstips #startuplife #entrepreneurquotes #mindsetiseverything",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DIrDMD-NSIw-2.mp4
"Everyone's obsessed with tools and tactics, but @foundr reminds us what actually matters—your ability to curate, choose, and refine in a world flooded with AI-generated noise. Taste is the new competitive advantage.

Comment PODCAST to listen to the full episode.

#AI #ArtificialIntelligence #Taste #Business #Entrepreneurship #Podcast #Foundr",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DKOa2i0Trq1-2.mp4
"A single blazer. £12,000 in savings. Zero industry connections. That's all @aimeesmalex had when she walked away from corporate life to launch @oddmuselondon.

Fast forward to today: she's built a multi-million dollar fashion empire that's been copied by industry giants like PrettyLittleThing—and she's fought back to protect what she created.

@foundr's CEO & Founder @NathanChan sits down with Aimee to explore the unfiltered reality of building a global brand from scratch—the product that sold out overnight, the funding tactics that eliminated the need for investors, and the precise moment she knew there was no turning back from her 9-5.

This conversation delivers the blueprint for turning an idea into an obsession-worthy brand, even when you're starting with nothing but belief and determination.

Search 'Foundr Aimee Smale' on YouTube to watch the full episode.

Drop your biggest takeaway in the comments after watching!

Comment ""PODCAST"" for a DM with the full conversation.

#entrepreneur #businesspodcast #fashionbrand #startupstory #womenentrepreneurs #buildinpublic #smallbusiness #brandstrategy #founderpodcast #businessgrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DGEddghT3Yt-2.mp4
"Social media only. Zero funding. $100K in 12 weeks.

While most entrepreneurs see Australia's TGA approval process as an impossible barrier for sunscreen brands, Tori Gill turned it into her launching pad.

The regulations are brutal—sunscreen is literally classified as medicine there. But she didn't let complexity stop her from building what she believed in.

Pure founder-led execution proved stronger than any marketing budget could ever be.

Want the full breakdown? Comment 'PODCAST' for the complete interview, or search 'Tori Gill Foundr' on YouTube.

Credit: @foundr

#founderpodcast #foundrstories #entrepreneurship #startupstory #businesspodcast #womeninbusiness #foundertips #businessstrategy #skincarebrand #australianbusiness #bootstrapped #socialmediamarketing",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DITPwe-puSk-1.mp4
"Look who just dropped the ultimate reality check for entrepreneurs 👀

Not all advice hits the same when you're building something from scratch. The people giving you directions? They better have walked the path themselves.

Worth the watch if you're tired of taking notes from people who've never actually done it.

Via @foundr

#entrepreneurship #businessadvice #startuplife #entrepreneurmindset #businesstips #foundermindset #entrepreneurlife #businessgrowth #startupadvice #entrepreneurship101",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DLa5lM1zj0w-2.mp4
"When the lightbulb moment hits, it's never by accident. This breakdown reveals the exact framework successful founders use to validate product ideas before investing a single dollar. @foundr breaks down the methodology that separates profitable launches from expensive mistakes.

#entrepreneurship #businesstips #startupadvice #productdevelopment #foundr #businessstrategy #entrepreneurmindset #startuplife #businessgrowth #productidea",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DP0X3pzE9Yt-1.mp4
"Values first, partnership second—that's the formula @brianlittlefield_ and the @jockofuel team built their business on.

In a powerful conversation on the Foundr Podcast, Brian revealed how shared discipline from being black belts in jiu-jitsu created an unbreakable foundation with his co-founders. Their alignment wasn't just about business strategy—it was about mission, mindset, and a brotherhood that carried them through every challenge.

The result? A partnership with the resilience to weather storms and the clarity to scale together.

Real talk: values alignment isn't optional. It's everything.

🎧 Comment PODCAST for the full episode.

#Foundr #Entrepreneurship #BusinessPartnership #StartupLife #CoFounders #BusinessMindset #EntrepreneurMindset #JiuJitsu #Leadership #ScalingBusiness #Partnership #BusinessSuccess #FoundrPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DO2FYSBkcSq-2.mp4
"Every business has a ceiling—and usually, it's the founder's own limitations.

Want to scale? Start with yourself. The company can only rise as high as the person leading it. Personal development isn't separate from business growth—it's the foundation of it.

Via @foundr

#entrepreneurship #businessgrowth #foundermindset #personaldevelopment #businessowner #startuplife #entrepreneurlife #growthmindset #businesstips #leadershipdevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DQVW_osk_qu-2.mp4
"The weight of everyone else's opinions? That's exactly what kept him stuck for way too long.

During his conversation with @thesimplifiedmodel, he opened up about the turning point—the day he decided other people's judgments didn't get a vote anymore. For founders, that shift changes everything.

Building a business from a place of freedom instead of fear hits different.

Stop chasing approval. Start chasing progress.

via @foundr

#foundr #founderlife #foundermindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DOppDAwEeBg-1.mp4
"Community over everything—that's the lesson Ty Haney learned the hard way.

After building @outdoorvoices into a $100M brand by 30, she faced a very public unraveling. Most founders would disappear. Ty came back stronger with @getjoggy and @tyb.xyz, proving that resilience beats perfection every time.

@foundr sat down with her to unpack the real strategies behind her second act—the unglamorous truths about modern DTC, how she's building deeper relationships with customers instead of chasing vanity metrics, and the brutal lessons from her first company that shaped everything she's doing now.

This conversation covers:
- The fatal flaws in today's direct-to-consumer model
- How to transform casual customers into ride-or-die advocates
- Behind-the-scenes of the Outdoor Voices rise and fall
- Why founders showing up authentically is non-negotiable
- The boundaries she's protecting as she scales again

Raw, tactical, and refreshingly real—this episode hits different if you're in the trenches building something.

Comment PODCAST for the link.

#FounderStory #DTCBrands #Entrepreneurship #StartupJourney #BrandBuilding #CommunityFirst #FounderLedGrowth #BusinessPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DNByavSz2-z-1.mp4
"The real risk isn't quitting your job—it's staying too long after your side project already proves it works.

@foundr's founder was stuck between two worlds: an IT career offering security and a magazine business gaining serious momentum. Revenue was flowing. Customers were buying. Growth was happening. Yet fear kept him anchored to that desk job, convinced he was playing it safe.

A mentor's words shattered that illusion: ""The longer you wait, the more money you lose.""

That reframe changed everything. He wasn't protecting his future by holding onto his paycheck—he was actively limiting it. Split focus meant split results. Within weeks of going all in, the business exploded.

The conversation around entrepreneurship obsesses over jumping too soon, but rarely addresses the opposite trap: staying comfortable while your breakthrough waits on the other side of commitment.

Tag someone building something real who needs to see this.

#entrepreneur #sidehustle #foundrstory #businessgrowth #entrepreneurship #quitthejob #startuplife #businessmindset #entrepreneurmindset #takerisks #sidehustletips #businessadvice #entrepreneurlife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\foundr\DOmyQCckkyX-2.mp4
"@garyvee delivered a full-length speech at NYU Stern business school that hits different for anyone between 16-26. He's challenging everyone who watches this to actually take action—copy the link and drop it in your family group chats, send it to teachers, share it with literally anyone in that age range. This isn't your typical motivational moment, it's the complete unfiltered version that deserves to reach beyond the algorithm.

#college #commencement #nyu #university #graduation #graduationday #speech #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\C7NZ42ZgrPz-2.mp4
"The weight of expectations versus the freedom of reality – @garyvee breaks down why ""supposed to"" is the phrase keeping people stuck. He explains how happiness comes from adapting to what IS rather than mourning what ""should have been."" Reality doesn't follow anyone's script, and the sooner that clicks, the lighter life gets. Worth a rewatch if this one hits different.

#garyvee #mindset #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DMh_9rRAGbu-1.mp4
"@garyvee drops the reality check everyone's avoiding: stop waiting for permission to chase your dreams. This might be exactly what you need to hear right now to finally make that move. 

Drop a 🔁 to share this with someone who's been playing it safe for too long.

Got questions? Text: 📱 1-212-931-5731

#garyvee #mindset #motivation #perspective",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DN5icBLDh28-1.mp4
"The ones who show up every single day without the spotlight? @garyvee made this one for them.

Not the celebrities or public figures—but the people grinding with loyalty, resilience, and grit. The ones who carry their families with accountability and patience, no matter what life throws at them.

They deserve the recognition.

Tag someone below who embodies this energy and give them their flowers 💐

#inspiration #grit #love #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DN8JeVijmyB-2.mp4
"Gary Vee's coffee cup serves up reality without the filter. When you understand the message, everything shifts. 

He's challenging the first 100 to spread it - if you repost 🔁🔁 send him this emoji 🔁

Pro tip: Hit that ⭐️ button next to follow/following on his profile to favorite

Credit: @garyvee

#perspective #quotes #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DNYE4FSue_U-1.mp4
"Game day isn't just Sundays for @garyvee and the NY Jets—it's a 365-day mentality. Watch the journey unfold when The Home Team: NY Jets drops August 21. This is what happens when cameras capture the real grind behind America's most passionate fanbase.

#NYJets #TheHomeTeam #GameDay #NFL #August21 #JetsNation #FootballSeason #BehindTheScenes #GaryVee #NewYorkJets #JetUp",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DNQsmXLRcBH-1.mp4
"Gary Vaynerchuk's message is hitting different: we're crushing our children's resilience by never letting them experience loss or disappointment. His ""jersey"" take on why kids need to cry, need to lose, and need to struggle through hard moments. Not the popular opinion, but maybe the necessary one.

Credit: @garyvee

#parenting #perspective #parentingtips #mindset #reality #toughlove #resilience #kidsneedtolose #parenthood #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DOCcc3WDBjN-1.mp4
"Gary's dropping the real Friday night debate that matters 🥩

While everyone's arguing about other stuff, @garyvee wants to know how YOU do your steak. Drop your answer below.

Oh, and he's bored on a flight Monday - shoot him a text at 1-212-931-5731 and actually get a reply back.

#steak #questionoftheday #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DPFTLzmjjPj-2.mp4
"Gary Vee breaks down why fear of failure is keeping talented people trapped in jobs they hate. The truth? That safety net everyone's worried about losing isn't going anywhere – your fallback option will still exist if entrepreneurship doesn't work out. But here's what most don't calculate: the moment you commit full-time to your side hustle, the results multiply exponentially. @garyvee tells it like it is in this one, and somebody watching needs to hear this exact message today.

✅If you're ready to jump 👣 leave a feet 👣 emoji in the chat and if you're really serious DM me the 👣 emoji! Also pls 🔁 hit the repost 🔁 button on this post - too many need to see it ❣️",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DOgJNP_jny4-2.mp4
"@garyvee's cutting through the noise with what we all need to hear: stop overthinking it. The blueprint's already in your head—now it's about showing up and putting in the hours. No more waiting for perfect timing or permission. He's reminding us that execution beats intention every single time. The work is calling 🔥

#GaryVee #Motivation #Entrepreneur #Success #Hustle #Mindset #BusinessMotivation #EntrepreneurLife #SuccessMindset #WorkHard #ExecutionOverEverything #TakeAction #GetToWork",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DP2zDcjjJHV-1.mp4
"Gary Vee (@garyvee) just issued a challenge most people will scroll past instead of accepting 💀

The ask? Create THAT piece of content. The one that shifts everything. The one you've been putting off because it feels too vulnerable, too real, too much.

He drops absolute truth in the final 5 seconds that separates the talkers from the doers ❤️

#GaryVee #ContentCreation #Motivation #Entrepreneurship #CreateContent #MindsetMatters #TakeAction #ContentCreator #DigitalMarketing #SocialMediaMarketing",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DPESINoDsbX-2.mp4
"Gary Vaynerchuk (@garyvee) testing if you're really paying attention 👀

Drop your comment below if the message clicked for you.

Want to dive deeper into this? He's actually available via text: 📱 1-212-931-5731

#garyvee #perspective #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DPoRBt4DuFI-1.mp4
"Gary Vaynerchuk (@garyvee) just dropped a goldmine for anyone paying attention: the ""unplug"" movement isn't just a lifestyle choice—it's an untapped market. After 25 years of going all-in on digital, the pendulum is swinging back. Smart entrepreneurs will build empires around helping people disconnect.

Drop your take below: Are you capitalizing on this shift? What unplug business are you creating? 

#2026 #trend #businessadvice #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DPWPbfijkoK-2.mp4
"Gary Vaynerchuk (@garyvee) holds this close as the ultimate compliment he's ever received. The reminder here hits different: that single post you're doubting right now could be the one that shifts everything. Your breakthrough content is hiding in the work you haven't shared yet. The answer isn't perfection—it's consistency.

📱 DM him at 1-212-931-5731 for questions

#garyvee #wine #latenightshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DQnLNVyDBnX-1.mp4
"@garyvee reminds us that the most valuable currency doesn't come from your wallet. While everyone's busy pointing fingers at problems, he's challenging us to BE the solution. Showing up with genuine kindness for young people—especially those outside your circle—creates ripple effects that money can't buy. This message hits different when you realize how simple yet powerful it really is.

Who's ready to hop on this train? 🚂 Tag them below.

#motivation #happiness #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DQjkuPFjmY8-2.mp4
"Gary Vee breaks down the invisible prison most people live in: the fear of ""they."" 

That nameless, faceless group of critics? They're stealing your happiness without you even realizing it. He's challenging everyone to do the ""2fingersUpSpin"" and finally break free from caring what others think.

If you take the challenge, share your video and watch how fast your perspective shifts.

📌 Tap the ⭐️ on @garyvee's profile to save this reminder when you need it most.

#garyvee #mindset #advice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DQPIcFIjCt_-2.mp4
"Gary Vaynerchuk (@garyvee) isn't asking about the years on your birth certificate—he wants to know about the fire in your soul, the vibe you're putting out into the world, and how young your spirit actually feels.

He's going live today from 1-2pm on garyvee.com/stan, dropping knowledge for thousands of entrepreneurs and creators on how to unlock financial opportunities in today's landscape.

Want in? Send a DM with ""Tell me about Stan Store"" for automatic access details, or hit up his line directly at 📱1-212-931-5731 for any questions.

#stan #socialmedia #mindset #garyvee",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DPwAkGhDv2r-2.mp4
"The lifestyle landscape might be shifting in a major way. @garyvee recently appeared on Bloomberg TV to break down why he believes collecting is about to reach the same cultural status as music, sports, fashion, food, and travel. If this trend plays out the way he thinks it will, the business implications could be massive for entrepreneurs and brands across every industry.

What's in your collection? Drop it below 👇

#garyvee #collecting #collectibles",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DRr0BynEpbi-2.mp4
"Talk is cheap. @garyvee breaks down why getting your hands dirty in the trenches beats reading about success from the sidelines every single time.

He's 50, built multiple businesses, influenced millions—and still feels like he's just getting started. That's the mindset that separates dreamers from doers.

If you're in your 20s, 30s, or 40s thinking you're behind, you're not. Stop consuming content about success and start creating your own story through action.

Field experience > textbook knowledge

#garyvee #entrepreneurmindset #takingaction #businessadvice #hustlehard #entrepreneurlife #mindsetshift #successmindset #motivationmonday #doer #gettowork #buildinpublic #startuplife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\garyvee\DRUif5JDrqO-1.mp4
"The way @marthahigareda breaks down love as an action word instead of just a feeling hits different 💯 

Drop a YES below and the full episode lands in your DMs ✉️

What's your take—does love live in what we do or what we say? 👇

Via @greatness

#relationships #love #marriage #dating",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DLVL9AJx0hi-1.mp4
"Every year adds something irreplaceable—and @sagerobbins breaks down exactly what that is ✨

Want the full episode? Comment ""YES"" below 👇

Drop a 💛 if you appreciate who you've become 🙏

via @greatness

#mindset #wisdom #lifeisbeautiful",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DNB4_GlzZ1i-2.mp4
"The timeline to success? @mrbeast says multiply whatever you're thinking by 10 😅 If you can't fall in love with the grind itself, the destination won't matter 💯

Drop ""YES"" below for the complete episode 👇

Tag someone chasing their vision right now ✨

via @greatness

#mindset #entrepreneur #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DND5GR9JnzW-1.mp4
"The human body's hidden healing network is about to change medicine forever. 🧠⚡

@greatness sits down with Dr. Kevin Tracey in tomorrow's episode to explore a groundbreaking biomedical device that taps into the nervous system's natural power—offering healing beyond traditional drugs and surgery.

The future of healthcare drops TOMORROW 🎙️

#greatness #neuroscience #biomedicine #schoolofgreatness #health",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DNeAAmlSTKU-1.mp4
"The 'great nerve' might be the medical breakthrough that changes everything for chronic pain sufferers 🧠⚡

Neurosurgeon Dr. Kevin Tracey breaks down the science behind this ONE nerve pathway that could revolutionize how we treat autoimmune diseases.

Drop ""YES"" below for the complete episode in your DMs 💬

via @greatness

Tag someone dealing with chronic pain 🙏

#schoolofgreatness #neuroscience #chronicpain #autoimmunedisease #healing #health #wellness #medical #breakthrough #science #podcast #education",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DNgDWYHxtza-1.mp4
"What do theater kids and Broadway dreams have in common? Everything you'll hear in today's School of Greatness podcast episode 🎭✨

@greatness brings you the conversation you didn't know you needed 🎙️

Link in bio – your cue to listen 👆

#SchoolOfGreatness #TheaterKids #Gleeks #Broadway #Podcast #MusicTheater #PerformingArts #TheaterLife #BroadwayDreams #PodcastEpisode",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DOETal3ErcP-2.mp4
"Twin girls on the way! 🌸🌸 The couple shares their beautiful announcement with the world. @marthahigareda couldn't contain the joy—two daughters are joining their family. Double the love, double the blessings 🩷🩷

via @greatness

#twins #babygirls #pregnancy #pregnancyannouncement #babyannouncement #twingirls #blessed #family #growingfamily #doubletrouble #twinsisters #babynews #expecting #expectingtwins #momtobe #dadtobe",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DOhDva4j8Ar-1.mp4
"Taylor's latest move just gave the entire internet a masterclass in bold, unapologetic living. 🧡 

Orange energy is taking over—it's the vibe of fearless creativity and chasing what sets your soul on fire. Every Swiftie and dream-chaser is feeling it right now. 🌟

Want to turn that energy into real-life action? The 2025 Summit of Greatness is happening September 12–13 at the iconic Dolby Theatre. Two transformative days with world-class speakers and a community ready to elevate you. Drop a ""YES"" below to claim your seat and step into your greatness ✨🙌

Via @greatness

#greatness #manifestation #summitofgreatness #taylorswift #ts12 #orange",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DNTudSUSpdj-2.mp4
"When chasing motivation leaves you running in circles, it's time to shift your focus to something deeper. @greatness breaks down why meaning—not motivation—is what truly transforms your life. After over a decade of conversations with the world's most successful minds, Lewis Howes discovered that popular advice might actually be holding you back. This episode challenges 7 common beliefs that could be keeping you stuck. Tag someone who needs to hear this truth 🙏

#schoolofgreatness #personaldevelopment #selfimprovement #motivation #mindset #success #growthmindset #lifelessons #personalgrowth #inspiration #successmindset #selfgrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DOJXvspETrw-2.mp4
"What happens when a top neuroscientist starts talking about the universe sending signals? @drtaraswart takes this conversation into unexpected territory — exploring the science behind grief, abundance, and connections that can't be explained in a textbook. Full episode coming tomorrow. 🧠✨ (via @greatness)

#neuroscience #manifestation #consciousness #podcast #abundance #mindset #spirituality #science #universe #connection",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DPa4mttkuJ7-1.mp4
"When @bayavoce sat down with @greatness, she dropped a perspective that changes everything about conflict: there's no single truth between two people—just two different realities trying to meet in the middle. The real relationship work? It's not about winning the argument. It's about bridging the gap between what you see and what they see.

Want the full conversation? Drop ""TRUTH"" below for the link 💌

#love #relationships #couplegoals #greatness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DPy6t4AjblH-2.mp4
"The universe might be speaking directly to you, but are you listening? 

Dr. Tara Swart (@drtaraswart) returned to The School of Greatness with groundbreaking insights that merge cutting-edge neuroscience with timeless spiritual truths. Her message: the signs from loved ones, ancestors, and the cosmos aren't just coincidence—there's actual science behind the connection our souls recognize.

This conversation with @greatness goes deep into how we're all linked in ways modern society forgot to teach us ♾️

Tag someone who's been searching for answers 💛

Comment ""SIGNS"" below for the full episode 👇

#neuroscience #spirituality #signs #grief #connection #healing #consciousness #schoolofgreatness #podcast #universe #ancestors #lovedones #energy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DPeTkF0kY75-2.mp4
"The history books weren't written by people who stayed comfortable. 💯

@tonyrobbins breaks down why your current struggles are literally building the person you're meant to become. Real talk: comfort zones don't create legends. 🔥

Drop a ""YES"" below for the complete episode 🎧

Credit: @greatness

#TonyRobbins #Motivation #Mindset #PersonalGrowth #SelfDevelopment #Success #Inspiration #MotivationalQuotes #Greatness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DQKF2u6ElTC-1.mp4
"The many moods of Scott Galloway in one reel 😂 Which version showed up to your Monday?

🎥 @greatness

#ScottGalloway #BusinessHumor #MondayMood #Entrepreneur #ProfG #Mood #Relatable #BusinessPodcast #ContentCreator",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DRfUUZfEjw6-2.mp4
"When pressure hits, people's true patterns emerge — and that's where you learn to read them. Behavioral shifts reveal everything. 

via @greatness

#mindset #psychology #bodylanguage #communication #peoplesskills #emotionalintelligence #selfimprovement #personaldevelopment #socialskills #success",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DRPzmmPj-yb-1.mp4
"The grind never stops—and neither does this athlete's vision for Team Handball in America. After 15 years repping @usateamhandball, he's now owner and president of @lateamhandball 🤾‍♂️🇺🇸

Fresh off their first tournament in Chicago last weekend, he's juggling business ventures, preparing for twins with @marthahigareda, and commuting to Spain to train with @leonademar (shoutout @danielgordorios). The mission? Build a home base in LA and finally put this massive European sport on the map stateside.

It's all happening at once, but that's how legacies are built—one day at a time.

Credit: @greatness

#handball #håndball #handballplayer #balonmano #handebol #olympics #teamusa",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DQhViUOj1e6-1.mp4
"The mind-body connection isn't some woo-woo theory—it's backed by science, and @gabormatemd breaks down exactly why western medicine might be missing the point 🧠✨

When healing happens from the inside out, everything changes 👀🩻

Via @greatness

#mindbodyconnection #holistichealth #healing #gabormatemd #wellness #mentalhealth #westernmedicine #healthylifestyle #mindfulness #consciousness #selfhealing",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DRxMhwbD7fe-1.mp4
"The numbers don't lie, and @profgalloway isn't here to sugarcoat them. 

What's actually happening to young men in 2025? Tomorrow's conversation reveals the uncomfortable truths most people refuse to acknowledge—and the real cost of looking away.

Mark your calendar: 11.24.2025 👀

Full episode drops tomorrow. 🔥

via @greatness

#Podcast #YoungMen #SocietyTrends #ScottGalloway #RealTalk #MentalHealth #NextGeneration #HardConversations #SocialIssues #PodcastEpisode #ComingSoon",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\greatness\DRaIL4ukv8D-1.mp4
"Tag someone who needs to see this perspective shift 👇

Alex Hormozi (@hormozi) breaks down why your current situation might be the exact advantage you need. Sometimes what feels like a disadvantage is actually your competitive edge in disguise.

Drop a 💡 if this changed how you see your position.

#alexhormozi #businessmindset #entrepreneurmindset #mindsetshift #businessstrategy #competitiveadvantage #entrepreneurship #businessgrowth #successmindset #businesstips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\Ct2zx94onmh-1.mp4
"Most people spend their whole lives protecting a life they never wanted in the first place.

@hormozi drops the uncomfortable truth: your time here is limited. The only real question is whether your dreams expire before you do—or if you'll actually chase them.

Death is guaranteed. Regret is optional.

#alexhormozi #hormozi #entrepreneurmindset #businessmindset #motivationmonday #SuccessMindset #entrepreneurlife #businessowner #mindsetmatters #growthmindset #personaldevelopment #selfimprovement #motivationalquotes #businessgrowth #takeaction",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DN3T65g4h4E-2.mp4
"@hormozi breaks down why your tolerance for discomfort today directly predicts how far you'll go tomorrow. The winners? They're not avoiding the grind—they're built different because of it.

#success #motivation #entrepreneurship #mindset #growth #discipline #businessmindset #entrepreneurmindset #alexhormozi #gym #fitness #entrepreneur #business #successmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DNzIHoVIAjl-1.mp4
"Most people chase complexity thinking it'll make them stand out. @hormozi flips that mindset completely—mastering the fundamentals is what separates amateurs from experts. The advanced move? Never skipping the basics.

#business #entrepreneur #success #motivation #mindset #growth #entrepreneurship #businessowner #goals #hustle",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DOMVwVxlPUm-1.mp4
"@hormozi breaks down the real test of friendship: it's measured in how many times someone defends you—especially when you're not in the room to hear it.

The flip side? You've got to show up for them the same way.

#friendship #loyalty #relationships #realfriends #character #integrity #trust #personaldevelopment #lifelessons #mindset #growth #values #authenticity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DOWO6BgjkbE-2.mp4
"When's the last time you tapped into your raw, unstoppable force? @hormozi reminds us that capability for relentless action lives inside everyone—it just needs to be awakened. 💪

#alexhormozi #hormozi #entrepreneur #business #motivation #success #mindset #entrepreneurship #businessowner #entrepreneurlife #millionaire #millionairemindset #businessman #relentless #discipline #growthmindset #successmindset #motivation101",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DOqzzq2EtZe-1.mp4
"The difference between amateurs and masters? Masters were willing to embarrass themselves first. @hormozi breaks down why your ego is your biggest obstacle to growth.

#alexhormozi #businessmindset #growthmindset #entrepreneurship #successmindset #personaldevelopment #motivation #businesstips #selfimprovement #mindsetshift",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DP4GNZKjgjZ-2.mp4
"The difference between those who make it and those who don't? It's not talent or luck—it's having a stronger ""why"" to continue than excuses to stop. @hormozi breaks down the mindset that separates winners from quitters.

#motivation #entrepreneur #business #success #mindset #entrepreneurship #businessowner #growthmindset #successmindset #entrepreneurlife #hustlehard #millionairemindset #businessmindset #nevergiveup #keepgoing",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DPE-illDtaz-1.mp4
"The entire wealth equation, stripped to its core by @hormozi: Either you haven't mastered solving a problem people will pay for, or you've mastered it but stayed invisible. Everything else is just noise.

#business #entrepreneur #money #success #businessowner #entrepreneurship #mindset #wealth #businesstips #motivation #entrepreneurlife #makemoney #businessgrowth #smallbusiness #marketing",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DPU-ZGJAVKR-1.mp4
"Growth demands a trade-off that most people refuse to make—and @hormozi breaks down exactly what you're sacrificing when you choose to level up. Your comfort zone isn't free; it costs you everything you could become.

#growth #comfort #mindset #entrepreneur #business #success #motivation #personaldevelopment #growthmindset #entrepreneurship #businessmindset #successmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DP7E3yKCMx8-1.mp4
"The stock market averages 10% annually. Your personal growth? Unlimited. @hormozi breaks down why betting on yourself will always outperform the S&P 500. Time to become your own best investment.

#investing #selfimprovement #personaldevelopment #growth #mindset #entrepreneur #business #motivation #success #investinyourself #financialfreedom #wealth #entrepreneurship #businessmindset #growthmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DPzXdsvkhpu-2.mp4
"The hardest business lesson nobody talks about: some hits, you just absorb. Can't fight back, can't lash out—just take it and keep moving. That's the separator between who makes it and who doesn't, according to @hormozi.

#business #entrepreneur #entrepreneurship #businessowner #success #motivation #mindset #growth #businesstips #entrepreneurlife #hustlehard #successmindset #businessmindset #entrepreneurmindset #growthmindset #businessgrowth #motivational",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DQ27auMEtkG-2.mp4
"@hormozi breaks down what discipline actually means on @impaulsiveshow — it's your ability to keep showing up for the punishing stuff even when there's zero reward waiting for you. The more reps you can handle without payoff, the more disciplined you are.

#alexhormozi #hormozi #discipline #selfimprovement #mindset #motivation #personaldevelopment #businessmindset #entrepreneur #success #growthmindset #motivational #impaulsive",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DQSPKOwiC7G-2.mp4
"@hormozi breaks down why protecting your image might be costing you everything. The paradox? Getting wealthy means you'll look broke while you invest every dollar. Building strength means people will see you struggling with weights you can't lift yet. Finding real love means being vulnerable enough that rejection becomes possible.

Your ego whispers that how things look matters more than what you're building. It's a trap that kills more potential than any actual setback ever could.

#alexhormozi #entrepreneurmindset #egokills #wealthbuilding #personalgrowth #mindsetshift #successmindset #entrepreneurlife #businessmindset #selfimprovement #growthmindset #motivation #vulnerability #realitytalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DQKhLAKkpE0-1.mp4
"Here's a mindset shift worth millions: while everyone's obsessing over cutting costs, @hormozi points out the obvious play sitting right in front of us—hiring talented people. The ROI? Somewhere between 10x and 100x. And despite what conventional wisdom says, underpriced talent exists everywhere. The question isn't whether it's available. It's whether you're actually looking.

#alexhormozi #businessgrowth #entrepreneurmindset #hiringtips #businessstrategy #roi #talentacquisition #scaleyourbusiness #businessowner #entrepreneur",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DQVWMtyCNum-1.mp4
"Reality keeps receipts when nobody else is watching. 

Every rep in the dark. Every hour nobody knows about. Every sacrifice that goes unposted. Reality logs it all while people sleep on your grind.

The scoreboard doesn't need witnesses to count your work. It just reflects what you actually put in, not what you talked about putting in.

Most people can't give you credit for work they've never done themselves. They literally don't have the reference point to understand what it costs.

But reality? It's the only accountant that never lies about your deposits.

Credit: @hormozi

#entrepreneur #business #success #motivation #mindset #growth #hustlehard #businessowner #entrepreneurship #workethic #discipline #grind #realitycheck",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DQAv6srEt7C-1.mp4
"The harsh truth? Most people hit replay on the same year over and over again until it's game over.

According to @hormozi, everyone's got the ability to flip the script on their life. The missing ingredient isn't potential—it's the guts to actually do something about it.

Stop being a spectator in your own story.

#hormozi #alexhormozi #motivation #mindset #personalgrowth #selfimprovement #businessmindset #entrepreneurmindset #successmindset #motivationalquotes #inspirationalquotes #changeyourlife #growth #discipline",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DQxNmZRkr47-2.mp4
"Most people pray for an easier life—but what if the hard one is the blessing? @hormozi breaks down why the struggles aren't mistakes in the plan, they ARE the plan. The setbacks, the chaos, the battles you didn't ask for—they're all sculpting something greater in you. Your worth isn't defined by what you endure, but by who you're becoming through it 🔥

#alexhormozi #mindset #personalgrowth #motivation #selfimprovement #entrepreneurmindset #growthmindset #lifelessons #adversity #faith #purpose #transformation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DRnCHSqiC8X-2.mp4
"The gap between beginners and masters? Everyone who's great now once absolutely sucked at what they do. @hormozi breaks down why your first attempt being terrible is actually proof you're on the right path. The embarrassment fades fast—but regret from never trying sticks forever.

#alexhormozi #entrepreneurmindset #businessmindset #successmindset #growthmindset #entrepreneurship #businesstips #motivationmonday #startuplife #mindsetshift #personalgrowth #takeaction #juststart",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hormozi\DRGYMIIgUo_-2.mp4
"Two powerful protocols for dream recall and nightmare release, shared by @hubermanlab after learning them from @rickrubin. The fascinating part? Both techniques align with the body's natural paralysis during REM sleep—when our most emotionally intense dreams occur. While solid science exists on dreaming mechanics, these specific methods haven't been formally studied... yet. Through @scicommedia, the company Huberman co-founded, research is currently underway on NSDR, depression treatments, eating disorders, neuro-immune connections, autism, and reproductive health—with plans to eventually include dream studies. The mission: delivering actionable tools for mental health, physical performance, and overall wellbeing to everyone.

#neuroscience #science #ciencia #neurociencia #sleep #dreams #night #memory",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\C--9A0UyMiA-2.mp4
"Dr. Martha Beck shares a transformative technique for building self empathy during her recent conversation with @hubermanlab. This episode has quickly become one of the podcast's most-shared discussions, packed with actionable tools for identifying core beliefs, distinguishing genuine empathy from codependency, and creating concrete pathways toward your ideal life. The full conversation with time-stamps is available at hubermanlab.com—drop your questions in the comments below.

@hubermanlab @stanford.med @stanford @themarthabeck

#neuroscience #science #ciencia #neurociencia #life #tools #empathy #self #others",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\C-eCy-0vamV-1.mp4
"Ever wondered how timing your sauna session could actually boost your body's oxygen-carrying capacity? @drstacysims breaks down a precise post-workout protocol with @hubermanlab that targets red blood cell production—but there's a catch involving strategic dehydration that requires careful attention. The conversation dives deep into performance optimization, with special focus on nutrition, training cycles, and whether popular trends like fasted workouts actually benefit women differently. Head to hubermanlab.com for the full breakdown with timestamps to skip straight to what matters most to you. Drop your questions below!

#neuroscience #science #ciencia #neurociencia #sauna #cells #training #endurance #strength #heat #kidney",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\C9xa6XjPm_X-2.mp4
"@hubermanlab sits down with @matthiasjbarker to unpack a striking statistic: up to 25% of people are estranged from a parent. Matthias brings actionable frameworks for handling complex family relationships, especially during holiday season. His approach centers on what he calls ""making peace with what's possible""—realistic, no-nonsense guidance that acknowledges family dynamics aren't one-size-fits-all. Drop your questions in the comments for a potential follow-up conversation. Credit: @hubermanlab @stanford.med @stanford @matthiasjbarker

#neuroscience #science #ciencia #neurociencia #parents #holidays",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DApSW4NP9b0-1.mp4
"@hubermanlab showing up unannounced for an 800-pound belt squat session on Christmas Eve proves the universe has a sense of humor. One gym post later and suddenly the neuroscientist-turned-meathead is flying in from LA ready to destroy legs. Some people bring fruitcake to Christmas—he brings the pain.

#train #hawaii #serendipity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DD-ayAcziSC-1.mp4
"Your brain's ability to mentally time travel could be the key to designing who you become. In this powerful segment, @hubermanlab sits down with @ariw, Founder of Longpath, to explore a science-backed writing protocol that connects present thoughts to future possibilities. Ari breaks down a straightforward exercise that takes minimal time but creates lasting impact—one that Huberman ranks alongside the ""perfect day"" protocol from @themarthabeck as an irreplaceable tool for personal development. The practice isn't about manifestation or attraction, but rather about deliberately directing cognition toward a version of yourself that doesn't exist yet. Worth trying to see what surfaces both during and after the exercise. Full timestamped episode available at hubermanlab.com

@hubermanlab @stanford.med @stanford @ariw

#neuroscience #science #ciencia #neuroplasticity #future #letter #script #create",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DBJ3nzUSce5-1.mp4
"Martha Beck's ability to transform abstract concepts into actionable steps caught @hubermanlab's attention years ago, and their recent podcast conversation proved why her work resonates with millions. Her new book ""Beyond Anxiety: Curiosity, Creativity, and Finding Your Life's Purpose"" is now available for presale—a resource he describes as spectacular and unlike anything else in personal development. The book emerged as an answer to countless listeners who wanted more of the somatic and narrative tools Martha shared during what became one of the podcast's most popular episodes. He emphasizes having zero financial ties to the work, just genuine appreciation for how it guides people toward their essential self and best possible life. Available on Amazon, Audible, and everywhere books are sold.

#neuroscience #science #ciencia #neurociencia #life #essential #self #beyondanxiety #marthabeck #create",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DAPYOhfPJEx-1.mp4
"The real reason sugar hijacks your brain isn't what most people think. @hubermanlab breaks down the hidden neurochemical pathway that makes certain foods literally rewire your motivation circuits from the inside out. It's not about willpower or taste—sugar and fat combinations trigger an unconscious drive that changes brain chemistry. Understanding this mechanism is the key to taking back control. Want the full science? Head to hubermanlab.com and search the relevant topics for timestamped episodes and references.

#neuroscience #science #ciencia #neurociencia #health #sugar #gut #brain #nutrition #vagus",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DFfqgAUvTIH-1.mp4
"Pavel Tsatsouline breaks down the optimal rest period strategy that most people completely ignore in their training. During his conversation with @hubermanlab, Pavel reveals what you should actually be doing between sets—and it's not what you'd expect. The discussion covers strength building without adding size, the ""grease the groove"" method, and why training to failure isn't always the answer. Full episode available at hubermanlab.com with detailed timestamps for easy navigation.

#neuroscience #science #ciencia #neurociencia #muscle #mind #performance #paveltsatsouline",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DF-3YoQyaqi-2.mp4
"Could red light on your back be the metabolic game-changer you never knew existed? @hubermanlab sits down with Dr. Roger Seheult MD to break down fascinating research revealing how red light and infrared exposure—whether from the sun or specialized devices—directly enhances mitochondrial function, leading to better blood sugar control and improved metabolism. While red light devices have their place, sunlight remains the ultimate source since it naturally contains both red and infrared wavelengths. The full conversation covers numerous free, science-backed strategies for optimizing physical health, circadian rhythm regulation, and immune function. Head to hubermanlab.com to watch the complete episode with detailed timestamps for easy navigation. Drop your questions and future topic suggestions in the comments.

#neuroscience #science #ciencia #neurociencia #skin #glucose #insulin #blood #sunlight #longevity #mitochondria #metabolism",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DGqiTlMPaDI-2.mp4
"Want instant stress relief? @hubermanlab breaks down the science-backed method during his sit-down with @billmaher on #RealTimeHBO.

Full episode streaming now on @hbomax.

#mindbodyconnection #destress #neuroscience #mentalhealth #physicalhealth #physiology",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DNynukd1Jim-1.mp4
"When a parody account nails your coffee order (minus the Shilajit), you know you've made it. @hubermanlab gives props to @abandonedmovies for the spot-on impression while opening the floor for listener questions on future podcast episodes and Instagram content.

Drop your science questions and topic requests below 👇

#neuroscience #science #ciencia #neurociência #dopamine #protocols #magnesium #bluelight #redlight #zinc",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DLvPJGgyfej-1.mp4
"Your nose knows who's genetically perfect for you – and science can prove it. @hubermanlab sits down with evolutionary geneticist Dr. Melissa Ilardo @superhumanscilab from @universityofutah to unpack fascinating research showing that sweaty T-shirt experiments reveal our biological blueprint for attraction. People consistently prefer the scent of those whose immune genes (MHC) are most different from their own – nature's way of engineering resilient offspring. The conversation spans from free-diving populations with evolved spleen function to how behaviors directly influence gene expression. Dr. Ilardo's groundbreaking work bridges genetics, human performance, and the science of why we're drawn to certain people. Full episode available at hubermanlab.com with detailed timestamps.

#neuroscience #science #ciencia #neurociência #smell #mhc #majorhistocompatibilitycomplex #immunesystem #preference #resilience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DKLcv7DpwP8-2.mp4
"The stress hormone everyone loves to hate might actually be your secret weapon for better energy and sleep—if you know when to spike it. @hubermanlab breaks down the cortisol timing strategy most people get completely backwards, explaining why your morning levels should actually be HIGH (yes, you read that right). He covers the four daily methods to optimize cortisol's natural rhythm, addresses common myths around cold plunges, and reveals why moderate exercise creates beneficial cortisol surges when scheduled properly. The difference between men and women? He's got that covered too. Understanding cortisol's rhythm rather than trying to eliminate it could transform your focus, mood, and nighttime rest.

#neuroscience #science #ciencia #neurociência #cortisol #mood #focus #coldplunge #health #circadian #exercise #caffeine #sleep",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DJuD_ZCJqHO-1.mp4
"Your body already knows who you're genetically compatible with — and smell is the secret weapon 👃

Dr. Melissa Ilardo @superhumanscilab breaks down fascinating research on @hubermanlab's podcast: subjects ranked sweaty t-shirts by attraction, and consistently chose scents from people with the most different immune genes (MHC) from their own.

Translation? Evolution designed us to seek partners whose genetic makeup creates the strongest, most resilient offspring possible.

The episode dives deep into how behavior shapes gene expression, Dr. Ilardo's groundbreaking work with free divers who've adapted superhuman spleen function for oxygen production, plus eye color inheritance and what it all means for human performance.

This conversation from evolutionary geneticist Dr. Melissa Ilardo at @universityofutah reveals how genes and behavior continuously influence each other in ways that impact health, attraction, and survival.

Full episode available at hubermanlab.com with timestamps for easy navigation.

#neuroscience #science #ciencia #neurociência #smell #mhc #majorhistocompatibilitycomplex #immunesystem #preference #resilience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DKLcv7DpwP8-1.mp4
"Stop letting protein myths ruin your relationship (and your gains). @hubermanlab breaks down what the science actually says: roughly 1g of quality protein per pound of lean body mass daily for both men and women—maybe even more. The old ""30g protein limit per meal"" claim? Debunked. Resistance training changes the game, and it's something everyone should be doing at any age. Translation: You're not stuck eating 4-6 times a day if that's not your thing. Shoutout to @willydennis and @chloe_troast for this dramatic demonstration—fingers crossed they figure it out before part 2 drops.

#neuroscience #science #ciencia #neurociencia #protein #brains #romance #repair #macros #whey #health",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DPXO3QagV9t-1.mp4
"Daily wins reshape what you believe possible—and @alexhonnold's approach proves it. In his conversation with @hubermanlab, the legendary free solo climber breaks down how his systematic tracking of small victories expanded his vision of what he could achieve (including that jaw-dropping El Capitan ascent). The discussion covers his journaling practice, weekly progress reviews, and how crossing items off a list literally rewires your brain's goal-setting capacity. Beyond climbing-specific insights, they explore strength training protocols, the sport's Olympic evolution, balancing elite performance with family life, and maintaining drive without burnout. Whether you climb or not, athlete or not, this episode delivers actionable frameworks for anyone chasing ambitious targets. Full episode available at Hubermanlab.com with timestamps for easy navigation. Drop questions below!

#neuroscience #science #ciencia #neurociencia #goals #checklist #progress #envision #nature",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DOHB5zjjWPF-2.mp4
"The mitochondria expert everyone's been waiting for has finally arrived on the podcast. Dr. Glen Jeffery joins @hubermanlab to break down how the light sources in your home could be working against your cellular health—and what to do about it.

Short wavelength light from LED bulbs may be damaging mitochondria, while longer wavelengths actually help repair them. Incandescent bulbs naturally emit the full spectrum your cells need. Morning sunlight exposure becomes even more critical when you understand it's protecting your mitochondria from artificial light damage throughout the day.

The evening routine matters too: dimming LEDs at night isn't just about sleep quality, it's about giving your mitochondria a break. Dr. Jeffery shares zero-cost and low-cost protocols to optimize light exposure for cellular health, plus the real science behind red light devices.

Full timestamped episode available at hubermanlab.com

#neuroscience #science #health #light #metabolism #mitochondria #blue",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DRxLar4iYFh-2.mp4
"Deep dive into why @hubermanlab became a partial owner of @mateina and brought their cold brewed yerba mate to @wholefoods shelves. Growing up with Argentine roots, he's been drinking yerba since age 3, making him uniquely qualified to spot what's missing in the market: air-dried (not smoked), zero sugar versions that actually contain substantial yerba instead of added synthetic caffeine. After finding Mateina's organic looseleaf, he helped develop five cold brew flavors using minimal stevia, all in BPA and PFAS-tested cans. Each contains 120mg of natural caffeine with antioxidants, digestive support, and no crash. Available at Whole Foods, Amazon, and Mateina.com in raspberry, peach, mango key lime, mint limeade, and lemon.

#yerbamate #mateina #caffeine #cleancaffeine #wholefoods #organic #coldbrew #healthylifestyle #hubermanlab #nutrition #wellness #functionaldrinks #nosugar #zerosugar #plantbased #argentine #matcha #energydrink #healthyliving #biohacking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\hubermanlab\DRA9ZCBktrg-1.mp4
"The tech world is buzzing after China just dropped an iPhone 17 alternative that's turning heads for all the right reasons. According to @icedcoffeehour, this isn't your typical knockoff situation – the dupe might actually have Apple beat on features. Sometimes the copy outdoes the original. 👀

#iPhone17 #TechNews #China #Apple #Smartphone #TechReview #AndroidVsApple #PhoneDupe #TechCommunity #MobileTech #Innovation #TechTrends",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DP4eLd6Eo_S-2.mp4
"The automotive industry's biggest restriction exposed 🚗 @icedcoffeehour breaks down the real reason Chinese vehicles can't enter the American market—and it's not what you'd expect. The geopolitical chess game behind your driveway choices.

#cars #china #america #automotive #geopolitics #trade #economy #carbusiness #autoindustry #explained",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DP6xXt5jyaa-2.mp4
"The uncomfortable truth about your bank account that nobody wants to talk about 📉

@icedcoffeehour breaks down why that $100 from last year doesn't hit the same anymore. Inflation isn't just some abstract concept—it's actively eating away at your purchasing power while you sleep.

The real question: are you keeping up or falling behind?

#inflation #money #personalfinance #financialeducation #moneytips #investing #wealth #financialfreedom #moneymindset #financetips #economy #financialliteracy #moneytok #investing101 #financialindependence",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DP9UjYgEcxY-1.mp4
"The line that turned Walt Jr into a breakfast legend 🍳

When @icedcoffeehour breaks down this iconic Breaking Bad moment, you realize how one simple scene created internet history. Walt Jr's delivery here became the most quoted moment of his entire character arc.

#BreakingBad #WaltJr #TVMoments #BreakingBadClips #IconicScenes #TVHistory #BreakingBadFans #BryanCranston #RJMitte #AMC #TVSeries #BreakingBadMemes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DQ2MYuRkjkz-1.mp4
"Money guru Dave Ramsey stays firm on his principles—even when presented with a billion-dollar loan at 0% interest, he's passing on it. His reasoning? Some values can't be compromised, no matter how tempting the terms. 

🎙️ via @icedcoffeehour

#DaveRamsey #PersonalFinance #DebtFree #MoneyMindset #FinancialFreedom #FinancialAdvice #MoneyTips #WealthBuilding #FinancialIndependence #DebtFreeJourney #MoneyManagement #FinancialPlanning #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DPzNuJqDpId-1.mp4
"Lab-grown gold is now a reality, and the implications are massive. @icedcoffeehour breaks down how scientists are synthesizing gold in laboratories using advanced chemical processes. This breakthrough could revolutionize industries from electronics to jewelry, potentially disrupting traditional gold mining forever. The technology mimics natural geological conditions but accelerates what normally takes millions of years into mere weeks.

#labgrowngold #sciencebreakthrough #futuretech #goldscience #innovation #scientificadvancement #techinnovation #goldproduction #sciencenews #futureofsustainability",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DQFYUsNEm7p-1.mp4
"The podcast world has a Democrat problem, and @icedcoffeehour breaks down exactly why the left keeps avoiding long-form conversations. While Republicans flood every mic available, something's keeping Democratic voices off the airwaves. This analysis cuts deep into the strategy (or lack thereof) behind who shows up and who stays silent.

#podcast #politics #democrats #republicans #podcastclips #icedcoffeehour #politicaltok #media #longform #podcasting #politicalpodcast #commentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DQkwu6QgTn_-1.mp4
"The math behind America's $37 trillion debt crisis just got explained in the simplest way possible by @icedcoffeehour—and it's wild how few people actually understand what's happening to the economy right now.

#debt #economy #finance #money #business #investing #stocks #entrepreneur #wealth #financially #success #motivation #stockmarket #trading #crypto #bitcoin #realestate #personalfinance #financialfreedom #investment #usa",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DQnENUAkorF-2.mp4
"The grind never stops when you're building an audience from scratch. While most people clock out at 5, content creators are just getting started—editing, engaging, and constantly showing up. @icedcoffeehour breaks down why streaming demands more than just turning on a camera.

#ContentCreator #Streaming #Streamer #ContentCreation #CreatorEconomy #DigitalCreator #StreamerLife #ContentCreators #OnlineCreator #CreatorCommunity #Hustle #SideHustle #Entrepreneur",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DQQC0hOEgR0-1.mp4
"The FBI just got called out by Eric Trump and the details are wild 👀

@icedcoffeehour captured this moment that has everyone talking about what's really going on behind the scenes.

#EricTrump #FBI #Trump #Politics #Viral #Trending #News #MAGA #Trump2024 #Conservative #Republican #TrumpFamily #Exposed",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DQnEPQVEqk7-1.mp4
"The wild story of how RJ Mitte landed the role that would define Breaking Bad's heart 🎬

Via @icedcoffeehour

#breakingbad #bettercallsaul #walterwhite #jessepinkman #bryanfcranston #aaronpaul #rjmitte #waltjr #breakingbadcast #breakingbadfan #bcs #tvtrivia #castingstory",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DQxw7JXCa-Z-2.mp4
"Amazon didn't just compete with brick-and-mortar stores—they systematically dismantled the entire model. This breakdown from @icedcoffeehour reveals the calculated strategy behind retail's biggest disruption.

#amazon #jeffbezos #business #entrepreneur #amazonfinds #amazonfba #businessstrategy #entrepreneurship #startup #onlineshopping #ecommerce #retail #businessgrowth #amazonseller",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRaW3r8EmbM-2.mp4
"Looking to stretch your Chipotle budget? There's a genius method that @icedcoffeehour breaks down that'll get you a loaded burrito for just $3. The secret is all in how you order. Worth trying next time you're craving that burrito bowl life without the premium price tag.

#chipotle #chipotlehack #foodhack #budgetfriendly #collegefood #cheapmeals #fastfoodhacks #moneysavingtips #chipotleburrito #foodtiktok #lifehacks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRaYlmtEnRS-1.mp4
"AI isn't going anywhere, and pretending it doesn't exist won't save anyone's job. @icedcoffeehour breaks down why burying your head in the sand is the worst career move you can make right now.

#AI #ArtificialIntelligence #CareerAdvice #TechTrends #FutureOfWork #CareerGrowth #ProfessionalDevelopment #WorkTips #CareerTips #TechCareer",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRkVGfACbkV-2.mp4
"The biggest names running the game right now 👀 @icedcoffeehour breaks down the top 3 CEOs dominating 2025

#ceo #business #entrepreneur #success #motivation #leadership #businessowner #entrepreneurship #mindset #money #startup #marketing #smallbusiness #goals #hustle #businessmindset #inspiration #motivationalquotes #successquotes #entrepreneurlife #millionaire #wealth #businesstips #growthmindset #businessman #financialfreedom #businessgrowth #leadershipdevelopment #businessstrategy #ceomindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRiFWnvEsQL-1.mp4
"The housing industry's biggest game-changer wasn't about helping families – it was about keeping the economy alive. @icedcoffeehour breaks down the real reason behind the 30-year mortgage that nobody talks about.

#mortgage #housingmarket #economy #realestate #financialliteracy #moneytok #economics #history #housing #homebuying #investing #finance #wealth #business",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRm-oVOj_d2-2.mp4
"ChatGPT's ad-free experience might not last forever, and the timeline could surprise you. @icedcoffeehour breaks down when we might start seeing ads appear on the platform and what that could mean for users.

#chatgpt #openai #ai #artificialintelligence #tech #technology #technews #aiadvertising #futureofai #digitalmarketing #techpodcast #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRSsa8QEk4z-2.mp4
"Los Angeles: dream city or cautionary tale? @icedcoffeehour tackles the question on everyone's mind as residents continue their mass exodus from the City of Angels. 🌴

#losangeles #california #LA #citylife #urbanplanning #costofliving #housing #podcast #interview #conversation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRYSBq2AeK4-2.mp4
"Ed Bolian's strategy for scoring Lamborghinis without breaking the bank might surprise you 👀

The secret? It's all about timing, market knowledge, and knowing exactly when to make your move. @icedcoffeehour breaks down how he's built an empire of exotic cars while keeping costs way lower than most people think possible.

This is the kind of insider knowledge that separates collectors from dreamers 🏎️

via @icedcoffeehour

#lamborghini #supercars #luxurycars #carmarket #edbolian #exoticcars #carcollector #lamborghinihuracan #luxurylifestyle #carbuying #investmentcars",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\icedcoffeehour\DRtEplXjpE9-1.mp4
"robertgreene believes that emotional resilience comes from embracing vulnerability, not avoiding it. In this conversation with @impacttheory, he breaks down why ""nice guy"" behavior backfires and reveals the real psychology behind attraction and influence.

#ImpactTheory #Relationships #emotionaldamage #lovehurts",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\C07T_-Qvkxu-1.mp4
"Jordan Peterson breaks down the connection between morality and religion while tackling some of today's most divisive topics. From the eternal battle of good vs Evil to Andrew Tate's influence, P*rn's impact on society, the Israel-Hamas conflict, and the crisis of Weak Men—this conversation with @impacttheory holds nothing back.

Full episode link in bio.

#impacttheory #jordanpeterson #men #morals #controversial",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\C4a96mmr4vI-2.mp4
"Chris Voss (@thefbinegotiator) breaks down the psychology behind what really drives people's decisions in his conversation on @impacttheory. These negotiation strategies aren't just theory—they're tools that actually shift outcomes when you need them most.
.
.
.
.
.
.
#impacttheory #tombilyeu #chrisvoss #negotiation #empoweryourself",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\CakXRirAYU_-1.mp4
"@gabbybernstein breaks down the art of staying calm under pressure in her latest conversation with @lisabilyeu. The NY Times bestselling author and spiritual coach shares practical wisdom on handling difficult people without losing yourself in the process. Don't miss this powerful Women of Impact episode from @impacttheory – full conversation available now through link in bio.

#WomenOfImpact #GabbyBernstein #SpiritualGrowth #PersonalDevelopment #InnerPeace #Mindfulness #SelfControl #EmotionalIntelligence #Boundaries #SpiritualCoach #NYTimesAuthor #PodcastEpisode #WomenEmpowerment #MentalStrength #Composure",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\CaZ2rvkAjMN-2.mp4
"The philosophy behind ""One More"" gets unpacked as @edmylett sits down with @impacttheory to break down the mindset that separates those who dream from those who achieve.

Full episode available now—link in bio.

#ImpactTheory #EdMylett #OneMore #Motivation #Mindset #Success #PersonalDevelopment #GrowthMindset #SuccessMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\CeOuOZ1j0QN-1.mp4
"Dr. Rangan Chatterjee (@drchatterjee) breaks down the science behind happiness on @impacttheory—and it's not what you think. According to him, feeling happy isn't about luck or circumstance. It's a trainable skill that anyone can develop with the right approach.

Full episode available now—link in bio.

#ImpactTheory #DrRanganChatterjee #HappinessSkills #MentalHealth #PersonalDevelopment #SelfImprovement #Mindset #Wellness #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\CfHLgkmDihs-2.mp4
"@minoritymindset just broke down something most employees don't want to hear—but need to. In his conversation with @impacttheory, Jaspreet Singh makes the case for why ownership beats a paycheck every single time, and how building equity creates wealth that a salary alone never will.

Full episode waiting at the link in bio.

#ImpactTheory #MinorityMindset #JaspreetSingh #BusinessOwnership #BuildingEquity #FinancialFreedom #WealthBuilding #Entrepreneurship #MoneyMindset #FinancialEducation #PassiveIncome #BusinessMindset #InvestInYourself",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\Ce1ZoGdppEX-2.mp4
"The fountain of youth isn't a myth—it's a science, according to @drkarafitzgerald's conversation with @tombilyeu on @impacttheory. When stress literally accelerates aging at the cellular level, understanding how to hit the biological ""pause button"" becomes essential. This Health Theory episode breaks down the research-backed methods for reversing age markers and extending your healthspan. Full episode streaming now on YouTube!

#HealthTheory #ImpactTheory #AntiAging #Longevity #BiologicalAge #HealthOptimization #Biohacking #WellnessJourney #HealthyAging #StressManagement #Epigenetics #LifeExtension #OptimalHealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\Capvg6MAo53-2.mp4
"Every woman scrolling right now needs to hear what @devonfranklin just dropped on Women of Impact 🎯 @lisabilyeu sits down with him for a conversation that's hitting different. The advice? Absolutely game-changing. Full episode is live - don't sleep on this one. 🔥

🎥 @impacttheory

#WomenOfImpact #DevonFranklin #RelationshipAdvice #EmpoweringWomen #PodcastClips #MotivationalContent #WomenEmpowerment #MustWatch #RelationshipGoals #LifeAdvice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\Ch7l4ESDbiD-2.mp4
"Rachel Hollis breaks down her playbook for bouncing back when everything falls apart. In this powerful Women of Impact conversation with Lisa Bilyeu, she's teaching exactly how to rebuild when life knocks you down. @impacttheory delivers the resilience masterclass you need right now—full episode available at the link in bio.

#WomenOfImpact #RachelHollis #Resilience #PersonalGrowth #SelfDevelopment #Mindset #Motivation #Inspiration #PodcastClips #LifeAdvice #MentalStrength #OvercomingAdversity #GrowthMindset #Empowerment #WomenEmpowerment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\CifWaXqD0sN-2.mp4
".@michael_saylor breaks down why property rights might be humanity's most critical asset—and where Bitcoin fits into protecting what you've built.

The MicroStrategy co-founder joins @impacttheory to explore wealth preservation strategies that actually work in today's economy.

Full conversation available through the link in bio.

#cryptonews #cryptotrading #bitcoin #decentralizedeconomy #propertyrights #recession",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\Ckyc7eFpzwB-1.mp4
"Graham Stephan @gpstephan breaks down the millionaire blueprint that actually works—and it's not what most people think. The Personal Finance Enthusiast & Real Estate Investor sat down with @impacttheory to reveal why YouTube and Real Estate are his top picks for building serious wealth.

Full episode link in bio.
.
.
.
.
.
#entrepreneurlife #hustlemidset #hustler #hustlelife #entrepreneurmindset #goalgetter #growthmindset #realestatetips #youtuber #youtubetips #REtips #realestateinvestment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\Cn5iUZNo9TO-2.mp4
"Looking for life advice you wish you'd learned earlier? @ryanholiday breaks down critical lessons men discover too late, straight from @impacttheory's vault.

Meanwhile, what's your take—is ""Sober January"" actually worth it?

#ryanholiday #impacttheory #masculinity #mensadvice #lifelessons #personalgrowth #selfimprovement #mindset #motivation #success #wisdom #soberjanuary #menshealth #mentaldevelopment #personaldevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\Cw3US-cyKin-2.mp4
"A 50% fertility crash isn't just a statistic—it's humanity's future hanging in the balance. @impacttheory sits down with leading Environmental and Reproductive Epidemiologist @drshannaswan, who breaks down the stark reality: we're heading toward guaranteed economic population collapse. The contributing factors? More alarming than most realize.

Full episode link in @impacttheory's bio.

#infertility #epidemiology #depopulation #populationcontrol",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\CsT0SELgMwk-2.mp4
"The education system might be failing an entire generation—@realcandaceowens didn't hold back when she sat down with @impacttheory to discuss why she believes society is being systematically dumbed down. Her take on declining intelligence among kids sparked serious conversation.

Drop your perspective in the comments below. Full episode available on YouTube through the link in profile.

#ImpactTheory #CandaceOwens #Education #Society #CriticalThinking #Podcast #Conversation #DeepTalk #Mindset #Truth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\DAd2DAXqumV-1.mp4
"A bold 5-year timeline just got put on the table by @impacttheory. The question isn't if America will fracture—it's whether that fracture comes through revolution or civil war. The clock is already ticking, and the cracks are showing. What side of history will we choose?

#impacttheory #civilwar #revolution #americanpolitics #politicaldebate #futureofamerica #society #culturalshift #freedomofspeech #criticalthinking #awareness #socialjustice #unity #division #politics #controversy #debate #freedom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\C_Jfcobh3O1-2.mp4
"PBD's verdict on Trump's performance? One word: ""Embarrassing...""

Watch the full perspective over at @impacttheory

#Trump #PBD #PatrickBetDavid #Politics #Leadership #BusinessPodcast #PoliticalCommentary #Analysis #ImpactTheory",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\impacttheory\DMix4R0tm9J-2.mp4
"The mind's greatest illusion? Thinking it's always on your side. @jayshetty breaks down the mental traps we fall into at his 2025 Princeton Commencement—drop a ""YES"" for the full speech in your DMs 👇

#JayShetty #Princeton #Commencement #MindsetMatters #Consciousness #SelfAwareness #Motivation #Inspiration #PersonalGrowth #MentalHealth #Wisdom #LifeLessons #Commencement2025",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DLH11zWsLlz-1.mp4
"@jayshetty sits down with @profgalloway to unpack the hard truths about today's economic reality — from millennials earning less than the generation before them to navigating money conversations in relationships without the drama. Comment ""YES"" to get the full episode in your DMs 💬

#JayShetty #ProfGalloway #MoneyTalk #RelationshipAdvice #FinancialWellness #MillennialMoney #HealthyRelationships #PodcastClips #RealTalk #MoneyMindset #GenerationalWealth #RelationshipGoals #CouplesMoney #FinancialLiteracy #ModernRelationships",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DLIRV9dMVSy-1.mp4
"Watch @jayshetty bring out pure wisdom from these incredible minds 🎙️✨ Each conversation hits different – which one speaks to you? Drop it below 👇

Full episodes available everywhere you listen 🎧

Featuring insights from @naraaziza @itsbennyblanco @michaelbjordan @rickrubin @africabrooke @j_corden @orlandobloom

#jayshettypodcast #onpurpose #podcast #wisdom #inspiration #personalgrowth #mindfulness #lifecoach #motivation #podcastclips #selfimprovement #consciousness #authenticity #purpose #mindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DMkiiEGRGph-2.mp4
"Jay Shetty (@jayshetty) breaks down why feeling ""stuck"" might actually be something deeper during his conversation with Mel Robbins. It's not about being trapped—it's about processing who you used to be. Drop a ""YES"" if this perspective shifts something for you 👇❤️

#jayshetty #melrobbins #personalgrowth #selfawareness #healing #mindset #transformation #lettinggo #growth #mentalhealth #selfdiscovery #wisdom #motivation #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DN28VJr3HwF-1.mp4
".@jayshetty brings wisdom from Imam Al-Shafi'i that hits different: What missed you was never for you and what is for you will never miss you ❤️ Tag someone who's been holding onto what wasn't meant to be 🙏

#jayshetty #wisdom #perspective #lettinggo #trust #faith #islamicwisdom #imamshafii #mindset #healing #motivation #spirituality #lifelessons #growthmindset #trusttheprocess",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DMsQ3IvPi5l-1.mp4
"Jay Shetty (@jayshetty) reminds us that running from pain only prolongs it—true healing starts when we stop resisting and start accepting ❤️ Drop a ""YES"" if this resonates 👇

#jayshetty #healing #emotionalhealth #mentalwellness #personalgrowth #selfawareness #mindfulness #innerpeace #healingjourney #growthmindset #mindsetshift #emotionalintelligence #selfgrowth #mentalhealthmatters #selflove #awakening #consciousness #wisdom #lifecoach #motivation #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DM-SccIsk7V-2.mp4
".

@jayshetty couldn't resist sharing this gem of @radhidevlukia 😍😂

#love #couplegoals #funny #relatable #marriage #relationships #marriedlife #couplecomedy #husbandwife #relationshipgoals",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DOvlXVKgMHf-2.mp4
"A moment @jayshetty can't forget: meeting Kim and her guide dog Emily at his NYC live show earlier this year 🙏 The connections he makes with his audience and the stories they share are what make it all worthwhile ❤️ Drop a ❤️ if this touched you

#jayshetty #motivation #inspiration #guidedogsofinstagram #guidedog #meaningfulmoments #connection #nyc #liveshow #gratitude #storytelling #community",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DO0vDjzDi29-2.mp4
"Jay Shetty (@jayshetty) breaks down why protecting your energy doesn't mean closing yourself off 🔑

The balance? Being intentional about who shapes your closest circle while staying curious enough to learn from diverse perspectives. It's not about building walls—it's about knowing when to open the door and when to guard your peace.

Drop a ""YES"" if you want the full podcast in your DMs where he unpacks everything he wishes he knew before 30 ❤️

#jayshetty #personalgrowth #boundaries #energyprotection #innercircle #mindset #selfawareness #consciousness #wisdom #podcast #lifecoach #motivation #inspiration #wellbeing #mentalhealth #personaldevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DO8darDDmQN-1.mp4
"Jay Shetty (@jayshetty) and Radhi can't escape this question no matter where they go 😂😂

#jayshetty #relationships #couplegoals #marriage #love #relatable #couplehumor #marriedlife #funny",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DQ9UC8mDpOm-1.mp4
"When @jayshetty dropped this truth bomb, it hit different 💭 That thing that irritates you most about someone else? There's a chance it's reflecting something within you that needs acknowledgment. The mirror doesn't lie—it just shows us what we're ready to see 👁️

#jayshetty #selfreflection #personalgrowth #selfawareness #mindfulness #consciousness #innerwork #spiritualawakening #growthmindset #selfimprovement #wisdom #lifecoach #mentality #perspective #awakening",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DOiuD4JjnmM-1.mp4
"A legendary late-night host gets real about rejection, anxiety, and staying true to yourself 💭

@jayshetty sits down with @jimmykimmel at the Greek Theatre in LA for an episode that starts with roasts and ends with raw honesty.

Between the laughs, Jimmy shares stories most people never hear: getting fired repeatedly before finding success, battling anxiety behind the scenes, navigating marriage and therapy, and how becoming a grandfather changed everything.

They dive into the pressure of fame, the weight of everyone wanting a piece of you, and what it actually takes to stay authentic when the spotlight never turns off.

This one hits different. 🎙️

🎧 Full episode at LINK IN BIO or search 'On Purpose Jimmy Kimmel' on YouTube

Drop a ""YES"" below if you want this episode sent to your DMs 👇

#JayShetty #JimmyKimmel #OnPurposePodcast #PodcastEpisode #MentalHealthMatters #AuthenticSelf #LifeLessons #DeepConversations #Anxiety #PersonalGrowth #SelfDevelopment #Mindfulness #Therapy #RealTalk #BehindTheScenes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DNS4w03Mzy7-2.mp4
".@jayshetty shares his gratitude for the overwhelming response to his conversation with @emmawatson ❤️ The episode is available now across all platforms - simply search 'Jay Shetty Emma Watson' to dive in 🙏

#JayShetty #EmmaWatson #OnPurpose #Podcast #Inspiration #Motivation #PersonalGrowth #SelfDevelopment #Mindfulness #WisdomWednesday #PodcastRecommendation #MustListen",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DPRDyP4ji76-1.mp4
"@jayshetty's conversation with @iamcardib continues to resonate with millions 🎙️ There's a reason this episode keeps showing up on everyone's feed - the insights are pure gold ✨ Drop a ""YES"" in the comments and he'll send you the complete interview 👇 Trust us, you don't want to skip this one 🔥

#JayShetty #CardiB #Podcast #OnPurpose #Inspiration #Mindfulness #SelfGrowth #PersonalDevelopment #Motivation #PodcastClips #DeepConversations #RealTalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DPy9kwgDgSo-1.mp4
"This one hit different 💭 @jayshetty breaks down why self-betrayal affects everyone around you—not just yourself. Real love starts with honoring who you are ❤️

Drop a ""YES"" if this perspective shifted something for you 👇

#jayshetty #selflove #boundaries #personalgrowth #selfrespect #mindfulness #healingjourney #emotionalhealth #selfworth #authenticity #mentalhealthmatters #growthmindset #selfcare #innerwisdom #relationshipgoals",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DPjF619jsKy-2.mp4
"Drop this in someone's DMs who needs to hear it today 💫 Jay Shetty (@jayshetty) breaks down the small moments we forget to appreciate when life gets overwhelming ✨

#jayshetty #motivation #mindfulness #dailyreminder #gratitude #positivevibes #selflove #mentalhealthmatters #inspiration #lifecoach #wisdom #personalgrowth #mindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DRHnKd_jiQY-2.mp4
"@jayshetty reminds us that the destination stays the same—it's just the journey that surprises you 💫 Life has a way of getting you there through unexpected detours and plot twists you never saw coming.

Drop a ""YES"" if this resonates 👇

#jayshetty #lifelessons #mindsetshift #personalgrowth #motivationmonday #wisdomwednesday #inspirationalquotes #mindfulness #selfgrowth #dailyinspiration #positivevibes #personaldevelopment #growthmindset #successmindset #lifequotes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DQ_4w75ju7M-1.mp4
"When the mind becomes a maze instead of a sanctuary, @jayshetty sits down with @emonthebrain to decode the neuroscience of breaking free.

Emily McDonald—neuroscientist, @mindcraft founder, and the viral educator transforming how millions understand brain rewiring—reveals the mechanisms behind self-sabotage and the pathways to genuine transformation.

This conversation unpacks:

• The neurological reasons your brain fights against desired change
• Techniques for reprogramming limiting subconscious beliefs
• Real science behind ""manifestation"" beyond the buzzwords
• Breaking the cheap dopamine cycle for authentic fulfillment
• Micro-habits that physically rewire your brain toward clarity and peace

🎧 Search On Purpose Emily McDonald on your favorite podcast platform or watch the full episode on YouTube — LINK IN BIO

#OnPurposePodcast #JayShetty #Neuroscience #MentalHealth #SelfGrowth #BrainScience #PersonalDevelopment #Mindfulness #SelfImprovement #PodcastRecommendation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DQmIz7MjgkF-1.mp4
"Ever wonder what a divorce lawyer would tell you *before* you need one? @jayshetty sat down with James Sexton (@nycdivorcelawyer) — a top divorce attorney who's seen it all — to unpack the patterns that quietly unravel relationships before couples even notice.

This conversation goes deep into the daily behaviors that erode intimacy, the real stats on what ends marriages (it's rarely what you think), and the simple practice that could save your relationship before it's too late.

Inside this episode:

• What actually destroys relationships (spoiler: cheating isn't #1)
• Small behaviors that quietly disconnect couples
• Why long-term partners become invisible to each other
• Eye-opening truths about divorce and remarriage
• How to catch disconnection early
• A weekly ritual every couple needs
• Why choosing love takes real courage

🎧 Search On Purpose James Sexton on your favorite podcast platform or watch on YouTube — LINK IN BIO

Comment ""LOVE"" and get the episode sent straight to your DMs 👇

#RelationshipAdvice #MarriageTips #DivorceLawyer #LoveAndRelationships #HealthyRelationships #CoupleGoals #RelationshipGoals #ModernLove #OnPurposePodcast #JamesSextonDivorce #RelationshipPodcast #MarriageAdvice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jayshetty\DRcNgoQDrSD-1.mp4
"@jockowillink breaks down the paradox of time management: you'll never control the clock, but you can always stay ahead of it.

The strategy? Ruthless prioritization. Every task must serve your mission's goals. Then execute sequentially—highest priority first, no exceptions.

What separates good leaders from average ones is the ability to see around corners. They anticipate obstacles before they appear and have contingency plans mapped out before problems strike.

#leadership #discipline #timemanagement #priority #execution #planning #leadershipdevelopment #missionfirst #strategy #mindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DIl0Xp_Kr-2-2.mp4
"The weight women carry isn't always visible—and that's exactly why @jockowillink says real protection goes beyond the physical. From questioning their safety in parking lots to being conditioned since childhood that they're somehow not enough, the women in our lives navigate pressures most men never consider. True strength means building an environment where wives and daughters don't just survive these realities—they thrive beyond them, feeling genuinely secure, valued, and understood.

🎥 @jockowillink Podcast Episode 477

#TheManTheMomentDemands",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DHZPC2IJfv2-1.mp4
"The battle isn't against the world—it's against the person staring back at you in the mirror. @jockowillink breaks down why ""You vs. You"" is the only competition that truly matters. Your real opponent? The version of yourself that chooses comfort over growth.

April 14 to May 15: One goal. One plan. Daily execution.

Drop YOU in the comments for the complete framework and your free habit tracker to dominate this challenge.

#discipline #youchoose #jockowillink #disciplineequalsfreedom #selfimprovement #mindset #motivation #personaldevelopment #goals #execution #winning #dailyhabits #accountabilty #consistency #mentalstrength",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DIbmDaEJVVq-1.mp4
"The Nock On Nation brought unprecedented energy to NOCKSTOCK 25, delivering an unforgettable experience that @jockowillink and the entire crew witnessed firsthand. When passion meets precision, this is what happens. @ben_gallaher @originusa @jockofuel @hoytbowhunting @eastonarchery @totalarcherychallenge @leupoldoptics @yeti @teamqad @g5outdoors @montanaknifecompany

#NockOn #NockStock #Bowhunting #Archery #OriginUSA #JockoFuel #HoytArchery #EastonArchery #LeupoldOptics #YETI #Outdoors #HuntingLife #ArcheryLife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DKnp3p6pPYW-2.mp4
"@jockowillink and his team connected with Ethan after the community rallied to help get them in touch. The roadmap is set, the goals are clear, and now the real work begins. Ethan's journey proves what's possible when people show up for each other. This is only the beginning.

JOCKOFUEL.COM

#discipline #motivation #jockopodcast #jockofuel #getafterit #leadership #mindset #transformation #goals #community",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DK-GbrLpfqo-1.mp4
"@jockowillink refuses to let his immune system fight alone. Cold War from JOCKOFUEL.COM is his tactical advantage when the body needs reinforcements. This isn't passive defense—it's an aggressive counterstrike against anything trying to take you down.

#jockopodcast #jockowillink #discipline #immunesupport #coldwar #jockofuel #leadership #noexcuses #getafterit #warriormindset #supplementstack #immuneboost #stayhealthy #tacticalnutrition",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DMvoUsHPCUG-1.mp4
"When doubt creeps in, the answer isn't to push harder — it's to zoom out. @jockowillink breaks down why your perspective determines your confidence level, and how creating mental distance from your problems might be the exact strategy you need to overcome them. Real confidence isn't built in the comfort zone.

#jockopodcast #jockowillink #confidence #mindset #discipline #motivation #selfimprovement #personalgrowth #mentalstrength #leadership #successmindset #motivationalquotes #inspirationalquotes #disciplineequalsfreedom #selfmastery #growthmindset #mentaltoughness #perspective",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DLaJL5GOzE--1.mp4
"What separates a fleeting moment from a lifetime of fulfillment? @jockowillink breaks it down: chase what brings lasting happiness, not just instant gratification. Embrace the grind that pushes you today—because that's where real growth lives. The path forward is clear.

#JockoWillink #Discipline #LongTermThinking #GrowthMindset #DisciplineEqualsFreedom #Motivation #ChallengeYourself #MindsetMatters #WarriorMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DNyJs85YpUn-2.mp4
"Another week, another opportunity to dominate. @jockowillink reminds us that Monday isn't the enemy—it's the launchpad. Time to attack. 

JOCKOFUEL.COM

#monday #motivation #discipline #jockowillink #leadership #mindset #goagain #getafterit #extremeownership",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DPeTfC-kZQg-2.mp4
"When duty calls, @jockowillink never forgets those who answered. A powerful Veterans Day message honoring the warriors who serve beyond the calendar, beyond the spotlight, beyond the headlines. Their mission never stops—and neither does his gratitude.

#VeteransDay #Veterans #Military #Service #JockoWillink #Leadership #Sacrifice #ArmedForces #Warrior #NeverForget #DutyFirst",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DQ7BDBEFANU-2.mp4
"Inside a cockpit versus boots on the ground – two completely different wars. @jockowillink and Task Unit Bruiser were among the American servicemembers who showed what true leadership looked like in 115-degree heat, hauling 100 lbs. of gear through enemy territory where bullets, mortars, and bombs became the soundtrack of survival. Those combat operations forged lessons that demanded to be shared. Discover them all in The Need to Lead – the next installment of the Extreme Ownership Series. www.daveberke.com

#leadership #extremeownership #military #veterans #combat #navy #navyseals #jockowillink #taskunitbruiser #militaryleadership #combatleadership #warfighter #operator #specialoperations #TeamGuy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DO8_GbTifOB-2.mp4
"When the water's cold and your mind's screaming no, remember what @jockowillink teaches: the shock only hits once, then you're already in. Stop negotiating with weakness and dive.

#jocko #jockopodcast #discipline #motivation #getafterit #gogetsome #coldplunge #mindset #mentalstrength #stayhot #discipline #gogetsome",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DQmg-7-D0WC-1.mp4
"When leaders gather, missions get accomplished. @jockowillink brings together The Muster—where @echelonfront transforms how teams operate under pressure.

#TheMuster #EchelonFront #Leadership #ExtremeOwnership #DisciplineEqualsFreedom #LeadershipDevelopment #TeamBuilding #Military #Navy #SEALs #Business #Management #JockoWillink",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DQo-wJRiQ1g-1.mp4
"When the mission depends on every decision, here's how elite warriors think about leadership. @jockowillink breaks down the principles that keep SEAL teams alive and successful in the most hostile environments on Earth.

#navyseals #motivation #wisdom #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DRnMs-ziU1_-2.mp4
"When leaders stumble, they don't hide—they teach. Dave Berke's The Need to Lead shows how turning your failures into lessons is what separates those who lead from those who follow. Real growth happens when you own what went wrong and share it with your team. Another powerful addition to the Extreme Ownership Series from @jockowillink that proves falling down is part of the process, but staying down isn't an option.

#ExtremeOwnership #Leadership #TheNeedToLead #DaveBerke #LeadershipDevelopment #TakeOwnership #LeadershipLessons #GrowthMindset #TeamLeadership #LeadByExample",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DQFc4EvkScr-2.mp4
"When comfort becomes the enemy of progress, warriors like @jockowillink remind us that adapting to ease is the fastest path to weakness. Your surroundings will try to coddle you—refuse to let them win.

JOCKOFUEL.COM

#discipline #motivation #jockowillink #mindset #warrior #grind #nevergiveup #stayhard #mentaltoughness #noexcuses #getafterit #gogetsome",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DQ4gdVAjwrc-1.mp4
"The struggle isn't just physical—it's mental, emotional, and spiritual too. Every level tests you differently. @jockowillink breaks down why the path demands everything from you.

#discipline #motivation #jockopodcast #jockopodcast #echelonfront #thepath #mindset #leadership #growth #mentaltoughness #warriormindset #nevergiveup #extremeownership",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jockowillink\DRxJIgaFKjS-1.mp4
"@joeroganexperience sits down with award-winning actor, director, producer, and screenwriter Mel Gibson in episode 2254. Gibson's latest directorial project ""Flight Risk"" hits theaters January 24, starring Mark Wahlberg. @flightriskmovie

www.flightrisk.movie

#JoeRogan #JRE #MelGibson #FlightRisk #MarkWahlberg #Podcast #JoeRoganPodcast #JoeRoganExperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DEnmL6UTvMd-2.mp4
"Andrew Schulz sits down with @joeroganexperience in episode 2285 to talk comedy, life, and everything in between. The multi-talented comic brings his unfiltered energy from hosting ""Flagrant"" with Akaash Singh and ""Brilliant Idiots"" with Charlamagne Tha God. Catch his upcoming Netflix special ""Life"" dropping March 4.

#jre #joerogan #joeroganpodcast #andrewschulz #standupcomedy #comedy #podcast #flagrant #brilliantidiots #netflix #comedyspecial #comedian",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DG3q-8oycB9-2.mp4
"Netflix just dropped ""American Primeval"" and director Peter Berg (@pberg44) pulled up to break it all down with @joeroganexperience on episode 2280. The writer-director-producer shares the vision behind his latest series in this conversation.

https://www.netflix.com/title/81457507

#JoeRogan #JRE #PeterBerg #AmericanPrimeval #Netflix #Director #FilmMaking #Producer #Podcast #JoeRoganPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DGliHHzynmG-2.mp4
"Three powerhouse comedians walked into @joeroganexperience for Episode 2236, and the result was pure chaos. @shanemgillis brings his Matt and Shane's Secret Podcast energy alongside Matt McCusker, plus his Gilly and Keeves sketches with John McKeever—catch his Netflix series ""Tires"" and special ""Beautiful Dogs."" @marknormand keeps the laughs rolling from his Tuesdays with Stories podcast with Joe List and We Might Be Drunk with Sam Morril, with his ""Soup to Nuts"" special streaming now. @arishaffir rounds out the trio as host of You Be Trippin' podcast, with his special ""Ari Shaffir: Jew"" live on YouTube. All three comics bringing their A-game to the JRE studio.

#jre #joerogan #joeroganpodcast #standup #standupcomedy #comedy #podcast #comedypodcast #shanemgillis #marknormand #arishaffir",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DC7zL29SfIE-1.mp4
"Warren Smith—educator and the mind behind Secret Scholars on YouTube—sits down for episode 2261 with @joeroganexperience to explore the mysteries that challenge conventional thinking.

https://www.youtube.com/@SecretScholars

#JoeRogan #JRE #WarrenSmith #SecretScholars #Podcast #Education #Mystery #History #Knowledge #Learning",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DFLmzCUTtK3-2.mp4
"The wilderness has stories to tell, and Steven Rinella knows them all. Fresh off announcing his latest project ""MeatEater's American History: The Mountain Men (1806-1840)"" dropping February 11, 2025, the @meateater host and conservationist sits down with @joeroganexperience for episode 2258. Rinella's also bringing history to life with ""Hunting History With Steven Rinella"" premiering on HISTORY January 28. For the outdoorsman who turns every expedition into education, check out www.themeateater.com

#JoeRogan #JRE #StevenRinella #MeatEater #Podcast #HuntingHistory #Conservation #Outdoorsman #AmericanHistory #MountainMen",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DE5oSeHzUjb-1.mp4
"@joeroganexperience sits down with Robert Rodriguez, the filmmaker behind Troublemaker Studios and Brass Knuckles Films. Rodriguez's work spans from ""Desperado"" to ""From Dusk Till Dawn"" and ""Machete"" – a director, producer, and screenwriter who's built his own creative empire. Episode 2310 🎬

www.brassknucklefilms.com

#JoeRogan #JRE #JoeRoganPodcast #JoeRoganExperience #Podcast #RobertRodriguez #Film #Director #Hollywood #Filmmaker #Cinema",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DI1qD45vbD8-2.mp4
".@joeroganexperience sits down with NFL legend @aaronrodgers12 for episode 2325 — the four-time MVP and Super Bowl champion who's cemented his legacy as one of football's greatest quarterbacks. From his historic run with the Green Bay Packers to his time with the New York Jets, Rodgers ranks among the all-time elite in both career passing touchdowns and passer rating.

https://www.nvcf.org/aaron-rodgers-norcal-recovery-fund

#JoeRogan #JRE #AaronRodgers #NFL #GreenBayPackers #NewYorkJets #SuperBowl #Quarterback #Football #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DJ7gyhozx2M-1.mp4
"The fitness powerhouse behind ""The Biggest Loser"" sits down with @joeroganexperience in episode 2313. Jillian Michaels brings her expertise as a certified nutritionist, author, and host of ""Keeping It Real: Conversations with Jillian Michaels"" to discuss what really matters in health and wellness. From transforming lives on ""Losing It With Jillian"" to her current work, she's built a career on no-nonsense fitness truth.

#JillianMichaels #JoeRogan #JRE #JoeRoganPodcast #JoeRoganExperience #Fitness #Nutrition #TheBiggestLoser #FitnessExpert #Health #Wellness #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DJFmBPwzDog-2.mp4
"Jimmy Carr joins @joeroganexperience for episode 2326, bringing his razor-sharp wit and dark humor to the conversation. The comedian, writer, and television host's latest Netflix special ""Jimmy Carr: Natural Born Killer"" showcases exactly why he's one of the most provocative voices in comedy today. Catch him live on tour this year at www.jimmycarr.com

#jimmycarr #joerogan #jre #joeroganpodcast #comedy #standup #netflix #comedian #podcast #jreclips #joeroganexperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DJ9ywJ7ShIR-1.mp4
"A sit-down with Texas State Representative James Talarico (@jamestalarico), who represents District 50 in the Texas House. @joeroganexperience dives into conversation with the Democratic lawmaker in episode 2352.

www.jamestalarico.com

#JoeRogan #JRE #JoeRoganExperience #JoeRoganPodcast #Podcast #JamesTalarico #Texas #Politics #TexasPolitics #Democrat #StateRepresentative",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DMQl5NCS0zV-2.mp4
"A profound conversation about transformation and freedom with @shakasenghor on @joeroganexperience • Episode 2353 features the writer, entrepreneur, and resilience expert who spent 19 years behind bars for murder and emerged to help others break free from their own invisible chains. His upcoming book ""How to Be Free: A Proven Guide to Escaping Life's Hidden Prisons"" drops September 9 • www.shakasenghor.com

#JoeRogan #JRE #ShakaSenghor #Podcast #Transformation #SecondChances #Resilience #PersonalGrowth #Freedom #NewBook #Entrepreneur #Writer #LifeLessons",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DMbE9MohIOD-2.mp4
"Ralph Barbosa sits down with Joe Rogan (@joeroganexperience) to talk comedy, life, and everything in between. The rising comic is taking over with his new special ""Ralph Barbosa: Planet Bosa"" dropping August 8th on Hulu. Catch him bringing the heat on his ""Bean Without A Cause"" theater tour. 🎤 @ralphbarbosa03

Tour dates: www.barbosacomedy.com

#JoeRogan #JRE #RalphBarbosa #Podcast #Comedy #StandUpComedy #Comedian #PlanetBosa #Hulu #JoeRoganExperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DNGza9aycdY-1.mp4
"Episode 2338 brings evolutionary molecular biologist Beth Shapiro, Ph.D. to @joeroganexperience for a deep dive into human innovation and nature. As Chief Science Officer @itiscolossal Colossal Biosciences and author of ""Life as We Made It: How 50,000 Years of Human Innovation Refined―and Redefined―Nature,"" she breaks down the incredible ways we've shaped the natural world.

https://www.hachettebookgroup.com/titles/beth-shapiro/life-as-we-made-it/9781541644151

https://colossal.com/team/beth-shapiro-ph-d/

#JoeRogan #JRE #JoeRoganPodcast #JoeRoganExperience #Podcast #BethShapiro #Science #Evolution #Biology #Nature #HumanInnovation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DLA76_JzLxp-2.mp4
"Business titan Elon Musk sits down with @joeroganexperience in Episode 2404 to discuss his groundbreaking ventures spanning Tesla's electric vehicle revolution, SpaceX's private spaceflight missions, Neuralink's brain-computer interface technology, X, and his broader vision for humanity's future. The designer and engineer's multifaceted empire continues pushing boundaries across multiple industries.
https://x.com/elonmusk

#JoeRogan #JRE #JoeRoganExperience #ElonMusk #Tesla #SpaceX #Neuralink #podcast #podcasting",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DQe64W9EnSp-1.mp4
"Jeff Dye brings the laughs to the JRE studio in episode 2410 🎙️ The comic, actor, and ""Dye Hard with Jeff Dye"" podcast host sits down with @joeroganexperience to chop it up. Catch his latest special ""The Last Cowboy in LA"" streaming now on YouTube – link in his bio at www.jeffdye.com

#JoeRogan #JoeRoganExperience #JRE #JREPodcast #JoeroganPodcast #Podcast #Comedy #StandUp #JeffDye",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DQ-BF4tEhbh-2.mp4
"Gregg Braden joins @joeroganexperience to explore humanity's hidden potential in this thought-provoking conversation. The renowned author and scientist discusses key insights from ""Pure Human: The Hidden Truth of Our Divinity, Power, and Destiny"" — diving deep into what it truly means to be human. Episode 2387 delivers another powerful dialogue you won't want to miss.

www.greggbraden.com

#JoeRogan #JRE #GreggBraden #PureHuman #JoeRoganPodcast #JoeRoganExperience #Podcast #Consciousness #Science #Spirituality #HumanPotential",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DPR7bAAj5Kt-1.mp4
"Mark Kerr's incredible journey from the octagon to Hollywood gets the spotlight as @joeroganexperience welcomes the legendary fighter whose life story captivated A24 enough to create ""The Smashing Machine"" - a feature film directed by Benny Safdie with Dwayne Johnson bringing Kerr's story to the big screen this October 3, 2025. The retired mixed martial artist and wrestler opens up in episode 2384.

www.markkerr.com
@markkerrtsm

#JoeRogan #JRE #MarkKerr #TheSmashingMachine #MMA #Wrestling #A24 #DwayneJohnson #BennySafdie #Podcast #MixedMartialArts",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DPCM1FHD-6a-1.mp4
"Tim Dillon sits down with @joeroganexperience in episode 2375 to discuss everything from comedy to culture. The stand-up comic, actor, and host of ""The Tim Dillon Show"" podcast brings his signature perspective to the conversation. Catch his latest Netflix special ""Tim Dillon: I'm Your Mother"" now streaming. 
www.timdilloncomedy.com

#JoeRogan #JRE #TimDillon #StandUpComedy #Podcast #Comedy #Netflix #TheJoeRoganExperience #JoeRoganPodcast #Comedian #TimDillonShow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\joeroganexperience\DOMISsmj9C4-2.mp4
"The relationship between challenge and personal growth gets dissected here—raw truth that hits different. @jordanbpetersonfans brings the perspective that makes you rethink everything.

#jordanpeterson #inspired #speaktruth #hardship #difficulty #challenge",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DHEZBPltXT_-1.mp4
"When the meat-only lifestyle becomes more than just a diet—it becomes an identity. This journey into carnivore living shows what happens when someone fully commits to the path.

Credit: @jordanbpetersonfans

#carnivore #carnivorediet #carnivorelifestyle #carnivorelife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DHBxQNcNG0d-2.mp4
"The question that's dividing the comments section right now ⚡

What's your take on jordan.b.peterson's perspective here? Drop your thoughts below while @jordanbpetersonfans keeps bringing these thought-provoking moments to the feed 👇

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #motivationday #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #orderandchaos #order #societyfeelings #jordanpetersononsociety #bookstagram #motivationday",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\C-lJw_DyrZJ-2.mp4
"His perspective challenges conventional thinking – but does the logic hold up? @jordanbpetersonfans brings this thought-provoking moment that's sparking debate in the comments.

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #motivationday #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #orderandchaos #order #societyfeelings #jordanpetersononsociety #bookstagram #motivationday",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DIagatFS8EY-1.mp4
"The wisdom drops hard when jordan.b.peterson breaks it down like this. @jordanbpetersonfans consistently delivers these powerful moments that make you stop scrolling and actually think. Worth a watch.

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DJitCeJSCtN-1.mp4
"The question lingering in everyone's mind after hearing this perspective. What's your take on jordan.b.peterson's viewpoint here?

Credit: @jordanbpetersonfans 

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DJ2NZMaTVpb-2.mp4
"The weight of his words always hits different when you really listen. Jordan B. Peterson breaks down truth in a way that makes you reconsider everything. 

@jordanbpetersonfans brings these powerful moments to your feed daily 🔥

What's your take on this perspective?

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DJfHdM9TSZq-1.mp4
"The uncomfortable truth that's making people rethink everything they thought they knew. @jordanbpetersonfans brings the conversations that matter most.

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DJPrCm8z92w-2.mp4
"The question isn't whether you agree—it's whether you're ready to hear it. jordan.b.peterson breaks down what most won't say out loud.

Credit: @jordanbpetersonfans

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DJvjNTxuR4W-2.mp4
"Jordan Peterson's perspective cuts through the noise—but does his argument hold up under scrutiny?

🔥 @jordanbpetersonfans brings you the thought-provoking moments that challenge conventional thinking

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DKJJkD3SyEh-2.mp4
"The psychology professor's perspective cuts through the noise—but does his take resonate with you?

Credit to @jordanbpetersonfans for bringing this moment to light 🔥🔥

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #motivationday #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #orderandchaos #order #societyfeelings #jordanpetersononsociety #bookstagram #motivationday",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DJGLrWbI_ZO-1.mp4
"The perspective shared here by jordan.b.peterson has viewers split down the middle—some nodding in agreement, others ready to debate. Where does this account stand on his take?

Credit to @jordanbpetersonfans for consistently sharing thought-provoking moments like this one.

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #comedyreels #automobile",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DJKtivRTcxC-1.mp4
"The question isn't whether you agree—it's whether you're ready to hear it. Jordan B. Peterson cuts through the noise once again.

Thought-provoking content courtesy of @jordanbpetersonfans ⚡

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DKXlPg_z1FO-2.mp4
"The psychological insights shared here from jordan.b.peterson continue to spark important conversations about personal responsibility and truth-telling. This perspective challenges viewers to examine their own relationship with honesty and accountability in daily life.

Credit to @jordanbpetersonfans for consistently sharing these thought-provoking moments that resonate with those seeking meaningful self-improvement.

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DKXeWgbyW5u-1.mp4
"The question isn't whether you agree—it's whether you're ready to hear it. Jordan B. Peterson delivers another perspective that challenges conventional thinking.

What's your take on this? Drop your thoughts below.

Content courtesy of @jordanbpetersonfans 

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DKXlPg_z1FO-1.mp4
"The comment section is about to get interesting after this one from jordan.b.peterson 👀

@jordanbpetersonfans bringing the heat with clips that make you think twice about everything

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DMk8R_OSBv7-2.mp4
"The way jordan.b.peterson breaks down complex ideas into digestible wisdom never gets old. This perspective hits differently when you really sit with it.

Credit to @jordanbpetersonfans for consistently sharing these powerful moments 💯

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DLWV6JxSrMp-2.mp4
"The perspective shared here challenges conventional thinking in ways that spark necessary conversations. jordan.b.peterson breaks down complex ideas into digestible wisdom that forces viewers to examine their own beliefs and behaviors.

Credit to @jordanbpetersonfans for consistently sharing these thought-provoking moments that get people talking.

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DMoCxfdzFXn-1.mp4
"The question isn't whether you agree—it's whether you're willing to sit with the discomfort of what jordan.b.peterson just laid out. This perspective challenges the comfortable narratives most people cling to.

Credit: @jordanbpetersonfans

#jordanpeterson #jordanpetersonquotes #jordanbpeterson #jordanbpetersonquotes #psychology #lifelessons #tellthetruth #tellthetruthtuesday #speaktruth #speaktruthtopower #12rulesforlife #12morerulesforlife #societyfeelings #jordanpetersononsociety #bookstagram #googleads #marketingdigital #personality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\jordanbpetersonfans\DMLo4iCSz_y-1.mp4
"@legionofskanks drops Part 1 of their two-part crowd work special that's bringing it back. Filmed live in Denver—THEM. hits YT Feb 20.

Director: @salacuse 
VO: @dansoder 
Editor: @anthony.verderame.edit 
Producer: @ginivisigram

#comedy #crowdwork #special",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DGD_4xyvgfp-2.mp4
"When Bryce Mitchell starts talking, you know it's going to get wild 😳

Catch @legionofskanks dropping absolute gems like this—@wolfmate & @timbutterly are hitting the show TONIGHT at 8PM E for an all new episode exclusively on @gasdigital 🔥

Want full access? Set up your #GaSDigital profile with promo code LOS for the discount ‼️

#LegionOfSkanks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DFqd7MhSo5F-1.mp4
"Mark your calendars for November 14th-16th, 2025 because New Orleans is about to host the most massive Skankfest in history 🎭 @legionofskanks just dropped the official lineup and it's absolutely stacked. General admission tickets drop May 2nd at 1pm ET exclusively at skankfest.com - set those reminders now 📲

#skankfest #skankfestnola #standupcomedy #comedy #neworleans #nola #comedyfestival #livecomedy #standup #comedians #podcasts #legionofskanks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DIkQayQNb_B-1.mp4
"@legionofskanks dives into Big Jay Oakerson's estate planning and it gets wild 💀💵

ALL NEW #LegionOfSkanks w/ @columtyrrell @arishaffir @steverannazzisi @ryanoneillcomedy and MORE premieres at 2PM E! Link in bio‼️",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DLIXvKsAYS7-1.mp4
"When Tim Dillon sits down for dinner with RFK, you know the stories are going to be wild 🍽️ @legionofskanks brings the receipts

#TimDillon #RFK #Comedy #Podcast #StandUpComedy #Comedian #Funny #PodcastClips #ComediansOfInstagram",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DLoKYkVtj9h-2.mp4
"The Rogansphere has claimed new visitors 🛸🙏🏼

@legionofskanks brings this moment from JRE 2339

Catch ALL NEW #LegionOfSkanks dropping every Tuesday at 8PM E exclusively on @gasdigital

Use promo code LOS when you create your profile for discounted full access‼️",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DLDjREwS7zX-2.mp4
"Shane's SNL crush confession has everyone talking 👀 @legionofskanks captures the moment he spills the details on who caught his eye during his time at Studio 8H. Sometimes the backstage stories hit different than what makes it to air.

#ShaneGillis #SNL #LegionOfSkanks #SaturdayNightLive #StandUpComedy #ComedyPodcast #PodcastClips #BehindTheScenes #SNLCast #ComedyCommunity #StandUp #PodcastCommunity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DJUXTfzOCKW-1.mp4
"When your comedy hits so hard they ban you from an entire country 💀 Ali Siddiq shares the wild story of getting permanently blocked from England on the latest episode with Kim Congdon - shoutout to @legionofskanks for always delivering the most insane stories! Stream now 🔥

#LegionOfSkanks #AliSiddiq #KimCongdon #StandUpComedy #Comedy #Podcast #Banned #England #ComedyPodcast #Comedian",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DKkRszCAtiK-2.mp4
"When @legionofskanks gives you the chance at GOLDEN TICKETS, you take it 🎟️✨ Head to BodyBraincoffee.com and find out how to score your way into #SkankfestNOLA—zero purchase required, because they're generous like that. Don't sleep on this one.

#Skankfest #StandUpComedy #ComedyFestival #NewOrleans #NOLA #GoldenTicket #FreeEntry #ComedyFans #LegionOfSkanks #PodcastComedy #ContestAlert",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DLNfTyCuR-c-2.mp4
"Nate Bargatze's theme park naming strategy gets hilariously exposed🎢😂

@aaronbergcomedy stops by to break down the Nateland universe on the latest episode with @legionofskanks - streaming now! Link in bio‼️

#nateland #natebargatze #comedy #LegionOfSkanks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DMlGucTgTom-1.mp4
"The Superman debate gets heated when these three weigh in on whether the latest version crossed a line. @legionofskanks doesn't hold back on this topic—catch the full unfiltered discussion streaming tonight at 8PM E exclusively for @gasdigital subscribers. New profiles get instant savings with promo code LOS. @bigjayoakerson @luisjgomez @ComicDaveSmith deliver their take in classic fashion.

#LegionOfSkanks #FridayNightHang #GaSDigital #superman",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DMRMVdjAsoO-2.mp4
"@legionofskanks is going live at 8PM E with @bigjayoakerson, @gomezcomedy, and @theproblemdavesmith for an exclusive #FridayNightHang that @gasdigital subscribers get first access to. Want in? Head to GaSDigital.com and use promo code LOS for a discount on your subscription. #LegionOfSkanks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DNrRFsrXF-Z-1.mp4
"@hfoleycomedy, @kevinryancomedy, and @steverannazzisi deliver comedy gold on the latest #LegionOfSkanks episode, courtesy of @legionofskanks. Watch the complete show exclusively on @gasdigital – use promo code LOS when you create your #GaSDigital profile for discounted full access to all the chaos!",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DOeVn3Cjiwu-2.mp4
"The crew is back with another unmissable Friday night session as @bigjayoakerson, @gomezcomedy, and @theproblemdavesmith deliver the chaos subscribers have been waiting for. Tonight at 8PM E, exclusively on @gasdigital – this is the content that keeps fans coming back. Head to GaSDigital.com and use promo code LOS for discounted full access to all the mayhem from @legionofskanks. #LegionOfSkanks #FridayNightHang",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DOPV9r-jhEJ-1.mp4
"When Kanye decides to drop his definition of Black culture, you know the conversation is about to get wild 👀

@naim__ali & @drdrewpinsky break it all down on the latest episode with @legionofskanks – streaming everywhere now! Link in bio‼️

#LegionOfSkanks #podcast #comedy #standupcomedy #comedypodcast #podcasting #KanyeWest #podcastclips #funnyvideos #comedyclub",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DP9iT64Dr6s-2.mp4
"Dr. Drew gets put on the spot about his bank account 💰

@legionofskanks brought out @drdrewpinsky alongside @snl & @nickrochefort for Episode 865 and things got financially interesting real quick

Catch ALL NEW #LegionOfSkanks drops every Tuesday 8PM E exclusively on @gasdigital • • Sign up with promo code LOS for discounted full access‼️",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DPHt-oaDmb8-1.mp4
"When Whitney Cummings got introduced to the Little D contest winner by @legionofskanks, nobody expected her to handle it quite like this—and just like that, a Skankfest Legend was born 🏆

From Episode 833 featuring @whitneycummings & @joederosacomedy

Catch brand new #LegionOfSkanks every Tuesday at 8PM E exclusively on @gasdigital • Sign up with promo code LOS for discounted full access‼️",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DQxLzh3Dt_L-1.mp4
"Looking for plans tonight? @bigjayoakerson, @gomezcomedy, and @theproblemdavesmith are going live at 8pm E for the #FridayNightHang exclusively on GaSDigital.com! 

Don't miss this one from @legionofskanks – grab your access with promo code ""LOS"" for a discount!

#LegionOfSkanks #StandUpComedy #LiveComedy #ComedyPodcast #GaSDNetwork",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DQfhZ1-DhnM-2.mp4
"The crew is back! @bigjayoakerson, @gomezcomedy, and @theproblemdavesmith are delivering another episode of #FridayNightHang exclusively for @gasdigital subscribers at 8PM E. Want in? Head to GaSDigital.com and use promo code LOS for a discount on full access. 🔥 @legionofskanks #Legion",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\legionofskanks\DRVrfqUDoQ6-1.mp4
"When life gets brutal, your mission becomes everything - Dr. Kevin Tracey breaks down the psychology behind unshakeable purpose 💯

Tag someone who needs to hear this truth right now ⬇️

via @lewishowes

#mindset #inspiration #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DNjI_4CyBBW-2.mp4
"The friendship trap: @lewishowes explains why chasing approval from critics turns you into someone you don't recognize. His perspective? Quality over quantity when it comes to your inner circle. Yes, people will get upset when you stop performing for them—but that discomfort reveals who's really in your corner. The right people celebrate your growth, not demand your conformity.

#CatConfessions #mindsetmatters #greatnessmindset #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DM3clUXhzqF-2.mp4
"The gap between dreaming and achieving? It's all in your head. @lewishowes breaks down why self-doubt is the silent killer of potential and how daily actions become the antidote. His perspective: self-worth isn't given, it's built through consistent proof that you're conquering your obstacles. The evidence you create for yourself becomes the foundation of belief. Lewis is in your corner—the question is, are you in yours?

#SelfWorth #BelieveInYourself #OvercomeDoubt #DailyHabits #MindsetMatters #PersonalGrowth #SuccessMindset #MotivationDaily #GrowthMindset #SelfImprovement #Confidence",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DOFHh9Uj5j1-1.mp4
"**Sometimes the armor we build becomes the prison we live in.** 

@lewishowes opens up about using achievement as a shield—how becoming an All-American athlete was actually an escape from childhood abuse and the pain of having his brother behind bars. The accolades came, but so did an emptiness he couldn't shake. His breakthrough wasn't another medal or milestone—it was finally releasing the grip on old wounds and tuning into what his heart actually wanted. That's when everything shifted. Your dreams aren't just goals to chase; they're calling you toward healing. 🙏🏼

Drop a YES if this resonates. You are loved, you are worthy, and you matter. 🧡

#SelfDiscovery #Resilience #MentalHealth #PersonalGrowth #HealingJourney #Motivation #Inspiration #Mindfulness #InnerStrength #OvercomingTrauma",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\C3ausp3xNJm-1.mp4
"Looking back, @lewishowes realizes the pattern was always there. The people who genuinely cared would warn him. The red flags would show up early. But ignoring trusted voices? That's where the costly mistakes happened—in dating, business deals, and partnerships that should've never started. His advice now: protect your peace fiercely and let the people who love you be your filter. Their perspective might save you years of regret. Do you let your inner circle weigh in on big decisions?

#boundaries #relationships #character #trustyourtribe #lifelessons #datingadvice #businessmindset #personalgrowth #wisdomwednesday #protectyourpeace",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DN1x4hq3lOD-2.mp4
"Lewis Howes (@lewishowes) celebrates a milestone moment for @lateamhandball as they build momentum toward the 2028 Olympics 🇺🇸🤾‍♂️ The team is committed to elevating @usateamhandball both domestically and internationally. Shoutout to @mizunohandball for backing their opening weekend! #WeAreLA

#handball #handballplayer #ihf #balonmano #handebol #handbol #olympics #la2028 #teamusa",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DQ149u1Cd8d-1.mp4
"The difference between dreaming and doing? Sometimes it's just showing up. @lewishowes is bringing the Summit of Greatness 2025 to LA's Dolby Theatre this September 12–13, and it's designed for anyone ready to stop watching from the sidelines. Two full days of world-class speakers, thousands of like-minded people, and the kind of energy that shifts your entire trajectory.

Drop a ""YES"" below and Lewis will send you the ticket link 🎟️

The room is filling up—your move matters.

#SummitOfGreatness #PersonalGrowth #Motivation #LeadershipDevelopment #SelfImprovement #Inspiration #GrowthMindset #SuccessMindset #DreamBig #TakeAction",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DOZcHjgEsGo-2.mp4
"@lewishowes explores the profound connection between generosity and wealth in his book Make Money Easy, revealing how our emotional patterns with money shape our entire financial reality. He breaks down the psychology of giving and receiving, offering a fresh perspective on abundance that goes beyond traditional money advice. Drop ""BOOK"" below to get access and start transforming your relationship with wealth. How do you practice generosity in your daily life? 💫🙏

#MakeMoneyEasy #MoneyMindset #AbundanceMindset #FinancialFreedom #WealthBuilding #MoneyTips #PersonalGrowth #SelfDevelopment #Mindset #FinancialWellness #GenerosityMatters #EmotionalIntelligence #MoneyGoals #SuccessMindset #FinancialEducation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DPmuNysAczD-1.mp4
"When Bob Proctor dropped this truth bomb, it changed everything: insecurity and intuition cannot coexist ✨

Tag someone ready to trust themselves more 👇

via @lewishowes

#BobProctor #Intuition #SelfTrust #PersonalDevelopment #MindsetShift #InnerWisdom #SelfConfidence #GrowthMindset #Motivation #Inspiration #SuccessMindset #TrustYourself #OvercomeInsecurity #SelfDevelopment #LifeLessons",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DQFGF-Zj5xG-1.mp4
"The grind continues for @lewishowes and @lateamhandball – three down, one to go. Tomorrow's the day to seal it. The brotherhood this team has built? That's what makes it all worth it. Shoutout @viranmorros for coming through with the perfect play 🤝#WeAreLA

#handball #balonmano #handbol",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DQQG_lwjxqU-2.mp4
"@lewishowes drops a powerful reminder that you're worthy of your biggest dreams ⭐️

""I deserve everything I could ever want""

Say it until you believe it 🔄

#affirmation #affirmations #dailyaffirmation #positiveaffirmations #morningaffirmations #selfworth #selflove #mindset #positivemindset #manifestation #lawofattraction #selfcare #personaldevelopment #motivation #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DRxmVc_k-oL-2.mp4
"The late Bob Proctor breaks down a truth so simple yet so powerful that @lewishowes says you need to hear it twice to really get it 🎯

Your perception creates your reality. Change one, and the other follows.

So what's the perspective shift you're making today?

#BobProctor #Mindset #PersonalDevelopment #SelfImprovement #Motivation #Success #GrowthMindset #Manifestation #LawOfAttraction #SuccessMindset #MindsetShift",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\lewishowes\DRSiRHjEl-Z-2.mp4
"Mark Manson (@markmanson) says the lack of embarrassment in your life isn't a flex—it's a red flag. Playing it safe means you're staying small. The moments that make you cringe are proof you're actually pushing boundaries and growing beyond your comfort zone.

#growth #personaldevelopment #selfimprovement #mindset #motivation #inspiration #lifelessons #wisdom #markmanson #growthmindset #selflove #mentalhealth #personalgrowth #selfcare #mindfulness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DKQHbG9zx0P-2.mp4
"According to @markmanson, there's one critical element that holds successful marriages together. He's curious what people believe it might be—so what's your take? Drop your answer below. 👇

#marriage #relationships #relationshipadvice #marriageadvice #love #couples #relationshiptips #healthyrelationships #couplegoals #marriagetips #relationshipgoals #dating #partnership",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DKQ7ydTuT9k-1.mp4
"Life's difficulties are non-negotiable—the real power lies in deciding which struggles align with who you actually want to be. @markmanson breaks down why most people waste energy on battles that mean nothing: chasing perfection, seeking validation from those they don't respect, pursuing hollow goals. The solution? Get brutally clear on your values. When you know what truly matters, you'll automatically know which problems deserve your time and which ones don't. Instead of trying to eliminate challenges, ask yourself what pain you're willing to endure—that answer reveals everything. Drop VALUES below to get the full podcast episode plus a free guide on figuring this out for good.

#values #personalgrowth #selfawareness #mindset #lifelessons #priorities #personaldevelopment #growth #selfimprovement #consciousness #philosophy #meaningfullife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DJH-HXpTczj-2.mp4
"# Understanding the Happiness Paradox

Success doesn't guarantee happiness—and @markmanson breaks down why some people can't hold onto joy even when life looks perfect on paper.

The culprit? Deep-seated beliefs from past trauma that whisper ""you don't deserve this."" These convictions literally drain your capacity for happiness, no matter how much good comes your way.

Most reach for quick fixes—overworking, substances, endless distractions—but these are just temporary patches on a persistent problem. Mark explains that lasting change requires confronting and transforming those core beliefs at their root.

#happiness #mentalhealth #selfimprovement #personalgrowth #innerwisdom #psychology #healing #mindset #selfwork #betterlife #values #emotionalhealth #mentalhealthawareness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DJUSVMhKzk0-2.mp4
"Mark Manson (@markmanson) spent years running from commitment before reality handed him the bill. His younger self dodged the hard conversations, the real connections, the deep work—until the consequences caught up.

Now he's asking: What are you actually committed to? And more importantly—how does that commitment sit with you right now?

#commitment #personalgrowth #lifelessons #selfawareness #growth #mindset #authenticity #realitycheck #selfimprovement #markmanson",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DM3Kz2fqdQf-1.mp4
"In a world where everyone's consumed by their own internal monologue, @markmanson drops a reality check that might just change your perspective. That anxiety about being constantly judged? It's mostly in your head. Everyone else is too preoccupied with their own worries to fixate on yours. He challenges viewers to recognize how much mental energy gets wasted on imaginary criticism—energy that could be redirected toward actually living. The freedom comes when you realize you're not the main character in everyone else's story.

#mentalhealth #psychology #anxiety #selfawareness #mindset #personalgrowth #overthinking #confidence #selfdevelopment #modernwisdom #philosophy #lifecoach #mindfulness #socialanxiety #selfimprovement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DL0O7sPSxpj-1.mp4
"The real secret to transformation? It's not in the massive leaps—it's in the tiny steps nobody notices at first. @markmanson breaks down why chasing enormous goals often backfires, while committing to bite-sized progress compounds into something extraordinary. His community, Momentum, was designed around this exact principle: one daily action, one small win, repeated until growth becomes inevitable. It's how sustainable change actually happens. Drop ""WIN"" in the comments to discover more.

#momentum #smallwins #personalgrowth #selfimprovement #consistency #habitbuilding #mindsetshift #growthmindset #dailyhabits #lifetransformation #motivationmonday #successmindset #goalsetting",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DLtNpb4y1pJ-2.mp4
"According to @markmanson, there's a simple filter for whose opinions actually matter. His rule? If you wouldn't seek their guidance, their judgment holds zero weight. Now he wants to know: what's the most memorable insult someone's thrown your way? Drop it below 👇

#markmanson #advice #criticism #mindset #selfimprovement #personalgrowth #boundaries #mentalhealth #lifelessons #wisdom #motivation #selflove #confidence #growthmindset #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DN5k84XihHy-1.mp4
"Science confirms what ancient philosophers knew centuries ago—Mark Manson (@markmanson) breaks down Jonathan Haidt's The Happiness Hypothesis and the timeless teachings from Buddha, Confucius, Plato, and the Stoics that modern research validates. Buddha's insight on attachment creating suffering? Backed by data. The Stoic practice of visualizing loss to amplify present gratitude? Proven effective.

Haidt's rider-and-elephant metaphor perfectly captures the struggle: your rational mind is the rider attempting control, while your emotional brain—the elephant—actually runs the show. True mastery isn't about dominating the elephant, but becoming skilled at guiding it through meditation, therapy, and when necessary, medication.

Comment WISDOM for the Shortform link to access the full book summary, plus a free trial and 20% off.

#ancientwisdom #stoicphilosophy #emotionalintelligence #personalgrowth #selfimprovement #mindfulness #psychology #bookrecommendations #philosophyforlife #mentalhealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DLQwo-cTadE-1.mp4
"The difference between strong and weak isn't about muscle or power—it's about character. Strong people own their mistakes, seek growth, and speak the truth. Weak people avoid discomfort, chase attention, and try to prove themselves.

@markmanson breaks down what real strength actually looks like.

#strength #personalgrowth #mindset #selfimprovement #characterdevelopment #growthmindset #authenticity #accountability #mentalstrength #innerwork #selfawareness #truth #wisdom #motivation #selfdevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DOBTLyagF3a-2.mp4
"# The quiet love that doesn't make headlines but makes a lifetime 💙

While everyone's chasing butterflies and grand gestures, @markmanson points to what actually goes the distance: companionate love. That's when your person becomes your favorite person to do nothing with—your best friend, your teammate, the one who makes ordinary moments extraordinary.

It's not flashy. It's not what movies sell you. But it's the kind of love that fills up your life instead of just your camera roll.

Tag your everyday person below 👇

#RelationshipAdvice #HealthyRelationships #LoveAndRelationships #RelationshipGoals #CompanionateLove #RealLove #Partnership #BestFriend #RelationshipTips #ModernLove #Teammates #RelationshipQuotes #CoupleGoals",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DMlJPZqqdcW-2.mp4
"Mark Manson (@markmanson) flips the script on how we think about happiness. He points out that meaningful experiences—whether it's pushing yourself in your career, navigating the complexities of relationships, or exploring new places—all come with their share of difficulty. But that's exactly what gives them value. When you focus on building something substantial rather than chasing a feeling, happiness naturally follows. It's not the destination; it's what happens along the way.

#happiness #personalgrowth #mindset #motivation #lifelessons #selfimprovement #personaldevelopment #wisdom #inspiration #growth #mindfulness #purpose #meaningfullife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DOV5iBEDwvh-1.mp4
"Mark Manson (@markmanson) points out the liberating truth most of us forget: that cringeworthy moment you're replaying? Nobody else is. They're too busy worrying about their own slip-ups to archive yours. And on the rare chance someone noticed, it's gone from their mental hard drive before they finish scrolling.

What's one thing you've been overthinking that probably doesn't matter?

#markmanson #selfdevelopment #mindsetshift #overthinking #socialanxiety #personalgrowth #mentalhealth #selfimprovement #anxietyrelief #confidence #psychology #selfawareness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DOGc53WiZEr-1.mp4
"Mark Manson (@markmanson) says the real test of a happy relationship isn't whether you fight or not—it's whether you can come back together after the fight and feel even closer than before.

#relationships #datingadvice #relationshipadvice #dating #love #couple #relationshiptips #healthyrelationships #couples #relationshipgoals #relationship #lovequotes #marriageadvice #communication #marriage",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DPRH2WIiWsL-2.mp4
"What if the happiness you're chasing tonight is exactly why you'll need another fix tomorrow? @markmansonnet breaks down the trap we all fall into: pleasure isn't fulfillment. That dopamine hit from instant gratification—whether it's pizza, sex, or scrolling—creates a cycle where you're constantly running but never arriving. The hedonic treadmill keeps spinning, and your happiness becomes an exhausting roller coaster of highs and crashes. Real contentment isn't found in the next rush.

#hedonictreadmill #happiness #philosophy #dopamine #mindfulness #personalgrowth #selfimprovement #mentalhealth #psychology #wisdom #lifechoices #fulfillment #consciousness #modernlife #truthbomb",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DOJBkdNAcJq-2.mp4
"Mark Manson (@markmanson) breaks down a distinction most people get backwards: confidence isn't about proving anything, ego is. The confident person acts without needing validation. The ego-driven person performs for approval. One builds, the other protects. One creates, the other defends. Understanding this difference changes how you show up in every room you walk into.

#confidence #ego #selfimprovement #personaldevelopment #mindset #growth #psychology #selfdevelopment #selfawareness #motivation #authenticity #mentalhealth #selfgrowth #lifecoach #wisdom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DQmM5FAj2k7-1.mp4
"Mark Manson (@markmanson) breaks down the core difference between secure and insecure attachment styles—and it's simpler than you think. The secure person doesn't need constant validation because they've already built trust within themselves. The insecure? They're stuck in a loop, seeking reassurance from everyone except the person who matters most: them. Understanding this changes everything about how you show up in relationships.

#attachmentstyles #secureattachment #insecureattachment #relationshipadvice #emotionalintelligence #selfawareness #datingadvice #relationshiptips #mentalhealthmatters #personalgrowth #selflove #emotionalhealth #boundaries #healthyrelationships",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DQhoVX2jChy-1.mp4
"Mark Manson (@markmanson) dropping perspective: the ceiling you see? It's just in your head.

#motivation #inspiration #mindset #success #motivationalquotes #inspirationalquotes #selfimprovement #personaldevelopment #growthmindset #successmindset #believeinyourself #motivational #inspired #goals #dreambig #positivevibes #lifequotes #dailymotivation #motivationmonday #hustle #grind #entrepreneur #entrepreneurship #business #lifestyle",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DQHNJ0FjRVA-2.mp4
"According to @markmanson, there's a clear difference between how secure and insecure people show up in relationships. Secure attachment means you're comfortable with both closeness and independence—you don't cling or pull away when things get real. Insecure attachment? That's when fear runs the show, either making you chase validation or keep everyone at arm's length. He breaks down what healthy connection actually looks like versus the patterns that keep people stuck.

#attachmentstyles #secureattachment #insecureattachment #relationshippsychology #emotionalhealth #datingadvice #relationshiptips #attachmenttheory #healthyrelationships #personalgrowth #selfawareness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\markmanson\DQhoVX2jChy-2.mp4
"False compromises kill brilliant ideas before they ever take flight.

That's the belief driving @DanielLubetzky, the founder of Kind Snacks, who knows that questioning what everyone accepts as truth is where innovation begins. This perspective from @mastersofscale shows why the best founders refuse to settle for ""either/or"" when they can create something entirely new.

Masters of Scale Summit is presented in alliance with @capitalonebusiness.

.
.
.
.
.
.
.
.
.
.
#MoSsummit",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DBzWE8_Pov7-1.mp4
"Sometimes the most famous stories in history are missing their most important chapters. @Fawn.Weaver, whiskey connoisseur and founder of @UncleNearest, went on a mission to find the truth behind Jack Daniels' legendary whiskey—and discovered a narrative that had been overlooked for generations. The full story, featuring insights from @JeffBerman, is available now via @mastersofscale (link in bio).

#MastersofScale #JackDaniels #Whiskey",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DFgDxgap8ya-2.mp4
"The label ""techno-optimist"" comes with baggage, but Vinod Khosla, founder of @KhoslaVentures, wears it differently. He's redefining what the term actually means—and it's not what you'd expect. @mastersofscale captures his take on optimism with guardrails.

.
.
.
.
.
.
.
.
.
.
#technooptimism #artificialintelligence #MoSsummit #mastersofscale",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DB9JyoYtItp-2.mp4
"@ReidHoffman and @RobertSafian dive into a critical question: Will we let AI shape us, or will we shape AI? In his book Superagency, Reid makes the case that humanity's relationship with transformative technology has always been a choice—not a predetermined outcome. From the printing press to the internet, disruption arrived alongside unprecedented opportunity for those who seized it. This conversation with Robert on @mastersofscale challenges viewers to stop being passive observers and start becoming active architects of the AI era. The technology is here—now it's about how we wield it.

The full episode is waiting at the link in bio.

#RapidResponse #Superagency #AI #Leadership #Innovation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DFbVY7vNxzO-1.mp4
"The real game-changers aren't wearing corporate badges. Vinod Khosla—Founder of Khosla Ventures and Co-Founder of Sun Microsystems—breaks down why strategic entrepreneurs operating behind the scenes are actually orchestrating the biggest industry transformations, not Fortune 500 boardrooms. While major corporations get the headlines, it's the visionaries challenging conventional thinking who architect the future. @mastersofscale explores how these big-picture thinkers become the invisible force reshaping entire markets.

#MastersofScaleSummit #Leadership #BusinessInsights",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DFWS9bshYeN-2.mp4
"Three days. Hundreds of visionaries. One mission: building a better future.

@mastersofscale is bringing together the world's most influential founders, CEOs, and innovators in San Francisco this October 7–9, 2025. This isn't just another conference—it's where fast-scaling entrepreneurs gain game-changing insights, where bold partnerships are born, and where the future of business takes shape through curated connections and world-class speakers.

The immersive environment has been carefully designed to activate change-makers and spark new ventures through exclusive access and genuine moments that attendees won't find anywhere else.

Ready to be part of something transformative? Attendance is by application or invitation only—apply now at summit.mastersofscale.com to secure a spot at this unparalleled experience.

#MoSSummit #Summit2025 #SanFrancisco #Business",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DGV5Arbp6wF-1.mp4
"Financial empowerment shouldn't be a privilege reserved for just half the country. @mellodyhobson, president and co-CEO of Ariel Investments, broke down a startling reality at Masters of Scale Summit: despite being essential for navigating adult life, financial education is mandatory in only 25 U.S. states. She emphasized that core concepts like compounding and inflation need to reach children far earlier than they currently do.

The foundation for money management begins in childhood, often absorbed without formal instruction. Teaching kids to weigh simple trade-offs — a cupcake versus a toy — builds the critical thinking skills that translate into sophisticated financial decisions later in life.

The question remains: what will it take to close this educational gap?

Full insights from @mastersofscale available at the link in bio.

#MosSummit #FinancialLiteracy #MoneyMatters #Investing #FutureofFinance",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DFs7x-ApUN_-1.mp4
"When a painful bout of cellulitis and crushing prescription costs revealed the true state of America's healthcare crisis, @johngreenwritesbooks channeled his frustration into fighting tuberculosis worldwide. The author and educator shares with @jeffberman how personal struggle transformed into a global mission against one of humanity's deadliest threats.

Obsession met purpose. Outrage sparked change.

Full episode available through the link in @mastersofscale's bio.

#MastersOfScale #JohnGreen #Healthcare #Tuberculosis #GlobalHealth #PublicHealth #AuthorLife #Storytelling #SocialImpact #Advocacy #HealthcareReform #Innovation #Leadership #Purpose",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DJ7QPUWtchi-1.mp4
"When a basic necessity becomes a luxury, an entire system reveals its cracks. @Baby2Baby co-CEOs Norah Weinstein and Kelly Sawyer Patricof sat down with @JeffBerman at Masters of Scale Live in LA to expose the overlooked crisis affecting millions of American families—and explain why solving the smallest problems creates the biggest change. The ripple effects? Health outcomes, human dignity, and real opportunity for communities that need it most. Full conversation with @mastersofscale is linked in bio. #MastersOfScale #SocialImpact #Baby2Baby #CommunityStrength #Leadership #Entrepreneurship",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DL3DVwMSZOx-1.mp4
"When missionaries go head-to-head with mercenaries in Silicon Valley, there's only one winner—and @simonsinek breaks down exactly why in his no-holds-barred conversation with @reidhoffman on @mastersofscale.

The discussion cuts deep: how chasing outputs destroys what you're actually trying to build, the real dynamics of scaling movements (not just companies), what makes AI ""friendship"" nothing but smoke and mirrors, and the leadership principles that separate lasting impact from flash-in-the-pan wins.

There's also one success hack hiding in plain sight that most people completely ignore.

Full episode link in bio.

#SimonSinek #ReidHoffman #MastersOfScale #Leadership #StartupCulture #SiliconValley #BusinessStrategy #Entrepreneurship #ScalingBusiness #LeadershipLessons #TechLeadership #BusinessPodcast #StartupLife #MissionDriven",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DKsJzLCP2SC-1.mp4
"@cowgirlaileen stepped onto the Summit stage with a powerful message: when diverse founders lead in AI, innovation doesn't just happen—it accelerates. The Founder and Managing Partner of Cowboy Ventures breaks down how representation transforms into tangible results, better products, and breakthrough ideas. Via @mastersofscale

#MoSSummit",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DPmPKhgFbWI-2.mp4
"Remote work might be holding careers back more than people realize. NYU professor @suzywelch tells @jeffberman on @mastersofscale that climbing the ladder from home has real limits—being physically present in the office creates opportunities for trust-building and accelerated learning that video calls simply can't replicate. Her take: face time isn't outdated, it's essential for long-term career growth. Does the data support this or is remote work still the future?

#MastersOfScale #CareerGrowth #RemoteWork #OfficeLife #Leadership #WorkCulture #CareerAdvice #ProfessionalDevelopment #FutureOfWork #WorkplaceDebate",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DMvocluSuFa-1.mp4
"The energy backstage at Summit 2024 with @rachelsthomas_ was absolutely electric ⚡

@mastersofscale is gearing up to deliver that same magic again at Summit 2025 — where game-changing conversations happen and genuine connections are made.

Link in bio for all the details on Summit 2025.

#MastersOfScale #Summit2025 #Leadership #Business #Entrepreneurship #Innovation #Networking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DPRuIlWAi00-2.mp4
"When an influencer gets it wrong, sometimes you have to set the record straight. @justbobbidotcom shares with @jeffberman the story behind her viral response that she didn't even realize was a ""clap back"" – plus the wild ride from her first venture to launching @jonesroadbeauty. The full conversation with @mastersofscale is available now.

#entrepreneurship #businesspodcast #founderstory #beautybusiness #startupstory #businessjourney #womeninbusiness #entrepreneurlife #foundertalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DQ47tH6iOfM-1.mp4
"Jeremy Levine turned @underdogfantasy into a unicorn by obsessing over product—and host @jeffberman got the full breakdown on how to dominate in a competitive space. The CEO and founder shares his playbook with @mastersofscale while simultaneously throwing shade at Yahoo's Jim Lanzone for his fantasy football performance. Sometimes the best business lessons come with a side of trash talk. Full episode linked in bio.

#NFL #FantasyFootball #Entrepreneurship #StartupLife #ProductDevelopment #Unicorn #BusinessStrategy #TechStartup #SportsIndustry",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DOZWAztDMRD-1.mp4
"Aaron Levie just broke down the real challenge behind AI agents in business—and it's not what most people think.

The @box CEO joined @robertsafian at @mastersofscale Summit to tackle the critical question: how do we actually teach these systems to deliver value? Their insights cut through the AI hype to reveal what truly matters for implementation.

Want the complete discussion? Aaron's conversation with Bob, @meta's @clarashih, and @linkedin's Aneesh Raman is waiting at the link in bio.

#AI #AIAgents #BusinessStrategy #TechLeadership #Innovation #ArtificialIntelligence #BusinessGrowth #Leadership #TechTrends #FutureOfWork",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DQe5Os-iidJ-2.mp4
"@brenebrown and @reidhoffman's Masters of Scale Summit conversation reveals a powerful truth: emotional intelligence starts with recognition. The research professor and author breaks down why naming what you feel is the first step to mastering it as a leader.

The full discussion from @mastersofscale is available now (link in bio).

#MoSSummit",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DQXZ8LsiQaM-1.mp4
"When revenue stops being the only scoreboard that matters, business transforms into something more powerful. 

Ryan Gellert from @patagonia sat down with @hamdi.ulukaya of @chobani and David Gelles from @nytimes at the @mastersofscale Summit to explore how protecting the planet became Patagonia's North Star—and reshaped everything about how they operate.

Full conversation available now.

#MastersOfScale #BusinessLeadership #SustainableBusiness #Patagonia #PurposeDriven #Leadership #BusinessStrategy #Entrepreneurship #Innovation #Sustainability",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DQuhp3QDS7s-1.mp4
"When Elmo crashes your business summit, you stop and take notes. @rhymeswithshmameron, Head of Content & IP Strategy at @sesameworkshop, brought along a very special guest to Masters of Scale Summit—and the lesson went deeper than anyone expected. Breathe with Elmo for a moment, then catch Scott's complete presentation at the link in bio. He reveals the original mission behind @sesamestreet: closing early-learning gaps across America, and how that vision now spans the globe. Local storylines, culturally-adapted characters, and authentic representation all stem from one core practice—actually listening to children. Credit: @mastersofscale

#MastersOfScale #SesameStreet #SesameWorkshop #Elmo #Leadership #SocialImpact #Education #ContentStrategy #Mindfulness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mastersofscale\DRiUN1hkfS9-2.mp4
"The establishment doesn't want you hearing facts that challenge their narrative, so they silence anyone brave enough to speak them. @mattwalshblog breaks it down.

#MattWalsh #CancelCulture #FreeSpeech #Conservative #Politics #Truth #Censorship #TheDailyWire",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DO1cQhLCa-7-2.mp4
"According to @mattwalshblog, this legal argument is going absolutely nowhere fast.

#MattWalsh #DailyWire #Conservative #Politics #News #Viral #CourtCase #Legal",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DOZgF41Ce5s-2.mp4
"A traffic stop survival guide that actually works, according to @mattwalshblog. The advice? It's simpler than most people want to admit.

#MattWalsh #Police #TrafficStop #LawEnforcement #CommonSense #Compliance #SafetyTips #PoliceInteraction #DailyWire",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DP4w9S1iSas-2.mp4
"According to @mattwalshblog, even major pharmaceutical brands are aligning with the President's stance on this one. When Tylenol's messaging backs up Trump's position, you know something's shifting in the mainstream conversation.

#Trump #Tylenol #President #Conservative #Politics #BigPharma #Culture",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DPB4w3jDs8x-2.mp4
"The hypocrisy couldn't be more clear-cut. @mattwalshblog breaks down a double standard that's hiding in plain sight.

#DoubleStandard #Hypocrisy #MattWalsh #Truth #Conservative #Politics #Reality #CommonSense",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DPIG-rliUuy-2.mp4
"The mental gymnastics are Olympic-level on this one 🤸‍♂️ Chicago's mayor really tried to pin his city's violence problem on Trump, and @mattwalshblog wasn't letting that slide without a reality check.

#Chicago #Trump #MayorJohnson #Crime #ViolencePrevention #Politics #Conservative #PoliticalNews #ChicagoCrime #Accountability #Leadership #UrbanPolicy #MattWalsh",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DOQ9mk4iV0u-2.mp4
"A country's refusal to reclaim one of its own tells you everything you need to know about Ilhan Omar's reputation. Even Somalia isn't interested in taking her back, as @mattwalshblog points out.

#IlhanOmar #Somalia #Politics #Conservative #PoliticalCommentary #Congress #Immigration #MattWalsh",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DPHCRCoCUoJ-1.mp4
"When the whole internet actually finds common ground for once 👀 @mattwalshblog shares the rare take that's got everyone nodding along.

#mattwalsh #politics #conservative #debate #currentevents #viral #trending #fyp",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DPT62oxCVBI-2.mp4
"Don Lemon's obsession has reached a breaking point, according to @mattwalshblog's latest analysis.

#DonLemon #MattWalsh #Politics #News #Conservative #Media #Commentary #Viral #Trending",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DPU-_5WCRcV-2.mp4
"@mattwalshblog with the most heartfelt anniversary message that proves sometimes the simplest words carry the deepest meaning 💕

When you know, you know – and after all these years, he's still keeping it beautifully straightforward. Here's to love that doesn't need elaborate captions to say everything. 🥂

#anniversary #happyanniversary #marriagegoals #loveandmarriage #relationshipgoals #couplegoals #married #marriedlife #husbandwife #truelove",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DQaUvUdDHHp-2.mp4
"The Walshes are celebrating another year together! @mattwalshblog keeps it simple but sweet with this anniversary tribute to his wife. Sometimes the best messages are the ones that need no extra words. 💕

#Anniversary #HappyAnniversary #MarriageGoals #Love #Married #Husband #Wife #Relationship #CoupleGoals #MarriedLife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DQaUvUdDHHp-1.mp4
"The entertainment industry's shift toward ideological content in children's programming continues to spark debate, as @mattwalshblog points out in this eye-opening breakdown. When cartoons start pushing agendas instead of telling stories, parents are taking notice.

#Woke #WokeAgenda #Wokeness #ChildrensTV #KidsShows #Parenting #ParentalRights #Entertainment #Media #TVShows #Cartoons #ProtectKids #Culture #CultureWar",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DPZD2XfCSu3-2.mp4
"The machines haven't won yet, and @mattwalshblog isn't letting them 🤖❌

#AI #ArtificialIntelligence #Technology #TechSkepticism #HumanityFirst #AntiAI #TechCritique #DigitalAge #AIDebate #KeepItReal",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DRBAifGAF3q-2.mp4
"According to @mattwalshblog, this moment with Hasan deserves some sympathy.

#politics #conservative #news #debate #reaction #commentary #viral #trending",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DQZ3PtRgkfx-2.mp4
"@mattwalshblog exposes the uncomfortable truth about MLK's legacy being twisted beyond recognition.

The civil rights icon dreamed of a colorblind society where character mattered more than skin color. Today's activists are pushing the exact opposite—judging people solely by race and championing segregation under new labels.

From separate graduation ceremonies to ""diversity"" initiatives that exclude rather than unite, the very principles MLK dedicated his life to are being dismantled by those who claim to honor him.

#MattWalsh #MLK #CivilRights #Legacy #ColorblindSociety #MartinLutherKing #Character #Truth #Conservative #Politics #SocialCommentary #CriticalThinking #America",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DQ5aAADj-v9-1.mp4
"Looking for attention in all the wrong places 👀

Some people will do anything to make sure all eyes are on them – but @mattwalshblog points out that desperate grabs for attention usually backfire. When you demand everyone look at you, they might be watching for all the wrong reasons.

Credit: @mattwalshblog

#Attention #LookAtMe #SocialCommentary #MattWalsh #ModernCulture #Validation #Cringe #Reality #Truth #SocialMedia #AttentionSeeking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DQr8Ogxkxeg-1.mp4
"A timepiece enthusiast through and through – @mattwalshblog keeps it refreshingly straightforward about his passion for watches ⌚

#watches #timepiece #watchcollector #watchesofinstagram #luxury #style #fashion #mensstyle",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DRssJb7iewC-2.mp4
"Taking the holiday shopping game to the next level 💪 @mattwalshblog knows where to find gifts that actually make a statement. Daily Wire Shop has everything you need to make this season memorable.

#DailyWire #HolidayShopping #GiftIdeas #BasedGifts #ChristmasShopping #HolidayGifts #ConservativeValues #ShopSmall #HolidaySeason",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\mattwalshblog\DRm0_CDgk0u-2.mp4
"The moment RFK became ""controversial"" changed everything at home—@_cherylhines opens up about the reality: it was ""more challenging than fun."" @megynkellyshow gets the honest answer we've all been wondering about.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DPw-mbFEoFQ-2.mp4
"The reality of public life? Learning to navigate criticism while staying true to yourself. @megynkelly and @_cherylhines open up about their approach to handling negativity: ""It's a weird ecosystem."" Catch the complete conversation from @megynkellyshow—link in bio for the full episode.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DPwu0gMkjxQ-2.mp4
"The corporate media's ""No Kings"" narrative gets dismantled by @megynkellyshow in this must-watch reaction. She breaks down the hypocrisy behind their peace and unity messaging. Full episode available on YouTube.com/MegynKelly.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DQCvRV-EQw9-1.mp4
"The cat's out of the bag. @kennethpvogel from the New York Times isn't holding back—Joe Biden ""CLEARLY did know"" about Hunter's dealings. @megynkellyshow gets the full story. Catch the complete episode on YouTube.com/MegynKelly

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DPkNM_zkm-9-1.mp4
"Michelle Obama's recent move has @megynkellyshow pointing out a pattern—and according to Megyn, it's another moment where Barack ends up looking foolish. The full breakdown is worth the watch.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DP2Hwp-El9A-1.mp4
"The music industry's power players just got called out—and @johnrichofficial isn't holding back. He sits down with @megynkellyshow to expose the ""whack job communists"" controlling record labels from the top down. This is the raw conversation you won't hear anywhere else. Full episode available now through the link in bio.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DQ49_Pakz4--2.mp4
"The Sydney Sweeney controversy over her Republican registration gets addressed by @megynkellyshow, who calls it exactly what it is: ""Below the belt hit."" Full episode available on YouTube.com/MegynKelly.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DQ7n2_CkfWr-1.mp4
"@megynkellyshow breaks down the one thing that could pull leftists out of their toxic spiral. Catch the complete breakdown on her YouTube channel.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DQU764bE40e-1.mp4
"The GOP's 2025 election performance? @megynkellyshow pulls zero punches calling it a ""f*cking nightmare"" in her direct message to Republicans. Catch the complete breakdown—subscribe and download the FULL show at the link in bio.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DQsQTCDEhpf-1.mp4
"Behind the scenes of something major—@megynkellyshow is hitting the road, and Mark Evan Halperin is coming along for the ride. ""Megyn Kelly Live!"" makes its Fort Worth debut October 25th, and from what we're hearing, this isn't your average speaking tour. Megyn Kelly is bringing the conversations that matter straight to Texas, with Halperin joining to break down the stories everyone's talking about. This is her first-ever live tour, and tickets are moving fast. Link in bio to secure your spot before they're gone.

#MegynKelly #MarkEvanHalperin #MegynKellyLive #FortWorth #Texas #LiveTour #PoliticalCommentary #MediaTour #October25",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DQH6_4njwRg-1.mp4
"The psychics made her do it? @megynkelly and @maureen_callahan_writer of @TheNerveShow aren't buying Kim Kardashian's excuse for lying about passing the bar. Watch them break down this wild celebrity moment. Full episode available now – link in bio to subscribe and download.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DRAvlgdkYwQ-1.mp4
"The ""dumb liar"" label Karine Jean-Pierre just earned from @megynkellyshow? Completely deserved after that latest interview and press tour, according to Megyn. She called the whole spectacle ""a thing of beauty"" – and not in a good way. Catch the full breakdown on the podcast.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DQXWELCkexO-1.mp4
"The left's sudden Epstein obsession has one clear target, according to @megynkellyshow—and it's Trump. Catch the complete breakdown by downloading the full episode on your favorite podcast platform.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DRA1kfQkUsY-2.mp4
"Teen Vogue employees thought confronting their HR head was a power move—they found out otherwise. @megynkellyshow weighs in on Stan and the staffers who learned corporate politics the hard way. Full episode available through the link in bio.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DRDDR_Dkj4c-2.mp4
"The truth might be closer than we think 👁️ @walterkirn joins @megynkellyshow to discuss UFOs, non-human intelligence, and the revelations that could be coming our way. Full conversation available now on YouTube.com/MegynKelly

#megynkellyshow #ufo #aliens #nonhumanintelligence #disclosure #ufonews #interview #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DRdO39kkpxr-1.mp4
"A MSNBC segment featuring Jasmine Crockett's comments on white supremacist deportation gets dissected by @megynkelly and @markevanhalperin, host of @nextuphalperin. Catch the complete breakdown—subscribe via the link in bio.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DRvQZ1NEqh--1.mp4
"@mrserikakirk shares powerful wisdom on denying your opposition the reaction they're hoping for, plus her heartfelt message to the Robinson family. More from @megynkellyshow 💯

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DRZzHeokTxd-2.mp4
"Anonymous FBI sources are speaking out against Kash Patel, but @megynkellyshow cuts through the noise with a simple truth: these disgruntled employees simply don't like him. Hear the full breakdown on her podcast.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\megynkellyshow\DRxkrrpkYU--2.mp4
"Michael J. Knowles (@michaeljknowles) questions the motivations behind certain research agendas when it comes to studying the effects of gender transition on children.

#MichaelKnowles #Conservative #Politics #GenderIdeology #Children #Research #Studies #PoliticalCommentary #DailyWire #MediaBias #CriticalThinking #ParentalRights #TransDebate",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DB1uSGvSjP0-1.mp4
"Michael Knowles (@michaeljknowles) understands what authentic leadership looks like. No shortcuts, no excuses—just men stepping up when it matters most.

#leadership #masculinity #conservatives #conservative #michaelknowles #realmen #accountability #tradition #values #strength #character #responsibility",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DBO7o-axZIH-1.mp4
"Looking at the numbers tells you everything you need to know about modern culture. @michaeljknowles breaks down why this matters more than people think. 🎶 ➕

#MichaelKnowles #DailyWire #Conservative #Politics #Culture #PopCulture #Music #Commentary #PoliticalCommentary #ConservativeValues #AmericanCulture #CulturalDebate #SongTrivia",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DEs5rbpOCeV-2.mp4
"The Conspiracy expansion pack just dropped for the Yes or No game 🎯 Michael Knowles (@michaeljknowles) says if you've already got the original, this is your next move. Link's in his bio.

#YesOrNoGame #ConspiracyTheories #GameNight #PartyGames #MichaelKnowles #CardGames #ExpansionPack #TabletopGames #AdultGames #FunWithFriends",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DDaRjNUinRN-1.mp4
"The crossover episode nobody saw coming 🎬 @michaeljknowles links up with @mikeohearn for this moment

#podcast #clips #viral #trending #fyp #explore #reels #instagram #comedy #entertainment #michaelknowles #mikeohearn #unexpected #collaboration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DDs2UnmyM82-2.mp4
"---

When you're trying to survive as a conservative in the digital jungle 😅 @michaeljknowles reminds everyone that being a Republican on Instagram basically means you're walking on eggshells daily.

#conservative #republican #politics #instagram #socialmedia #politicalmemes #conservatives #politicalhumor #rightwing #censorship",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DFLR9q3OTTs-2.mp4
".@michaeljknowles and The Daily Wire return to DC for CPAC with an exclusive Daily Wire Backstage event. A decade milestone celebration meets real-time analysis of the cultural and political forces redefining America's trajectory.

#CPAC #TheDailyWire #DailyWireBackstage #Conservative #Politics #Culture #DC #Washington #PoliticalCommentary #DailyWire10Years",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DGD7qN6OOQw-2.mp4
Standing firm in what matters—even when it comes to bathroom attire. @michaeljknowles defends his choice with zero apologies. 🪒 #jeremysrazors,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DIjWQilszCI-2.mp4
"Michael J. Knowles (@michaeljknowles) is bringing the heat at the Young Leaders Summit—this is where the movement grows stronger 🔥

Running out of tickets fast. Drop ""LEADERS"" below to claim yours before they're gone 🎟️

#YoungLeadersSummit #MichaelKnowles #Leadership #Conservative #YouthMovement #TakeAction",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DHW5dOBSAEq-2.mp4
"When @michaeljknowles breaks down the cultural shift happening in real time 🎯 The way society's pendulum swings never fails to create these moments of clarity.

#michaelknowles #conservative #politics #culture #truth #viral #trending #fyp #reels #instagram",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DG3ZXkEvGlK-2.mp4
"When the live-action Snow White bit into that apple on screen, the audience broke into applause—a moment @michaeljknowles found revealing about where we are culturally. Sometimes the crowd's reaction tells you everything you need to know.

#MichaelKnowles #SnowWhite #Disney #Culture #MovieTheater #LiveAction #Commentary #Politics #Conservative #Viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DHynU2avXVT-1.mp4
"Disney's getting called out and the question is simple: where's the lie? 🎯

@michaeljknowles breaks down why their latest move has people questioning everything. Sometimes the most straightforward question hits the hardest.

#Disney #MediaCriticism #Conservative #PoliticalCommentary #Culture #Entertainment #Hollywood #WokeDisney #DisneyControversy #MichaelKnowles #Commentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DIRnQ4dv8yZ-2.mp4
"@michaeljknowles thinks someone needs a history lesson – and a one-way ticket on the Mayflowers 📦⛴️

#MichaelKnowles #Conservative #Politics #PoliticalHumor #DailyWire #America #Mayflower #History #PoliticalCommentary #RightWing #ConservativeMedia",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DJXQN1dOc59-1.mp4
"Archaeological evidence silences doubters: A 1968 discovery of Yehohanan's remains—complete with an iron spike still lodged in the heel bone and wood fragments attached—proves crucifixion by nails was standard practice during Pontius Pilate's era, directly contradicting modern theories claiming Jesus was merely tied with ropes. @michaeljknowles breaks down why this finding matters and examines crucifixion mechanics, the Shroud of Turin's authenticity, and why wrist placement details align with ancient execution methods. Full discussion available on YouTube. #CrucifixionNail #ShroudOfTurin #HistoricalAccuracy #ChristianArt #BiblicalHistory #ReligiousArtifacts #Archaeology #FaithAndReason #ShroudEvidence #CrucifixionHistory",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DIzjzo9yQJz-1.mp4
"The campus tour rolls on, and the mission is clear: preserving what Charlie Kirk built at TurningPoint USA. @emilyjashinsky joins @michaeljknowles to break down why that matters now more than ever.

Catch the complete episode – link in bio.
#AfterPartyEmily",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DPEgcvPkUMy-1.mp4
"The silence speaks volumes here 👀 Michael Knowles (@michaeljknowles) caught this moment that has everyone talking.

#MichaelKnowles #Conservative #Politics #Viral #MAGA #Trump #Republican #News #Political #Conservatives #ConservativeMemes #DailyWire #Podcast #Conservative",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DPl95IRkcSV-1.mp4
"@michaeljknowles breaks down why this ideology spells trouble for society. The collision of identity politics and Marxist economics creates a dangerous framework that undermines traditional values and individual freedom.

#conservative #politics #communism #identitypolitics #culture #commentary #podcast #freedom #traditional #values",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DQp1aqGj27S-2.mp4
".@michaeljknowles is bringing Bar Fight back to Nashville this Thursday 🎙️ He's linking up with @berecker and @ryanbasham for what's bound to be an unforgettable night. RSVP link is waiting in his bio and story — don't miss it!

#BarFight #Nashville #LiveShow #PodcastLive #Conservative #PoliticalCommentary #LivePodcast #NashvilleEvents #ThursdayNight #MichaelKnowles",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DQ7vt8XjbMv-2.mp4
"Michael Knowles (@michaeljknowles) breaks down why certain professions get celebrated while others get criticized—and the reasoning might surprise you.

#MichaelKnowles #PoliticalCommentary #CulturalAnalysis #ConservativePodcast #SocialCommentary #PoliticalDiscourse #ModernCulture #ThoughtProvoking #PodcastClips #PoliticalPodcast #CulturalDebate #ConservativeThought #MediaAnalysis #CurrentEvents",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\michaeljknowles\DPZ_uD_gGzk-1.mp4
"When the profile pic looks innocent but the bio link tells a different story 👀 @moreplatesmoredates weighs in on the modern dating dilemma that's got everyone divided.

JRE #2073

#jre #joerogan #jreclips #joeroganpodcast #joeroganexperience #datingadvice #redflags #moderndating #relationshipadvice #datingtips #relationships #dating #onlyfans #dealbreaker #podcastclips #viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\C0vBEjmp9gv-2.mp4
"Looking at the crossover potential between the mats and the cage 🥋➡️🔥 @moreplatesmoredates breaks down which elite Jiu-Jitsu competitors have the skill set to make serious waves in MMA if they decided to transition. Not every grappling phenom can handle strikes, but these athletes might be built different.

#jiujitsu #mma #grappling #bjj #brazilianjiujitsu #mixedmartialarts #combat #fighting #ufc #submission #grapplers #martialarts #bjjlifestyle #jiujitsulifestyle #fighter #mmafighter",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\C-1Ft1uS2F6-1.mp4
"Blood work insights from @moreplatesmoredates reveal the critical health markers most people are missing. He breaks down why comprehensive lab testing through @marekhealth can catch problems before symptoms even appear, explaining which panels actually matter for optimal performance and longevity. The difference between standard doctor visits and specialized health optimization becomes clear when you understand what's really happening beneath the surface.

#bloodwork #health #optimization #hormones #testosterone #trt #wellness #longevity #fitness #gym #bodybuilding #healthspan #biohacking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\C3n8OzQI2xy-1.mp4
"The B-Team just leveled up their health game 💉

Craig Jones and his crew are now partnering with Marek Health to maximize their performance and recovery. If you're at CJI, swing by the @marekhealth booth to learn how they're helping elite grapplers get their bloodwork and hormones dialed in.

Want the same optimization protocol? Head to MarekHealth.com

Via @moreplatesmoredates

#BJJ #Grappling #CraigJones #BTeam #MarekHealth #TRT #HRT #Optimization #Performance #MMA #NoGi #Jujitsu #BrazilianJiuJitsu #ADCC #CJI #Wrestling #SubmissionGrappling",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\C-zDBKCA-Io-2.mp4
"@moreplatesmoredates sits down with the 400-pound Georgian giant Levan Saginashvili, who openly discusses his SARM usage in this candid conversation.

Full video available on YouTube now.

#LevanSaginashvili #SARMs #armwrestling #moreplatesmoredates #fitness #bodybuilding #PEDs #strengthsports #armwrestler #athlete",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\Cs90MbDOqDK-1.mp4
"The carnivore diet's impact on thyroid function gets examined through Paul Saladino's personal health journey, as @moreplatesmoredates breaks down the physiological changes that occurred. A deeper look at what really happened when animal-based eating met endocrine response.

#carnivore #carnivorediet paulsaladino #thyroid #thyroidhealth #moreplatemoredates #health #wellness #nutrition #diet #fitness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\C7Ad768PyvD-2.mp4
"A devastating loss for the fitness community. Jo was an incredibly kind soul and genuine person who left a lasting impact on everyone fortunate enough to know him.

@moreplatesmoredates shares his heartbreak over the passing of someone truly special.

Rest in peace, Jo. Gone too soon. 🕊️

#RIP #GoneTooSoon #FitnessFamily #RestInPeace #Forever",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\CuLRJZPJiaL-1.mp4
"Looking at what it takes to fuel a growing body, Peter Attia breaks down his teenage years consuming over 6000 calories daily paired with 6-hour training sessions—a reminder that nutrition requirements for developing athletes operate on a completely different scale. More insights from @peterattiamd via @moreplatesmoredates

#PeterAttia #NutritionScience #TeenAthletes #YouthNutrition #CalorieIntake #AthleticDevelopment #GrowingAthletes #SportsNutrition #TrainingVolume #AdolescentAthletes #NutritionForKids #HighPerformance #YouthSports #AthleteNutrition #DevelopmentalYears",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\C7Fov65PMmL-2.mp4
"@moreplatesmoredates sits down with the legend himself to unpack a mindset that separated champions from competitors. Dorian Yates reveals why he never found value in watching bodybuilding shows—because for him, the real battle was already won before stepping on stage. The mental warfare, the discipline, the relentless pursuit of perfection—that's where victory lived. Stage time was just the victory lap.

From The Shadow Talk With Dorian Yates Podcast | EP 5

#bodybuilding #dorianyates #fitness #gym #workout #motivation #fitnessmotivation #gymmotivation #bodybuildingmotivation #muscle #training #fit #powerlifting #bodybuilder #gains #fitfam #gymlife #personaltrainer #strong #dedication",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\C9TixDkPDFd-1.mp4
"According to @moreplatesmoredates, here's a question that challenges conventional thinking: when APOB levels drop to childhood ranges, does that eliminate the risk of developing Atherosclerotic Cardiovascular Disease (ASCVD)? He breaks down the science behind lipoproteins and what the data actually reveals about cardiovascular protection.

#APOB #ASCVD #cardiovascular #heartdisease #cholesterol #lipoproteins #hearthealth #longevity #preventativemedicine #biohacking #healthoptimization #cardiology",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\Czrdy_wyL4z-1.mp4
"@moreplatesmoredates breaks down the science behind creatine's real impact on muscle growth and why that initial weight jump isn't what most people think 🧪 The truth about water retention vs actual gains might surprise you 💪

#creatine #creatinemonohydrate #supplements #bodybuilding #fitness #gym #musclegrowth #fitnesstips #gymtips #workoutmotivation #fitnessmotivation #bodybuildingmotivation #natty #naturalbodybuilding #science",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DASLodHv4TS-2.mp4
"@moreplatesmoredates breaks down why natural lifters and enhanced athletes need drastically different protein protocols. The science behind muscle protein synthesis changes completely when anabolic steroids enter the equation, and most people are either overshooting or undershooting their intake based on outdated broscience. He explains the optimal gram-per-pound ratios that actually matter for both camps.

#proteinintake #natty #steroids #mpmd #bodybuilding #musclebuilding #fitnesstips #gymknowledge #nattyornot #enhanced #proteinrequirements #musclescience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DA1zzwQykgI-1.mp4
"Jordan Syatt (@syattfitness) breaks down the critical importance of health optimization before problems arise. @moreplatesmoredates brings this essential conversation about preventative wellness strategies and why waiting until something breaks is the worst game plan for longevity.

#health #fitness #longevity #wellness #healthoptimization #preventativehealth #fitnesstips #healthylifestyle #biohacking #menshealth #womenshealth #fitnessmotivation #healthadvice #wellnessjourney #proactive",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DCc1dZbO-xh-2.mp4
"When @moreplatesmoredates realized he was speed-running through content without retention, he flipped the script entirely. Instead of racing through podcasts at 2x speed and blasting through books just to check them off a list, he started drilling the valuable information until it actually stuck. The shift from quantity to quality transformed how fast he could genuinely absorb and apply knowledge. Worth considering if you're consuming tons of content but remembering none of it.

From his podcast conversation with Andrew Wilkinson – and stay tuned for the reverse episode coming soon on Andrew's channel.

#podcast #learning #personaldevelopment #productivity #mindset #selfimprovement #knowledge #contentcreator #focus",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DD569h0J4Nn-1.mp4
"Starting height matters less than you'd think when it comes to limb lengthening—the real question is whether your body can handle the brutal recovery process. @moreplatesmoredates breaks down the mechanics of this controversial procedure with @brianthesasquatch, explaining how surgeons literally cut your bones and force them to regenerate longer. Full conversation drops next week.

#limblengthening #heightsurgery #podcast #fitness #bodybuilding #gym #workout #fitnessmotivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DFyh8a7SmvW-2.mp4
"@moreplatesmoredates breaks down the reality behind Hollywood's most jaw-dropping body transformations and whether the film industry's tight timelines make enhanced performance inevitable. The conversation with @awilkinson on the 'Never Enough' podcast explores what's actually achievable naturally versus what requires pharmaceutical assistance when actors need to bulk up or shred down in months instead of years.

#moreplatesmoredates #hollywood #steroids #bodybuilding #fitness #transformation #podcast #neverenough #peds #trt #bodytransformation #actors #fitnesstransformation #gym #nattyorjuice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DEkvPmjyTjt-2.mp4
"The legend is back in stock 👀

Gorilla Mind RUSH - the OG formula from @moreplatesmoredates that built the empire - is finally live again after being sold out.

This is the one that started everything. Peak productivity, laser focus, and energy that actually lasts.

If you know, you know 🦍

#gorillamind #rush #nootropics #focus #productivity #energy #supplements #preworkout #cognition #brainfuel #mentality #productivity #derek #moreplatesmoredates #mpmd",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DM8s_4gpNDN-2.mp4
"The line between therapeutic use and enhancement gets blurrier every day. When someone claims ""just TRT,"" @moreplatesmoredates breaks down whether that's become the new cop-out in fitness culture. While there are legitimate medical reasons for testosterone replacement therapy, equating it to natural status misses the entire point. This topic came up during his appearance on @awilkinson's new podcast—full episode drops Monday over at @neverenough2024 on YouTube.

#TRT #TestosteroneReplacementTherapy #Natty #FakeNatty #Bodybuilding #Fitness #Hormones #Testosterone #FitnessIndustry #PEDs #MorePlatesMoreDates #Podcast #FitnessPodcast #GymCulture #BodybuildingCommunity #FitnessTruth #Enhancement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DEdJFK-x7uV-1.mp4
"The harsh reality? Most TRT clinics aren't investigating the root cause of your low testosterone—they're just masking symptoms with hormones, according to @moreplatesmoredates

He explains how countless men get locked into lifelong hormone therapy after one low Total Testosterone reading, without anyone bothering to ask the critical question: WHY is your testosterone low in the first place?

The real issue could be inadequate pituitary signaling, poor testicular response despite normal signaling, or something completely different that actually has a solution beyond permanent TRT.

Comprehensive bloodwork reveals whether you're dealing with a hormone production problem, a signaling problem, or metabolic dysfunction—information that drastically changes your treatment path.

For those ready to understand what's actually happening in their body before making a permanent decision, www.marekhealth.com offers expert consultation with personalized lab panels that go beyond the surface-level testing most clinics provide.

#TRT #testosterone #hormonehealth #menshealth #trttherapy #hormones #optimization #bloodwork #health #wellness #fitness #lifestyle",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\moreplatesmoredates\DJ7S_19S6-v-2.mp4
"The audacity of spreading false information to millions deserves nothing less than public ridicule, according to @officialbenshapiro. When misinformation becomes the currency of public discourse, mockery might be the only appropriate response left.

#benshapiro #politics #misinformation #media #news #conservative #political #debate #truth #facts #publicdiscourse #accountability",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DCIMeQkP_T0-1.mp4
"When society redefines basic terms, @officialbenshapiro calls it out for what it really is. The question isn't about being behind the times—it's about whether we've lost our collective minds.

#BenShapiro #Conservative #Politics #DailyWire #PoliticalDebate #Culture #SocialIssues #FreeSpeech #Debate #Commentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DNjXVlzvDgR-2.mp4
"The grudge that keeps on giving 😂 Trump's got a memory like an elephant and @officialbenshapiro is here for every second of it

#Trump #DonaldTrump #BenShapiro #Politics #Conservative #PoliticalHumor #MAGA #Republican #DailyWire #PoliticalCommentary #TrumpNews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DNEJMFqOj83-1.mp4
"When Hollywood legend Denzel Washington speaks, people listen—and this time he's taking aim at cancel culture. @officialbenshapiro breaks down why this matters.

#DenzelWashington #CancelCulture #Hollywood #FreeSpeech #BenShapiro #Conservative #Politics #Culture",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DN_sJ8rDjgG-1.mp4
"The economic patterns that led to history's biggest financial disasters aren't as distant as we'd like to think. @officialbenshapiro breaks down the warning signs that appeared before major market collapses and why they matter for today's economy.

#economy #economics #finance #markets #investing #stockmarket #recession #inflation #federalreserve #monetary #fiscal #debt #crisis #history #education",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DNL3lfxueiO-2.mp4
"The debate that has everyone talking 💭 @officialbenshapiro puts the spotlight on how social media stardom compares to professional athletic careers in women's basketball. Where does the real influence lie? 🤔🏀

#benshapiro #dailywire #politics #conservative #news #debate #wnba #socialmedia #tiktok #influence #culture",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DNRV2kIugiw-1.mp4
"Michael Knowles' proposal story takes an unexpected turn when @officialbenshapiro nearly derails the whole thing. Plus, six-pack secrets you didn't see coming.

#BenShapiro #MichaelKnowles #ProposalStory #DailyWire #Conservative #PodcastClips #FitnessAdvice #SixPack #EngagementStory #BehindTheScenes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DP43yM0jOMl-2.mp4
"The argument breaks down when you try to measure human worth by capability, as @officialbenshapiro points out here. Worth isn't conditional—it's inherent.

#BenShapiro #Conservative #Politics #ProLife #HumanRights #Debate #PoliticalDebate #ConservativeValues #Truth #Logic",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DP9iggJj-80-1.mp4
"The conversation everyone's talking about just dropped 📚 @officialbenshapiro wrapped an incredible week diving deep into his latest work, and the insights are absolute fire. Lions and Scavengers is officially available – don't miss out on getting your hands on this one.

#BenShapiro #LionsAndScavengers #NewBook #PoliticalCommentary #ConservativeThoughts #MustRead #BookRelease #PoliticalDiscourse",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DOWnOHYD5VZ-1.mp4
"The distinction between biblical justice and social justice gets broken down by Voddie Baucham in this powerful moment shared by @officialbenshapiro. When theology meets cultural movements, understanding the foundation matters more than ever.

#voddiebaucham #benshapiro #socialjustice #biblicaljustice #christianity #theology #faith #truth #wisdom #conservative #politics #culture",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DPHyXmgDyC9-1.mp4
"The champagne socialist community just got a new PSA from @officialbenshapiro – apparently dog training via shock collar isn't the progressive flex you think it is. Hasan Piker learned this the hard way after footage surfaced of him allegedly using one on his dog mid-stretch.

#BenShapiro #HasanPiker #ChampagneSocialist #DogTraining #Controversy #PoliticalCommentary #NewsOfTheWeek",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DPmsfiQjnXT-1.mp4
"The roadmap to sustainable peace isn't what most people think. @officialbenshapiro breaks down the strategic approach that could actually work for lasting stability in the region.

#peace #israel #gaza #hamas #ceasefire #middleeast #benshapiro #politics #news #currentevents #geopolitics #conflict #solution #strategy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DPuaQQHjJsu-2.mp4
"The Daily Wire baby race has a frontrunner, and @officialbenshapiro wants to know if Matt Walsh is following the rules. With the highest kid count among his colleagues, Walsh's winning strategy might need an official review.

#BenShapiro #MattWalsh #DailyWire #Conservative #Politics #PoliticalHumor #Commentary #ConservativeMedia #Family #Kids",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DQaTbH2j9Sn-1.mp4
"The workforce is shrinking and major corporations are announcing layoffs left and right. @officialbenshapiro breaks down this week's troubling economic developments and what these cuts signal for the broader market.

#economy #economics #news #currentevents #business #corporateamerica #workforce #jobs #employment #marketanalysis #financialnews #economicnews",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DQcuYZJD3Yg-2.mp4
"According to @officialbenshapiro, Kim Kardashian's take on the moon landing just set a new bar for internet absurdity. She actually believes it was staged. He's calling this the dumbest clip currently circulating online—and that's saying something.

#BenShapiro #KimKardashian #MoonLanding #Internet #Viral #Politics #Commentary #DailyWire",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DQfOm9CCbPK-1.mp4
"**DEVELOPING:** Terrorist attack near White House—National Guard targeted in shocking incident. @officialbenshapiro reports on the breaking situation unfolding in the nation's capital.

#BreakingNews #NationalGuard #WhiteHouse #TerroristAttack #Washington #News #Breaking #CurrentEvents #Politics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DRkNo27DoPf-2.mp4
"The economic illusion is strong with this one. @officialbenshapiro breaks down how New York's leadership is operating under a fundamental misunderstanding of basic economics—and the state's economy is about to pay the price for their socialist fantasy.

#BenShapiro #Socialism #NewYork #Economics #Politics #Conservative #PoliticalCommentary #EconomicPolicy #NYC #PoliticalDebate #Conservatives",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DRiSnvhksuT-1.mp4
"The solution to America's economic challenges? @officialbenshapiro breaks down why free market capitalism—not government intervention—holds the answer to prosperity. When markets are allowed to function without excessive control, innovation thrives and opportunities multiply. It's a principle that's built economies, and Ben explains why it still matters today.

#benshapiro #capitalism #freemarket #economics #conservative #politics #economy #government #liberty #freedom #americaneconomy #conservativevalues #politicaltok #dailywire",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DRDf8q9Dq6S-1.mp4
"The immigration debate gets real when @officialbenshapiro breaks down the question everyone's thinking but few are asking: what values should unite us? Latest Friendly Fire episode tackles the tough conversations that matter.

#FriendlyFire #BenShapiro #Immigration #Politics #PoliticalDebate #ConservativeValues #PoliticalDiscussion #FreeSpeech #AmericanValues #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\officialbenshapiro\DRxgM5lDyKe-2.mp4
"Tom Cruise just got called out and the reaction is priceless 😂 @pbd.podcast captures the moment everyone's been thinking about

#podcast #podcasting #podcastclips #valuetainment #patbetdavid #business #entrepreneur #motivation #comedy #funny #funnyvideos #viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQ-gKToEw3l-1.mp4
"```
The price tag on regime change? $212 million. @pbd.podcast sits down with someone who turned down one of the most dangerous contracts in modern history—a hit on Maduro. The conversation that follows is nothing short of jaw-dropping.

#pbd #podcast #valuetainment #patrickbetdavid #business #entrepreneur #maduro #venezuela #politics #money #interview
```",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQhhWLIDlYm-2.mp4
"Tom Brady came prepared with proof to back it up 💯

📍 via @pbd.podcast

#TomBrady #PBDPodcast #PatrickBetDavid #NFL #Football #GOAT #Receipts #Proof #Legendary #Champion #Quarterback #TB12 #BradyReceipts #Valuetainment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQ5bng7E0qf-1.mp4
"@pbd.podcast teases a potential New York City appearance in the works 👀

#nyc #newyorkcity #podcast #valuetainment #pbd #patrickbetdavid #business #entrepreneur",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQpYBjsk5ZT-2.mp4
"Looking for perspectives on this one 🤔 What's your take?

Via @pbd.podcast

#podcast #podcasting #podcasts #podcastclips #spotify #podcastersofinstagram #motivation #motivational #inspiration #inspirational #inspire #success #successmindset #successquotes #motivationalquotes #inspirationalquotes #motivationalspeaker #inspirationalspeaker #motivationalvideo #valuetainment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQaXNHFE6RN-1.mp4
"@pbd.podcast catches the moment when reality hits different 😂

#valuetainment #patrickbetdavid #business #entrepreneur #success #motivation #inspirational #motivational #entrepreneurship #goals #leadership #entrepreneurlife #businessowner #mindset #successful #hustlehard #businessmindset #motivationalquotes #successtips #businessgrowth #leadershipdevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQNTRePk6yY-2.mp4
"PBD just said what everyone was thinking and the internet can't stop replaying it 😂 @pbd.podcast isn't holding back on this one

#pbd #valuetainment #patrickbetdavid #podcast #business #entrepreneur #entrepreneurship #motivation #success #mindset #businesspodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQfa-Eak7yb-1.mp4
"@pbd.podcast sits down for another powerful conversation that you won't want to miss. Tune in now 🎙️

#podcast #podcasting #valuetainment #patrickbetdavid #business #entrepreneur",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQU-0WRk_oO-2.mp4
"A deep dive into the missile misinformation that's been circulating about Trump and Ukraine – @pbd.podcast breaks down what's really happening versus what's being reported. When headlines don't match reality, these are the conversations that matter.

#Trump #Ukraine #FakeNews #MediaBias #PoliticalNews #NewsAnalysis #FactCheck #CurrentEvents #Politics #Media #Podcast #PBDPodcast #PatrickBetDavid",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQUTlQiCUKT-2.mp4
"The mask slips and the truth comes out – this is what real communism looks like, and it should alarm everyone paying attention.

Credit: @pbd.podcast

#communism #socialism #politics #economics #freedom #liberty #capitalism #政治 #podcast #podcastclips #viral #fyp",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQwvLkEk0cC-2.mp4
"The Muslim community celebrates a monumental win 🙏

via @pbd.podcast

#islam #muslim #muslims #allah #quran #islamicquotes #makkah #islamicpost #islamic #islamicreminders #hijab #sunnah #pakistan #prophetmuhammad #muslimah #jannah #madinah #ramadan #islamicreminder #allahuakbar #dua #deen #muftimenk #ummah #dubai #islamicart #prayer #india #turkey #indonesian",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQrpl-kDBCu-1.mp4
"The long-term implications? They could be absolutely catastrophic.

Via @pbd.podcast

#podcast #podcasts #podcastclips #valuetainment #patrickbetdavid #business #entrepreneur",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DRcTDu3DrtU-2.mp4
"Tom MacDonald and Adam Calhoun break down the harsh reality of political prisoners still locked up from January 6th while violent criminals walk free. Worth the watch. 🎥 @pbd.podcast

#TomMacDonald #AdamCalhoun #January6th #PoliticalPrisoners #Justice #PBDPodcast #Valuetainment #PatrickBetDavid #DoubleTandards #FreeSpeech #Truth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DRK1886jMmZ-1.mp4
"Tom Brady just revealed what actually drives championship teams, and it's not what most people think.

During his conversation on @pbd.podcast, the NFL legend broke down the real difference between good players and great ones – and why ego is the silent killer of potential dynasties.

Brady didn't hold back on what separates winners from everyone else in high-pressure moments.

#TomBrady #PBDPodcast #PatrickBetDavid #Leadership #Championship #NFL #Mindset #Success #Winning #TeamWork #Football #GOAT #BusinessPodcast #Motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DQ_-FceiUUW-2.mp4
"Tom drops a bombshell take that has everyone questioning everything they thought they knew. 👀

Does his argument hold up, or is there more to the story? Watch till the end and drop your take below. 

Via @pbd.podcast

#podcast #podcastclips #viral #trending #debate #controversy #pbd #valuetainment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DRNh19Nk6DQ-1.mp4
"Scott Jennings shares his unexpected observations from Dick Cheney's funeral service

Via @pbd.podcast

#ScottJennings #DickCheney #PoliticalCommentary #Funeral #WashingtonDC #Politics #PBDPodcast #Commentary #InsideView",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DRVMzaukz87-2.mp4
"Marty Makary breaks down the story behind his appointment in this revealing moment.

🎙️ Via @pbd.podcast

#MartyMakary #PBDPodcast #Podcast #Leadership #Interview #BehindTheScenes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DRpa5ejk0uJ-1.mp4
"Stephen Miller weighs in on this heated exchange 🎯

What's your take on his perspective? Drop your thoughts below 👇

Via @pbd.podcast

#StephenMiller #Politics #PoliticalDebate #Conservative #Trump #Biden #Election #PoliticalNews #Debate #AmericaFirst #MAGA #Republican #GOP #PoliticalDiscussion #CurrentEvents #News #Viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DRVgXGvkxWn-1.mp4
"The numbers don't lie and Vinnie came prepared with receipts 😂

via @pbd.podcast

#podcast #podcasting #podcasts #vinniepolitan #truecrime #news #debate #courttv #spotifypodcast #applepodcast #shorts #reels",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\pbd.podcast\DRx0A2Qk1dg-1.mp4
"The harsh reality check nobody wants to hear: no amount of documentation, legal status, or appearance will shield anyone from what's unfolding. @podsaveamerica breaks down why everyone needs to pay attention right now.

#crookedmedia #citizenship",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DN37EqqEmrF-1.mp4
"The highly anticipated Trump-Putin meeting drops Friday, but @podsaveamerica isn't holding their breath for any masterful dealmaking that actually stops Russia's assault on Ukraine.

#PodSaveAmerica #CrookedMedia",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DNQpxAisdIJ-2.mp4
"A sobering reality check from Dr. Lilly Mason via @podsaveamerica: America's struggle with violence and politics isn't always separate—and the intersection is where things get dangerous.

#podsaveamerica #crookedmedia #politicalviolence",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DO3p2Y0DTyF-1.mp4
"JD Vance's irritation factor gets dissected by @podsaveamerica in this one. The crew breaks down exactly what makes him tick in the most grating way possible.

#podsaveamerica #crookedmedia #jdvance",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DOJ6IV8lZic-2.mp4
"Marc Maron breaks down what happens when you stand up to power – and @podsaveamerica captured this essential moment. The comedian doesn't mince words about the price of resistance in today's political climate.

#PodSaveAmerica #CrookedMedia #Trump #MAGA",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DNwcXR4ZA44-1.mp4
"@podsaveamerica highlights the moment Jimmy Kimmel came back swinging 👊

#PodSaveAmerica #CrookedMedia #JimmyKimmel",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DPAClmLkS5C-1.mp4
"Senator Chris Murphy's stark warning cuts through the noise: ""What has already been a pretty dark year, could get a lot darker."" The conversation with @podsaveamerica captures a sobering assessment of where things stand and what's potentially ahead.

#crookedmedia #podsaveamerica",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DOpNctsgs_c-1.mp4
"Jon Favreau didn't hold back when @podsaveamerica discussed the silence from Chuck Schumer and Hakeem Jeffries on Zohran Mamdani's campaign. Three words said it all: ""It is pathetic.""

#podsaveamerica #crookedmedia #newyork #zohranmamdani",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DOKQF62DS8H-2.mp4
"Protests are happening again—No Kings returns this Saturday, October 18, as highlighted by @podsaveamerica

#PodSaveAmerica #CrookedMedia #NoKings",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DPzMju5gQ_s-1.mp4
"Looking for healthcare that doesn't actually exist? The far-right has a plan for that. @podsaveamerica breaks down the absurdity.

#PodSaveAmerica #CrookedMedia #Healthcare",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DPPRSTVgZ40-1.mp4
"The messaging war has a playbook, and Dan Pfeiffer just shared it. @podsaveamerica dives into the strategic moves Democrats need to make to come out on top.

#PodSaveAmerica #CrookedMedia #Democrats",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DPW-hbajRUK-1.mp4
"Standing firm against pressure tactics – Zohran Mamdani delivers a powerful message about resilience in the face of Trump's threats. His confidence in both the administration and the city's resolve speaks volumes. Via @podsaveamerica

#PodSaveAmerica #CrookedMedia #ZohranMamdani",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DQcxRDaDqZz-1.mp4
".@podsaveamerica's Tommy gets FTC Chair Lina Khan's take on her most unexpected supporters 🎯

Stream the full #crookedcon2025 lineup at crookedcon.com/program

#CrookedCon #LinaKhan #Politics #PodSaveAmerica #PoliticalPodcast #FTC #Interview",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DQ2TlHCkdX7-2.mp4
"A conversation about accountability and owning up to past online behavior – Graham Platner sits down to discuss his previous internet posts and comments.

The complete interview is available now on @podsaveamerica's YouTube channel.

#PodSaveAmerica #Politics #Interview #Accountability #PoliticalDiscussion #YouTube",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DQE4nELiYQI-2.mp4
"A decorated Army veteran shouldn't have to prove he belongs in the country he served—but that's exactly what George Retes was forced to do after being wrongfully detained by ICE. @podsaveamerica shares his powerful account of what happened.

#PodSaveAmerica #CrookedMedia #GeorgeRetes #Detainment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DQsHxisk_nd-2.mp4
"The message at #crookedcon was crystal clear when @sarahlongwell25 took the stage: keeping Epstein in the conversation isn't optional. @podsaveamerica captured this powerful moment where silence stops being an option.

#politics #politicaltiktok #podsaveamerica #crookedmedia #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DQxJmIRDxbE-1.mp4
"Representative Summer Lee weighs in on the congressional shake-up as Marjorie Taylor Greene steps down—@podsaveamerica catches her unfiltered take on what this means for Capitol Hill.

#PodSaveAmerica #CrookedMedia #MarjorieTaylorGreene",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DRhqnJjgBi--1.mp4
"According to @podsaveamerica, Senate offices are signaling to Rep. Ro Khanna that his bill demanding the Epstein files be released is on track for a swift Senate vote.

#RoKhanna #EpsteinFiles #Congress #Senate #Transparency #Politics #PoliticalNews #Breaking #PodSaveAmerica",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DRLPIiOj1sv-2.mp4
"Progressive voices Jon and Dan weigh in on the House drama surrounding Chuy Garcia in this must-watch breakdown from @podsaveamerica

#PodSaveAmerica #CrookedMedia #ChuyGarcia",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\podsaveamerica\DRVdnE1lNZA-2.mp4
"@profgalloway and @ed_elson_ dive into the dog debate—one makes his case for why the other needs a furry companion 🐕

From episode: The Great Sloppification of AI

#podcast #profgalloway #dogs #doglovers #petowner #aiconversation #lifedecisions #shouldigetadog",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DPesyEMCd0y-1.mp4
"The unsexy truth about wealth? It's built in the mundane moments nobody wants to talk about. @profgalloway breaks down why the boring stuff is actually your golden ticket.

#money #wealth #rich #investing #financialfreedom #personalfinance #success #millionaire #motivation #entrepreneur #business #finance",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DPplri2je4n-2.mp4
"@ProfGalloway needed some comfort, so @KaraSwisher offered her hand—though a hug was apparently asking too much.

via @profgalloway

#PivotTour",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQ-F35sErOM-1.mp4
"The dating résumés couldn't be more different: one's never experienced single life, the other built a career in it. When @KaraSwisher and @profgalloway get into relationship history, the ""beachfront property"" debate gets real. #PivotTour",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQ2vRoRjCb7-1.mp4
"According to @profgalloway, this pod episode features @kylascan breaking down how money and markets actually function. She's an economic commentator, educator, and the author behind ""In This Economy? How Money and Markets Really Work.""

#Economics #Money #Markets #Podcast #Finance #Economy #Business #Investing #FinancialEducation #MoneyTalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQcT6EhkYG9-1.mp4
"@profgalloway caught @KaraSwisher bringing the Rydell High energy with her inner Danny Zuko on full display 🎤⚡

#PivotTour",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQ8Eee8DLe9-1.mp4
"The Oval Office just got a DIY upgrade—two pieces of paper with gold script, and suddenly any room gets presidential status. @profgalloway and @karaswisher proved exactly that when they transformed the Pivot Tour stage into their own command center.

#PivotTour",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQ9-TRjEpp5-2.mp4
"@profgalloway calls out the harsh reality: waiting for tech companies to safeguard kids is a losing game. The industry won't regulate itself when profit is on the line. Parents and policymakers need to step up because Silicon Valley isn't coming to save our children.

#tech #technology #socialmedia #bigtech #techcompanies #children #parenting #regulation #siliconvalley #ai #podcast #profg",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQC_fH0jTzj-2.mp4
"Democracy under pressure becomes democracy refined. When @profgalloway sat down with @KaraSwisher, they explored a powerful truth: America's institutions are flexing under unprecedented strain during the Trump presidency—but that resistance might be exactly what makes them stronger. The real question isn't whether we're being tested. It's what we become after.

#PivotTour",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQ2m0LSjN34-2.mp4
"The healthcare debate just got a major voice: @profgalloway makes his case for why America needs to fundamentally restructure its medical system through nationalization. His perspective cuts through the noise with data-driven reasoning that's sparking serious conversation.

#healthcare #medicare #medicareforall #healthinsurance #universalhealthcare #politics #uspolitics #americanpolitics #healthcarereform #publichealth #medicalcare #healthpolicy #profgalloway",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQCq-yhERLv-1.mp4
"The tech industry's role in male isolation isn't what you'd expect. In his latest book ""Notes on Being a Man,"" Scott Galloway breaks down how AI and big tech are creating what he calls ""asocial, asexual males"" during his conversation with Anderson Cooper. @profgalloway tackles the loneliness epidemic affecting men today with raw honesty.

#scottgalloway #andersoncooper #mensmentalhealth #loneliness #masculinity #bigtech #AI #socialskills #modernmasculinity #menshealth #mentalhealth #relationships #dating #technology #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQo1srYkeQ6-2.mp4
"The real responsibilities of running a city might surprise you 🏛️

@profgalloway breaks down what being a mayor actually entails—and it's not what most people think. From budget decisions to crisis management, the role goes far beyond ribbon-cutting ceremonies.

Credit: @profgalloway

#mayor #leadership #politics #citygovernment #civics #publicsector #government #localgovernment #politicaleducation #civicengagement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DQxDsy-ic4x-1.mp4
".@profgalloway breaks down masculinity with Ben Stiller in a conversation that hits different. Their talk at @92ndstreety dives into his #1 New York Times Bestseller 'Notes On Being a Man' – and the full episode on The Prof G Pod is worth your time.

#ProfG #BenStiller #NotesOnBeingAMan #NYTBestseller #Masculinity #PodcastClips #BookTok #MensHealth #PersonalGrowth #SelfImprovement #92Y #TheProfGPod",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DRA8J6_Dbue-1.mp4
"The AI market has everyone asking the same question: are we in a bubble? @karaswisher and @profgalloway break down what investors need to know right now—and Scott's advice might surprise you. (Credit: @profgalloway)

#AI #investing #stockmarket #techbubble #marketanalysis #investingtips #artificialintelligence #financialadvice #techstocks #wealthbuilding",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DRhfk5pAEY4-2.mp4
".@profgalloway wasn't holding back when he gave @karaswisher this absolutely unhinged description of Marjorie Taylor Greene's entire vibe 💀

#ProfGalloway #KaraSwisher #MarjorieTaylorGreene #MTG #Politics #PoliticalCommentary #Podcast #Costco #RotisserieChicken #PoliticalHumor #Commentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DRM3boEABke-1.mp4
"The question isn't whether men are struggling—it's what kind of risk actually transforms them. @profgalloway breaks down why the current narrative around masculinity misses the mark entirely.

#scottgalloway #masculinity #mensmentalhealth #personaldevelopment #risktaking #modernmasculinity #menshealth #growthmindset #selfimprovement #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DRiEZMIklEA-1.mp4
"Looking back at that unforgettable night at @92ndstreety when @profgalloway sat down with @benstiller – the conversation that followed was pure gold. Worth revisiting every moment.

#BenStiller #ScottGalloway #ProfG #92Y #Conversation #Interview #Comedy #Business #Leadership #Insights #NYC #NewYork #PodcastClips #Wisdom #Entertainment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DRu1MaiEYpV-1.mp4
"Kara Swisher isn't holding back with her advice for NYC Mayor-elect Zohran Mamdani before he heads into a meeting with President Trump. Her message? Watch out for those couch moments with JD Vance. @profgalloway captures the tech journalist's signature sharp commentary as she weighs in on the political optics that could make or break Mamdani's early days in office.

#KaraSwisher #ZohranMamdani #Trump #JDVance #PoliticalAdvice #NYCMayor #TechJournalism #PoliticalCommentary #Leadership #Politics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\profgalloway\DRUkG63jVEQ-2.mp4
"The newest member just joined the crew, and Mochi Man is officially in! 🤩🐾 @realalexclark welcomes another one to the family.

#dog #dogs #dogsofinstagram #puppy #puppies #puppiesofinstagram #pet #pets #petsofinstagram #funny #funnyvideos #comedy #relatable",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DBgl7IOP174-1.mp4
"@realalexclark sits down with Dr. Joel 'Gator' Warsh to tackle the questions everyone's asking but few are answering—what's really behind the autism rate explosion? This Culture Apothecary episode dives deep into integrative pediatric insights, Amish community observations, and whether intervention can change outcomes. Dr. Warsh, a Board Certified Pediatrician and author of Parenting at Your Child's Pace plus the upcoming Between A Shot And A Hard Place, brings his expertise from @DrJoelGator straight to this conversation 💚🌿 Stream now on all podcast platforms and the Real Alex Clark YouTube channel. Drop 'AUTISM' below for the direct link 🧩

#podcast #autism #integrativemedicine #pediatrician #parenting #health #wellness #cultureapothecary #drjoelgator #parentingtips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DDyFuDcuw4K-1.mp4
"When a vegetarian and a carnivore walk into the same conversation, chaos is guaranteed. @primetimestein and @realalexclark prove that diet debates never disappoint. 🥩🥗

📹 @realalexclark

#vegetarian #carnivore #meatdebate #dietdebate #comedy #funny #memes #relatable #fyp",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DG6FBNYuYp6-1.mp4
"Getting 90+ biomarkers checked without leaving home? That's exactly what @realalexclark discovered with @gogeviti. A phlebotomist comes straight to the door, tests everything from lipids to thyroid panels to vitamin levels and hormones, then a virtual health team breaks down the results and tracks progress through their app. Retests happen every 6 months, plus they can prescribe peptides and other treatments as needed.

Memberships run $110–$130 monthly, but his code ALEX takes 20% off the first month at gogeviti.com—no waitlist.

#gevitipartner

When's the last time you got comprehensive bloodwork done?!",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DFOQrG6zU7g-1.mp4
"@realalexclark sits down with @drwillcole—Hollywood's go-to functional medicine expert and The Art of Being Well host—for a deep dive on Culture Apothecary that's already turning heads. From the unique protocol he designed for Gwyneth Paltrow to his bold MAHA stance that had colleagues up in arms, Dr. Cole holds nothing back. They unpack cortisol face, expose how alcohol research gets manipulated, break down peptides, discuss PCOS solutions, and so much more. Stream it now on the Real Alex Clark YouTube channel or wherever you get your podcasts 💚🌿 Drop 'ALCOHOL' below for the episode link sent straight to your DMs!

#CultureApothecary #DrWillCole #FunctionalMedicine #MAHA #AlcoholTruth #CortisolFace #Peptides #PCOS #GwynethPaltrow #HealthPodcast #IntegrativeMedicine #WellnessJourney #TheArtOfBeingWell #PodcastEpisode #HealthyLiving",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DEgZPiFSP7J-1.mp4
"A bold statement incoming from @realalexclark 👀

Glam: @kissbykatietx

#trend #trends #style #outfit #ootd #ywls2025 #outfits",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DK3DhQDyWjE-2.mp4
"Will Harris has been working his family's Georgia land for four generations, and what he revealed about modern farming practices might change how you look at your grocery cart forever. In this Culture Apothecary conversation with @realalexclark, the White Oak Pastures owner doesn't hold back—from exposing greenwashing tactics to breaking down what's really happening with antibiotic chicken and debunking organic labels. The discussion covers regenerative agriculture, conventional farming's darker side, and whether grass-finished vs grain-finished actually matters. Stream the full episode now on Real Alex Clark's YouTube or wherever you listen to podcasts 🌿

Drop 'MEAT' below for the episode link 🥩

When brands slap ""organic"" on the label, are we getting the truth or just good marketing?

#RegenerativeAgriculture #OrganicFarming #SustainableFarming #EthicalFarming #WhiteOakPastures #CultureApothecary #GrassFedBeef #RegenerativeFarming #KnowYourFarmer #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DEoKaxovalc-2.mp4
"The health insurance system isn't working for most people—but Andy Schoonover built something different. In this @cultureapothecary conversation, @realalexclark sits down with the @joincrowdhealth founder to explore how his Christian platform is helping people crowdfund medical expenses while ditching traditional insurance limitations. From functional medicine to chiropractic visits, members get to spend their dollars on wellness that actually matters. Stream it now on your favorite podcast app or YouTube! Drop 'INSURANCE' below for the link 💌💚🌿

#healthinsurance #crowdhealth #christianbusiness #functionalwellness #medicalfreedom #wellnessjourney #holistichealth #healthcarereform #podcast #newepisode",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DI2bAbNzjff-2.mp4
"When the furniture store sees her pulling up after a breakup 💀 @realalexclark captures the chaotic energy of redecorating your entire life instead of just getting bangs

#women #healthandwellness #healthandfitness #relationships #propaganda #trends",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DKSxhDjTWoS-1.mp4
"Helen Morrison just revealed why Hollywood's been obsessed with these mysterious patches for over a century—and it's not what you'd expect. @realalexclark sits down with the 5th generation CFO of @frownies to uncover how this vintage beauty secret became the clean alternative celebrities choose over injections. 💚✨

Stream the full @cultureapothecary episode now on YouTube under 'Real Alex Clark' or your favorite podcast platform! 🌿

Drop 'FROWNIES' below for the direct link 💌

Ever heard of them before? 👀

#frownies #cleanbeauty #skincare #naturalskincare #antiaging #beautysecrets #skincareproducts #botoxalternative #podcast #podcastepisode #cultureapothecary #beautypodcast #skincaretips #naturalbeauty #beautyproducts",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DIcpjjPSOOs-1.mp4
"Alex from @realalexclark is testing out a personalized peptide serum from @regenere_skincare, and the early glow-up is real 💧✨ He's documenting his progress over 60 and 90 days to show the full transformation.

Want to try your own custom formula? Use code REALALEXCLARK for 10% off. Drop ""SKIN"" in the comments for a link to the personalized quiz and first-order discount 🌿

#RegenerePartner #MyRegenere #skincarejourney #cleanbeauty",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DKfV0wDyRSj-2.mp4
"Behind the scenes of his latest podcast, Alex Clark (@realalexclark) put his own apartment under the microscope—literally 🔬

Ryan Blaser from @testmyhome didn't just show up to chat. He came equipped to test everything: mold spores, EMFs, air quality, water toxicity, the works. The trusted environmental health expert who's worked with Lauryn Bosstick and Paul Saladino turned Alex's one-bedroom into a full-on health investigation site 🏠⚠️

Could invisible threats in your living space be the reason you feel off? Brain fog, constant fatigue, unexplained symptoms—sometimes the culprit isn't your body, it's your building 😷

After surviving his own battle with environmental illness, Ryan now helps people detect what's lurking where they live. This @cultureapothecary episode breaks it all down (and Alex promises a vlog with the shocking results coming soon) 🎥

Stream it now on all podcast platforms or catch it on Real Alex Clark's YouTube 💚🌿

Drop 'MOLD' in the comments for the direct link!

Ever questioned if your home environment was affecting your health?

#mold #moldtoxicity #emf #healthyhome #environmentalhealth #podcast #wellness #holistichealth #toxins #airquality #homehealth #chronicillness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DIutv_JTvAO-2.mp4
"Tucker Carlson opens up like never before in @realalexclark's latest Culture Apothecary episode! From navigating fatherhood and marriage challenges to the Epstein files, Elon and Trump's relationship shift, his Fox News exit, and even nicotine benefits—plus that raw truth about husbands feeling jealous when babies arrive. Alex pulls out the unfiltered stories you won't hear anywhere else. Stream now on all podcast platforms or search 'Real Alex Clark' on YouTube! Drop 'TUCKER' below for the direct link! 🎙️✨

#TuckerCarlson #AlexClark #CultureApothecary #PodcastEpisode #CandidConversation #Marriage #Parenting #FoxNews #ElonMusk #Trump #RealTalk #NewEpisode #PodcastRecommendation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DMDaNesO7oK-1.mp4
"When @realalexclark brings on @healthillie, you know the wellness industry is about to get exposed 👀 These two don't hold back, and Illie Balaj—holistic health coach, clean wellness store founder, and author of Yummy Colors—is serving up unfiltered truths alongside her friend Alex on the latest Culture Apothecary episode.

Stream wherever podcasts live or catch 'Real Alex Clark' on YouTube 📺 Want it sent straight to you? Drop 'TEA' below for the DM link 💌

This conversation hits different when it's two savage friends who actually know their stuff, calling out industry frauds while sharing the health hacks that actually work 🌿✨ Plus: has Alex's Trader Joe's obsession finally converted you? 

#CultureApothecary #HealthilliE #HolisticHealth #WellnessPodcast #PodcastEpisode #CleanWellness #HealthTips #WellnessCommunity #PodcastRecommendation #YummyColors",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DMrBd8nytTh-1.mp4
"The biological age test that put @realalexclark at 18 years old has everyone talking. 👀

Through @gogeviti's system, he gets more than supplements—it's a complete analysis of 100+ biomarkers combined with his actual lifestyle habits, training schedule, and recovery patterns. The result? Custom daily packs designed specifically for his body's needs.

Everything lives in their app: his customized plan, tracking tools, and health data consolidated in one dashboard. What makes Geviti different is their philosophy—wellness adapts to fit his life, not the other way around. Zero filler. Zero cookie-cutter formulas. Just targeted results.

Grab 20% off your first order with code 'ALEX' at gogeviti.com/cultureapothecary ✨

Drop 'AGE' below for the direct 🔗 + discount code via DM!

Ever checked your biological age? 

#biohacking #longevity #menshealth #wellness #antiaging #healthoptimization #supplements #fitness #recovery #geviti",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DN3osFGZJrC-1.mp4
"@realalexclark sits down with @calleymeans, the co-founder of TrueMed and voice behind the Make America Healthy Again movement, for a raw conversation that cuts through the noise. Fresh on @cultureapothecary, Calley breaks down his time as a special government employee at the White House and reveals the real story: Trump's alleged pharma deals, why kids are hitting puberty earlier than ever, the infertility crisis nobody's talking about, RFK Jr.'s controversies, and where MAHA is headed in year two.

Drop 'MAHA' below for the full episode link 🔗

Cell phones in schools—ban them or keep them? Weigh in 📱

#MAHA #MakeAmericaHealthyAgain #CalleyMeans #BigPharma #RFKJr #HealthFreedom #Wellness #PodcastEpisode #CultureApothecary #AlexClark #TrueMed",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DQppy58EhZm-1.mp4
"@gogeviti just made functional medicine accessible to 47 states — @realalexclark shows how personalized health testing is finally within reach for everyone. 🏡💉

Their at-home wellness program includes a concierge health team analyzing over 100 biomarkers to customize your care. No more being left out of advanced health solutions. ⚡️

Head to gogeviti.com/cultureapothecary with code 'ALEX' for 20% off. Drop ""HEALTH"" below for the direct link 🔗💌

#healthrevolution #functionalmedicine #wellness #biomarkers #personalizedhealth #wellnessjourney #healthoptimization #preventivehealth #holistichealth #biohacking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DQe-IGrEmd3-2.mp4
"Mike Feldstein never imagined disaster zones would teach him the secret to better sleep, clearer skin, and calmer mornings—but here we are. The @jasprco founder sits down with @realalexclark on the latest @cultureapothecary episode to explain how invisible toxins in your living room might be the reason you feel ""off"" even after a full night's rest 💚🌿

From contaminated nurseries to the real reason behind chronic snoring, Mike breaks down what hospital-grade air quality actually means and why most homes are quietly sabotaging our health. He's even building a non-toxic school in Austin based on these principles 🏠☁️

Stream it now—search 'Real Alex Clark' on YouTube or your favorite podcast app 📺 Drop 'AIR' in the comments for a direct link sent straight to your DMs 🔗💌

Have you ever considered what you're actually breathing indoors?

#airquality #nontoxic #wellness #holistichealth #cleanliving #healthyhome #podcast #newepisode #indoorair #toxinfree #naturalhealth #sleepbetter #anxietyrelief",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\realalexclark\DQVV8v_Aa-F-2.mp4
"The airwaves, international asylum, and artificial intelligence deception—three questions that demanded answers. Rory and Alastair tackled them all in their latest question time session, dissecting Reform's media presence, the case for a worldwide refugee alliance, and whether AI manipulation was always inevitable. @restispolitics delivers the analysis worth hearing.

#politics #ukpolitics #britishpolitics #news #greatbritain",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DK-DVChoDRk-2.mp4
"Alastair Campbell and Rory Stewart unpack one of politics' biggest contradictions: voters with strong values backing leaders who seem to have none 🎯

Via @restispolitics

#politics #politicians #society #restispolitics #podcastclips #politics101 #ukpolitics #podcast #politicstok #politicaltiktok #politicalpodcast #politicalcommentary #podcastclip",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DK97YFRBpAb-2.mp4
"```
When political strategy meets reality check – Rory weighs in on what Kemi Badenoch needs to hear 👀

Via @restispolitics

#restispolitics #politics #politicstiktok #politicstok #ukpolitics #rorystewart #kemibadenoch
```",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DKVDQ4PPpa3-1.mp4
"When the internet demands answers, Rory and Alastair deliver – diving into the Han Solo meme that's been on everyone's mind 🎬

🎙️ @restispolitics

#RestIsPolitics #Politics #UKPolitics #PoliticalPodcast #PoliticalDiscussion #Podcast #HanSolo #Meme #InternetCulture",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DLps2Tyojk9-1.mp4
"Europe's energy dependency isn't something they can just switch off overnight. Rory and Alastair from @restispolitics break down the complex reality behind why cutting off all energy imports would create more problems than it solves 🔋

#RestIsPolitics #Politics #Energy #Europe #GeopoliticalAnalysis #PoliticalDiscussion #CurrentAffairs #EnergyPolicy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DN5uyE4DBA9-1.mp4
"@restispolitics just wrapped another double-header with Katty K and Alastair Campbell, and the chemistry? Already on point 👏

Fresh episode drops tonight – you know what to do. ✅

#RestIsPolitics #Politics #Podcast #KattyK #AlastairCampbell #PoliticalPodcast #UKPolitics #NewEpisode #PodcastRecommendation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DMsD8xeod7j-2.mp4
"The numbers don't lie – Reform UK's media presence has exploded beyond anyone's predictions. @restispolitics breaks down why they're dominating your screen time lately.

#RestIsPolitics #UKPolitics #PoliticalNews #ReformUK #BritishPolitics #Politics #MediaAnalysis #UKNews #PoliticsExplained #PoliticalCommentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DLPVC3ePhoy-2.mp4
"Episode 2 drops into the JD Vance story where things get interesting—peeling back the carefully crafted image to reveal the power players pulling strings behind closed doors. @restispolitics asks the question everyone's thinking: if he's the voice of working America, whose interests is he actually serving?

Dive into ""The Real JD Vance: The Power Behind the Man"" exclusively on The Rest Is Politics Plus. New episodes every Friday.

Join at www.therestispolitics.com

#JDVance #Politics #PoliticalPodcast #TheRestIsPolitics #PoliticalAnalysis #AmericanPolitics #Documentary #BehindTheScenes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DLZ1oympxUf-2.mp4
"Looking for answers on how Democrats lost to Trump twice? Congressman Seth Moulton breaks it all down with Alastair & Rory in this episode of Leading. Worth watching before your evening plans kick in. 

Via @restispolitics

#RestIsPolitics #Leading #SethMoulton #Democrats #Trump #Politics #PoliticalPodcast #USPolitics #PoliticalAnalysis #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DMLLMSmCQvx-2.mp4
"Who would they pick in a nightmare scenario ballot box showdown? @restispolitics tackles the ultimate political dilemma: Corbyn vs Farage at the polls. Rory and Alastair reveal their choice when faced with this hypothetical election decision.

#RestIsPolitics #Politics #UKPolitics #PoliticalDebate #Corbyn #Farage #Election #PoliticalDiscussion #PoliticalPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DNfXUdoiIWH-1.mp4
"When America's playbook becomes impossible to read, what's the next move for its allies? @restispolitics breaks down the diplomatic dilemma 🌍

#restispolitics #politics #politicstok #geopolitics #international #diplomacy #worldnews #foreignpolicy #uspolitics #globalpolitics #allies #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DOndOL_DYUJ-2.mp4
"Wild doesn't even begin to cover this story from Rory, according to @restispolitics 🤯

#RestIsPolitics #Politics #PoliticsUK #UKPolitics #PoliticsPodcast #Podcast #RoryStewart #AlistairCampbell",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DPBSoUaiuCs-1.mp4
"Michael Gove steps into the Leading chair for an unmissable conversation 🎙️

@restispolitics drops this one soon and it's set to be compelling viewing.

#Leading #RestIsPolitics #MichaelGove #Politics #PoliticalPodcast #UKPolitics #PoliticalInterview",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DQHoAP7juOa-1.mp4
"A 78-year-old man's thoughts on pregnancy pain? Alastair and Rory aren't buying it. They break down Trump's Tylenol remarks with their signature wit 🎯

via @restispolitics

#RestIsPolitics #Politics #Trump #PoliticalCommentary #PodcastClips #UKPolitics #Commentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DPLbMSTCugQ-2.mp4
"A Gazan artist is turning survival into statement. Ahmed Muhanna takes World Food Programme boxes and creates something the world needs to see—art born from resilience. @restispolitics brings us this powerful story.

#RestIsPolitics #Gaza #AhmedMuhanna #Art #WFP #Resilience #PalestinianArt #HumanitarianCrisis #ArtForChange #MiddleEast #Politics #PoliticalPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DPV0iXYE1VH-2.mp4
"The polls tell a brutal story for Keir Starmer right now. But Emmanuel Macron faced similar numbers and managed to turn things around. Could the PM follow the same playbook? @restispolitics breaks down whether a political comeback is on the cards.

#KeirStarmer #UKPolitics #EmmanuelMacron #PoliticalAnalysis #RestIsPolitics #Labour #LabourParty #UKPoliticalNews #PMQuestions #PoliticsUK #BritishPolitics #PollingData",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DOs937SkXyp-1.mp4
"The Christian Right's expansion isn't slowing down—it's gaining momentum, with Nick Fuentes at the center of the storm. 🇺🇸

Rory and Alastair break down the forces driving this movement and what it means for America's future. @restispolitics

#Politics #ChristianRight #NickFuentes #USPolitics #PoliticalAnalysis #CurrentEvents #PoliticalPodcast #TheRestIsPolitics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DRP52E6ACqj-2.mp4
"The quest to pinpoint humanity's greatest triumph leads to an unexpected conclusion in this exchange between Alastair and Rory. Through their discussion, the duo arrives at a profound realization: perhaps our collective momentum matters more than any single breakthrough. @restispolitics explores this thought-provoking question with @peoplespostcodelottery

#RestIsPolitics #HumanAchievement #BiggestMoment #Philosophy #Progress #Podcast #DeepThoughts #CollectiveProgress #History",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DRiA-OmAFOL-2.mp4
"What would happen if Keir Starmer finally said what millions are thinking about Brexit? Alastair Campbell lays out the exact speech he believes needs to be delivered.

Via @restispolitics

#RestIsPolitics #AlistairCampbell #KeirStarmer #Brexit #UKPolitics #LabourParty #PoliticalCommentary #BritishPolitics #Politics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\restispolitics\DRKeiLVCcOw-1.mp4
"@russellbrand addresses the situation head-on, delivering his side of the story without holding back. Sometimes silence isn't an option, and this is one of those moments where speaking up becomes necessary. Watch his full perspective unfold.

#russellbrand #response #truth #speakingout #settingtherecordstraight #perspective #accountability #controversy #statement #publicfigure #media #2024",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DIB7350sSGx-2.mp4
"@russellbrand breaks down the moment it became undeniable – the establishment's narrative just hit a wall they can't spin their way out of. When the facts speak this loud, even the most carefully crafted story falls apart. Watch him connect the dots between what they're telling us and what's actually happening.

#russellbrand #truth #media #awakening #conscious #awareness #questioning #reality #narrative #establishment #facts #breaking #official #exposed",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DHUOFarP6qj-2.mp4
"The ultimate showdown: a century of humans versus one silverback 🦍 @russellbrand breaks down this wild hypothetical that's got everyone picking sides

#gorilla #silverback #animalfacts #nature #wildlife #debate #hypothetical #animalkingdom #strength #power",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DJew4D9O0sY-1.mp4
"@russellbrand breaks down the uncomfortable truth about how power really operates behind closed doors – and why the public rarely gets to see what's actually happening. This perspective challenges everything we think we know about transparency in leadership.

#russellbrand #news #awareness #truth #consciousness #exposed #reality #wakeup #mindset #perspective #media",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DHNH4xjsrHU-1.mp4
"Media mayhem gets the breakdown it deserves as @russellbrand joins from Nashville to dissect the headlines spinning out of control—Greta Thunberg's deportation drama, the Simone Biles and Riley Gaines showdown, plus Elon Musk's apology to Trump. Meanwhile, @rubinreport delivers the hard truth about Los Angeles descending into chaos, offering practical steps for protection and peace amid the unrest.

Episode 6 of The Actual Friends Podcast tackles it all (and yes, @sagesteele was missed!)

#RussellBrand #ActualFriends #Podcast #MediaAnalysis #CurrentEvents #GretaThunberg #SimoneBiles #RileyGaines #ElonMusk #LosAngelesRiots #DaveRubin #PoliticalCommentary #NewsBreakdown",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DK2hxxqy1eD-1.mp4
"The disbelief is real 😭 When @russellbrand says he can't handle it, you know it hit different. Watch till the end 👀

#russellbrand #viral #fyp #explore #trending #comedy #funny #relatable #react #reaction",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DLYJtsSv4ZH-2.mp4
"@russellbrand breaks down how modern power structures actually operate behind the scenes of democracy. The uncomfortable truth about who really pulls the strings might surprise you.

#russellbrand #politics #truth #awareness #democracy #power #society #critical #thinking #wakeup #reality #media #control #freedom #questioning",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DLSQdStsaXN-2.mp4
"What happens when @russellbrand sits down with Sage and Dave? Sparks fly over Tucker Carlson's latest takes, the Iran situation, Caitlan Clark's impact, Whoopi's comments, and so much more. Episode 7 is serving the unfiltered conversations you need to hear 🔥

#RussellBrand #Debate #TuckerCarlson #Iran #CaitlanClark #Whoopi #Episode7 #Podcast #HotTakes #DeepConversations #RealTalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DLInApDJIjw-1.mp4
"What if everything we've been told about the war on drugs is backwards? @russellbrand breaks down the legalization debate that has everyone divided.

Drop your stance below ⬇️

#drugs #legalization #debate #politics #society #controversy #warondrugsfailed #policy #freedebate #criticalthinking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DNilqRPStfi-1.mp4
"@russellbrand breaks down what happens when power goes unchecked and accountability disappears. This is corruption at its finest.

#corruption #politics #power #accountability #truth #awareness #wakeup #exposed #system #media #news #currentevents #political #society #justice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DPZyI-3kwK9-1.mp4
"Comedy's ultimate test? When it roasts you so hard your PR team has to issue a statement. South Park's latest episode landed Trump in bed with Satan—literally—and triggered an official White House clap-back labeling the show ""irrelevant."" But here's what makes it brilliant: NPR, 60 Minutes, and cancel culture all got torched in the same episode. @russellbrand breaks down why authentic satire doesn't pick sides—it picks targets.

#SouthPark #Comedy #Satire #FreeSpeech #Trump #CancelCulture #ComedyIsNotDead #StandUpComedy #PoliticalComedy #RussellBrand",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DMvYet3sixV-1.mp4
"A widow's impossible act of grace just days after tragedy—Erika Kirk chose forgiveness over revenge when she faced her husband Charlie's killer. While empires crumble and kingdoms turn to dust, moments like these reveal what truly endures beyond human power and pride.

Credit: @russellbrand

#faith #forgiveness #grace #christ #christianity #testimony #hope #strength #jesus #godisgood #faithoverfear #christianfaith #gospel",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DO7G2nnjEC9-1.mp4
"@russellbrand teams up with Dr. Drew to examine a mayor's controversial stance: violence is just ""a construct"" and Rikers Island should become a rehabilitation center. They dissect how political ideology collides with the reality of keeping communities safe.

#russellbrand #drdrew #publicdebate #politicaldiscussion #publicpolicy #publicsafety #politics #podcastclips #controversy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DQ4q8avkmDR-2.mp4
"@russellbrand is giving away a Jeep 392 with an incredible entry boost for Thanksgiving – 25X entries for every dollar spent at TryReborn.com. Whether you've been curious about the methylene blue, colostrum, or tallow products, now's the perfect moment to stock up and maximize your chances to win. #RebornWellness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DRfOppXkY_T-1.mp4
"A woman's voice matters on The View—apparently only when her husband isn't RFK Jr. @russellbrand calls out the selective empowerment 👀

#TheView #RFKJr #MediaBias #PoliticalCommentary #RussellBrand #Hypocrisy #MainstreamMedia #FemaleEmpowerment #DoubleStandards #Media",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DQ-PiQrCSku-2.mp4
"@russellbrand highlights Thomas Massie's shocking revelation about the Epstein files containing names of 20 men, with the CEO of Barclays among them.

#Epstein #ThomasMassie #Barclays #Truth #Accountability #PowerExposed #JusticeMatters #EliteSecrets",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DRiZpH4greO-1.mp4
"The Epstein files reportedly contain names of 20 men, with Barclays' CEO among them—according to Thomas Massie's recent statements, as shared by @russellbrand

#ThomasMassie #EpsteinFiles #Barclays #CEO #Transparency #Accountability #Truth #Politics #News #Viral #Trending #Exposed",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DRiZpH4greO-2.mp4
"@russellbrand breaks down the contradictions we're all living with but nobody wants to say out loud. When the system claims to protect you while simultaneously benefiting from your dependence, you have to question what's really going on. This perspective hits different when you realize how deep it goes.

#russellbrand #awakening #consciousness #truth #criticalthinking #questioneverything #awareness #mindset #perspective #reality #systemicchange #wakeup #truthseeker #deepthoughts #society",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DRIAMbKDfu--1.mp4
"The clock's ticking on your shot at a Jeep 392 with unnecessary amounts of horsepower—and @russellbrand wants to know what's stopping you. Every dollar at tryreborn.com unlocks 50X entries into the giveaway. Fortune favors the bold, not the hesitant. ⚡ #WeAreAllReborn",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\russellbrand\DRxkgC0De8j-2.mp4
".@williamh.mcraven, a four-star Navy admiral, stopped by for a personal tour of the bookstore owned by @ryanholiday – @paintedporchbookshop just outside Austin, Texas.

#books #bookstore #booklover #reading #bookstagram #austintexas #texas #navy #admiral #paintedporch #independentbookstore #bookshop #localbookstore",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DMmGkyTsJbf-1.mp4
"A powerful reminder that not all routines serve us well – some quietly work against us. @ryanholiday breaks down how certain patterns in our lives can become our downfall.

Full conversation with @elliot.ackerman drops soon on @dailystoicpodcast

#stoicism #dailystoic #habits #selfimprovement #personalgrowth #mindset #philosophy #stoicphilosophy #wisdom #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DLu1riTMOT_-2.mp4
"What if the career path society applauds is actually leading nowhere? Historian and bestselling author @rutgerbregman sits down with @ryanholiday to dismantle conventional wisdom about what makes work truly matter. From ordinary individuals who achieved extraordinary moral victories to the uncomfortable truth about prestigious jobs that contribute nothing—this conversation challenges the metrics we use to measure a life well-lived.

🎙️ Listen on The Daily Stoic Podcast

#stoicism #philosophy #meaningfulwork #careerdevelopment #lifepurpose #personalgrowth #selfimprovement #motivation #podcast #worklifebalance #success #rutgerbregman #dailystoic",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DLnHn1-OACW-2.mp4
"The question everyone's asking right now gets explored in Austin this September 17. @ryanholiday goes live with Daily Stoic to tackle the AI conversation head-on. This is your chance to be in the room where it happens.

Tickets and full details at dailystoiclive.com

#DailyStoic #Stoicism #ArtificialIntelligence #AI #AustinTexas #LiveEvent #Philosophy #ModernStoicism #StoicPhilosophy #RyanHoliday",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DNgfaftBJ3x-1.mp4
"A chance encounter with ancient philosophy changed everything for Ryan Holiday (@ryanholiday). What started as research for a book became a lifelong practice—Stoicism wasn't just something to write about, it became the framework for how he lives. Sometimes the subjects we study end up studying us back.

#stoicism #stoicphilosophy #philosophy #ancientwisdom #personalgrowth #lifelessons #mindset #selfimprovement #dailystoic #stoic #philosophyoflife #wisdom #mentalhealth #mindfulness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DOlv77PjYEH-1.mp4
"When parenting success isn't measured by how long they stay in your house, but by who they become when they leave it. @ryanholiday breaks down what really matters in raising kids.

Catch the complete discussion between Ryan and Dr. Aliza Pressman (@raisinggoodhumanspodcast) on @dailystoicpodcast—available everywhere you stream.

#parenting #parenthood #stoicism #dailystoic #parentingtips #raisingkids #stoicphilosophy #parentingadvice #modernparenting #philosophy #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DNGXsZfOiSO-2.mp4
"When Ryan Holiday (@ryanholiday) spotted his name alongside questionable company on a recent Freedom Fest lineup, he did what his younger self never would have—called it out in real time from the stage. No PR-approved dodge, no backstage whispers. Just straight honesty with an audience that could've turned on him for it. They didn't. Growth isn't always polite, and sometimes the most stoic move is refusing to stay silent.

#RyanHoliday #Stoicism #FreedomFest #SpeakingTruth #PersonalGrowth #IntegrityMatters #PublicSpeaking #ModernStoic #PhilosophyInAction #StandForSomething #AuthenticLeadership #NoFilter #RealTalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DMI4nqRRUzm-1.mp4
"The Ross Ulbricht story stopped @ryanholiday in his tracks. After reading a New York Times piece, he knew silence wasn't an option anymore. Standing on stage at Freedom Fest, he broke from his earlier-career playbook of avoiding controversy. His message wasn't about picking teams—it was a challenge to actually think. Sometimes the most important conversations are the uncomfortable ones.

#freedomfest #rossulbricht #criticalthinking #speakyourtruth #philosophyinaction #stoicism #modernstoic #courageover comfort #questioneverything #authenticity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DOtwkZTAe47-2.mp4
"Just announced: @ryanholiday is bringing a rare live experience to Austin, Texas this September 17th. He doesn't hit the stage often, so this is one you won't want to miss. Grab your spot at dailystoiclive.com before they're gone 🎟️

#RyanHoliday #DailyStoic #Stoicism #AustinTexas #LiveEvent #StoicPhilosophy #ATX #PersonalGrowth #Philosophy #Mindfulness #SelfImprovement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DOeKb0TESMa-2.mp4
".@angelalduckworth stopped by @paintedporchbookshop, and Ryan Holiday (@ryanholiday) made sure she left with some carefully chosen reads from his personal favorites collection 📚

#books #bookstore #reading #bookshop #booklover #bookstagram #independentbookstore #bookish #angeladuckworth #paintedporch #bookrecommendations #readinglist #mustread",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DP_ytO2jTGS-2.mp4
"The final piece of a six-year journey started in an unexpected place. Back at Bastrop State Park with his kids, @ryanholiday conceived what would become an entire series on the Stoic Virtues. Now ""Wisdom Takes Work"" – the last book in that series – drops in under 2 weeks. Pre-order at dailystoic.com/wisdom for signed copies and bonus chapters.

#stoicism #stoic #ryanholiday #dailystoic #philosophy #stoicvirtues #wisdom #mindset #selfimprovement #personaldevelopment #books #newbook #preorder",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DPjx8sHDQUa-2.mp4
".@ryanholiday joined @stephruhle on @11thhourmsnbc to discuss his latest release, Wisdom Takes Work. He breaks down why the path to wisdom isn't passive—it requires real effort and intention. Grab your copy at dailystoic.com/wisdom for a signed edition, or find it at your favorite bookstore.

#WisdomTakesWork #RyanHoliday #DailyStoic #Stoicism #PhilosophyBooks #NewBookRelease #MSNBC #BookRecommendations #PersonalDevelopment #SelfImprovement #Wisdom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DQH42nWD3go-1.mp4
"Ryan Holiday (@ryanholiday) proves that some things never change – and maybe they shouldn't.

#stoicism #stoic #philosophy #wisdom #ryanholiday #dailystoic #motivation #inspiration #mindset #growth #lifelessons #stoicphilosophy #ancientwisdom #modernphilosophy #selfimprovement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DQpRZlfgcA7-1.mp4
"The hustle culture myth gets exposed here. Working smarter beats working longer every single time—proper weekly planning is the real productivity hack that nobody wants to hear about. @ryanholiday breaks down why those marathon work sessions everyone brags about are actually counterproductive.

#productivity #timemanagement #worklifebalance #hustleculture #smartwork #productivitytips #worksmarternotharder #weeklyplanning #entrepreneurmindset #successmindset #businesstips #efficiencymatters #productivityhacks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DQruYJtEQy8-2.mp4
"Three cities are getting an experience usually reserved for championship teams and Fortune 500 boardrooms. @ryanholiday has delivered Stoic wisdom everywhere from the White House to NBA locker rooms—but those doors are typically closed to the public. Seattle (December 3rd), San Diego, and Phoenix (February) are the rare exceptions. His speaking calendar includes Special Forces units, Super Bowl champions, and groundbreaking startups, with international venues stretching to Australia and the Netherlands—but public access is uncommon. That's what makes these upcoming dates different. Secure tickets at dailystoiclive.com or join the Daily Stoic newsletter (dailystoic.com/email) for future announcements if these locations don't work.

#DailyStoic #RyanHoliday #Stoicism #StoicPhilosophy #LiveEvent #Seattle #SanDiego #Phoenix #Stoics #AncientWisdom #ModernStoicism",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DQIUByojXbq-2.mp4
"Every parent needs these three books on their shelf, according to @ryanholiday. Each one offers timeless wisdom for raising kids with character and purpose.

Head to @paintedporchbookshop to grab your copies.

#parenting #parentingtips #parentingadvice #bookstagram #bookstoread #parenthood #raisingkids #bookrecommendations #mustread #bookshop #readinglist #parentingbooks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DRxhsomARix-1.mp4
"Life doesn't always cooperate with your plans – some days flow smoothly, other days throw obstacles in your path. @ryanholiday reminds us that this contrast is just part of the human experience.

#stoicism #stoic #philosophy #growth #mindset #wisdom #motivation #discipline #resilience #personaldevelopment #selfimprovement #dailystoic",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DRXTcJ6ASM5-2.mp4
"The barrier to entry isn't a bug—it's a feature. When something's intimidating enough to make others turn back, that's exactly what clears the path for those willing to push through. @ryanholiday breaks down why difficulty is your competitive advantage.

Catch him live in Seattle, WA on December 3rd. Tickets at dailystoiclive.com

#stoicism #stoic #dailystoic #motivation #discipline #philosophy #mindset #growth #resilience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DRS0HBlAQ6--2.mp4
"The numbers tell a powerful story: @ryanholiday and his team are challenging their community to turn Cyber Monday into something meaningful—transforming $300,000 into 3 million meals through @feedingamerica. He's leading by example with a personal $30,000 contribution to kick things off. This marks their sixth year of choosing impact over excess, where every single dollar multiplies into 10 meals for families in need. Head to dailystoic.com/feeding to be part of something that actually matters.

#FeedingAmerica #CyberMonday #GiveBack #DailyStoic #Stoicism #Charity #EndHunger #MakeADifference #Philanthropy #CommunityImpact",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ryanholiday\DRudXjXjaQ--2.mp4
"The future of warfare isn't what you think—and Steve Kwast breaks down exactly why in this mind-bending conversation. When a retired Lieutenant General starts talking about weapons that transcend conventional thinking, you listen. This clip captures the moment that changes everything.

Via @shawnryanclipped

#ShawnRyanShow #SRS #SteveKwast #MilitaryStrategy #NationalSecurity #DefenseTechnology #FutureWarfare #Leadership #Military #Podcast #Veterans #SpaceForce #Innovation #StrategicThinking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DKas1AStxPB-2.mp4
"The price of rock and roll fame hits different when Dave Mustaine breaks it down. @shawnryanclipped brings this raw conversation about the rockstar lifestyle that most fans never see behind the curtain. What it really takes to live at the top of the music world.

#ShawnRyanShow #DaveMustaine #Megadeth #RockstarLife #MusicIndustry #HeavyMetal #BehindTheMusic #RockLegends #MusicHistory #Podcast #TrueStory",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DKbM0wRNfX--2.mp4
"Erik Prince breaks down California's decline under Gavin Newsom's leadership in this revealing segment. From policy decisions to their real-world consequences, Prince doesn't hold back his perspective on the governor's track record. Watch the full breakdown.

via @shawnryanclipped

#ShawnRyanShow #ErikPrince #GavinNewsom #California #Politics #Leadership #PolicyDebate #SRS #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DLVCeIXyZ5Q-1.mp4
"Nick Bryant breaks down the explosive details behind the infamous black book on this episode with @shawnryanclipped. The investigative journalist doesn't hold back as he exposes the elite network that few dare to discuss. This conversation pulls back the curtain on one of the most controversial topics in modern history.

#shawnryanshow #srs #nickbryant #investigativejournalism #blackbook #truth #podcast #exposed #elite #corruption #documentary #journalism #truecrime #conspiracy #coverup #whistleblower",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DL7u_ZvNdbV-1.mp4
"A $7 billion mystery unfolds as Kash Patel breaks his silence on the Shawn Ryan Show. The former Chief of Staff to the Secretary of Defense pulls back the curtain on one of the most significant financial revelations you need to hear. This isn't just about the money—it's about what it represents.

Credit: @shawnryanclipped

#shawnryanshow #kashpatel #srs #podcast #government #transparency #billions #truth #interview #mustwatch #viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DM857c9pwpK-2.mp4
"@shawnryanclipped brings Sarah Adams to the conversation, breaking down why everyday vigilance matters more than most Americans realize. Adams pulls no punches discussing the reality of threats and what citizens can actually do to stay aware. This segment cuts through the noise with practical intel you won't hear anywhere else.

#shawnryanshow #sarahadams #srs #vigilance #situationalawareness #nationalsecurity #intelligence #cia #terrorism #safetytips #awareness #protectyourfamily #stayvigilant #homelandsecurity #threatassessment #americansecurity #podcast #vigilant",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DLGd4UUyoPF-2.mp4
"@shawnryanclipped captures the moment Shawn Ryan breaks down his philosophy on identifying quality individuals worth having in your corner. In a world full of surface-level connections, he shares what truly separates genuine people from the rest. The kind of insight that changes how you view your inner circle.

#shawnryan #shawnryanshow #shawnryanpodcast #srs #vigilanceelite #podcast #podcasting #podcastclips #leadership #trust #relationships #character #peopleandculture",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DMJqVvWtHfC-2.mp4
"A priest who understands the unseen battles we face daily. Father Stephen Gadberry breaks down spiritual warfare in ways that challenge modern perspectives. @shawnryanclipped brings you the moments that matter from this profound discussion on SRS 194.

#shawnryanshow #srs #shawnryan #spiritualwarfare #faith #priest #catholic #Christianity #god #Jesus #prayer #evil #demon #exorcism #supernatural #truth #podcast #viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DM_ssdatomY-1.mp4
"DJ Shipley opens up about one of the hardest calls a team leader can make—continuing the mission after losing a teammate. The mental weight of that decision and what it takes to push forward is something most will never understand. Credit to @shawnryanclipped for capturing this powerful conversation.

#shawnryanshow #srs #djshipley #navyseal #sealteam6 #devgru #specialoperations #combatvet #militarypodcast #warrior #leadership #brotherhood #sacrifice #neverforgotten #teamguy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DNEzHspNt2l-2.mp4
"A turning point moment that changed everything. Shawn opens up about the forces that pushed him to walk away, revealing the raw truth behind his decision. The kind of conversation that makes you rethink everything you thought you knew.

Full episode over at @shawnryanclipped

#shawnryanshow #shawnryan #srs #podcast #podcasting #podcastclips #clips #viral #trending #fyp #explore",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DO5BHPqjHNy-1.mp4
"Tim Tebow opens up about the profound impact of his father's mission to rescue children around the world. A deeply moving conversation that showcases the Tebow family's unwavering commitment to making a difference where it matters most.

Via @shawnryanclipped

#TimTebow #ShawnRyanShow #SRS #Podcast #Faith #Rescue #Children #HumanitarianWork #MakingADifference #Purpose #Family #Mission #Inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DO__Xuxkq-H-2.mp4
"Sarah Adams breaks down the threat posed by Hamza Bin Laden in this powerful segment. The intelligence insights she shares reveal why this figure remains critical to global security discussions. @shawnryanclipped brings another essential conversation to light.

#shawnryanshow #podcast #sarahadams #hamzabinladen #intelligence #nationalsecurity #terrorism #cia #binladen #geopolitics #security #truthseeker #military",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DPhBHYtjEvL-1.mp4
"Anna Jacobsen breaks down the engineering marvel behind Israel's Iron Dome defense system in this clip from @shawnryanclipped. The technology that's intercepting threats in real-time is more sophisticated than most people realize.

#shawnryanshow #annajacoobsen #irondome #defensetechnology #military #militarytechnology #israel #missildefense #engineering #podcast #defense",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DPo7OcdkXmv-2.mp4
"A deep dive into the defense tech revolution as Trae Stephen's breaks down his journey from Palantir to launching Anduril, where cutting-edge AI meets national security. The co-founder's insights reveal how silicon valley innovation is reshaping America's defense capabilities in ways most people never see.

via @shawnryanclipped

#shawnryanshow #shawnryan #srs #anduril #palantir #traestephens #defensetech #military #specialforces #navy #navyseals #podcast #defenseindustry #technology #ai #nationalsecurity #startup #founder",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DP5Kkx6jKCb-1.mp4
"The money trail behind global terror operations gets exposed in brutal detail. Sarah Adams walks through the complex web of funding networks that keep extremist organizations alive. @shawnryanclipped brings this eye-opening segment where Adams connects dots most people never see. The financial infrastructure supporting terrorism isn't what you think.

#shawnryanshow #sarahadams #terrorism #nationalsecurity #cia #podcast #terror #funding #extremism #investigation #intelligence #geopolitics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DNUHOgINIQX-1.mp4
"Brandon Tseng opens up about the power of gratitude in this powerful moment from the Shawn Ryan Show. The Shield AI Co-Founder shares perspective that'll make you think twice about what really matters. Worth the watch.

Credit: @shawnryanclipped

#shawnryanshow #srs #shawnryan #brandontseng #shieldai #gratitude #perspective #motivation #podcast #mindset #inspiration #success #entrepreneurship #leadership #veteran #military #ai #technology #startup #founder",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DQNV78TAZXQ-2.mp4
"CIA officer Sarah Adams breaks down what really happened in Benghazi on this powerful episode. @shawnryanclipped brings you the unfiltered truth from someone who was there. Don't miss this one.

#shawnryan #shawnryanshow #podcast #sarahadams #benghazi #cia #military #specialforces #navy #army #marine #usmc #greenberets #seals #navyseals #specialoperations #war #soldier",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DRBTVQ7DAMW-1.mp4
"DJ Shipley shares the powerful story of Matty's courage in the face of unimaginable circumstances. A moment that defines what true bravery looks like when everything is on the line.

Credit: @shawnryanclipped

#ShawnRyanShow #DJShipley #SRS #Matty #Bravery #Courage #MilitaryStories #VeteranStories #Sacrifice #TrueStory #Hero #Inspiration #Podcast #MilitaryPodcast #NavySEAL #SpecialOperations #Warriors",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DROHSkyDBuQ-1.mp4
"Leading from the front isn't just a motto—it's a lifestyle Jocko Willink has mastered through decades of service. This powerful segment breaks down what separates real leaders from those who simply hold titles. @shawnryanclipped brings you the raw wisdom from episode 257 of the Shawn Ryan Show.

#JockoWillink #ShawnRyanShow #Leadership #Military #NavySEAL #Podcast #Motivation #Discipline #Veterans #Inspiration #MilitaryLeadership #TeamWork #Excellence",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanclipped\DRvkV9vDLbA-2.mp4
"When reality writes better punchlines than Hollywood ever could. 😂 @shawnryanshow captures another moment that proves truth really is stranger than fiction.

#tech #comedy #funny #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DP7u0rIjFoC-1.mp4
"The privacy debate hits different when it involves Palantir's data capabilities 👁️

@shawnryanshow explores whether American citizens are under digital surveillance through one of the most sophisticated tech systems in existence.

#spy #intelligence #tech #news #technology",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DP7YM9ZiY6x-1.mp4
"A scientist casually drops the bombshell that real Jurassic Park-style experiments aren't just Hollywood fantasy 🦖

Full conversation over on @shawnryanshow - SRS Episode 244

#science #tech #history #didyouknow #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DPwvwsMCViL-2.mp4
"A SEAL Team 6 operator just went on record about President Obama, and the internet can't stop talking about it. @shawnryanshow got the exclusive sit-down that's breaking the algorithm right now. 👀

#obama #navyseals #military #history #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DQ9ivzpkY9C-2.mp4
"When the bedroom becomes a home improvement zone 🔨 @shawnryanshow captures this hilarious relationship reality check

#romance #love #relationship #dating #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DQC7CJ4iRXW-1.mp4
"A medical professional drops a bombshell about a popular trend permanently damaging men's health. The full breakdown comes from @shawnryanshow and it's not what anyone expected.

#menshealth #didyouknow #doctor #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DQm4NGTiXAI-1.mp4
"Behind the scenes of the platform millions of kids are logging into right now. 🎮

Via @shawnryanshow

#roblox #videogames #parenting #onlinegaming #gameplay shawnryanshow podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DRdcu_rDPpO-1.mp4
"A commercial pilot's routine flight over Mexico turned into an encounter he'll never forget—aliens took control of his aircraft. @shawnryanshow brings us this jaw-dropping story that challenges everything we think we know. 👽✈️

#aliens #mystery #mysterious #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DQdFWAeDPkR-1.mp4
"When spiritual warfare gets tactical – Father reveals what he brings to battle demons. 😳

@shawnryanshow sits down with an exorcist to discuss the sacred weapons and tools used in the fight against evil.

#bible #catholic #religion #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DQsiRcoDL6s-1.mp4
"The future of transportation just landed, and it's not what you expected. @shawnryanshow breaks down how flying Ubers have officially become reality. 🤯

#tech #technology #engineering #shawnryanshow #podcast #didyouknow #interesting",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DQxLGGMCQWL-2.mp4
"When @shawnryanshow sat down with these guests, nobody expected the conversations to go THIS dark. Victor Marx, Nick Irving, Father Dan Reehil, Pete Scobell, Victor Vescovo, and Brandon Fugal shared moments that left everyone speechless. Some stories aren't meant to be easy to hear.

#shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DQxvxwAjPAp-1.mp4
"When it comes to protecting what matters most, this is non-negotiable for anyone who carries.

Check out the full conversation on @shawnryanshow

https://USCCA.com/srs

#selfdefense #edc #navyseals #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DRnBJMkiTTZ-2.mp4
"A car hack demonstration that'll make you rethink your vehicle's security system 🚨 Via @shawnryanshow

#hack #hacker #shawnryanshow #podcast #didyouknow tech gadgets",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DRf-u8xDOcg-1.mp4
"A 3D-printed device just exposed a major security flaw in Apple's iPhone system that has the tech world buzzing. 📱🔓

Via @shawnryanshow

#hack #hacker #tech #gadgets #coolgadgets #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DRVZ_bTibJB-1.mp4
"A hacker pulls back the curtain on a disturbing platform targeting teenagers—@shawnryanshow breaks down what every parent needs to hear. 🚨

#parenting #parents #police #crime #didyouknow #shawnryanshow #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DRTAb28iW60-1.mp4
"The speed at which a vehicle can be completely compromised will make you rethink everything about modern cars. 🚗💻

Via @shawnryanshow

#hack #hacker #shawnryanshow #podcast #didyouknow #tech #gadgets",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\shawnryanshow\DRf-u8xDOcg-2.mp4
"The best leaders treat their teams the way great parents treat their children—constantly growing themselves while ensuring everyone around them grows too. @simonsinek breaks down this powerful leadership parallel.

📍 Parker Seminars Las Vegas, February 2024

#leadership #leadershipdevelopment #simonsinek #leaders #leadershiplessons #leadershipskills #leadershiptips #parenthood #parenting #growth #personalgrowth #motivation #motivational #inspiration #inspirational #mindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\C8w3ROzRd4h-1.mp4
"@simonsinek sits down with @brenebrown and @adamgrant on A Bit of Optimism for a conversation that proves the best mirror is sometimes another person. Self-awareness isn't always a solo journey—metacognition hits different when friends are involved. Part one is live now 🎧

#SimonSinek #BreneBrown #AdamGrant #ABitOfOptimism #Podcast #SelfAwareness #PersonalGrowth #Leadership #Metacognition #PodcastRecommendation #Inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\C8pTc3CRfUQ-1.mp4
"@simonsinek explains why lending a hand isn't just good for others—it's the ultimate mood booster for yourself. Stop waiting for the perfect moment and start helping today.

From a February 2024 Vituity conversation with CEO Mu Tomlinson

#simonsinek #leadership #helpingothers #kindness #motivation #inspiration #mindset #positivevibes #makeanimpact #leadershipdevelopment #personalgrowth #feelgood",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\C9m3T3TxtkC-2.mp4
".@trevornoah sits down with the legendary @simonsinek for an episode that's surprisingly chaos-free (shocking, we know 😂). Available now wherever you get your podcasts! #WhatNowPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DDw02JeRVZB-2.mp4
"@simonsinek breaks down why going solo isn't the answer – friendship and real community are the actual shields against burnout. It's not just about having people around, it's about having YOUR people around.

Check out more from Simon at youtube.com/@SimonSinek

#simonsinek #friendship #community #burnout #mentalhealth #wellness #selfcare #leadership #motivation #mindset #relationships #support #worklifebalance",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\C8ADkurJhPI-2.mp4
"@profgalloway pulls no punches when he calls out America's economic war on young people—and @simonsinek wanted to hear every word of it.

In Scott's new book ""The Algebra of Wealth"", he exposes the massive wealth transfer leaving younger generations behind while older ones prosper. Their conversation on A Bit of Optimism started with brutal financial truths, then wandered into unexpected territory: what love, money, and real friendship actually mean.

Prof G is back, unfiltered as ever 🎧

Full episode available on all podcast platforms.

#ProfG #SimonSinek #ABitOfOptimism #TheAlgebraOfWealth #WealthBuilding #FinancialFuture #Economics #YouthEconomy #Podcast #WealthInequality #Money #Friendship #PersonalFinance",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\C8XSmOlJfjn-2.mp4
"From troubled beginnings to Grammy nominations, Logic transformed hip-hop with his introspective style—then shocked everyone by pivoting to sci-fi novels and film. The platinum-selling artist became the only rapper with a New York Times bestseller, proving creative evolution knows no limits. @simonsinek sits down with Bobby Hall to explore the messy, uncertain process of chasing new artistic visions when you're starting from scratch. Full conversation available now on podcast platforms 🎧

#Logic #BobbyHall #Podcast #HipHop #Rapper #CreativeProcess #Grammy #NewYorkTimesBestseller #ScienceFiction #ArtistInterview #MusicIndustry #Storytelling #CareerTransition #Innovation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DAJWMElJsyw-2.mp4
"Kevin Warren runs the Chicago Bears with a simple philosophy: create moments so incredible they stop you in your tracks. The seasoned football executive—former Big Ten Commissioner and Minnesota Vikings COO—sits down with @simonsinek to reveal an unexpected truth about reaching the top. His advice for driven achievers? The fast lane isn't always the winning strategy. Discover why pausing to soak in life's smaller moments might be the secret ingredient to stronger leadership and genuine fulfillment.

Full episode available now 🎧

#Leadership #Podcast #SimonSinek #KevinWarren #ChicagoBears #NFL #BigTen #PersonalGrowth #LeadershipDevelopment #Success #Mindfulness #ExecutiveLeadership #SportsManagement #ProfessionalDevelopment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DBb1uhfpssN-1.mp4
"The friendship between President Biden and Senator John McCain proves something powerful: real progress happens when we can look past our differences. @simonsinek sat down with Joe Biden to uncover the wisdom from five decades in public service—lessons that transcend politics and speak to how we all navigate relationships, disagreement, and getting meaningful work done.

#leadership #friendship #respect #joebiden #johnmccain #publicservice #bipartisanship #unity #politics #wisdom #leadershiplessons #collaboration #civildiscourse #relationships",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DBG9CGpplDm-1.mp4
"A hard-earned title doesn't silence self-doubt—so why do we keep fighting battles we've already won?

@simonsinek sits down with @jockowillink to unpack this and other leadership struggles that show up everywhere from boardrooms to battlefields. New episode of A Bit of Optimism is live.

#leadership #leadershipdevelopment #leaders #simonsinek #jockowillink #podcast #leadershiplessons #businessleadership #military #selfimprovement #personalgrowth #abitofoptimism",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DGn9nvXpSnL-2.mp4
"The mic drops, the projector dies, you forget your entire speech... @simonsinek wants to hear about the moment everything went sideways during your presentation 🎤💥

Drop your most cringe-worthy speaking disaster below 👇

#publicspeaking #presentationskills #leadership #communication #businesstips #professionaldevelopment #careergrowth #speakingtips #leadershipdevelopment #personalgrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DHTrz3ixULe-1.mp4
"Understanding your own worth takes more than just positive thinking—it requires real work. @simonsinek sits down with @lewishowes, New York Times bestselling author, former pro athlete, and host of The School of @greatness podcast, to explore the difficult journey from self-loathing to self-acceptance. Lewis opens up about overcoming a traumatic childhood, learning disabilities, and years of insecurity that shaped his path to personal growth. In this A Bit of Optimism episode, they dive into the insecurities we all carry, examine their relationship with money trauma, and reveal why courage is the gateway to genuinely liking who you are. Hear the complete conversation on your favorite podcast platform 🎧

#selfawareness #personalgrowth #mentalhealth #podcast #leadership #innerwork #selfacceptance #courage #greatness #mindset #abitofoptimism",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DH6JTIJRuPs-1.mp4
"@suzywelch has spent years guiding students through one of NYU's most transformative classes: ""Becoming You."" Her approach? A simultaneously brutal and liberating deep dive into authentic living that challenges everything people think they know about themselves.

In this episode, @simonsinek sits down with Suzy to unpack the real reasons people lose touch with their values, whether luck actually matters, and how to build a life anchored in genuine purpose. The conversation gets honest, thought-provoking, and at times, delightfully heated.

Full episode available on all podcast platforms 🎧

#podcast #purpose #authenticity #selfawareness #leadership #personalgrowth #values #SimonSinek #SuzyWelch #NYU #podcasting #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DJUR0XJxXL5-1.mp4
"When clinical psychologist @drbeckyatgoodinside sat down with @simonsinek, she revealed something most leaders miss: the exact same skills that help parents navigate tantrums and bedtime battles are the ones that create exceptional workplace cultures. Dr. Becky Kennedy, known as the ""Millennial Parent Whisperer"" and founder of Good Inside, breaks down how mastering boundaries, understanding emotional triggers, and processing big feelings aren't just parenting strategies—they're leadership fundamentals. Her pandemic-era approach to caretaking reached millions because it worked, and now those same principles are transforming how people show up at the office. This conversation proves that whether you're managing a team or a toddler, the path to better leadership runs through the same skills. Full episode available now 🎧

#leadership #parenting #podcast #simonsinek #drbeckykennedy #goodinside #emotionalintelligence #worklifebalance #leadershipdevelopment #parentingtips #boundaries",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DFYC9owJE7b-2.mp4
"Simon Sinek (@simonsinek) wants to hear from you 👇 Got questions? Drop them in the comments—yours could be featured in an upcoming Q&A session. Keep inspiring, keep growing.

#SimonSinek #Leadership #Inspiration #Motivation #QandA #AskQuestions #PersonalGrowth #LeadershipDevelopment #Inspire #GrowthMindset #QuestionEverything #LeadershipTips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DQMjyvEDo6Z-1.mp4
"Leadership isn't found in corner offices or fancy business cards. The real transformation happens the moment someone chooses to prioritize others over themselves—that's when a leader is truly born.

@simonsinek breaks down what authentic leadership actually means in this powerful moment from Equinix Connect 2025, where he sat down with Chief Sales Officer Mike Campbell.

Worth the watch if you've ever questioned what separates a title from true leadership.

#leadership #simonsinek #leadershipdevelopment #leaders #motivation #inspiration #business #success #mindset #personaldevelopment #growthmindset #leadershipquotes #businessleadership #management #teamwork",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DNqVrNZuvZF-2.mp4
"Bob Chapman's entire leadership philosophy flipped when he realized one crucial thing: his training prepared him for spreadsheets, not souls.

The result? Taking care of his people meant the metrics handled themselves.

@simonsinek shares this powerful lesson that changes how we think about success in business.

💬 Comment ""Bob"" and I'll DM you the link to the full conversation.

Or, find the full episode of A Bit of Optimism wherever you get your podcasts: ""The Man Who Proved Me Right with CEO Bob Chapman""

#leadership #business #management #success #motivation #inspiration #leadershipdevelopment #businessleadership #ceo #peoplefirst #companyculture #workculture",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DQwnJO9AocA-2.mp4
"One of @simonsinek's friends was drowning in suicidal thoughts and complete burnout. The solution? Three nightly questions tracked over 28 days: What energized me? What drained me? What did I learn?

The revelation shocked him: his depression wasn't rooted in career pressure at all. The real culprits were sleep deprivation, terrible eating habits, and endless scrolling through social media.

Sometimes the answers we're desperately searching for are hiding in our daily patterns. Connection, proper fuel for your body, and genuine rest aren't luxuries—they're necessities.

Next time you're in a dark place, consider tracking these three questions. You might discover what's really stealing your light.

#mentalhealth #depression #burnout #selfcare #wellnessjourney #mentalhealthawareness #healthyhabits #mindfulness #sleepmatters #digitaldetox #healing",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DQU8rDdkodC-2.mp4
"Fredrik Backman (@backmansk) shared a powerful practice with @simonsinek that transforms tense interactions: breathe in while searching for just one small thing you have in common with the person triggering you, then breathe out and watch how it changes your entire approach.

The author reminds us this isn't about tolerating toxicity—it's recognizing that we're all flawed humans capable of the same messy moments. That single realization can calm everything.

🎧 This episode of A Bit of Optimism is sponsored by the @porscheusa Macan.

Comment ""Friends"" and we'll DM you the full episode.

Or

Find the full episode wherever you get your podcasts: ""Choose Your Seven Humans Wisely with author Fredrik Backman""

#SimonSinek #ABitOfOptimism #FredrikBackman #EmotionalIntelligence #Mindfulness #PersonalGrowth #SelfAwareness #Conflict #Communication #Empathy #PodcastClips #Inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\simonsinek\DRPg9pKgkSB-1.mp4
#BillHader opens up about his friendship with #ConanOBrien in this must-watch moment from @teamcocopodcasts. The chemistry between these two is undeniable. #CONAF,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DJCm18VTS1k-1.mp4
"While @lamorne and @kyleshevrin showed up expecting just another @divalaci Scam Goddess session, they walked straight into her real masterplan. 🏓🏓🏓

📹 @teamcocopodcasts

Producer: @jayfoxx__ 
Engineer: @richardhenrygarcia 

#pingpong #scams #thelamorningafter #studiorecording #scamgoddess",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DIeUOPaJZ7z-1.mp4
John Mulaney's reaction says it all 😂 That look of pure disbelief is everything. @teamcocopodcasts always captures these golden moments. #CONAF,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DKxLvTfparf-2.mp4
"John Mulaney witnessed the moment Conan finally opened up to Paul McCartney about his true feelings 😭 Via @teamcocopodcasts

#PaulMcCartney #CONAF #JohnMulaney #ConanOBrien #TheBeatles #PodcastClips #ComedyPodcast #ConanNeedsAFriend",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DIt-JHdTV8O-1.mp4
"Patrick Schwarzenegger shares behind-the-scenes insight into Mike White's dedication to staying fit during #WhiteLotus production in this conversation with Rob. The full discussion is available now on #Literally from @teamcocopodcasts — link in bio.

#PatrickSchwarzenegger #MikeWhite #TheWhiteLotus #BehindTheScenes #PodcastClip #HBO #LiterallyPodcast #RobLowe #TeamCoco #Podcast #Celebrity #FilmProduction #FitnessMotivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DKSKbXmpxw--1.mp4
"Tom Hanks and Conan O'Brien proving they share one brain cell in the best way possible 🧠 

Via @teamcocopodcasts

#CONAF #ConanOBrien #TomHanks #ConanOBrienNeedsAFriend #Podcast #Comedy #Interview #Funny #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DMdK21dxE10-1.mp4
"Andy Samberg gets real about his friendship with Conan O'Brien, and the answer might surprise you 👀

Via @teamcocopodcasts

#AndySamberg #ConanOBrien #CONAF #ConanPodcast #Comedy #Podcasts #FriendshipGoals #CelebFriendships #TeamCoco",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DMvUMm1Jd_x-1.mp4
"#FlulaBorg might just be the perfect candidate to take over the 007 legacy 🎬🍸 @teamcocopodcasts explores why this could actually work on #CONAF

#FlulaBorg #JamesBond #007 #ConanOBrien #Podcast #TeamCoco #BondDebate #NextBond #Hollywood #SpyCast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DMqsa39hdwN-2.mp4
"While @gayleking and @divalaci delivered another incredible episode this week, the Team Coco Podcasts crew can't stop thinking about one thing: Norma's fate remains a mystery. Fingers crossed a listener comes through with answers!

Weigh in below with your theories.

Almost time to celebrate the 4th of JuLaci! 

Produced by @jayfoxx__ 
Engineered by @richardhenrygarcia 
Letters by YOU ❤️

📸: @teamcocopodcasts

#gayleking #listenerletters #comedy #podcast #thinkingofnorma #4thofjulaci #scamgoddess",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DLqQ6oOSazC-2.mp4
"Nicole Byer and Shereen Lani Younes pull up to spill the tea with Laci Mosley about the Enhanced Games drama heading to Resorts World in 2026! 🎙️ @teamcocopodcasts

#bestfriends #enhancedgames #scam #scamalert #scamgoddess",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DNi4BtRum2A-1.mp4
"Tony Hawk's comfort zone? Definitely four wheels over ocean waves. According to @teamcocopodcasts, the skateboarding legend admits surfboards just aren't his thing. #Literally #TonyHawk #Skateboarding #ConanOBrien #PodcastClips #TeamCoco",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DOKIfZGkh38-2.mp4
#CharlieSheen opens up about his friendship with #ConanOBrien in this revealing moment from @teamcocopodcasts. The candid conversation shows a side of their bond that fans rarely get to see. #CONAF,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DPgyCJWkYqE-2.mp4
"When @richtercommaandy traded his talk show desk for the DWTS dance floor, chaos ensued 💃✨ He's spilling all the behind-the-scenes details on ""The Andy Richter Call-in Show"" via @teamcocopodcasts!

#AndyRichter #DWTS #DancingWithTheStars #TeamCoco #Podcast #ComedyPodcast #LateNightTV #PodcastRecommendation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DO8oc3DiBWf-1.mp4
"When Mark Ruffalo and Woody lock eyes across the table, you know there's a story coming—and this one involves thrown punches and questionable decisions. The duo revisit their wild bar fight memory via @teamcocopodcasts, proving some nights out become legendary for all the wrong reasons. #WEKYN",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DP4HcooEds6-2.mp4
Rachel Senott drops some astrological wisdom on Conan about Saturn Returns 🪐✨ via @teamcocopodcasts #CONAF,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DRiOoN0jppe-2.mp4
Nate Bargatze's effortless approach gets the ultimate stamp of approval from Conan O'Brien himself. When genuine talent recognizes genuine talent 👏 via @teamcocopodcasts #CONAF,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DPRl_dhCVBL-1.mp4
".@harveyguillen and @divalaci are serving up the scares (and the schemes) on this week's episode from @teamcocopodcasts – wishing everyone exactly what's coming to them this Halloween 🎃🩸👻

#scamgoddess #halloween🎃 #themortician #spooky #stayscheming",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DQXLxQbkneR-2.mp4
When Ted can't hide his pure admiration for the legendary Carol Burnett 🎭✨ (via @teamcocopodcasts) #WEKYN,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DRnecH0Dk6v-2.mp4
Two Hollywood legends rolled into Austin for an unexpected sit-down—Ted Danson and Woody Harrelson linking up with Jesse Eisenberg for a conversation you don't want to miss. @teamcocopodcasts captured the whole thing. #WEKYN,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\teamcocopodcasts\DRDEnLKklSY-1.mp4
"A complete remodel, three months of enjoying it, then gone in the Malibu fires 💔 @theadamcarollashow shares this devastating story of timing and loss

#malibu #malibufires #losangeles #losangelesfire #palisadesfire #podcast #adamcarolla",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DL5RRsYRz9y-1.mp4
"Mike Rowe's take on what society actually needs might surprise you—hint: it involves both comfort AND combat 🥊

According to the ""Dirty Jobs"" legend via @theadamcarollashow, there's room for safe spaces AND the octagon in people's lives. Balance is everything.

#MikeRowe #AdamCarolla #Podcast #SafeSpaces #MMA #Octagon #RealTalk #Balance #ModernSociety #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\C_oJDgbS3Fv-2.mp4
"Stephen Baldwin opens up about watching @haileybieber rise to stardom and reveals the story of how he first connected her with Justin Bieber 💫 

Via @theadamcarollashow

#StephenBaldwin #HaileyBieber #JustinBieber #Baldwin #Bieber #ProudDad #HollywoodFamily #CelebrityInterview #Podcast #BaldwinFamily",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DLYFEpvR_Zj-1.mp4
"When Bridget Phetasy's husband literally became healthier just by leaving California, you know the stress was real 😅 @theadamcarollashow gets into how a simple move dropped his blood pressure

#BridgetPhetasy #AdamCarolla #California #BloodPressure #MovingOut #HealthJourney #StressRelief #Podcast #Comedy #LeftCalifornia #HealthyLiving #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DLsugM-BDms-1.mp4
"Obama's signature power move has Adam Carolla breaking down the psychology behind that *legendary* leg cross 😂 @theadamcarollashow going full analyst mode on this one

#AdamCarolla #Obama #BarackObama #PodcastClips #Comedy #Podcast #Funny #StandUpComedy #Comedian #PodcastHighlights",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DLQTvd0SnJQ-2.mp4
"Zohran Mamdani tried turning a bench press into a political moment, and @theadamcarollashow wasn't having any of it 😬

#AdamCarolla #TheAdamCarollaShow #Comedy #Podcast #PoliticalCommentary #PublicityStunt #Cringe",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DN3aVmIYtc3-2.mp4
"When @dustin_ybarra sits down with @adamcarolla, every plate becomes fair game and nobody's meal is getting eaten in peace 😂

via @theadamcarollashow

#AdamCarolla #DustinYbarra #Comedy #Podcast #FoodThief #Funny #ComedyClips #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DMwMbG5JVF3-1.mp4
"The wait is over – @theadamcarollashow has dropped two must-watch specials that are streaming everywhere right now. Meme Gods and When We Went MAD! just hit most cable providers and digital platforms, so there's no excuse to miss out 🔥

#AdamCarolla #TheAdamCarollaShow #ComedySpecial #StreamingNow #NewRelease #StandUpComedy #MustWatch #Comedy #Podcast #Entertainment",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DOJ-cwtkpR5-1.mp4
"When you're fresh off the wedding and Adam's got the kitchen advice you didn't know you needed 😂 @theadamcarollashow coming through with that slow-cooker wisdom for the happy couple!

#AdamCarolla #AdamCarollaShow #Comedy #Comedian #StandUp #Podcast #Podcasting #Funny #ComedyClips #Podcaster",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DOBytvViStR-1.mp4
"Adam Carolla draws a hard line when it comes to his food, and fake cheese is officially on his banned list 🧀 @theadamcarollashow

#AdamCarolla #TheAdamCarollaShow #Comedy #Podcast #FakeCheese #FoodOpinions #KeepingItReal #PodcastClips #ComedyPodcast #Funny",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DP61gzCDxgW-2.mp4
"Adam Carolla breaks down what's really driving the political divide in America right now 🎯

Via @theadamcarollashow

#AdamCarolla #PoliticalDivide #Politics #Commentary #Podcast #RealTalk #America #PoliticalDiscussion #CurrentEvents #SocialCommentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DO_iyFxCTzd-1.mp4
"Adam Carolla breaks down the absurdity of modern parenting trends in this hilarious take from @theadamcarollashow that'll have you questioning everything 🎯

#adamcarolla #theadamcarollashow #comedy #podcast #funny #standup #humor #comedian #podcasting #podcasts",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DQAM_h2ElLW-2.mp4
"When @adamcarolla and @samtripoli witness peak Phillies Karen behavior, their reaction is everything 😭💀

🎙️ Via @theadamcarollashow

#AdamCarolla #SamTripoli #Phillies #KarenAlert #PhilliesKaren #BaseballKaren #MLB #Comedy #Podcast #Reaction #Viral #BaseballFans #SportsKaren #PhiladelphiaPhillies",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DOZd5HNEXl7-2.mp4
"Jimmy Kimmel has a friend for life in Adam Carolla, and there's a powerful reason behind that unwavering loyalty. @theadamcarollashow breaks down the bond that's kept their friendship solid through the years and why nothing will change that. Catch the full conversation on your favorite podcast platform.

#megynkellyshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DQ46aibkdc4-1.mp4
"Charlie Sheen gets candid about the connection between substance use and his exploration of sexuality in this conversation with @theadamcarollashow

#CharlieShe #AdamCarolla #PodcastClips #RealTalk #HonestConversation #CelebrityInterview",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DQwtt-3ks33-1.mp4
"This Thanksgiving, @theadamcarollashow sends gratitude your way. Cheers to turkey, touchdowns, and time well spent. 🦃

Get it on!

#Thanksgiving #HappyThanksgiving #ThankfulThursday #ThanksgivingDay #AdamCarolla #GetItOn #Podcast #Comedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DRkNsxMjyg1-1.mp4
"K-Pop's hidden dark side gets exposed as @jiaoyingsummers pulls back the curtain on boy band reality. The truth behind the glitz hits different when you hear what really goes down. Via @theadamcarollashow

#kpop #kpopidol #kpopnews #bts #comedy #standup #standupcomedy #comedian #comedyvideo #funny #funnyvideos #funnymemes #podcast #podcasting #podcastclips #viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theadamcarollashow\DRSgbYWkbdX-2.mp4
"What happens when your job requires you to lie to everyone except your coworker who becomes your spouse? 

Former CIA officers Andrew and Jihi Bustamante explain why the agency actually pushes officers to date each other. The secrecy demands of intelligence work make normal relationships nearly impossible when you can't be honest about your career.

Real-life Mr. and Mrs. Smith vibes 👀

Via: @everydayspy x @thediaryofaceopodcast

#CIA #SpyLife #RelationshipGoals #IntelligenceCommunity #ClassifiedLife #SpyCouple #AgencyLife #Espionage #SecurityClearance #CovertOperations #SpyStories #RelationshipTalk #ModernDating",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DN80j_-jcS7-1.mp4
"Arthur C. Brooks breaks down an unexpected truth about life after loss in this conversation from @thediaryofaceopodcast.

Comment ""Watch"" and I'll personally DM you our conversation.

When husbands pass away, research shows many wives go on to live surprisingly fulfilling lives. He dives into the psychology behind finding happiness even after profound grief.

Can joy and loss coexist?

Credit: @arthurcbrooks x @thediaryofaceopodcast

#happiness #grief #psychology #arthurcbrooks #mentalhealth #healing #lifelessons #widow #podcast #deeptalks #humanemotion #movingforward #resilience #emotionalintelligence",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DNtlTpN2otX-2.mp4
"The line between prevention and punishment is blurring, and Mo Gawdat isn't staying quiet about it.

Comment ""watch"" and I'll personally DM you our conversation.

Society's approach to justice is transforming in real time—people face consequences for crimes they haven't committed yet. Mo Gawdat breaks down this troubling pattern where assumptions replace evidence and guilt comes before proof. He argues that genuine ethics requires one non-negotiable standard: evidence must come first, always.

Has the foundation of justice crumbled right under our noses?

Credit: @mo_gawdat x @thediaryofaceopodcast

#MoGawdat #Justice #Ethics #Society #Philosophy #CriticalThinking #SocialIssues #Podcast #DeepConversations",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DNLsFLGI2ft-2.mp4
"Matthew McConaughey grew up with a household rule that became his life philosophy: eliminate ""I can't"" from your vocabulary.

This single principle, enforced throughout his childhood, built the foundation for his relentless determination and ability to push past every barrier in his path.

Drop ""Matthew"" below and I'll send you the full conversation straight to your DMs.

How has this kind of thinking shown up in your own life?

Via @officiallymcconaughey x @thediaryofaceopodcast

#MatthewMcConaughey #Mindset #SuccessMindset #Motivation #SelfBelief #PersonalGrowth #NeverGiveUp #MotivationMonday #Inspiration #PodcastClips #MindsetMatters #SuccessPrinciples #GrowthMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DO37JGfjQ14-1.mp4
"Former Secret Service agent Evy Poumpouras breaks down the productivity trap most people fall into—confusing motion with progress.

Her insight? Decision fatigue is draining your mental energy before you even tackle what matters. The solution isn't doing more, it's eliminating the noise.

Comment ""Evy"" and I'll personally DM you our conversation.

Are you making progress or just staying in motion?

Via @thediaryofaceopodcast

Credit: @evypoumpouras

#productivity #decisionfatigue #secretservice #mindset #success #entrepreneurship #personaldevelopment #timemanagement #focus #goals #evypoumpouras #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DP98pWijH7F-2.mp4
"Vanessa Van Edwards just dropped a truth bomb about attraction that flips the script on what we think we know.

Comment ""Watch"" and I'll personally DM you our conversation.

Here's the fascinating part: women gravitate toward men with humor, but men? They're attracted to women who appreciate their jokes. Two sides of the same coin, completely different perspectives.

Does genuine laughter equal chemistry, or is there more to the story?

Credit: @vvanedwards x @thediaryofaceopodcast

#attraction #datingadvice #relationshipgoals #datingtips #relationshiptips #datingpsychology #bodylanguage #flirting #datingcoach #relationshipadvice",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DOUImNqjY0B-2.mp4
"Dr. Mike breaks down what CPR actually does—and it's not what most people assume.

The real purpose? Buying critical time. CPR keeps blood and oxygen circulating until emergency medical professionals arrive with the tools to truly save a life. It doesn't restart the heart or revive someone on its own.

This reality check from @thediaryofaceopodcast featuring @doctor.mike changes how you'll think about those life-saving compressions.

Did you know CPR works this way?

#CPR #DoctorMike #MedicalFacts #EmergencyMedicine #FirstAid #HealthEducation #MedicalMyths #LifeSavingSkills #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DOhAHqvjI5Z-2.mp4
"Dr. Robert Lustig breaks down the uncomfortable truth about inherited belief systems in this eye-opening conversation with @thediaryofaceopodcast

Success. Happiness. Morality. The core frameworks passed down through generations might not hold up under scrutiny.

Comment ""Watch"" for the full conversation in your DMs.

How often do you actually question what you've been taught to believe?

Credit: @robertlustigmd x @thediaryofaceopodcast

#podcast #psychology #beliefs #mindset #consciousness #personaldevelopment #criticalthinking #philosophy #success #happiness #morality",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DPZJE7QjGEE-1.mp4
"The science behind staying connected might surprise you. Andrew Huberman breaks down why that single daily text carries more weight than most people realize, particularly as male loneliness becomes increasingly prevalent. According to his insight shared on @thediaryofaceopodcast, the length of your message matters far less than the consistency of showing up. A simple ""good morning"" creates patterns of accountability and reinforces that connection exists, which directly impacts mental wellbeing. Tag someone who deserves that daily reminder they're not alone.

#AndrewHuberman #MentalHealth #Loneliness #Connection #Friendship #MensMentalHealth #DailyHabits #Consistency #Accountability #MindsetShift #SelfImprovement #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DPHhtoTjSbT-1.mp4
"Jimmy Carr drops truth that hits different: the age you are today? Future you would do anything to have it back.

Most of us are guilty of rushing through life, always focused on the next milestone, the next goal. But this moment—right now—is the one we'll be nostalgic for years down the line. That's the perspective shift we all need.

So what part of your current reality deserves more appreciation before it becomes a memory?

Via @jimmycarr and @thediaryofaceopodcast

#JimmyCarr #PerspectiveShift #Gratitude #LiveInTheMoment #Mindfulness #LifeLessons #Wisdom #SelfReflection #Appreciation #PresentMoment #MotivationalQuotes #LifeAdvice #PersonalGrowth #MindsetShift",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DPt4LiqjKc1-2.mp4
"Three financial experts walk into a room—and completely disagree on nearly everything about money.

@thediaryofaceopodcast brought @raoulgmi, @minoritymindset, and @humphreytalks together for a rare roundtable where opposing views on wealth, debt, and homeownership clash in real time.

Comment 'Watch' and I'll personally DM you the full conversation.

The debate tackles the questions most people are too afraid to ask right now: Is renting actually smarter than buying? Are your savings secretly losing value? Does passive income really exist, or is it just another fantasy sold online?

With interest rates crushing budgets and inflation eating paychecks, this conversation couldn't be more urgent. But here's what stands out—despite all the disagreement, one thing remains clear: understanding money and technology are non-negotiable skills if you want to survive what's coming.

Full episode available now on YouTube: search ""The Diary of a CEO Financial Roundtable""

#PersonalFinance #MoneyTok #FinancialFreedom #WealthBuilding #DebtFree #PassiveIncome #FinancialLiteracy #Investing #BuyingAHome #MoneyManagement #FinanceTips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DOnRzGjjNEI-1.mp4
"# When Politicians Use Smoke and Mirrors

@thediaryofaceopodcast captured this revealing moment where Kamala Harris breaks down Trump's approach to public discourse—intentionally steering conversations away from actual policy and achievements.

The question worth asking: has misdirection become the dominant force in modern politics?

Drop 'Kamala' below for the complete discussion in your DMs.

Credit: @kamalaharris x @thediaryofaceopodcast

#KamalaHarris #Trump #Politics #PoliticalStrategy #Gaslighting #Election #Leadership #PoliticalDiscourse #ModernPolitics #PolicyMatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DQekz0_DHZf-2.mp4
"Jürgen Klopp breaks down exactly why Arne Slot's Liverpool transition has been seamless – it wasn't about revolution, it was about evolution.

According to Klopp, Slot's genius was recognizing what was already working and enhancing it rather than tearing everything down to start fresh.

Was sticking with the existing foundation the key to Slot's flying start, or would any approach have worked?

Via @thediaryofaceopodcast

#JurgenKlopp #ArneSlot #Liverpool #LFC #PremierLeague #Football #Soccer #LiverpoolFC #YNWA #FootballTactics #PL #Anfield #LiverpoolNews #FootballAnalysis #SoccerTalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DQCUihDDEeR-1.mp4
"Mel Robbins drops a game-changing truth: your actions create your identity, not the other way around.

The mindset expert explains that waiting to ""feel ready"" keeps most people stuck forever.

Instead, she shares how behaving as your future self triggers your brain to adapt and form new neural pathways that support who you're becoming.

Comment ""Mel"" for the full conversation sent directly to your inbox.

This clip from @thediaryofaceopodcast featuring @melrobbins might be the perspective shift you didn't know you needed.

#melrobbins #mindsetshift #personaldevelopment #selfimprovement #motivational #neuroscience #habitbuilding #growthmindset #successmindset #lifecoaching #transformation #podcastclips #inspirationalquotes #mindsetmatters #becomingbetter",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DQ9tIxbjVjr-1.mp4
"# Three minds, one impossible question: what if everything we've been told about life's meaning is wrong?

A psychiatrist who sees people at rock bottom, a Christian philosopher defending divine purpose, and an atheist thinker dismantling comfortable truths walked into the same room.

@thediaryofaceopodcast wasn't looking for easy answers when he sat down with Dr K (@healthygamer_gg), Greg Koukl, and Alex O'Connor (@cosmicskeptic).

Dr K brings insight from working directly with those who've lost their sense of direction, translating their pain into wisdom the rest of us desperately need.

Greg argues that meaning isn't something we create in our heads, it's embedded in reality by something greater than ourselves.

Alex challenges both sides, questioning whether meaning exists at all or if we're just telling ourselves stories to feel better.

The conversation cuts through surface-level takes on why young people are struggling with purpose, why traditional structures are crumbling, and what's actually happening beneath the cultural shift.

They tackled the hard stuff: invented versus discovered meaning, whether this generation is uniquely directionless, religion's actual role in human flourishing, and how our terror of death dictates everything.

No one left with all the answers, but the collision of worldviews created something more valuable than certainty.

Comment 'Life' for the full conversation in your DMs.

#meaningoflife #philosophy #religion #mentalhealth #existentialism #purpose #spirituality #atheism #christianity #deepconversations #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DPLU_dPDPv3-1.mp4
"What if the fat causing the most harm is completely invisible to the eye?

Dr Stacy Sims, Dr Vonda Wright, Dr Mary Claire Haver, and Dr Natalie Crawford break down visceral fat—the type wrapped around your organs that can't be liposuctioned away. Their solution? Transform your body's internal environment rather than chasing external results.

Drop ""Watch"" below to get the full conversation sent directly to your DMs.

Credit: @drvondawright x @drstacysims x @drmaryclaire x @nataliecrawfordmd x @thediaryofaceopodcast

#visceralfat #womenshealth #healthyaging #longevity #metabolichealth #hormonehealth #perimenopause #menopause #healthtips #wellness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DQUmcmDDSHy-1.mp4
"Ever watched someone decode thoughts like they're reading a script? 

Oz Pearlman doesn't call it magic—he calls it pattern recognition.

The mentalist who's performed for presidents and billionaires sat down with @thediaryofaceopodcast to break down what most people completely miss in daily interactions.

Inside this conversation:

- A 5 second memory improvement hack
- How to spot when someone's lying
- The signals you're sending without realizing
- Why rejection fear stops most people cold

Pearlman's spent decades mastering psychology and body language, turning human behaviour into a readable skill. He reveals that communication starts long before words are spoken—it's in how we think, connect, and what we leave unsaid.

The patterns are always there. Most just don't know where to look.

Comment 'Magic' for the full conversation in your DMs.

#OzPearlman #BodyLanguage #HumanBehavior #Psychology #Mentalist #CommunicationSkills #ReadingPeople #SocialSkills #PodcastClips #MindReading #BehaviorAnalysis #SuccessMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DQJIFlhAKjQ-2.mp4
"Kevin Hart breaks down a truth most people avoid: your biggest wins come from your losses.

Want the full conversation? Drop ""Kevin"" in the comments and it's yours.

Hart's perspective challenges everything we're taught about failure. Instead of running from it, he leans into setbacks as the exact tool that sharpens resilience and fuels momentum toward bigger achievements.

The question isn't whether you'll fail—it's how you'll use it.

via @kevinhart4real x @thediaryofaceopodcast

#KevinHart #Motivation #SuccessMindset #Resilience #PersonalGrowth #Inspiration #Mindset #EntrepreneurLife #FailureIsPartOfSuccess #GrowthMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thediaryofaceopodcast\DRSVm8JjVP6-2.mp4
"Media manipulation takes center stage as the conversation shifts to how the Democratic Party allegedly alters Trump's words to push their narrative. A fascinating exchange that questions what we're actually hearing vs. what was really said.

@thejrecompanion brings you this moment from The Joe Rogan Experience Episode 2223 with Elon Musk

Full episode link in bio

Follow @joerogan

#elonmusk #joerogan #jre2223 #thejrecompanion #joeroganpodcast #jre #joeroganexperience #jreelonmusk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DB_VEjYOqb7-2.mp4
"The mythology debate gets real when this topic comes up 🐉

@thejrecompanion keeps the best JRE moments coming (and yes, there's way more of this gold over on X if you need your fix 👀)

The Joe Rogan Experience

Follow @joerogan
Follow @thejrecompanion

#joerogan #jre #joeroganexperience #thejrecompanion #joeroganpodcast #DragonBeliever",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DCrXPDXOIHA-1.mp4
"Why would a sitting VP dodge questions about legalizing weed? @thejrecompanion breaks down the moment Kamala Harris steered clear of marijuana legalization talk during Joe Rogan's conversation with Adrienne Iapalucci on JRE #2227.

@adrienneiapalucci @joerogan

#adrienneiapalucci #joerogan #jre #joeroganexperience #thejrecompanion #jre2227 #joeroganpodcast #jreadrienneiapalucci",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DCXnT5DPh9j-1.mp4
"Data readers lurking on public WiFi networks – cybercriminals are using them to steal everything from passwords to financial information right as users scroll through their phones. Security experts warn that unsecured connections leave transmitted data completely exposed to interception, making personal photos, emails, and sensitive details easy targets. The recommendation? Skip public networks for anything important and use a VPN whenever possible.

Joe Rogan and Tim Dillon break down the threat on JRE Episode 2224 – full conversation available through the episode links courtesy of @thejrecompanion

Follow @timjdillon
Follow @joerogan

#timdillon #joerogan #jre2224 #thejrecompanion #joeroganpodcast #jre #joeroganexperience #jretimdillion",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DCJsOyMul1P-2.mp4
"Six essential chokes demonstrated by Ryron and Rener Gracie that form the foundation of grappling defense.

Content courtesy of @thejrecompanion

Dive deeper into technique breakdowns with @gracieuniversityhq and the GracieBreakdown YouTube channel

Follow @ryrongracie
Follow @renergracie

From The Joe Rogan Experience Episode 2242 with Bert Sorin

Full episode available through links in bio

Follow @bertsorin
Follow @sorinex
Follow @joerogan

#bertsorin #joerogan #jrec2242 #jre #thejrecompanion #jrebertsorin #joeroganpodcast #joeroganexperience #sorinex",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DDiD7_vS2nQ-2.mp4
"# When the comparison stops you in your tracks 💀

Adrienne Iapalucci dropped this wild take about Diddy and R. Kelly during her conversation with Joe Rogan that had everyone doing a double-take.

Catch the full discussion on The Joe Rogan Experience Episode 2227.

📍 via @thejrecompanion

Follow @adrienneiapalucci
Follow @joerogan

#adrienneiapalucci #joerogan #jre #joeroganexperience #thejrecompanion #jre2227 #joeroganpodcast #jreadrienneiapalucci",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DCXmPf9veog-2.mp4
"James Fox breaks down his documentary 'The Program' during his conversation with Joe Rogan on JRE episode 2246. Stream the full discussion through the episode links, and catch the film on Amazon Video. Episode highlights courtesy of @thejrecompanion

Follow @jamesfoxdirector
Follow @joerogan

#jamesfox #joerogan #jrec2246 #jre #thejrecompanion #jrejamesfox #uap #joeroganpodcast #joeroganexperience #ufo",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DEE6W56R3BY-1.mp4
"When a presidential exchange became must-see viewing...

Donald Trump and Barack Obama's conversation at President Jimmy Carter's funeral didn't go unnoticed by everyone in attendance. Kamala Harris responded with an unmistakable huff, then locked eyes with her husband, Doug Emhoff—a silent moment that spoke volumes.

Shane Gillis, Mark Normand, and Ari Shaffir break it down on The Joe Rogan Experience Episode 2256 - Protect our Parks 14.

Link to Listen/Watch in Episode Links Highlight and Bio.

Credit: @thejrecompanion

Follow @shanemgillis
Follow @marknormand
Follow @arishaffir
Follow @joerogan
Follow @jamievernon

#joerogan #joeroganexperience #jrec2256 #jreshanegillis #jremarknormand #jrearishaffir #shanegillis #marknormand #arishaffir #protectourparks #jreprotectourparks #jrepodcast #thejrecompanion",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DE4lSzOugu2-1.mp4
"Flying saucers become the topic of conversation when @andrewdiceclay gets brought up during this moment from @thejrecompanion. Yannis Pappas and Chris Distefano break down the unexpected question on The Joe Rogan Experience Episode 2249.

Follow @chrisdcomedy
Follow @yannispappas
Follow @joerogan

#historyhyenas #chrisdistefano #yannispappas #joerogan #jrec2249 #jre #thejrecompanion #jrechrisdistefano #jreyannispapppas #joeroganpodcast #joeroganexperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DEkAr5fuDLE-2.mp4
"The cameras were rolling at @comedymothership as Bryan Callen captured his latest special! @thejrecompanion shares the news – keep up with @bryancallen for what's coming next

Follow @joerogan

#bryancallen #joerogan #comedymothership",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DEvUZ5gSQ8f-1.mp4
"Sinclair Broadcast Group made headlines when they had news anchors nationwide read the exact same script word-for-word in March 2018. The largest owner of local TV stations in America coordinated a message about ""biased and false news"" being ""extremely dangerous to our democracy"" - and Deadspin exposed it all in a viral compilation showing just how eerie identical broadcasts actually look. The irony? A single corporation controlling the narrative across hundreds of local newsrooms while warning about media manipulation. This wild moment got broken down on JRE Episode 2247 with Duncan Trussell - full context and clips over at @thejrecompanion. 🎞️ @deadspin

Follow @duncantrussell
Follow @joerogan

#duncantrussell #joerogan #jrec2247 #jre #thejrecompanion #jreduncantrussell #joeroganpodcast #joeroganexperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DEKN46zRB_u-2.mp4
"While regular people struggle with everyday posture, Formula 1 drivers transform their necks into specialized machinery capable of handling extreme punishment lap after lap.

During races, these athletes face forces up to 6 Gs through corners and braking zones—turning their 6-7 kg head and helmet combo into a crushing 36-42 kg weight. The average human neck? Built for a measly 1-2 Gs.

Their solution involves brutal training protocols: weighted helmets carrying an extra 10-15 kg, resistance bands, and dedicated neck machines. The commitment runs deep—1-2 hours every single day during off-season just for neck conditioning.

This specialized training allows them to maintain performance throughout entire 90-minute races. For comparison, most people couldn't even sit in the cockpit under race conditions without their neck giving out.

Derek from More Plates More Dates broke down the insane gap between F1 drivers and average humans on The Joe Rogan Experience Ep. 2239.

@thejrecompanion compiled the full discussion—link in bio.

Follow @moreplatesmoredates
Follow @joerogan

#moreplatesmoredates #jrec2239 #joerogan #thejrecompanion #jremoreplatesmoredates
#joeroganpodcast #joeroganexperience #jre",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DDQGRGhSG0C-2.mp4
"Seven years and one Christmas greeting changed everything. In 2017, Senator Kamala Harris questioned how anyone could say ""Merry Christmas"" while DACA recipients faced deportation uncertainty. Fast forward to 2020—Harris herself posted a festive holiday message with Doug Emhoff, wishing everyone a Merry Christmas. The contrast between her 2017 press conference and 2020 video caught attention during Duncan Trussell's conversation on The Joe Rogan Experience. Some called the shift hypocritical, others saw it as politicians being politicians. Either way, the receipts tell an interesting story about messaging and moments. @thejrecompanion breaks it all down.

Episode 2247 - Duncan Trussell

Link to Listen/Watch in Episode Links Highlight and Links in Bio

Follow @duncantrussell
Follow @joerogan

#duncantrussell #joerogan #jrec2247 #jre #thejrecompanion #jreduncantrussell #joeroganpodcast #joeroganexperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DEFMDzBOJPg-2.mp4
"What happens when the science catches up to the skeptics? @thejrecompanion breaks down a conversation that aged differently than expected.

House reports are now revealing what couldn't be said out loud during the pandemic's peak: natural immunity held its ground, and vaccine transmission prevention fell short of the bold promises plastered across headlines.

The unvaccinated became society's scapegoat while officials painted with broad strokes and incomplete data. Fast forward to today, and the ""conspiracy theorists"" don't look so crazy anymore.

Derek and Joe dissect how quickly certainty replaced curiosity, and why waiting for complete information matters more than rushing to judgment.

From The Joe Rogan Experience
Ep. 2239 - Derek From More Plates More Dates

Link to Watch/Listen in Episode Links Highlight and Bio.

Follow @moreplatesmoredates
Follow @joerogan

#moreplatesmoredates #jrec2239 #joerogan #thejrecompanion #jremoreplatesmoredates
#joeroganpodcast #joeroganexperience #jre",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DDukBlYPCAE-2.mp4
"Josh Waitzkin breaks down why the competitive rush toward AI development might be humanity's biggest blindspot—a perspective that'll make you rethink everything about technological progress.

From The Joe Rogan Experience Episode 2292, brought to you by @thejrecompanion

Stream the full conversation—episode links in bio.

Follow @joerogan

#joshwaitzkin #joerogan #jre2292 #thejrecompanion #jre #jrejoshwaitzkin #joeroganpodcast #joeroganexperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DHdpIuVuwNA-1.mp4
"The legendary @spherevegas made quite the impression during this unforgettable moment with Joe Rogan. Content courtesy of @thejrecompanion

From The Joe Rogan Experience Episode 2280 featuring Peter Berg

Episode links available in highlight and bio

Follow @pberg44
Follow @joerogan

#peterberg #joerogan #jre2280 #thejrecompanion #jre #jrepeterberg #joeroganpodcast #joeroganexperience #americanprimeval",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DGwP13ovLpd-2.mp4
"Tom Segura and Joe Rogan dive into whether society is checking out—but here's a hot take thrown in: grown men shouldn't be wandering grocery stores in pajamas. Sweats exist for a reason, fellas. 

Episode 2320 breakdown courtesy of @thejrecompanion

Follow @seguratom
Follow @joerogan

#tomsegura #joerogan #jrec2320 #thejrecompanion #jretomsegura #jre #joeroganpodcast #joeroganexperience #ymh",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DJruxdVvlmg-1.mp4
"Bert Kreischer's Kool-Aid obsession gets called out during a wild 2 Bears 1 Cave moment that made its way into Cameron Hanes and Joe Rogan's conversation on JRE 2316

🎞️ Via @thejrecompanion

🎞️ 2 Bears 1 Cave - @ymhstudios @seguratom @bertkreischer

Follow @cameronrhanes
Follow @joerogan

#camhanes #joerogan #jrec2316 #thejrecompanion #jrecamhanes #jre #keephammering #joeroganpodcast #joeroganexperience #liftrunshoot #undeniable",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DJaD68pyKU7-2.mp4
"The conversation between José Andrés and Joe Rogan touched on something crucial that deserves attention. Mental health struggles don't discriminate, and reaching out for support is a sign of strength, not weakness. The 988 Lifeline provides free, confidential help 24/7 for anyone who needs it.

This powerful moment comes from JRE Episode 2315 with José Andrés. Full episode available through the link in @thejrecompanion's bio.

Follow @chefjoseandres
Follow @joerogan

#joseandres #joerogan #jrec2315 #thejrecompanion #jrejoseandres #jre #joeroganpodcast #yeschef #joeroganexperience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\thejrecompanion\DJW5R2Ru009-2.mp4
"Dr. Thema Bryant, current president of the American Psychological Association, just called out everyone who falls asleep to true crime documentaries—and the reason behind it might surprise you. She asks a powerful question worth reflecting on: ""Why is trauma relaxing to me?"" Her conversation with @themelrobbinspodcast is packed with transformative insights like this that'll make you rethink everything. Tune in to ""6 Signs You're Disconnected From Your Power and How to Get It Back: Life-Changing Advice From the Remarkable Dr. Thema Bryant"" 🎧

#MelRobbins #TheMelRobbinsPodcast #DrThemaBryant #SelfDevelopment #PersonalGrowth #MentalHealth #Podcast #Motivation #Inspiration #SelfCare #Mindfulness #Psychology",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DHYfYcvPGgn-1.mp4
"The gap between knowing what to do and actually doing it? That's where most people get stuck.

@themelrobbinspodcast breaks down exactly why emotions cloud judgment and how to cut through the noise by trusting your intuition—then building an actual framework around it.

This episode delivers the psychology and science behind decision-making, plus the step-by-step process to stop overthinking and start taking action.

🎧 ""Trust Your Gut: How to Make a Hard Decision""

#MelRobbins #TheMelRobbinsPodcast #DecisionMaking #TrustYourGut #PersonalGrowth #SelfDevelopment #Mindset #Psychology #LifeAdvice #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DJMXPMLpbGM-1.mp4
"Jessie's about to become a first-time mom, and her conversation with @themelrobbinspodcast is the refreshingly honest parenting talk we all needed to hear.

No sugar-coating. No perfect Pinterest moments. Just real talk about guiding kids through life, what it means to be ""good enough,"" and why every parent—new or experienced—deserves to give themselves more grace.

This episode hits different whether you're preparing for your first baby, raising teenagers, or still processing your own upbringing.

🎧 ""What Every Mom Needs to Hear Today"" is streaming now.

#parentingpodcast #newmom #parenthood #motherhoodunfiltered #parentingtips #momlife #firsttimemom #positiveparenting #parentingadvice #momtalk #parentingjourney",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DJRg3uDpL3u-1.mp4
"When Mel Robbins gathered with first-time mom-to-be Jessie for this conversation, they unpacked the unfiltered truth about motherhood: joy mixed with guilt, love tangled with expectations, and everything society doesn't prepare you for. 

This Mother's Day weekend, @themelrobbinspodcast delivers exactly what moms everywhere are craving—validation without judgment and real talk without the filters.

Perfect for anyone celebrating their mother, living motherhood right now, or simply needing to feel understood today.

🎧 ""What Every Mom Needs to Hear Today"" is streaming now.

#MothersDay #Motherhood #MelRobbins #PodcastEpisode #MomLife #NewMom #ParentingJourney #HonestConversations #MomGuilt #MotherhoodUnfiltered",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DJeYsrnpTgK-2.mp4
"Jessie was weeks away from becoming a mother when she had this conversation with Mel Robbins—and what they discussed is something society rarely says out loud.

Being a mom doesn't mean erasing yourself. @themelrobbinspodcast delivers the honest perspective every parent deserves to hear: your identity matters, your needs matter, and building a life that supports you isn't selfish—it's essential.

Whether you're a mom or you love one, this episode hits different. 🎧 ""What Every Mom Needs to Hear Today.""

#motherhood #momlife #parenthood #selfcare #mentalhealth #personaldevelopment #melrobbins #momtok #parentingtips #workingmom #motherhoodunfiltered #momadvice #mindset #growth #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DJ6w6zpRMgz-2.mp4
"The secret to conquering fear? Picture yourself at the finish line first. Mel Robbins from @themelrobbinspodcast discovered this game-changing approach when planning her @letthemtheory Tour—she visualized those final moments of joy and connection before making any moves. This mental strategy transformed how she navigated her five-city live theater tour, where perfectionism and self-doubt tried to take over. She's breaking down the mindset shifts that helped her push through in the latest episode: ""6 Powerful Mindset Shifts That Will Change Your Life"" 🎧

#MelRobbins #MindsetShift #OvercomeFear #PersonalGrowth #SelfDevelopment #ConfidenceBoost #LetThemTheory #PodcastEpisode #MotivationMonday #GrowthMindset #FearlessLiving #GoalSetting #SelfImprovement",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DK9vF0cJbMz-2.mp4
"Sometimes the most powerful stories aren't written in books—they're lived at home.

@jamespattersonbooks opens up to @themelrobbinspodcast about fatherhood, love, and the lessons that matter most. Out of all his bestsellers, it's his role as a dad that tells his greatest story.

This conversation brings perspective for anyone with a father in their life—or who is one themselves. Real wisdom, real vulnerability, real impact.

🎧 ""What Every Dad Should Know: Lessons From Literary Legend James Patterson""

#fatherhood #parenting #parentingtips #fatherandson #dadlife #parenthood #familyfirst #relationshipadvice #podcast #podcastclips #parentingpodcast #raisingkids #familygoals",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DLDIR-HRmNI-2.mp4
"A renowned heart surgeon's grocery shopping rule might be the simplest health advice you'll ever hear. @drjeremylondon broke it down for @themelrobbinspodcast, and it's refreshingly straightforward.

Dr. Jeremy London joins Mel Robbins to cut through the noise and deliver straight facts about protecting your heart—no medical jargon, just the truth about what's silently damaging it and how to fight back.

This episode feels less like a podcast and more like getting VIP access to one of the world's leading heart surgeons without the appointment wait.

🎧 ""Don't Learn This Too Late: 5 Things Top Heart Surgeon Says You Must Avoid to Live Longer.""

#MelRobbins #TheMelRobbinsPodcast #DrJeremyLondon #HeartHealth #HealthPodcast #Longevity #WellnessTips #HealthyLiving #PodcastRecommendation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DLzu2oSszxC-1.mp4
"Steve Magness has worked with Olympians and elite Division 1 teams, and his biggest lesson on mental toughness might surprise you—it's not about those picture-perfect days of peak performance.

The real secret? Consistency when motivation is nowhere to be found. That's where actual growth happens and confidence gets built from the ground up.

@themelrobbinspodcast sits down with performance coach @stevemagness to break down the neuroscience behind mental resilience and give you practical strategies to strengthen your mindset right now.

Worth the listen: ""A Powerful Mindset Makes You Unstoppable: How to Train Your Mind & Unlock Your Full Potential"" 🎧

#mentaltoughness #mindsetcoach #performancecoaching #growthmindset #podcast #mentalresilience #consistencyiskey #mindsetshift",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DKZooIev8bR-1.mp4
"The difference between chasing goals and actually reaching them? It starts with believing you're worthy of the win.

According to legendary film producer @willpowerpacker, proving others wrong will never be a strong enough foundation. Real achievement comes when you know, deep down, that you deserve what you're working toward.

In this episode from @themelrobbinspodcast, Will breaks down how to build unshakable self-confidence, transform rejection into momentum, and push past doubt to design a life that makes you proud.

🎧 ""How to Stop Doubting Yourself & Get Anything You Want in Life"" — available everywhere now!

#podcast #selfconfidence #motivation #mindset #personaldevelopment #selfbelief #successmindset #inspiration #growth #podcastepisode",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DMNexsDtDkn-1.mp4
"# Brain science hidden in baby giggles 🧠

Dr. Aliza Pressman (@raisinggoodhumanspodcast) reveals the fascinating psychology behind peek-a-boo and shares 5 game-changing parenting principles with @themelrobbinspodcast.

Whether you have kids or just want to level up as a human, this conversation is for you.

🎧 ""You Learn This Too Late: Understanding This Will Change the Way You Look at Your Relationships.""

#MelRobbins #TheMelRobbinsPodcast #ParentingTips #DevelopmentalPsychology #ParentingAdvice #Parenting101 #HealthyParenting #ParentingPodcast #MindsetShift #PersonalGrowth #SelfImprovement #PodcastRecommendation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DNItIPWsRRS-2.mp4
"Hollywood heavyweight @willpowerpacker revealed something unexpected on @themelrobbinspodcast that challenges everything you think about timing and success.

The acclaimed producer's journey proves that the ""perfect moment"" is a myth – what matters is trusting yourself enough to begin. His conversation with Mel Robbins delivers real strategies for silencing self-doubt and creating the career and life you've always imagined.

Stream the full episode: ""How to Stop Doubting Yourself & Get Anything You Want in Life"" 🎧

#MelRobbins #TheMelRobbinsPodcast #WillPacker #SelfDoubt #CareerAdvice #Motivation #PersonalGrowth #PodcastClips #SuccessMindset #TrustYourself #Inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DMsYRwkSPZ0-1.mp4
"The human body stores fat in the strangest place first—and @themelrobbinspodcast sat down with @drwilliamli to uncover the shocking truth.

According to clinical research, fat doesn't begin accumulating where most people think. The tongue is actually patient zero. That unexpected snoring? It might be your body's early warning system for weight gain.

Dr. Li brings over three decades of metabolism research to this conversation, dismantling outdated beliefs with cutting-edge science about how our bodies actually burn fat.

This episode delivers the kind of information that shifts your entire perspective on health and weight management.

Episode: ""Do THIS to Boost Your Metabolism, Lose Fat, & Feel Better Now With Dr. William Li"" 🎧

#melrobbins #melrobbinspodcast #podcast #weightloss #metabolism #healthylifestyle #wellness #nutrition #metabolismbooster #fatloss #healthtips #sciencebacked #drwilliamli #weightgain",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DOQzjTpCGE1-1.mp4
"# The myth? Creativity belongs to artists.

The truth? It's already woven into everything you do—and @themelrobbinspodcast is here to prove it.

Mel Robbins sits down with musician @philcookmusic to dismantle the lie that creativity is reserved for a select few. They reveal how the small adjustments you make—whether it's perfecting Friday night pizza, improving your grandpa's fishing knots, or tweaking grandma's old recipes—are all acts of creative expression.

The real question isn't whether you're creative. It's whether you're paying attention to the nudges: that hobby you abandoned, the skill you keep thinking about, the thing that won't leave you alone.

Those aren't distractions. They're invitations.

🎧 ""4 Steps to Unlock Your Creativity & Feel More Inspired Every Day""

#MelRobbins #TheMelRobbinsPodcast #Creativity #PersonalGrowth #SelfImprovement #Inspiration #Mindset #PodcastEpisode #UnlockYourCreativity #CreativeThinking #DailyInspiration #LifeAdvice #MindsetShift",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DN5q5l4k3B8-1.mp4
"The reason your thoughts won't stop racing at bedtime? Those unfinished tasks are creating what scientists call ""open loops"" in your brain. @themelrobbinspodcast explains how writing down incomplete to-dos gives your mind permission to release them. Her latest episode reveals 4 practical steps to break through overwhelm and regain mental clarity. 

🎧 ""If You're Feeling Overwhelmed, You Need to Hear This.""

Search ""The Mel Robbins Podcast Overwhelm"" on your favorite platform or YouTube.

#MelRobbins #TheMelRobbinsPodcast #Overwhelm #MentalHealth #SelfHelp #Podcast #ProductivityTips #SleepBetter #MindsetShift #PersonalGrowth #Wellness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DQCDZGogEd3-1.mp4
"Research from Tim Kasser at Knox College revealed something crucial: the pursuit of money, status, and approval leads to exhaustion, not fulfillment.

@themelrobbinspodcast breaks down what actually creates peace and satisfaction in life - contribution, joy, connection, and meaning. She explores 3 powerful questions developed by Stanford University professors that will completely shift how you view your work, relationships, and life purpose.

These aren't just surface-level prompts. They're designed to help you build a life that actually aligns with what matters to you.

🎧 Episode: ""3 Questions to Ask Yourself to Figure Out What You Really Want""

Available now on all podcast platforms and YouTube.

#MelRobbins #TheMelRobbinsPodcast #PersonalGrowth #SelfDevelopment #LifeAdvice #Motivation #Podcast #MentalHealth #SelfImprovement #Mindset #LifePurpose #Fulfillment #InnerPeace",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DQmVZz1Aj7R-2.mp4
"A morning dog walk turned into absolute chaos when the news dropped—@themelrobbinspodcast just made the Golden Globes consideration list. While her pups couldn't care less about the announcement, Mel Robbins sprinted home to share the moment with her listeners, the ones she credits for making it all possible. Now she's manifesting a nomination (announced 12/8) while spiraling over the real questions: Can you wear glasses with a gown? Does Chris need a new tux after 30 years? And why is everyone from Vermont so committed to questionable footwear? Before calling her mom and childhood best friend Jodi, she wanted her community to celebrate first—because this win belongs to everyone who's listened, shared, and shown up.

#goldenglobes #podcast #melrobbins #celebration #gratitude #community #podcastnews #manifest",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DPWtWWOCve_-1.mp4
"Two kiwis daily could be the unexpected solution for the 90% of women struggling with constipation, according to @drdawnmussallem.

In this groundbreaking first appearance of a cancer doctor on @themelrobbinspodcast, Dr. Dawn Mussallem delivers game-changing insights about using food as medicine—covering what fuels your body, what depletes it, and the specific choices that can extend your life while enhancing vitality.

🎧 ""Mayo Clinic Cancer Doctor: 5 Foods That Heal the Body, Starve Cancer, & Prevent Disease..""

Available now on all podcast platforms and YouTube.

#MelRobbins #TheMelRobbinsPodcast #HealthTips #CancerPrevention #NutritionTips #Wellness #HealthyLiving #WomensHealth #GutHealth #FoodAsMedicine #Longevity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DRnyZ5rDwmH-2.mp4
"You've probably heard exercise is good for you - but here's what researchers actually discovered it does to your brain:

It fundamentally rewrites how you see yourself.

Charles Duhigg, Pulitzer Prize-winning journalist and bestselling author, breaks down why exercise functions as what he calls a ""keystone habit"" in this powerful conversation with @themelrobbinspodcast.

The shift happens fast. Move your body even slightly, and your identity begins to change. You become ""someone who works out"" - and that new self-image creates a ripple effect across your entire life.

The data shows these people naturally procrastinate less, make smarter financial choices, improve their eating habits, and actually follow through on commitments.

Charles shares 3 simple, science-backed habits that can rewire your mind and body in just 7 days - no massive overhaul required.

🎧 ""The 7-Day Habit Reset: Start Today, Feel Different By Next Week""

Available now on all platforms or YouTube - search ""Mel Robbins Charles Duhigg Habits""

#MelRobbins #CharlesDuhigg #Habits #KeystoneHabits #Exercise #SelfImprovement #Motivation #PodcastClips #PersonalDevelopment #Mindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\themelrobbinspodcast\DRuP_n1gWSf-1.mp4
"A cautionary tale straight from Charlotte that @theovon had to share with everyone 🚨 Ladies, stay vigilant because this trend isn't isolated to one city. @fda

#charlotte #safety #awareness #ladies #stayalert #publicsafety #important #viral #mustwatch #fda #psa #women #beaware #community #alert",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\C1sraGZvHX6-1.mp4
".@theovon wrapped up an unforgettable Nashville night with @morganwallen and @deandrehopkins 🔥 The energy was unmatched

🎥: @countrycentral

#Nashville #MorganWallen #DeAndreHopkins #NashvilleNights #CountryMusic #GoodTimes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\C6hKhiSvAH5-2.mp4
"During a conversation with @nikkiglaser, @theovon demonstrates the universal power of confident body language 💪

#theovon #nikkiglaser #comedy #standup #podcast #funny #comedyclub #comedians #standupcomedy #comedyvideos",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\C7E9xlMJ42r-1.mp4
"Bobby Lee breaks down the alphabet gang hierarchy while @theovon can barely keep it together 😭

📍 via @theovon

#theovon #bobbyleelive #tigerbelly #podcast #comedy #standup #comedian #funny #podcasting #podcastclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\C6xDld6vorY-1.mp4
"A heavenly harmony courtesy of @theovon and @maddoxbatson ☕️🎶

#comedy #funny #podcast #standup #comedypodcast #comedyvideos",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\C8uvRc0siUp-2.mp4
"@theovon sits down with JD Vance for an eye-opening conversation about the world of lobbyists and how Washington really works 🏛️

#podcast #jdvance #politics #lobbyists #washington #learning #conversation #interview",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DBeFGztJn4i-2.mp4
"@theovon wasn't ready for this Ryl Company disaster 😭 When the commercial goes completely off the rails @therylcompany

#theo #theovon #theovonpodcast #comedy #funny #podcast #standup #standupcomedy #comedian #podcasting #podcastclips #fyp",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\C_LmEgBxJat-2.mp4
"Thanksgiving dessert just hit different when @theovon's around 🥧 Nothing says holiday spirit quite like pie o'clock with the crew!

#thanksgiving #pie #comedy #funny #theovon #happythanksgiving #dessert #pieseason #turkeyday #holidayvibes",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DC4vzvJynmG-1.mp4
"Every fitness journey needs fuel, and Theo Von knows exactly what keeps him going 💪 @theovon stays powered with @celsiusofficial

#celsiusbrandpartner #celsiuslivefit",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DH92ZWyJHl7-2.mp4
"@theovon and @thekatvond are manifesting an entire aesthetic this summer ☀️🖤

@celsiusofficial #celsiusbrandpartner #celsiuslivefit",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DJFfJx-z5VO-2.mp4
".@theovon breaks down the hilarious 'Gay Hand' test alongside neuroscience powerhouse @hubermanlab – covering everything from Natural to Money Gays with his signature comedy twist 🌈

#theovon #hubermanlab #comedy #podcast #standup #comedyvideos #funny #funnyclips #podcastclips #neuroscience",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DKPor8Xp9Rc-1.mp4
"@theovon settles the real debate: what makes the perfect sundae? 🍨

Presented by @celsiusofficial

#TheoVon #Podcast #Comedy #Sundae #IceCream #FoodTalk #Comedian #StandUp #PodcastClips #Funny",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DJOx-NGuOgH-1.mp4
"@theovon breaks down his wildest conspiracy theory with @cheetosantino and you need to hear this one 🤯

@celsiusofficial #celsiusbrandpartner #celsiuslivefit",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DQcXIU_kvZ2-1.mp4
"Chris D'Elia might be making a comeback 👀

@theovon caught this moment that has everyone talking. The comedy world is watching closely.

Credit: @theovon

#ChrisDelia #TheoPodcast #ComedyNews #StandUpComedy #PodcastClips #Comedy #Comedian",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DOrAixxkbbP-1.mp4
"---

The age-old question that keeps you up at night 🤔 @theovon and @forrest.galante dive deep into humanity's place on this planet

w/ @celsiusofficial #celsiusbrandpartner #celsiuslivefit

---",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DPrISGCkUT--2.mp4
"@theovon and @postmalone celebrating Halloween together 🎃👻

#happyhalloween #postmalone #theovon #halloween #spooky #trickortreat #halloweenvibes #costume #october #scary #fall",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DQes0xxCZDB-1.mp4
"The Pavia family opens up in this moment with @theovon 👨‍👩‍👧‍👦

Watch how their family dynamic unfolds through honest conversation and genuine connection. These are the stories that matter.

#TheoVon #Family #PaviaFamily #Podcast #RealTalk #FamilyStories #HumanConnection #Conversation #PodcastClips #ViralPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theovon\DRw8bKggA9--2.mp4
"Looking for the answer to what government can't fix? @theproblemdavesmith breaks it down in this one. Catch the complete #partoftheproblem over at gasdigital.com – drop code POTP at checkout for your FREE trial!

#libertarian #libertarians #libertarianparty #davesmith #joerogan",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\C0sc34nAnGU-2.mp4
"When @theproblemdavesmith drops wisdom like this, you've got to stop and listen 👏

#comedy #standup #standupcomedy #comedyclub #comedyshows #comedian #standupcomedian #funny #lol #laugh #humor #jokes #entertainment #viral #explore",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\C1IS5xsxQP4-1.mp4
"Dave Smith (@theproblemdavesmith) breaks down the limits of government intervention in this clip.

Want the complete conversation? Head to gasdigital.com and use code POTP at signup for your FREE trial!

#partoftheproblem #libertarian #libertarians #libertarianparty #davesmith #joerogan",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\C0sc34nAnGU-1.mp4
"Comedy gold is hitting Brea Improv this Saturday, and @theproblemdavesmith is bringing the heat! 🔥 He's serving up non-stop laughs that'll have the entire room losing it. Tickets are going fast—don't sleep on this one! 🤣 #DaveSmithComedy #BreaImprov #ComedyNight 🎟️👏",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\C2LNS1zSnHm-2.mp4
"Chicagoland's chance to catch @theproblemdavesmith live at Zanies is slipping away fast—March 15 & 16 shows are down to their final seats. If you're still on the fence, now's the moment to commit. Link in bio before it's too late.

#chicago #chicagoil #rosemont #rosemontil #zaniesrosemont #zanies #comedyclub #standup #comedy #jokes #davesmith",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\C4YJD07OAOj-1.mp4
"Looking back at the COVID era, @theproblemdavesmith and Tucker Carlson aren't holding back their criticism of Republicans and Libertarians who stayed silent during lockdowns. ""That is totalitarianism,"" they argue. Full episode available at TuckerCarlson.com.

#DaveSmith #TuckerCarlson #COVID #Lockdowns #Republicans #Libertarians #Totalitarianism #Politics #Freedom #Liberty #PoliticalDiscussion",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\C7DR2cDrvNH-2.mp4
"Dave Smith (@theproblemdavesmith) and @robbiethefire dive into the chapters they conveniently left out of your textbook.

Full episode streaming now at gasdigitalnetwork.com – grab your 7 day FREE trial with code POTP at signup!

#partoftheproblem #conspiracy #americanhistory #conspiracytheory #conspiracytheories #ushistory",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\CpoMvPmjxHc-2.mp4
,,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\DN6V_iXkfLH-2.mp4
"Media's influence on the Ivermectin controversy runs deeper than most realize. @theproblemdavesmith breaks down how America became so divided on this topic.

Follow @pbd.podcast and @valuetainment for more.

#ivermectin #media #mainstream #america #divided #controversy #podcast #politics #healthcare #debate",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\C7vELEJqwgM-2.mp4
"A complicated past that shaped a nation's present. @theproblemdavesmith breaks down the complex historical layers of Ukraine that help explain today's geopolitical tensions. Understanding where a country has been is crucial to grasping where it's headed.

#ukraine #history #geopolitics #education #learn #historytok #worldhistory #easterneurope #podcast #theproblem",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\Ctb31CTuOoX-2.mp4
"@theproblemdavesmith brings you part 3 of Tucker's wild Iraq War story—and you won't believe where this goes next.

#TuckerCarlson #IraqWar #Storytelling #PodcastClips #TrueStory #Military #History #Viral #MustWatch",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\DEVns-tSS6T-2.mp4
"The algorithm gods are smiling today – @theproblemdavesmith dropped his entire comedy special on YouTube without charging a dime. He's asking for the usual suspects: likes, shares, comments, and whatever else keeps the digital powers pleased. Worth the watch if you haven't caught it yet.

#comedy #standup #standupcomedy #comedian #funny #comedyspecial #youtube #freecomedy #newspecial",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\CxRLGvGAIqu-1.mp4
"The countdown is on! Comedian and political commentator Dave Smith takes the stage at Detroit House of Comedy this October 10-12. Known for his appearances on The Joe Rogan Experience, Tim Pool, Kennedy, and The Greg Gutfeld Show, Dave made waves when his debut special 'Libertas' dominated the #1 spot on iTunes comedy for three weeks straight in 2017. As host of the libertarian podcast 'Part of the Problem' and comedy podcast Legion of Skanks, he brings sharp commentary on current events, government overreach, and corporate media straight to the mic.

Tickets: Detroit.houseofcomedy.net

📸: @theproblemdavesmith

#comedy #comedian #standup #comedyshow #standupcomedian #houseofcomedy #detroit #thingstodoindetroit #nightlife #comdeyclub #funny #standup",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\DAZEyW2ST_p-2.mp4
"The moment has arrived! @theproblemdavesmith is unleashing his 30-minute special TODAY at 4PM EST exclusively on YouTube. He's jumping in the live chat to hang with everyone, so clear your schedule and lock in 🔥

#Comedy #StandUp #ComedySpecial #YouTube #LivePremiere #Comedian #StandUpComedy #ComedyClips #Funny #NewSpecial",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\CwQOvBqg6pT-2.mp4
"Want to see what happens when the cameras keep rolling? 

@theproblemdavesmith captures the reality that some performances just don't have an off switch.

Catch Jim Live every TUESDAY @ 8:30PM EST on YouTube

#comedy #standup #podcast #jimflorentine #comedian #standupcomedy #funny #podcasting #liveshow",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\DPtmAwkDVli-2.mp4
"Dave Smith (@theproblemdavesmith) breaks down why America's true power has always been its people, not the politicians in Washington. When everyday citizens stand together and refuse to back down, that's when real change happens. The establishment fears an informed, united public more than anything else.

#america #freedom #liberty #constitution #politics #conservative #libertarian #truth #awakening #unity #wethepeople #patriot #standtogether #podcast #comedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\theproblemdavesmith\CwqKZzbAT7F-1.mp4
"A masterclass in parenting without the entitlement—Patrick breaks down exactly how he's building resilience in his kids instead of raising complainers 💯

@therealbradlea sat down with @PatrickBetDavid for this one, and the insights hit different. Full episode waiting at the link in bio under ""My Podcast""

#parenting #parentingtips #parentingadvice #patrickbetdavid #valuetainment #mindset #parenthood #raisingkids #familyvalues #modernparenting #podcast #podcastclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\Czxn5SZueOe-2.mp4
"The science of cellular optimization breaks down into three game-changing tools in this conversation. @therealbradlea sits down with guests @TereZalolli and @anthonylolli to discuss red light therapy for mitochondrial charging, hydrogen therapy for molecular-level hydration, and PEMF mats for cellular flow restoration. The reminder? Progress over perfection—these fundamentals matter more than attempting total life optimization overnight. Full episode available through the link in @therealbradlea's bio. 🔥

#redlighttherapy #hydrogentherapy #pemftherapy #cellularhealth #mitochondria #biohacking #wellnessjourney #healthoptimization #podcastclips #longevity #recovery #holistichealth #functionalwellness #cellularenergy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DO90QSXD5MD-1.mp4
"Looking at the data, one gender might actually have the upper hand when it comes to infidelity 👀

@therealbradlea breaks down the psychology behind cheating with guest @themccabelife on his podcast. The conversation gets real about which gender has mastered the art of deception.

Full episode available through the link in @therealbradlea's bio.

#podcast #relationships #cheating #datingadvice #relationshipadvice #dating #relationshippodcast #menshealth #mensadvice #datingtips #infidelity #relationshipgoals #couplesgoals",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DOpN4myjz7H-2.mp4
"The wealthy aren't breaking rules—they're playing by a completely different rulebook that nobody tells you about.

@therealbradlea breaks down how accelerated depreciation and tax strategies separate empire builders from paycheck chasers. This isn't political theater; it's financial education they don't want you to have.

While everyone demands tax returns, the real story is why the system protects these loopholes for those who know they exist.

Full episode with @karlpatrick3 at the link in @therealbradlea's bio.

#taxes #wealth #financialeducation #moneytips #taxstrategy #realestate #investing #financialfreedom #wealthbuilding #moneymindset #investingtips #passiveincome #financialindependence #businessstrategy #entrepreneurship #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DOzAOGKEjxU-2.mp4
"A question that's dividing the internet right now – and @therealbradlea wants to hear where YOU stand on Digital ID. Drop your thoughts below. 👇

#digitalid #digitalidentity #privacy #freedomofspeech #australia #australiantiktok #fyp #foryou #viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DPsJA8iD2sm-1.mp4
"The debate that splits investors down the middle: where does personal responsibility end and guidance begin? 🤔

Before recent revelations, @therealbradlea sat down with @RyanPineda to tackle this controversial question about high-risk investment decisions. The conversation isn't about defending anyone—it's about understanding the grey areas of accountability in the investment world.

Drop your take below 👇

Full episode linked in @therealbradlea's bio.

#investing #realestate #investor #entrepreneurship #podcast #business #investingtips #financialfreedom #wealth #money #realestateinvesting #entrepreneur #BusinessPodcast #RealEstatePodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DPFDVACkpRY-2.mp4
"The math behind $1.8M is simpler than most people think. @therealbradlea breaks down a wealth-building approach that doesn't require you to be a market genius or come from money. Just consistency over decades—even when markets tank. By 51, the numbers speak for themselves. Featured conversation with @joelbrrrr from @brrrr_loans. Full podcast episode available on YouTube.

#wealthbuilding #financialfreedom #investing101 #moneymindset #personalfinance #financialliteracy #millionairemindset #passiveincome #wealthstrategy #smartinvesting #moneygoals #financialindependence #investingtips #buildwealth #podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DPmlMeVkwgh-2.mp4
"Walking through storms doesn't mean God isn't with you—it means He's building something powerful through you. Every battle you face is shaping a testimony that someone else desperately needs to hear. The world is broken, but your faith in the fire is where transformation happens. @therealbradlea and @KellyKay dropped this truth bomb in a recent podcast episode that'll shift your perspective. Catch the full conversation on YouTube—link in @therealbradlea's bio 🎙️🔥

#Faith #ChristianPodcast #Testimony #GodsFaithfulness #FaithOverFear #ChristianContent #PodcastClips #KingdomMindset #FaithInTheFire #TrustGod #ChristianMotivation #GodsPromises #SpiritualGrowth #ChristianCommunity",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DPDUhT0kaEq-2.mp4
"The only certainty worth holding onto? @therealbradlea knows exactly where to place his faith when everything else remains a question mark. While the world debates what's real and what isn't, he's made his choice crystal clear.

#Faith #ChristianTikTok #FaithOverFear #JesusChrist #ChristianContent #Believer #TrustGod #ChristianFaith #GodFirst #FaithJourney #ChristianLife #Gospel #BibleTruth #Christianity #SpiritualGrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DPKvsTjCb-x-2.mp4
"When @joelbrrrr sat down with @therealbradlea on the podcast, he revealed something wild: a single job title quietly controls access to millions in foreclosed properties. Even better? One LinkedIn search phrase unlocks them all. The gatekeepers nobody's paying attention to might be your biggest advantage.

Catch the full conversation at the link in bio 🔥

#realestate #realestateinvesting #investing #investor #realestateinvesting #foreclosure #foreclosures #linkedin #podcast #realestatetips #investingtips #realestateagent #realestateinvestor #brrrr #brrrrmethod #dealfinding",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DPzSAKJEnee-1.mp4
"Brad's costume dilemma continues – after showing up as himself last Halloween, the search for something different came up empty. Guess we're getting another year of just Brad being Brad. 🎃

Via @therealbradlea

#Halloween #HalloweenCostume #Funny #Comedy #Relatable #HalloweenHumor #CostumeIdeas #Halloween2024 #Memes #Viral",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DQevYfCicuZ-1.mp4
"@therealbradlea sits down with @robertfrank615 @robert_frank615 to set the record straight on what really happened during that brutal 5-week hospital stint. The misconceptions are wild, but the real story hits different. 

Catch the full conversation on YouTube—link in bio.

#podcast #podcastclips #storytelling #realstory #hospitalstory #truth #documentary #interview #podcasting #podcasters #podcastersofinstagram #viral #trending",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DQlI66lEQXW-2.mp4
"The origin of life question keeps getting dodged. @therealbradlea challenges the mainstream narrative in this podcast moment – if we've never witnessed life emerging from non-life even once, why is spontaneous creation treated as settled science? The leap from dust particle to conscious human being, intricate giraffes, and complex bees requires more faith than most realize. Worth considering before dismissing design outright.

Featuring @superpatchco and @jay_decoded 

Full conversation available on YouTube – link in bio.

#podcast #originsoflife #consciousness #criticalthinking #designordebate #lifeorigins #podcastclips #deepquestions #scienceandfaith #thinkdifferent #questioneverything #philosophy #existence #creation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DQARnEvEs0w-2.mp4
"A powerful reminder that our emotions physically shape us 💯

@therealbradlea sits down with @drtsupernova to discuss how negativity literally manifests in your body. The mind-body connection is real.

Full episode streaming now—link in bio.

#podcast #mindset #mentalhealth #selfimprovement #motivation #wellness #personaldevelopment #psychology #healthylifestyle #inspiration",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DQsvmSZETOj-1.mp4
"A conversation women have been trying to have forever 👏

@therealbradlea sits down with @suzy.heyman and @nicolechaness from @BedroomConfessionals to discuss what men keep getting wrong – if she didn't ask for it, don't do it.

Catch the full podcast episode on YouTube (link in bio)

#relationships #dating #datingadvice #relationshipadvice #podcastclips #datingtips #communication #moderndating #relationshiptips #mensadvice #boundaries",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DQX6LMSD8xM-2.mp4
"The medical industry's dirty little secret? You don't need an MD to print money in telehealth. @therealbradlea breaks down how marketers are quietly pulling $100K monthly checks without ever touching a stethoscope. Traffic and lead generation skills trump medical degrees in this game-changing model. He explores the entire breakdown with guest @zenjessica_official @kickstartsocial.co in his latest podcast episode. Catch the full conversation on YouTube through the link in his bio 👉 @therealbradlea

#Ad #Sponsored",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DRkvCLtE2gY-1.mp4
"The raw truth about leadership that most won't admit—@therealbradlea breaks down why running a company means embracing chaos daily. Mark Matson from @matsonmoney joins him to discuss what separates those who build empires from those who fold under pressure. Catch the full conversation on YouTube.

Brad Lea is not currently a client of Matson Money but has been compensated in connection with this video. Compensation creates a financial incentive to support Matson Money. For additional information, please visit matsonmoney.com/podcasts.

#ad #sponsored",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DRxw7LRknv8-2.mp4
"When people take care of their health and build real wealth, they become impossible to manipulate. @therealbradlea breaks down why those in power prefer you sick and broke.

#health #wealth #freedom #mindset #motivation #truth #awareness #control #power #independent #selfimprovement #success #healthy #wealthy #wise",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DRmrpsOEcT4-1.mp4
"The technology that once seemed like pure science fiction is now silently documenting everyone's daily movements—and @therealbradlea breaks down exactly how it's happening. Every device carried becomes a witness. Every camera system adds another data point. AI processes it all before a single door gets knocked on. The question isn't whether the tech exists anymore, it's how far society lets it go before crossing into pre-crime territory. This conversation with @mike_timespace explores where that line actually is. 

#podcast #technology #ai #artificialintelligence #privacy #surveillance #tech #freedomofspeech #mindset #motivation #inspiration #motivational #society #future #modernworld #podcastclips #minorityreport #freedom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\therealbradlea\DROQsuhEUF1-2.mp4
"Jeff Dye opens up about his unconventional upbringing—turns out tough love was the family motto over at @tigerbelly

#tigerbelly ep. 476 #jeffdye #parentingmemes #toughlove",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DCnbRtMuilY-1.mp4
"The correlation between hand size and... well, you'll have to hear what @tigerbelly has to say about that 👀

#tigerbelly ep. 476 #standupcomedy #youtubepodcast #comedyclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DCfrGsQvKot-1.mp4
"Bobby channels pure 80s energy with his Korean vampire impression 🧛‍♂️

Via @tigerbelly

#tigerbelly ep. 478 #koreanactor #comedypodcast #comedyclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DDGX7vMOrue-2.mp4
"When cultural temperament becomes a whole personality trait 😤 @tigerbelly explores why that Korean fury hits different in episode 478

#tigerbelly #korean #youtubepodcast #comics",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DDQcbTtSfI3-1.mp4
"Bobby Lee teams up for charity work and the results are pure comedy gold 🤣 @tigerbelly drops another instant classic

#standupcomedy #adamray #bobbylee #tigerbelly #comedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DEs_PyHSSqt-1.mp4
"Michael Bay's name keeps popping up and @tigerbelly isn't letting it go 👀 Episode 483 dives right back into the saga

#tigerbelly ep. 483 #michaelbay #moviestars #standupcomedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DEd2Hjdu_f9-2.mp4
"Bobby Lee's getting some questionable medical advice and we're here for it 💀

Via @tigerbelly

#tigerbelly ep. 485 #tmj #podcasting #comedygold",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DFMGTk4yD3W-1.mp4
"Riley Reid proves she's got range when Bobby puts her acting chops to the test over on @tigerbelly 🎭✨

#tigerbelly ep. 487 #rileyreid #actingchallenge #startrek",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DFgrqtLyHdZ-1.mp4
"Bobby's got bits ready to drop at a moment's notice 🎯 What's the one you'd pull out anytime, anywhere? @tigerbelly breaks down their go-to moves in ep. 484

#tigerbelly #comedians #jokesfordays #comedywriter",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DE6JBGLuFge-1.mp4
"When you're *trying* to be nice but your brain hasn't downloaded the software yet 💀 @tigerbelly captures Matan's hilariously awkward attempt at giving a compliment

#tigerbelly ep. 479 #matan #reelstrending #podcastcomedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DDSsWNXSsUq-2.mp4
"What happens when grooming meets paradise? Bert Kreischer chooses the scenic route for his manscaping session 🏝️

Watch the full moment on @tigerbelly ep. 494

#tigerbelly #bertkreischer #manscaping #standupcomedian",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DHmOLrpSlF_-2.mp4
"Tim Dillon drops a wild theory about actors that'll make you rethink Hollywood 😂 @tigerbelly goes there in episode 498

#tigerbelly ep. 498 #timdillon #actors #standupcomedy",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DIzy6fiyHel-1.mp4
"Bobby from @tigerbelly has some words for the Stardew Valley creator, @gluten_puck 👀

#tigerbelly #stardewvalley #pcgames #switchgamer",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DJj9a8HunMU-2.mp4
"The method acting nobody asked for – when the smell hits different 😭 @tigerbelly captures the moment reality becomes cinema

#tigerbelly ep. 503 #comedians #podcasting #funnyclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DKIv2PotF28-2.mp4
"Carrot Top wasn't ready for Jaime's question 😂 Catch the full conversation over at @tigerbelly

#tigerbelly ep. 510 #carrottop #comedians",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DMG6ICGSgHE-1.mp4
"@dumbfoundead holds the unofficial title in K-town and @tigerbelly wanted to know all about it 🇰🇷🤭

#tigerbelly ep. 515 #koreatown #ktown #dumbfoundead",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DNoqnG-S6cI-2.mp4
"The specific scent of a financial institution has apparently taken over Matt McCusker's entire home, and this observation from @tigerbelly had to be shared 🏦

#tigerbelly ep. 526 @mccuskermatthewj #podcastclips #comedians",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DQe_kbyktp8-2.mp4
"The bar scene just got a reality check courtesy of @tigerbelly 🍹 When Sam Morril breaks down the games people play while out drinking, you realize dating is basically a strategic sport. This whole conversation hits different.

#tigerbelly ep. 521 @sammorril #podcastclips #comedians #dating #played #sammorril",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DPMyigGEvZa-2.mp4
"The most casual exit strategy ever recorded 😭 @tigerbelly keeps it real with @areyougarbage

#tigerbelly ep. 527 @areyougarbage #podcastclips #comedians",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tigerbelly\DQ7dRHJkiaL-1.mp4
"Curious which books Tim Ferriss gifts most often? @timferriss breaks down the reads he puts in people's hands again and again—because some lessons are too valuable not to share. These aren't just recommendations, they're the books that fundamentally shifted his perspective.

#TimFerriss #BookRecommendations #MustRead #ReadingList #BooksToRead #PersonalDevelopment #SelfImprovement #BooksThatMatter #GiftIdeas #ReadMore #BookLovers #Wisdom #LifeLessons #PersonalGrowth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\C6t-1eTOxQs-2.mp4
"When your biggest cheerleader shows up to talk about the thing they inspired you to create. @timferriss was a driving force behind @paintedporchbookshop coming to life, making this conversation even more special.

@timferriss & @kevinrose on The Tim Ferriss Show

#TimFerriss #KevinRose #TheTimFerrissShow #Podcast #Entrepreneurship #BookstoreLove #SmallBusiness #Inspiration #FollowYourDreams #PaintedPorchBookshop",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\C_vYsObx8He-1.mp4
"A wild @timferriss sighting caught on camera 📸

#timferriss #podcast #author #entrepreneur #productivity #lifehacks #selfimprovement #motivation #success #inspiration #businessmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DAyUMbkvOUq-1.mp4
"Looking at Tim Ferriss's recommendation here – when someone like @timferriss says something's worth your time, you listen. This breakdown deserves attention, especially from the people it's directed at.

🎬 Film by @nirvanmullick
Featuring @lauren.taus
Edited @umuima
Produced by: @interconnected.media @dreammullick @brialight

#FDA #Documentary #MustWatch #TimFerriss #HealthcareReform #PublicHealth #Awareness #Documentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\C-czcjCO-Gu-1.mp4
"The mind doesn't recognize ""don't"" – which is exactly why telling yourself to stop a bad habit backfires every time. @timferriss sits down with habit expert @jamesclear to break down the counterintuitive psychology behind why we repeat what we hate and how to actually rewire the pattern. Full conversation: tim.blog/jamesclear

#habits #jamesclear #atomichabits #selfimprovement #productivity #personaldevelopment #mindset #habitformation #psychology #behaviorchange #selfhelp #motivation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DCo_wRrP6-T-2.mp4
"The parenting wisdom everyone's talking about 👀 @timferriss sits down with Dr. Becky Kennedy (@drbeckyatgoodinside) for a conversation you won't want to miss. Stream it now on Apple Podcasts, Spotify, YouTube, or your favorite podcast platform.

#TimFerriss #DrBeckyKennedy #PodcastRecommendation #ParentingTips #MustListenPodcast #PodcastClips #ApplePodcasts #SpotifyPodcast #ParentingAdvice #GoodInside",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DF5mRKLPFR7-2.mp4
"The moment @timferriss discovered hypnosis could actually work for chronic low-back pain. Dr. David Spiegel walked him through a session that changed everything about how he thinks about pain management. Sometimes the most powerful solutions are the ones we've been skeptical about the longest.

#hypnosis #painmanagement #backpain #chronicpain #mindfulness #wellness #alternativemedicine #holistichealth #mentalhealthmatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DEXgAoBItqr-1.mp4
"The secret to better creative work might be simpler than you think—just put the phone down. @craigmod breaks down why this matters so much in his conversation with @timferriss.

Full episode available on Apple Podcasts, Spotify, YouTube, and all podcast platforms.

#writing #deepwork",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DHtKC3LM8Mq-2.mp4
"What separates the truly immortal from everyone else? According to Richard Taylor of @wetaworkshop, it's the ones who create and teach—passing knowledge forward so the next generation can carry it further.

The craft itself doesn't matter. Just start building. Start teaching. Leave something behind.

@timferriss dives deep into this philosophy in his full interview with Taylor—available now on Apple Podcasts, Spotify, YouTube, and everywhere you listen.

#TimFerriss #RichardTaylor #WetaWorkshop #CreativeProcess #Legacy #Teaching #Creativity #PodcastClips #Immortality #Knowledge #NextGeneration #MakeSomething #Artists #Craftsmen #Wisdom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DHq8QA6vobX-1.mp4
"Stephen West from Philosophize This! podcast drops wisdom that hits different: ""Be the one that takes advice."" 

@timferriss sits down with the philosophy host in a conversation you don't want to miss. Available now on all podcast platforms—Apple Podcasts, Spotify, YouTube, and more.

#TimFerrissShow #PhilosophizeThis #StephenWest #PodcastRecommendation #Philosophy #Wisdom #PodcastInterview #MustListen",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DIzuQHHPfYf-2.mp4
"Terry Real breaks down the shift from boyhood to manhood with one powerful contrast that'll make you rethink everything. @timferriss sits down with him in a brand-new interview that's streaming now on Apple Podcasts, Spotify, YouTube, and all podcast platforms.

#TimFerriss #TerryReal #Masculinity #PersonalGrowth #SelfDevelopment #Podcast #LifeLessons #Mindset #MaturityMatters #PodcastClips #WisdomShared #MentalHealth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DJhKxnStFvQ-2.mp4
"When @timferriss commissioned @lalospirits for a limited-edition tequila to honor his podcast's 10th anniversary, he made sure every dollar told a story. These bottles—each hand-decorated by individual Wixárika artisans—weren't designed for retail shelves. They were created to generate immediate impact: over $100,000 USD already flowing directly into Wixárika communities fighting to protect their ancestral lands from mining operations and commercial exploitation. The Wixárika people have maintained their sacred peyote (hikuri) traditions for generations, but as Pedro Medellin from a Mexican government study warns: ""If peyote disappears, then their whole culture disappears."" Tim Ferriss has supported this cause through the Indigenous Medicine Conservation Fund, Indigenous Peyote Conservation Initiative (IPCI), and The Wirikuta Preservation Project—and this collaboration proves that business partnerships can be vehicles for cultural preservation. Learn more at @goodness_sake_inc. (Language note: Wixárika = the language, culture, or one person / Wixáritari = the people, plural)

#TimFerriss #LaloTequila #WixarikaArt #IndigenousRights #CulturalPreservation #WirikutaPreservationProject #EthicalBusiness #IndigenousMedicine #PeyoteConservation #SacredLands",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DH6idEXvKBY-1.mp4
"What separates Olympic medalists from everyone else? According to 2x Olympic Archery champion Jake Kaminski, it's simple: ""Train hard to make competition easy.""

@timferriss sits down with @jake_kaminski_ in this must-listen conversation about peak performance, mental toughness, and what it really takes to compete at the highest level.

Available now on Apple Podcasts, Spotify, YouTube, and everywhere podcasts are found! 🎯

#TimFerriss #JakeKaminski #Olympics #Archery #PeakPerformance #Podcast #MentalToughness #Champion #Training #Competition",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DJrfjJ8tPDD-2.mp4
"Game designer Elan Lee just dropped a productivity hack that turns boring meetings into creative goldmines. @timferriss explores this unconventional brainstorming method in his latest podcast episode that's changing how teams collaborate.

Catch the full conversation with Elan on Apple Podcasts, Spotify, YouTube, or your favorite podcast platform!

#podcast #brainstorming #creativity #productivity #teamwork #innovation #gamedesign #collaboration #ellanlee #timferriss #podcastclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DNEGqFhv_6V-2.mp4
"When couples therapy pioneer Terry Real drops a phrase like ""Normal Marital Hatred,"" you know @timferriss secured another conversation worth your time. Real's latest sit-down with Ferriss unpacks the uncomfortable truths most relationship experts won't say out loud. Stream the full interview wherever you listen to podcasts.

#TerryReal #TimFerriss #RelationshipAdvice #CouplesTherapy #MarriageTherapy #PodcastRecommendation #RelationshipTherapy #MarriageTips #HealthyRelationships #TherapistTalk",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DJejwgrtJYD-1.mp4
"Jake Kaminski (@jake_kaminski_) drops a truth bomb about the simplest success habit most people ignore: detailed note-taking. Despite coaching countless individuals and pushing them to document their journey, barely anyone actually follows through. Sometimes the most powerful tools are the ones we overlook.

@timferriss sits down with Jake in this must-listen conversation—available now on Apple Podcasts, Spotify, YouTube, and everywhere you stream.

cc: @joelturneractual

#TimFerriss #JakeKaminski #ProductivityTips #SuccessHabits #CoachingAdvice #NoteTaking #PodcastClips #PersonalDevelopment #PerformanceTips #PodcastRecommendation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DJsB_x_vCTv-1.mp4
"The laws of physics don't care about your feelings, and @jackcanfield_official has a point worth considering. Via @timferriss – some truths just exist, whether we acknowledge them or not. Stop fighting what simply is.

#motivation #mindset #acceptance #reality #wisdom #personaldevelopment #growth #perspective #timferriss #jackcanfield",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DQu8HfbD0z9-2.mp4
"The counterintuitive path to becoming better: stop trying so hard. @timferriss breaks down why chasing self-improvement head-on might actually be holding you back 🎯

Drop LINK below for the full conversation

From E166 - Tim Ferriss: The Hard Truth About Self-Improvement (After 25 Years of Experimenting)

#timferriss #selfimprovement #selfdevelopment #personalgrowth #mindset #productivity #selfhelp #motivation #lifelessons #podcastclips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DPmJaBfkaPh-2.mp4
"Tim Ferriss built an empire teaching people how to work less—then realized he couldn't stop working himself.

Through two decades of deconstructing human performance, @timferriss uncovered an uncomfortable truth: the same drive that fuels extraordinary achievement might be running from something deeper.

Their conversation goes beyond productivity hacks and life optimization. It digs into why some people can't sit still, even when they've already won. Therapy helped Tim connect dots between his relentless output and patterns formed long before he wrote 'The 4-Hour Workweek'—the book that changed how millions view their relationship with work.

Inside this episode:

- The psychology behind our optimization obsession
- How early experiences create a need for control
- Trauma as fuel for high performance
- Why slowing down feels impossible for achievers
- Whether growth requires constant pressure

Tim pioneered long-form conversations before the format was validated, proving depth could capture attention. That risk created space for what this account does today—standing on foundations others built.

Comment 'Tim' for the full conversation in your DMs.

#TimFerriss #PodcastClips #HighPerformance #MentalHealth #SelfOptimization #ProductivityCulture #TherapyWorks #PersonalGrowth #EntrepreneurMindset #DeepConversations",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\timferriss\DQ_TqX5DDe8-1.mp4
"The legendary @tonyrobbins continues to transform lives across the globe—whether through empowering entrepreneurs or those unforgettable banana hands moments that keep everyone laughing 🍌😂

Drop your @tonyrobbins experience in the comments—has his work changed your perspective or were you lucky enough to meet him in person? 👇

#TonyRobbins #SageRobbins #BetterTogether #PersonalGrowth #Connection",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\C-tMsPSS0Db-1.mp4
"Tony Robbins (@tonyrobbins) shares a powerful reminder about the importance of self-compassion in this conversation on emotional wellness. He emphasizes that our mental state isn't determined by external circumstances, but by how we choose to relate to ourselves. When we release resistance and practice gentleness with ourselves, we unlock deeper understanding. 🪷

This message feels especially significant on #WorldMentalHealthDay — a reminder that you're supported and everything will be okay. ♥️

#mentalhealth #emotionalwellness #selfcompassion #mindfulness #innerpeace #mentalhealthmatters #wellness #personalgrowth #tonyrobbins #mentalhealthawareness #healing #lettinggo",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DA8-Llppa16-1.mp4
"Focus isn't just a mental exercise—it's the gateway to your emotional state, and @tonyrobbins breaks down exactly why in under 30 seconds. Where your attention goes, your feelings follow. 

#TonyRobbins #Focus #Mindset #PersonalDevelopment #SelfImprovement #Motivation #EmotionalMastery #LifeCoach #Inspiration #MindsetMatters #PersonalGrowth #SuccessMindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\Cx_ZNYaRLZd-2.mp4
"The wisdom drop everyone's been waiting for just landed 🎯 @tonyrobbins brought the heat and this episode is absolutely packed with game-changing insights you won't want to miss. Drop 'TONY' in the comments to catch the full conversation!

#TonyRobbins #Podcast #Motivation #SelfDevelopment #PersonalGrowth #Mindset #Success #Inspiration #PodcastEpisode #MustWatch",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DFDM1VHNfHi-2.mp4
"When @tonyrobbins drops truth bombs about where your attention goes, you listen. 

Your focus shapes everything—and this conversation proves exactly why that matters more than you think.

#TonyRobbins #Focus #Mindset #PersonalDevelopment #SelfImprovement #Motivation #MentalHealth #LifeAdvice #Podcast #WisdomShared",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DFLQjKxODMj-1.mp4
"The most valuable currency isn't money—it's attention. @tonyrobbins reminds us that being physically present means nothing without mental and emotional presence. Real connection happens when distractions fade and we fully engage with the moment, the person, the experience. That's where relationships transform and life becomes richer. ❤️

He and @sagerobbins have a complete holiday message waiting at the link in bio, plus a special gift designed to make 2025 your most extraordinary year yet. 🙌

#presence #tonyrobbins #connection #personaldevelopment #mindfulness #relationships #growth #2025goals #holidaymessage #powerofpresence #liveinthenow #deeperconnection #behere #authenticity #transformation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DEP-pn0xB-5-2.mp4
"The world celebrates the victory, but rarely witnesses the grind that made it possible. @tonyrobbins breaks down the hidden formula behind every extraordinary life—the unsexy, unglamorous work that nobody sees. While everyone wants the spotlight moment, few are willing to put in the private hours of sacrifice, discipline, and relentless commitment. This is what separates those who dream from those who dominate.

#tonyrobbins #motivation #success #mindset #personaldevelopment #selfimprovement #inspiration #grinding #discipline #entrepreneur #hustle #successmindset #goals #winners #dedication",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DFG2Lx2OAz_-2.mp4
"Most people don't realize their biggest obstacles are self-created illusions. @tonyrobbins breaks down how F.E.A.R. (False Evidence that Appears Real) operates as nothing more than interpretations from our past—not actual facts about our future 👻

The difference between those who break through and those who stay stuck? One group questions their limiting stories. The other accepts them as truth.

Skills can be developed. Solutions can be discovered. Setbacks become stepping stones. It all starts with recognizing which ""monsters"" are real and which ones we've conjured up ourselves 🎃

The power to move forward has always been there—it just requires calling out the false evidence for what it really is 💪

#fear #mindset #personalgrowth #selfimprovement #motivation #limitingbeliefs #innerstrength #personaldevelopment #growthmindset #overcomefear #believeinyourself #mentaltoughness #successmindset",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DBzCFqxxFYx-2.mp4
"The human spirit has no limits—just ask Siri Lindley. 🔥

@tonyrobbins shares how his dear friend went from being unable to swim to claiming 2x World Champion triathlete titles, then battling for her very survival. Her story proves that our greatest obstacles reveal our deepest strength.

TRI ME: The Siri Lindley Story drops this year as a documentary featuring Tony and his wife Sage, already selected for both the Durango Film Festival and Boulder International Film Festival. This isn't another sports documentary—it's a testament to what becomes possible when we refuse to let fear write our ending.

Follow @siritrimefilm for release updates. Prepare to be moved. 🙏💥

#TonyRobbins #SiriLindley #TriMe #Documentary #HumanSpirit #Triathlete #WorldChampion #Inspiration #NeverGiveUp #Motivation #FilmFestival #Courage #BelieveInYourself #OvercomeObstacles",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DGyM3aFRll5-2.mp4
"You can always find something to complain about if you look hard enough. The real power move? Training yourself to spot what's working just as quickly. @tonyrobbins reminds us that both perspectives exist simultaneously—we just get to choose which lens we look through.

#TonyRobbins #Perspective #Mindset #ChooseYourFocus #PersonalDevelopment #SelfImprovement #MindsetShift #PositiveThinking #GrowthMindset #Motivation #SelfGrowth #MindsetMatters #LifeLessons",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DKu-ZkPRAzL-2.mp4
"# The Hidden Connection

Neuroscientist Dr. Andrew Newberg is using cutting-edge brain imaging technology to reveal something extraordinary—what actually lights up in your mind during spiritual moments, and why it changes everything.

Speaking at the recent Platinum Partners Happiness Event in Abu Dhabi, he unpacked the science behind rituals, repeated practices, and those experiences that move us at our core. @tonyrobbins sat down with him for a full conversation breaking down these discoveries.

Want the full episode of The Tony Robbins Podcast? 👇

Comment ""BRAIN"" to get the link sent to you, or tap the bio to watch now.

#TonyRobbins #Neuroscience #BrainScience #Spirituality #Happiness #PersonalGrowth #SelfImprovement #Mindfulness #Podcast #AndrewNewberg #PlatinumPartners #AbuDhabi #MindsetMatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DJ4qyfXRdLe-2.mp4
"The human spirit's capacity to rewrite reality gets captured in @siritrimefilm - a documentary @tonyrobbins describes as proof that our greatest battles reveal our true essence. 💥

Siri Lindley went from non-swimmer to 2x World Champion triathlete, then faced an even bigger fight. Tony and his wife Sage joined this powerful film project that chronicles what happens when someone refuses to accept impossible as an answer.

TRI ME: The Siri Lindley Story drops this year and has already earned selections at Durango Film Festival and Boulder International Film Festival. According to Tony, if you've been to his events lately, you know Siri's name - now the world gets to witness why her story moves people beyond words. 🙏

Follow @siritrimefilm for release updates.

#TonyRobbins #SiriLindley #Documentary #HumanSpirit #Triathlon #Inspiration #NeverGiveUp #WorldChampion #FilmFestival #TriMeFilm #Courage #Resilience #TransformYourLife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DGyM3aFRll5-1.mp4
"The science of living longer and healthier just got its Hollywood moment 🎬 @tonyrobbins joins @edwardnortonofficial, @peterdiamandis, @mcuban, @steveaoki, @cbum and other visionaries in Longevity Hackers—now streaming on Apple TV and Amazon. This isn't your typical documentary. It's a deep dive into real breakthroughs that are transforming aging from inevitable decline into something we can actually control. Producer Ruben Figueres and director Michal Siewierski assembled the minds behind the movement, exploring the same revolutionary concepts Tony covers in Life Force and implements at Fountain Life. The future of healthspan isn't coming—it's already here 💪🔥

#longevity #tonyrobbins #healthspan #lifeforce #fountainlife #longevityhackers #biohacking #aging #wellness #documentary #health",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DHeVeqJSXYt-1.mp4
"Tony Robbins' wife @SageRobbins has designed a transformative 3-day virtual experience exclusively for women who refuse to settle — and it launches TOMORROW.

The She's Unstoppable Summit isn't another surface-level event. It's where thousands of women from across the globe gather to rediscover their power, gain crystal-clear direction, and step into their future with unwavering confidence.

This is for the woman ready to move forward — not by erasing her past, but by leveraging everything she's learned to build what's next.

Comment YES below and Tony will send you all the details to secure your free spot.

Your breakthrough moment could be one decision away. 🔥

#ShesUnstoppable #WomenEmpowerment #PersonalGrowth #TonyRobbins #SageRobbins #VirtualSummit #Transformation #WomenSupportingWomen #SelfDevelopment #Empowerment #FreeEvent #LiveYourBestLife",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DNi8pkTvlqu-1.mp4
"What if the problem isn't your productivity—it's your approach?

@tonyrobbins has spent nearly five decades perfecting a system that shifts everything: from drowning in tasks to designing a life with actual meaning.

This isn't another time management hack. This is RPM—the framework that's transformed millions who were stuck in the cycle of busy without the breakthrough.

July 29–31, he's going LIVE for the only RPM: Master Your Time & Design Your Life session of the year. Three days to rewire how you spend your hours and finally align with what actually matters.

Drop ""RPM"" below to claim your spot.

#TimeManagement #Productivity #PersonalDevelopment #LifeByDesign #TonyRobbins #RPM #GoalSetting #SelfImprovement #Mindset #SuccessMindset #LifeDesign #ProductivityHacks #PersonalGrowth #Motivation #FocusOnWhatMatters",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DMLupbnRODX-2.mp4
"Your reality isn't shaped by what happens—it's shaped by the story you tell yourself about it.

@tonyrobbins breaks down the power we all have to reframe any situation. The circumstances? They're neutral. It's the interpretation we attach that creates our emotional experience.

Every single moment, you're choosing the lens through which you see your life. That's not just philosophy—that's freedom.

#tonyrobbins #mindsetmatters #perspective #personaldevelopment #growthmindset #selfmastery #motivation #consciousness #empowerment #mindsetshift #lifelessons #wisdom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DQrsHk-EXxK-1.mp4
"When every dollar turns into 30 meals for hungry families, the power of community becomes undeniable. @tonyrobbins is challenging us all through his Giving Tuesday partnership with @feedingamerica, and the opportunity to triple your impact ends December 5. 🍽️❤️

Drop ""GIVE"" in the comments for the donation link, or head to FeedingAmerica.org/TonyRobbins directly.

Here's how the double-match works: Your $1 donation provides 10 meals through Feeding America. With the match active now through December 5, that same dollar delivers 30 meals to families facing hunger—up to $100,000 in total matching.

This isn't just about food. It's about becoming a force for good and proving what happens when people choose compassion over complacency. 🙏

#GivingTuesday #FeedingAmerica #ForceForGood #EndHunger #GiveBack #Compassion #Community #MakeADifference #TonyRobbins #CharityWork #Philanthropy #ActOfKindness #FeedTheHungry",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tonyrobbins\DRu8qprkRJ--2.mp4
"@tuckercarlson explores the Epstein conversation that has Shawn Ryan weighing in on recent statements from Kash Patel and Dan Bongino. The discussion cuts through the noise.

#shawnryan #kashpatel #danbongino #epstein #jeffreyepstein #tuckercarlson #podcast #truth",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DJ4Y3kSxWru-2.mp4
"# A 77-year-old former congressman is finally speaking out about what cost him everything.

Curt Weldon spent two decades in congress and was on track to chair the House Armed Services Committee—until he questioned the 9-11 report. The Bush administration's response? Federal agents at his daughter's door and the end of his political career. Now, after years of silence, Weldon is ready to reveal what actually happened on September 11, 2001.

Watch the full story with @tuckercarlson

#tucker #tuckercarlson #september11 #congress #politics #truth #government #whistleblower #political #unitedstates #usa #america",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DIcJmu_seft-2.mp4
"Scott Bessent drops the real strategy behind the tariff policy—it's about bringing manufacturing back home. The Treasury Secretary makes it crystal clear: relocate production to American soil. @tuckercarlson sits down with Bessent to discuss the administration's economic vision and what these tariffs are actually designed to accomplish.

#ScottBessent #TreasurySecretary #Tariffs #Manufacturing #AmericanJobs #Economy #Trade #BringJobsBack #MadeInAmerica #EconomicPolicy #TuckerCarlson",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DIMRyXkurik-2.mp4
"Senator Ted Cruz breaks down the Iran situation with insights you need to hear. @tuckercarlson sits down for this critical conversation.

Full interview available at TuckerCarlson.com

#TedCruz #Iran #TuckerCarlson #Politics #ForeignPolicy #MiddleEast #Interview #News",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DLBfQzDMtT8-2.mp4
"The man behind one of America's most progressive brands might surprise you with his take on Ukraine. Ben Cohen, who co-founded his ice cream empire after moving to Vermont in 1977, sits down with @tuckercarlson to share perspectives you wouldn't expect. Sometimes the most interesting conversations happen across the aisle.

#TuckerCarlson #BenCohen #UkraineWar #PoliticalDiscourse #UnexpectedConversations #Vermont #DifferentPerspectives #ListenFirst",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DJSV_t4snsq-1.mp4
"The unsolved mystery that haunts American history—RFK Jr. opens up to @tuckercarlson about the unanswered questions surrounding his father's assassination that still keep him searching for truth decades later.

#RFKJr #RobertFKennedy #Assassination #TruthSeekers #AmericanHistory #PoliticalHistory #JusticeForRFK #UnansweredQuestions #TuckerCarlson",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DLlCfB3hKMf-2.mp4
"Political realignment caught on camera. Ana Kasparian's take might surprise you more than you'd expect. When the usual labels stop making sense, that's when the conversation gets interesting. @tuckercarlson explores what happens when perspectives don't fit the script anymore.

#politics #anakasparian #politicalnews #freespeech #politicaldebate #media #culture #currentevents #politicalcommentary",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DMivn88R0RY-1.mp4
"Tucker Carlson (@tuckercarlson) cuts through the noise with a chilling truth about power and corruption. When innocence becomes currency for control, we're witnessing something far darker than scandal—we're seeing evil in its purest form. The Epstein case isn't just about one person; it's about understanding how predators weaponize what should be protected.

#TuckerCarlson #Epstein #Truth #Evil #PowerCorruption #Justice #Innocence #Speaking Truth #RealTalk #WakeUp #Corruption #Exposed",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DMPDnCzOqM7-2.mp4
"The UK arrested this many people for speech violations in 2023—and Tucker Carlson (@tuckercarlson) breaks down why the figure is more alarming than most realize.

#TuckerCarlson #FreeSpeech #UK #CensorshipNews #FirstAmendment #SpeechViolations #UnitedKingdom #PoliticalNews #MediaCensorship #NewsUpdate",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DPCkP5eDVOP-1.mp4
"Academia rarely produces voices this unfiltered—yet Dave Collum, an Ivy League professor, continues to defy expectations. @tuckercarlson sits down with someone who refuses to play by the establishment's rules.

#TuckerCarlson #DaveCollum #IvyLeague #Professor #FreeThought #Academia #UnfilteredTruth #IntellectualHonesty #AcademicFreedom #Interview",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DNlzE4vBYgu-1.mp4
"@tuckercarlson takes on the biggest unanswered questions about 9/11 in a groundbreaking documentary series. After nearly 25 years of secrecy, he's digging into what's really been kept from the public and exposing why the full truth remains hidden.

All 5 episodes drop September 11 exclusively at TuckerCarlson.com

#TuckerCarlson #911Truth #Documentary #September11 #Investigative #NeverForget #911Documentary #TruthSeekers #Journalism",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DN6r_bPj5hF-2.mp4
"The federal government's decision to classify these reports raises serious questions about transparency and accountability. @tuckercarlson examines what legal basis could possibly warrant keeping this information from the public eye.

#Tucker #TuckerCarlson #Government #Transparency #Classified #FederalGovernment #Accountability #Truth #Freedom #America",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DPpYrpqAYcX-2.mp4
"Tucker Carlson (@tuckercarlson) breaks down a question that's becoming impossible to ignore in modern politics.

The psychology of power, loyalty, and national interest—examined without the usual media filter.

#tuckercarlson #america #politics #leadership #truth #media #news #viral #trending #fyp #explore",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DPmz4dmEcU0-2.mp4
"The forests of Maine hold secrets that refuse to stay buried—@tuckercarlson ventures into terrain where the past still lingers.

#Maine #HauntedForest #Supernatural #Mystery #TuckerCarlson #Unexplained #Creepy #ForestMysteries #Paranormal",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DQfmlsMDY9D-2.mp4
"Tucker Carlson (@tuckercarlson) cuts through the noise with a principle that used to be universally accepted: judge people by who they are, not by the group they belong to. Individual character over collective identity.

#tuckercarlson #truth #individualism #personalresponsibility #character #principle #values #meritocracy #judgecharacter #individual",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DQVKYIeEZEn-1.mp4
"---

The principle couldn't be simpler, yet here we are still debating it. @tuckercarlson breaks down why judging people by skin color remains fundamentally wrong, no matter how it's packaged or justified.

#TuckerCarlson #Morality #CivilRights #Equality #ColorBlind #Justice #AmericanValues #PrinciplesOverPolitics #Character #Freedom",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DRaxbn5gUop-2.mp4
"The British government is now locking people up for not actively promoting homosexuality, according to @tuckercarlson's latest commentary on the state of free speech across the pond.

#FreeSpeech #UK #Britain #Freedom #CivilLiberty #FirstAmendment #Politics #News #TuckerCarlson #Breaking",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DRiqJNaEU8L-1.mp4
"Britain has officially criminalized prayer in public spaces. @tuckercarlson breaks down how freedom of religion has been reduced to a prosecutable offense in what was once a beacon of Western liberty.

#Tucker #TuckerCarlson #Britain #UK #UnitedKingdom #ReligiousFreedom #FreedomOfReligion #Prayer #Christianity #FreeSpeech #CivilLiberties #HumanRights #WesternCivilization",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\tuckercarlson\DRqONThkaB8-1.mp4
"Your underarms aren't just for temperature control—they're home to millions of bacteria that keep your body in balance. Commercial antiperspirants destroy that ecosystem and create a cycle of dependency that gets worse over time.

The numbers are alarming: CDC researchers detected parabens in 99% of tested urine samples, connecting these chemicals to early puberty, reproductive dysfunction, and hormonal chaos.

Via @ultimatehumanpod

Daily exposure adds up. Your skin absorbs everything you put on it.

👇 COMMENT ""160"" for the complete episode in your DMs!

#health #wellness #toxins #hormones #naturalhealth #healthylifestyle #nontoxic #cleanliving #biohacking #holistichealth #healthtips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DI1MMoSxTM8-1.mp4
"Gary Brecka tackles the controversial health questions most experts avoid—parasites, harmful multivitamins, and the one supplement he refuses to touch—in this no-fluff Q&A from @ultimatehumanpod that challenges mainstream advice with science-backed answers.

Drop ""162"" below to catch the full breakdown.

#GaryBrecka #UltimateHuman #HealthPodcast #Biohacking #HumanOptimization #Longevity #Supplements #Parasites #PregnancyHealth #FolicAcid #HealthMyths #WellnessJourney #HolisticHealth #FunctionalMedicine #HealthTips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DJHLR0TJ0jD-1.mp4
"When @dr.jess.md walked away from the ER, she uncovered truths about modern medicine that most doctors won't say out loud. @ultimatehumanpod sits down with the functional medicine expert to unpack the uncomfortable reality: the system isn't designed to heal you.

From pharmaceutical pressure on physicians to the hidden role of unresolved trauma in disease, Dr. Jess reveals why your ""normal"" lab results might be masking serious health issues.

If you've ever been told ""it's all in your head"" or sent home with another prescription instead of answers, this conversation will validate everything you've been feeling.

🎧 COMMENT ""156"" for the full episode link

#functionalmedicine #healthpodcast #chronicillness #holistichealth #wellness #trauma #rootcause #healthylifestyle",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DId9l4TJ51w-1.mp4
"The average person encounters over 200 synthetic chemicals before their morning coffee even brews. From the moment feet hit the floor—aluminum seeping through skin, PFAS leaching into eggs, microplastics floating in water, VOCs circulating with every breath—the body becomes a filter for the modern world's invisible assault. These compounds don't just pass through; they disrupt hormones, trigger inflammation, and quietly accelerate the aging process at a cellular level. @ultimatehumanpod breaks down exactly how these exposures stack up and what can actually be done about it. Drop ""TOXINS"" below for the complete breakdown.

#toxins #health #wellness #biohacking #healthylifestyle #detox #nontoxic #nontoxicliving #healthtips #hormonalhealth #guthealth #inflammation",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DKPR9z1RPv6-2.mp4
"# The deodorant industry's dirty secret? They're still using a chemical that's banned in soap.

Most people have no idea they're coating their underarms with aluminum and triclosan – ingredients linked to serious hormonal disruption. The irony? We call it ""personal care.""

Natural alternatives exist that actually work without sabotaging your endocrine system. @ultimatehumanpod breaks down exactly what's hiding in your bathroom cabinet and why it matters more than you think.

Comment DEO for the full episode link!

#deodorant #naturaldeodorant #toxicfree #hormonehealth #endocrinedisruptors #cleanliving #nontoxic #wellness #healthylifestyle #holistichealth #naturalproducts #cleanbeauty #detox",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DLHvYN9om52-1.mp4
"The secret to peak performance? Let your body be the guide. 🎯

@danicapatrick breaks down the fundamentals that actually matter in this powerful moment from @ultimatehumanpod.

Drop ""ATHLETE"" in the comments for the complete episode in your DMs 👊

#UltimateHuman #DanicaPatrick #Protein #Fitness #Strength #Wellness #HealthyLiving #WorkoutMotivation #FitnessGoals #PodcastClips",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DNNzOwsq9mt-1.mp4
"Joy isn't meant to be a distant memory from your past. Dr. Judith Joseph breaks down anhedonia—when happiness feels impossible to grasp, even in moments that should light you up. This isn't about hustling harder or ""adulting."" It's about reclaiming what you were designed to experience.

Catch the full conversation with @drjudithjoseph on @ultimatehumanpod to understand why settling for numbness was never the plan.

👇 Comment ""JOY"" below for the complete episode in your DMs.

#anhedonia #mentalhealth #mentalhealthawareness #joy #happiness #depression #burnout #purpose #selfcare #wellness #healing #therapy #podcast #podcastclips #ultimatehumanpod",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DNIpqdTt_yx-2.mp4
"A single solar flare could erase everything we've built—and @joerogan breaks down exactly why we're not ready for it.

In this episode on @ultimatehumanpod, Joe Rogan challenges us to face an uncomfortable truth: our entire civilization runs on systems so fragile, one blackout could bring it all down.

We've traded resilience for convenience. Connection for dopamine. Survival skills for screen time.

The question isn't if we're vulnerable—it's whether we're willing to admit it.

📲 Comment ""JOE"" to watch the full conversation.

#JoeRogan #SolarFlare #Survival #ModernSociety #SocietalCollapse #Resilience #Preparedness #FragileSystem #WakeUpCall #Podcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DMK2o8RBU4X-1.mp4
"The medical journals you trust? @robertfkennedyjr exposes the hidden business model behind them in this powerful segment from @ultimatehumanpod. Big Pharma doesn't just advertise—they fund the research, control the data, purchase bulk reprints, and turn science into a marketing tool distributed by sales reps. What you think is peer-reviewed evidence might actually be corporate propaganda.

👇 Comment ""TRUTH"" and I'll DM you the link.

#RobertFKennedyJr #BigPharma #HealthTruth #MedicalIndustry #PharmaScience #HealthFreedom #CorporateCapture #MedicalJournals #HealthcareSystem #WakeUp #QuestionEverything #HealthPodcast",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DMnLcMCtb3p-2.mp4
"200 episodes deep and The Ultimate Human Podcast just keeps delivering. On a reflective day like 9/11, with everything unfolding across the nation, @ultimatehumanpod puts the numbers into perspective—34M+ YouTube views, 14M+ podcast plays, 2.7M+ hours consumed, 500K+ subscribers, and 388K+ podcast followers. But beyond the metrics lies something greater: a mission built on truth, connection, and empowering people with knowledge to live longer, stronger lives. This community proves that meaningful content still matters. Here's to 200 more episodes of impact.

👉 Comment 200 for the link to the full episode.

#UltimateHuman #PodcastMilestone #HealthPodcast #WellnessJourney #Longevity #TruthMatters #PodcastCommunity #200Episodes #HealthOptimization #HumanPerformance",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DOdoeqmDpNp-2.mp4
"When potatoes actually behave like potatoes—sprouting, browning, living—most chip companies panic and reach for chemicals.

Steven Rofrano didn't. @masa_chips was built on a radical idea: let food be food. No CIPC sprays (used on 85% of U.S. potatoes), no toxic shortcuts to fake perfection. Just avocados with blemishes, potatoes that change color, and nature doing what it does.

Credit: @ultimatehumanpod

👇🏻 Comment MASA for the full conversation with Steven Rofrano.

#realfood #cleanfood #organicfood #nontoxicliving #foodtransparency #regenerativeagriculture #cleaneating #knowyourfood #foodwithintegrity #potatochips #organicsnacks #healthysnacks",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DO3siWtjKd9-1.mp4
"@ultimatehumanpod reveals the shocking truth about oral hygiene that's been hidden in plain sight.

The connection between your mouth and chronic disease isn't what you've been told. Every time you brush, you could be setting yourself up for long-term damage instead of protection.

This episode unpacks:
🦷 Why fluoride toothpaste is doing more harm than good
🦷 The mineral that unlocks Vitamin D3 (most people miss this)
🦷 The correct order for brushing + flossing to protect enamel
🦷 Why hydration is your first line of defense in the mouth

👇🏻 COMMENT MOUTH and we'll send you the link to the full clip.",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DOQwBOwDbV--1.mp4
"@dr.austin.lake breaks down a critical flaw in women's healthcare: jumping straight to medication without ever investigating the root causes.

The missing piece? Foundational health—hormones, thyroid function, proper nutrition, and lifestyle factors that rarely make it into the conversation.

Addressing these fundamentals doesn't just create temporary relief. It transforms outcomes entirely.

Catch the complete breakdown with @ultimatehumanpod.

👇🏻 Comment ""LAKE"" to watch the full episode now.

#womenshealth #hormonalhealth #thyroidhealth #functionalmedicine #rootcause #holistichealth #healthfoundations #wellness #healthoptimization",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DPB_pWDDDBv-2.mp4
"The science of standing barefoot is more powerful than most people realize—and @ultimatehumanpod breaks down exactly why it works.

Direct contact with the earth for just ten minutes can reduce inflammation, balance cortisol levels, and transform sleep quality. No products required. No complicated protocols. Just physics doing what it does best.

The shift in energy, mood, and rest happens faster than expected when grounding becomes part of the daily routine.

👇🏻 Comment ""GROUNDING"" to watch the full episode and discover how combining it with sunlight and breathwork amplifies the results.

#grounding #earthing #biohacking #inflammation #cortisolbalance #sleepoptimization #naturalhealing #ancestralhealth #wellness #holistichealth #circadianrhythm #healthoptimization",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DQMWn7hEUPN-1.mp4
"Gary Brecka's work with @danawhite proves that real transformation doesn't take years—it takes commitment. The UFC president ditched thyroid medications and a handful of daily pills in just six weeks, replacing them with cold plunges, red light therapy, and the unstoppable feeling of peak performance. True health becomes its own addiction once you know what it actually feels like. Catch the complete conversation on @ultimatehumanpod.

👇🏻 Comment ""DANA"" for the full episode link.

#DanaWhite #GaryBrecka #HealthTransformation #ColdPlunge #RedLightTherapy #UFC #HumanOptimization #Biohacking #WellnessJourney #PeakPerformance",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DQeXmzMEYtA-2.mp4
"Data over guesswork—that's the supplement philosophy from the co-founders of @bioptimizers in their conversation with @ultimatehumanpod.

The strategy they lay out? Get genetic testing first to understand your baseline needs. Follow up with consistent blood work to monitor your progress. Then make incremental daily improvements based on what the numbers actually tell you.

It's personalized optimization, not random bottles from the health food store.

👇🏻 Comment ""BIO"" for the full episode link.

#biohacking #supplements #genetictesting #bloodwork #optimization #datadriven #personalizedhealth #bioptimizers #humanoptimization #wellness #longevity #healthspan",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DPy6uP7kZzU-2.mp4
"The inputs you feed your body today determine whether your eyes stay sharp or slowly fade—and most people ignore the problem until it's too late.

@ultimatehumanpod breaks down how the AREDS 2 formula (vitamin C, E, zinc, copper, lutein, zeaxanthin) cuts risk by 25%, but whole foods like kale, spinach, egg yolks, and orange peppers deliver carotenoids your body actually absorbs better than pills.

Eye degeneration isn't inevitable if you act before symptoms appear.

👇🏻 Comment ""VISION"" for the full episode to learn more.

#vision #eyehealth #longevity #healthspan #biohacking #nutrition #supplements #preventivehealth #wellness #healthyaging #functionalnutrition",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DRimp_gEarm-1.mp4
"Looking at Gary Brecka's (@ultimatehumanpod) supplement protocol reveals something most people miss about cellular nutrition.

The research shows GLP-1—a gut hormone triggered by nutrient density—increases significantly when hydrogen-rich water accompanies a meal. Your gut's response literally changes based on hydrogen presence.

Another critical insight: amino acids are the actual building blocks, not protein itself. Collagen, elastin, immune cells, and tissue repair all require amino acids at the foundational level.

Gary's daily approach:
✔️ Hydrogen water @drinkh2tab
✔️ Amino acids @perfectamino
✔️ Essential trace minerals @bajagoldsaltco

👇🏻 Comment ""STACK"" for the full breakdown.

#GLP1 #HydrogenWater #AminoAcids #GaryBrecka #HumanOptimization #Biohacking #Supplements #GutHealth #Longevity #HealthOptimization #Wellness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DRKzr6gkqXa-2.mp4
"Joseph Pilates wasn't stretching on a mat—he was engineering a system to rebuild broken bodies during wartime, and @bryonydeery explains exactly how it worked.

Long before modern science caught up, Pilates understood that breath, resistance, and spinal alignment weren't separate—they were one integrated system designed to accelerate healing and build real strength from the inside out.

In this conversation with @ultimatehumanpod, Bryony reveals why classical pilates remains one of the smartest protocols for bulletproofing your core, protecting against injury, and keeping your body young.

Your powerhouse determines how you age. Your spine holds the answer.

👇🏻 Comment ""PILATES"" for the full episode.

#pilates #classicalpilates #CoreStrength #SpineHealth #MovementScience #Longevity #InjuryPrevention #BreathWork #FunctionalFitness",,,catalogId=,productIds=,Manual,C:\Users\asus\Desktop\projects\reeld\spoofed\ultimatehumanpod\DRPutowERoU-2.mp4
</file>

<file path="claude_analyzer.py">
"""
Claude UI Analyzer - AI-based UI analysis for Instagram automation.

This module encapsulates all Claude AI interactions for analyzing
UI elements and deciding next actions in the posting flow.

Extracted from SmartInstagramPoster to improve separation of concerns.
"""
import json
import time
from typing import List, Dict, Any, Optional

import anthropic


class ClaudeUIAnalyzer:
    """Analyzes UI elements using Claude AI to decide next actions."""

    def __init__(self, model: str = "claude-sonnet-4-20250514", max_tokens: int = 500):
        """
        Initialize the analyzer.

        Args:
            model: Claude model to use for analysis.
            max_tokens: Maximum tokens for response.
        """
        self.client = anthropic.Anthropic()
        self.model = model
        self.max_tokens = max_tokens

    def format_ui_elements(self, elements: List[Dict]) -> str:
        """Format UI elements into a text description for Claude.

        Args:
            elements: List of UI element dicts with text, desc, id, bounds, center, clickable.

        Returns:
            Formatted string description of UI elements.
        """
        ui_description = "Current UI elements:\n"
        for i, elem in enumerate(elements):
            parts = []
            if elem.get('text'):
                parts.append(f"text=\"{elem['text']}\"")
            if elem.get('desc'):
                parts.append(f"desc=\"{elem['desc']}\"")
            if elem.get('id'):
                parts.append(f"id={elem['id']}")
            if elem.get('clickable'):
                parts.append("CLICKABLE")
            ui_description += f"{i}. {elem.get('bounds', '')} center={elem.get('center', '')} | {' | '.join(parts)}\n"
        return ui_description

    def build_prompt(
        self,
        elements: List[Dict],
        caption: str,
        video_uploaded: bool = False,
        caption_entered: bool = False,
        share_clicked: bool = False
    ) -> str:
        """Build the analysis prompt for Claude.

        Args:
            elements: UI elements to analyze.
            caption: Caption text for the post.
            video_uploaded: Whether video has been uploaded.
            caption_entered: Whether caption has been entered.
            share_clicked: Whether share button has been clicked.

        Returns:
            Complete prompt string for Claude.
        """
        ui_description = self.format_ui_elements(elements)

        prompt = f"""You are controlling an Android phone to post a Reel to Instagram.

Current state:
- Video uploaded to phone: {video_uploaded}
- Caption entered: {caption_entered}
- Share button clicked: {share_clicked}
- Caption to post: "{caption}"

{ui_description}

Based on the UI elements, decide the next action to take.

Instagram posting flow:
1. Find and tap Create/+ button. IMPORTANT: On different Instagram versions:
   - Some have "Create" in bottom nav bar
   - Some have "Create New" in top left corner (only visible from Profile tab)
   - If you don't see Create, tap "Profile" tab first to find "Create New"
2. Select "Reel" option if a menu appears
3. Select the video from gallery (look for video thumbnails, usually most recent)
4. Tap "Next" to proceed to editing
5. Tap "Next" again to proceed to sharing
6. When you see the caption field ("Write a caption" or similar), return "type" action with the caption text
7. Tap "Share" to publish
8. Done when you see confirmation, "Sharing to Reels", or back on feed

Respond with JSON:
{{
    "action": "tap" | "tap_and_type" | "back" | "scroll_down" | "scroll_up" | "home" | "open_instagram" | "done",
    "element_index": <index of element to tap>,
    "text": "<text to type if action is tap_and_type>",
    "reason": "<brief explanation>",
    "video_selected": true/false,
    "caption_entered": true/false,
    "share_clicked": true/false
}}

CRITICAL RULES - NEVER GIVE UP:
- NEVER return "error". There is no error action. Always try to recover.
- If you see Play Store, Settings, or any non-Instagram app: return "home" to go back to home screen
- If you see home screen or launcher: return "open_instagram" to reopen Instagram
- If you see a popup, dialog, or unexpected screen: return "back" to dismiss it
- If you're lost or confused: return "back" and try again
- If you don't see Create button, tap Profile tab first
- Look for "Create New" in desc field (top left area, small button)
- Look for "Profile" in desc field (bottom nav, usually id=profile_tab)
- If you see "Reel" or "Create new reel" option, tap it
- If you see gallery thumbnails with video, tap the video
- If you see "Next" button anywhere, tap it
- IMPORTANT: When you see a caption field (text containing "Write a caption", "Add a caption", or similar placeholder) AND "Caption entered" is False, return action="tap_and_type" with the element_index of the caption field and text set to the caption
- CRITICAL: If "Caption entered: True" is shown above, DO NOT return tap_and_type! The caption is already typed. Just tap the Share button directly.
- Allow/OK buttons should be tapped for permissions
- IMPORTANT: Return "done" ONLY when Share button clicked is True AND you see "Sharing to Reels" confirmation
- If Share button clicked is False but you see "Sharing to Reels", that's from a previous post - ignore it and start the posting flow
- Set share_clicked=true when you tap the Share button
- CRITICAL OK BUTTON RULE: After caption has been entered (Caption entered: True), if you see an "OK" button visible on screen (text='OK' or desc='OK'), you MUST tap the OK button FIRST before tapping Next or Share. This OK button dismisses the keyboard or a dialog and must be tapped for Next/Share to work properly.

Only output JSON."""

        return prompt

    def parse_response(self, response_text: str) -> Dict[str, Any]:
        """Parse Claude's response into an action dict.

        Args:
            response_text: Raw response text from Claude.

        Returns:
            Parsed action dictionary.

        Raises:
            ValueError: If response cannot be parsed as JSON.
        """
        text = response_text.strip()

        # Handle markdown code blocks
        if text.startswith("```"):
            text = text.split("```")[1]
            if text.startswith("json"):
                text = text[4:]
            text = text.strip()

        try:
            return json.loads(text)
        except json.JSONDecodeError as e:
            raise ValueError(f"JSON parse failed: {e}. Response: {text[:100]}")

    def analyze(
        self,
        elements: List[Dict],
        caption: str,
        video_uploaded: bool = False,
        caption_entered: bool = False,
        share_clicked: bool = False,
        retries: int = 3
    ) -> Dict[str, Any]:
        """Analyze UI elements and return the next action.

        Args:
            elements: UI elements to analyze.
            caption: Caption text for the post.
            video_uploaded: Whether video has been uploaded.
            caption_entered: Whether caption has been entered.
            share_clicked: Whether share button has been clicked.
            retries: Number of retry attempts on failure.

        Returns:
            Action dictionary with action, element_index, text, reason, etc.

        Raises:
            ValueError: If analysis fails after all retries.
        """
        prompt = self.build_prompt(
            elements=elements,
            caption=caption,
            video_uploaded=video_uploaded,
            caption_entered=caption_entered,
            share_clicked=share_clicked
        )

        for attempt in range(retries):
            try:
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=self.max_tokens,
                    messages=[{"role": "user", "content": prompt}]
                )

                # Check for empty response
                if not response.content:
                    if attempt < retries - 1:
                        time.sleep(1)
                        continue
                    raise ValueError("Claude returned empty response")

                text = response.content[0].text.strip()

                # Check for empty text
                if not text:
                    if attempt < retries - 1:
                        time.sleep(1)
                        continue
                    raise ValueError("Claude returned empty text")

                try:
                    return self.parse_response(text)
                except ValueError as e:
                    print(f"  [JSON PARSE ERROR] attempt {attempt+1}: {e}")
                    print(f"  Raw response (full): {text}")
                    if attempt < retries - 1:
                        time.sleep(1)
                        continue
                    raise ValueError(f"JSON parse failed after {retries} attempts: {e}")

            except Exception as e:
                if attempt < retries - 1 and "rate" not in str(e).lower():
                    time.sleep(1)
                    continue
                raise

        raise ValueError(f"Failed to get valid response from Claude after {retries} attempts")


# Convenience function for backwards compatibility
def analyze_ui_for_instagram(
    elements: List[Dict],
    caption: str,
    video_uploaded: bool = False,
    caption_entered: bool = False,
    share_clicked: bool = False
) -> Dict[str, Any]:
    """Analyze UI elements for Instagram posting flow.

    This is a convenience function that creates a ClaudeUIAnalyzer
    and performs analysis. For repeated calls, prefer creating
    a ClaudeUIAnalyzer instance directly.
    """
    analyzer = ClaudeUIAnalyzer()
    return analyzer.analyze(
        elements=elements,
        caption=caption,
        video_uploaded=video_uploaded,
        caption_entered=caption_entered,
        share_clicked=share_clicked
    )
</file>

<file path="CLAUDE.md">
# Claude Code Instructions

## CRITICAL: ALWAYS READ ENTIRE FILES

**When reviewing Python scripts, ALWAYS read the ENTIRE file.**
- Use `Read` tool WITHOUT offset/limit to get the whole file
- Scripts with 1000+ lines need FULL review to understand the logic
- NEVER read just 50-80 lines - that leads to wrong conclusions
- Be thorough, not lazy

---

## CRITICAL: LIVE TESTS OVER TEST SCRIPTS

**ALWAYS prioritize live tests with actual functionality over creating test scripts.**

### DO:
- Test directly with `python posting_scheduler.py --run` or `python parallel_orchestrator.py --run`
- Use real accounts, real videos, real captions
- Monitor logs in real-time
- Fix issues as they appear in production

### DO NOT:
- Create `test_*.py` scripts to test isolated functionality
- Pollute the project with debugging scripts
- Write unit tests when you could just run the actual code
- Add test files that won't be maintained

### Why:
- Test scripts get stale and don't reflect real behavior
- Live tests expose real integration issues
- The actual scripts ARE the tests

---

## CRITICAL: ALWAYS STOP PHONES

**THIS IS THE MOST IMPORTANT RULE. PHONES COST MONEY WHEN RUNNING.**

### When to Stop Phones:
1. **EVERY TIME you kill a batch test** - IMMEDIATELY run the stop script
2. **After ANY test completes** - success or failure
3. **Before starting a new test** - verify no phones running
4. **When user interrupts** - FIRST thing to do is stop phones

### How to Stop ALL Running Phones:
```bash
cd /c/Users/asus/Desktop/projects/geelark-automation && python -c "
from geelark_client import GeelarkClient
client = GeelarkClient()
for page in range(1, 20):
    result = client.list_phones(page=page, page_size=100)
    for phone in result['items']:
        if phone['status'] == 1:
            client.stop_phone(phone['id'])
            print(f'STOPPED: {phone[\"serialName\"]}')
    if len(result['items']) < 100:
        break
"
```

**NEVER leave phones running. Check and stop phones PROACTIVELY.**

---

## CRITICAL: ACCOUNT MANAGEMENT

**ONLY USE ACCOUNTS FROM accounts.txt - NEVER USE RANDOM GEELARK ACCOUNTS**

### Single Source of Truth:
- **`accounts.txt`** - List of 82 approved accounts (one per line)
- **`scheduler_state.json`** - Tracks posting history per account (posts_today, last_post_date, failures, cooldowns)

### STRICT RULES:
1. **NEVER post to accounts not in accounts.txt** - even if they exist in Geelark
2. **NEVER post multiple times to the same account in one batch** - accounts will get BANNED
3. **ALWAYS check scheduler_state.json for posting history** before selecting accounts
4. **ALWAYS verify account exists in accounts.txt** before using it

### How Accounts Are Tracked:
```json
// scheduler_state.json -> accounts array
{
  "name": "podclipcrafters",
  "last_post_date": "2025-12-12",
  "posts_today": 1,
  "total_posts": 5,
  "total_failures": 2,
  "consecutive_failures": 0,
  "cooldown_until": ""
}
```

### Before Running ANY Batch:
```bash
# 1. Verify accounts.txt exists and has 82 accounts
wc -l accounts.txt

# 2. Check which accounts have been posted to today
python -c "
import json
from datetime import date
with open('scheduler_state.json', 'r') as f:
    state = json.load(f)
today = str(date.today())
posted_today = [a['name'] for a in state['accounts'] if a.get('last_post_date') == today]
print(f'Posted today ({len(posted_today)}): {posted_today}')
"
```

### DO NOT:
- Use the 173+ Geelark accounts (bubblegumlampspin, crookedwafflezing, etc.)
- Those are NOT our posting accounts
- Only the 82 accounts in accounts.txt are authorized for posting

---

## CRITICAL: PROGRESS FILE MANAGEMENT (parallel_progress.csv)

**NEVER DELETE THE PROGRESS FILE MANUALLY. EVER.**

### The Daily Ledger Rule:
- `parallel_progress.csv` is the **daily ledger** tracking all posts
- It tracks which accounts have successfully posted TODAY
- Deleting it = wiping the success history = accounts can get multiple posts
- This is how you get 6 posts on one account in one day

### Per-Account Daily Limits:
- Each account can have at most `max_posts_per_account_per_day` successful posts (default: 1)
- This is enforced at BOTH seeding time AND claim time (defense in depth)
- Once an account has N successes, it is EXCLUDED from all future jobs that day

### Starting a New Day:
```bash
# ONLY use --reset-day to start fresh for a new posting day
python parallel_orchestrator.py --reset-day
```
This will:
1. Check no orchestrators are running
2. Archive current progress to `parallel_progress_YYYYMMDD.csv`
3. Create a fresh empty progress file

### NEVER Do This:
```bash
# NEVER delete the progress file manually
rm parallel_progress.csv  # WRONG - NEVER DO THIS
del parallel_progress.csv  # WRONG - NEVER DO THIS

# NEVER delete mid-day to "fix" something
# NEVER delete because "it seems corrupt"
# NEVER delete to "start fresh" during the day
```

### Check Before Running Orchestrator:
```bash
# Always check for other running orchestrators first
python parallel_orchestrator.py --status
```
The orchestrator will automatically detect and refuse to start if another is running.

---

## CRITICAL: CODE REVIEW IMPLEMENTATION

**If conversation gets compacted, CHECK THESE FIRST:**
1. Run `task-master list --status pending` to see pending tasks
2. Read `reviews/review1.txt` for full implementation details
3. Tasks 21-24 contain the review implementation plan

**Review Tasks (in order of implementation):**
- Task 21: Port retry logic from PostingScheduler
- Task 22: Fix per-account daily cap enforcement
- Task 23: Add ADB/Appium lifecycle state machine
- Task 24: Enforce strict worker-phone-Appium bindings

---

## Task Master AI Instructions

**Import Task Master's development workflow commands and guidelines, treat as if import is in the main CLAUDE.md file.**
@./.taskmaster/CLAUDE.md

Always use taskmaster to research the best solution any time I ask you to do something. Do not use web search. Use taskmaster.

## MAIN ENTRY POINTS

### For Parallel Posting (RECOMMENDED):
```bash
python parallel_orchestrator.py --workers 5 --run
```

### For Single-Threaded Posting:
```bash
python posting_scheduler.py --add-folder chunk_01c --run
```

---

## Parallel Orchestrator (parallel_orchestrator.py)

**The primary way to run batch posts at scale.**

Architecture:
```
parallel_orchestrator.py (main process)
    ├── Worker 0 ──► Appium:4723 ──► Phone
    ├── Worker 1 ──► Appium:4725 ──► Phone
    ├── Worker 2 ──► Appium:4727 ──► Phone
    └── Worker N ──► Appium:472X ──► Phone
```

### Key Features:
- Runs N workers in PARALLEL (separate processes)
- Each worker has its own Appium server on unique port
- Workers coordinate via file-locked `parallel_progress.csv`
- Automatic retry for failed jobs (up to 3 attempts)
- Per-account daily limits enforced at seeding AND claim time
- Clean shutdown on Ctrl+C (stops all workers and phones)

### Usage:
```bash
# Start with 5 parallel workers
python parallel_orchestrator.py --workers 5 --run

# Check status
python parallel_orchestrator.py --status

# Stop all workers and phones
python parallel_orchestrator.py --stop-all

# Start a new day (archives old progress file)
python parallel_orchestrator.py --reset-day
```

### Progress Tracking:
- **CSV Ledger**: `parallel_progress.csv` - daily job tracking (file-locked)
- **State File**: `scheduler_state.json` - account history and job source
- **Worker Logs**: `logs/worker_N.log` - per-worker activity

---

## Legacy Single-Threaded Scheduler (posting_scheduler.py)

**Use this for smaller batches or debugging.**

### NEVER RUN THESE ARCHIVED SCRIPTS:
- Files in `archived/` folder - Old implementations, DO NOT USE

### Usage:
```bash
# Add videos and accounts, then run
python posting_scheduler.py --add-folder chunk_01c --add-accounts phone1 phone2 --run

# Check status
python posting_scheduler.py --status

# Retry all failed
python posting_scheduler.py --retry-all
```

---

## Key Files

### Core Parallel Posting System
| File | Purpose |
|------|---------|
| `parallel_orchestrator.py` | **MAIN ENTRY POINT** - starts N workers, coordinates shutdown |
| `parallel_worker.py` | Worker process - claims jobs, runs Appium, posts to phones |
| `parallel_config.py` | Configuration dataclasses (WorkerConfig, ParallelConfig) |
| `progress_tracker.py` | CSV-based progress tracking with file locking |
| `config.py` | **CENTRALIZED CONFIG** - all paths and settings |

### Posting Logic
| File | Purpose |
|------|---------|
| `post_reel_smart.py` | SmartInstagramPoster - Claude-driven UI navigation |
| `geelark_client.py` | Geelark API wrapper (upload, phone control) |
| `appium_server_manager.py` | Appium server lifecycle management |

### State Files
| File | Purpose |
|------|---------|
| `parallel_progress.csv` | Daily job ledger (file-locked, NEVER delete) |
| `scheduler_state.json` | Account history, job source |
| `accounts.txt` | 82 approved posting accounts |

### Legacy (Use Orchestrator Instead)
| File | Purpose |
|------|---------|
| `posting_scheduler.py` | Single-threaded scheduler |
| `dashboard.py` | Web dashboard (http://localhost:5000) |

## Dashboard

Real-time monitoring at http://localhost:5000

```bash
# Start dashboard (in separate terminal)
python dashboard.py
```

Features:
- Live stats: success/active/pending/failed counts
- Account status with color-coded progress
- Recent activity feed
- Live log streaming (when scheduler uses TeeWriter)

---

## Setup Requirements

### 1. Appium Server (REQUIRED for Android 15+)

```bash
# Install
npm install -g appium
appium driver install uiautomator2

# Run (must be running before posting)
appium --address 127.0.0.1 --port 4723
```

### 2. Environment Variables

```bash
# Required in .env
GEELARK_ACCESS_KEY=your_access_key
GEELARK_ACCESS_SECRET=your_access_secret
ANTHROPIC_API_KEY=your_claude_key

# Set in code (post_reel_smart.py)
ANDROID_HOME=C:\Users\asus\Downloads\android-sdk
```

### 3. ADB Platform Tools

Path: `C:\Users\asus\Downloads\platform-tools-latest-windows\platform-tools\adb.exe`

## Appium Integration (Android 15 Fix)

The original ADBKeyboard approach broke on Android 15. We migrated to Appium for all UI operations:

### Key Changes Made (Dec 2024)

1. **`dump_ui()`** - Uses `driver.page_source` instead of `adb uiautomator dump`
   - CRITICAL: Uses `root.iter()` not `iter('node')` - Appium uses class names as XML tags

2. **`tap(x, y)`** - Uses `driver.tap([(x, y)])` instead of `adb input tap`

3. **`swipe()`** - Uses `driver.swipe()` instead of `adb input swipe`

4. **`press_key()`** - Uses `driver.press_keycode()` instead of `adb input keyevent`

5. **`type_text()`** - Uses Appium's `send_keys()` - supports Unicode/emojis on all Android versions

### Why Appium?

| Feature | ADBKeyboard | Appium |
|---------|-------------|--------|
| Android 15 support | No | Yes |
| Unicode/emoji | Buggy | Native |
| UI inspection | Conflicts with Appium | Unified |
| Reliability | Flaky | Stable |

## Usage

### Single Phone Post (for testing)
```bash
python post_reel_smart.py <phone_name> <video_path> <caption>

# Example
python post_reel_smart.py reelwisdompod_ video.mp4 "Check this out!"
```

### Batch Posting (ALWAYS USE THIS)
```bash
# Using posting_scheduler.py (the ONLY correct way)
python posting_scheduler.py --add-folder chunk_01c --add-accounts phone1 phone2 --run
```

## Chunk Data Format

```
chunk_01c/
├── chunk_01c_cleaned.csv    # Caption + video shortcode mapping
├── 2bears.1cave/            # Video folder by source
│   ├── DM6m1Econ4x-2.mp4
│   └── DMbMMftoiDC-2.mp4
├── alexjones.tv/
└── ...
```

CSV columns: `Text, Image/Video link 1 (shortcode)`

## Troubleshooting

### "No UI elements found"
- Ensure Appium server is running: `curl http://127.0.0.1:4723/status`
- Check `dump_ui()` uses `root.iter()` not `root.iter('node')`

### "Device offline" in Appium
- Re-run `adb connect <ip:port>` then `adb -s <device> shell glogin <password>`
- Restart Appium server

### Caption not typed
- Verify `caption_entered` flag is only set AFTER actual typing (not from Claude's analysis)

## Testing

```bash
# Quick connectivity test
python test_full_flow_android15.py

# Full posting test
python post_reel_smart.py reelwisdompod_ video.mp4 "Test caption"
```
</file>

<file path="config.py">
"""
Centralized Configuration Module.

This is the SINGLE SOURCE OF TRUTH for all paths and configuration values.
All other modules should import from here instead of defining their own paths.

Usage:
    from config import Config, setup_environment

    # At module startup
    setup_environment()

    # Use paths
    adb_path = Config.ADB_PATH
"""

import os
from pathlib import Path
from dataclasses import dataclass
from typing import Optional


@dataclass(frozen=True)
class Config:
    """
    Centralized configuration constants.

    These values should NEVER be redefined in other files.
    If you need to change a value, change it HERE.
    """

    # ==================== PATHS ====================

    # Android SDK - use the one with Appium compatibility
    ANDROID_SDK_PATH: str = r"C:\Users\asus\Downloads\android-sdk"

    # ADB executable path - derived from SDK path for consistency
    ADB_PATH: str = os.path.join(ANDROID_SDK_PATH, "platform-tools", "adb.exe")

    # Project root directory
    PROJECT_ROOT: str = os.path.dirname(os.path.abspath(__file__))

    # ==================== APPIUM ====================

    # Base Appium port (workers use 4723, 4725, 4727, etc.)
    APPIUM_BASE_PORT: int = 4723

    # Default Appium URL for single-worker mode
    DEFAULT_APPIUM_URL: str = "http://127.0.0.1:4723"

    # ==================== PARALLEL EXECUTION ====================

    # Default number of parallel workers
    DEFAULT_NUM_WORKERS: int = 3

    # Maximum workers (limited by ports and system resources)
    MAX_WORKERS: int = 10

    # Port allocation for workers:
    # - Appium ports: 4723, 4725, 4727, ... (odd ports)
    # - systemPort ranges: 8200-8209, 8210-8219, 8220-8229, ...
    SYSTEM_PORT_BASE: int = 8200
    SYSTEM_PORT_RANGE: int = 10  # Ports per worker

    # ==================== JOB EXECUTION ====================

    # Maximum posts per account per day (prevents account bans)
    MAX_POSTS_PER_ACCOUNT_PER_DAY: int = 1

    # Delay between jobs in seconds
    DELAY_BETWEEN_JOBS: int = 10

    # Job timeout in seconds
    JOB_TIMEOUT: int = 300

    # Shutdown timeout in seconds
    SHUTDOWN_TIMEOUT: int = 60

    # ==================== RETRY SETTINGS ====================

    # Maximum retry attempts for failed jobs
    MAX_RETRY_ATTEMPTS: int = 3

    # Delay between retries in minutes
    RETRY_DELAY_MINUTES: int = 5

    # Non-retryable error types
    NON_RETRYABLE_ERRORS: frozenset = frozenset({
        'suspended', 'captcha', 'loggedout', 'actionblocked', 'banned'
    })

    # ==================== FILES ====================

    # Progress file for parallel workers
    PROGRESS_FILE: str = "parallel_progress.csv"

    # Scheduler state file
    STATE_FILE: str = "scheduler_state.json"

    # Logs directory
    LOGS_DIR: str = "logs"

    # Accounts file
    ACCOUNTS_FILE: str = "accounts.txt"

    # ==================== TIMEOUTS ====================

    # ADB command timeout
    ADB_TIMEOUT: int = 30

    # ADB device readiness timeout
    ADB_READY_TIMEOUT: int = 90

    # Appium connection timeout
    APPIUM_CONNECT_TIMEOUT: int = 60

    # Phone boot timeout
    PHONE_BOOT_TIMEOUT: int = 120

    # ==================== SCREEN COORDINATES ====================
    # For Geelark cloud phones (720x1280 resolution)
    # Used for swipe/tap operations in UI automation

    SCREEN_CENTER_X: int = 360          # Horizontal center of screen
    SCREEN_CENTER_Y: int = 640          # Vertical center of screen
    FEED_TOP_Y: int = 400               # Top position for feed scroll
    FEED_BOTTOM_Y: int = 900            # Bottom position for feed scroll
    REELS_TOP_Y: int = 300              # Top position for reels scroll
    REELS_BOTTOM_Y: int = 1000          # Bottom position for reels scroll
    NOTIFICATIONS_TOP_Y: int = 800      # Top position for notifications scroll
    STORY_NEXT_TAP_X: int = 650         # Right side of screen for story navigation
    SWIPE_DURATION_FAST: int = 300      # Duration in ms for fast swipes
    SWIPE_DURATION_SLOW: int = 200      # Duration in ms for slower swipes
    SWIPE_DURATION_MAX: int = 400       # Maximum swipe duration for randomization

    # ==================== CLASS METHODS ====================

    @classmethod
    def get_worker_appium_port(cls, worker_id: int) -> int:
        """Get the Appium port for a specific worker."""
        return cls.APPIUM_BASE_PORT + (worker_id * 2)

    @classmethod
    def get_worker_system_port_range(cls, worker_id: int) -> tuple:
        """Get the systemPort range for a specific worker."""
        start = cls.SYSTEM_PORT_BASE + (worker_id * cls.SYSTEM_PORT_RANGE)
        end = start + cls.SYSTEM_PORT_RANGE - 1
        return (start, end)

    @classmethod
    def get_worker_appium_url(cls, worker_id: int) -> str:
        """Get the Appium URL for a specific worker."""
        port = cls.get_worker_appium_port(worker_id)
        return f"http://127.0.0.1:{port}"


def setup_environment() -> None:
    """
    Set up environment variables for Android SDK and ADB.

    Call this early in your script before any Appium imports.
    """
    os.environ['ANDROID_HOME'] = Config.ANDROID_SDK_PATH
    os.environ['ANDROID_SDK_ROOT'] = Config.ANDROID_SDK_PATH

    # Add platform-tools to PATH if not already there
    platform_tools = os.path.join(Config.ANDROID_SDK_PATH, 'platform-tools')
    current_path = os.environ.get('PATH', '')
    if platform_tools not in current_path:
        os.environ['PATH'] = f"{platform_tools};{current_path}"


def get_adb_env() -> dict:
    """
    Get environment dict with ANDROID_HOME properly set.

    Use this when spawning subprocesses that need ADB.
    """
    env = os.environ.copy()
    env['ANDROID_HOME'] = Config.ANDROID_SDK_PATH
    env['ANDROID_SDK_ROOT'] = Config.ANDROID_SDK_PATH

    platform_tools = os.path.join(Config.ANDROID_SDK_PATH, 'platform-tools')
    if platform_tools not in env.get('PATH', ''):
        env['PATH'] = f"{platform_tools};{env.get('PATH', '')}"

    return env


# Validate configuration on import
def _validate_config():
    """Validate that critical paths exist."""
    if not os.path.exists(Config.ANDROID_SDK_PATH):
        print(f"WARNING: ANDROID_SDK_PATH does not exist: {Config.ANDROID_SDK_PATH}")

    if not os.path.exists(Config.ADB_PATH):
        print(f"WARNING: ADB_PATH does not exist: {Config.ADB_PATH}")


# Run validation on import
_validate_config()
</file>

<file path="CONTEXT_FOR_CLAUDE.md">
# Geelark Instagram Automation - Context Document

Use this to catch Claude up to speed on the project.

## Project Overview

Automated Instagram Reel posting to Geelark cloud phones using AI-driven UI navigation. The key innovation is using Claude AI to analyze UI hierarchy (via `uiautomator dump`) and decide what to tap at each step - no hardcoded coordinates.

## How It Works

1. Connect to Geelark cloud phone via their API
2. Enable ADB on the phone
3. Upload video to Geelark cloud → transfer to phone's Downloads folder
4. Open Instagram app
5. AI-driven navigation loop:
   - Dump UI elements via `uiautomator dump`
   - Send elements to Claude AI with current state
   - Claude decides next action (tap, type, back, scroll, done)
   - Execute action via ADB
   - Repeat until post is complete
6. Cleanup (delete video, disable ADB)

## Key Files

| File | Purpose |
|------|---------|
| `post_reel_smart.py` | Core posting logic with AI navigation - THE MAIN SCRIPT |
| `batch_post.py` | Sequential batch posting to multiple phones |
| `batch_post_concurrent.py` | Parallel batch posting with ThreadPoolExecutor |
| `geelark_client.py` | Geelark API wrapper (phones, ADB, uploads) |
| `post_gui.py` | Simple tkinter GUI for monitoring posts |

## Current CSV Format (chunk_01a)

Location: `chunk_01a/chunk_01a.csv`

| Column | Content |
|--------|---------|
| `Text` | Caption with hashtags, emojis, newlines |
| `Shortcode` | Full file path (needs `spoofed` replaced with `chunk_01a`) |

Videos are in subfolders: `chunk_01a/2bears.1cave/`, `chunk_01a/hubermanlab/`, etc.

**To load posts from this CSV:**
```python
with open(csv_path, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        video_path = row.get('Shortcode', '').replace('spoofed', 'chunk_01a')
        caption = row.get('Text', '').strip()
```

## Available Phones/Accounts

**Working (tested):**
- podmindstudio
- reelwisdompod_
- talktrackhub

**New (untested but available):**
- FusedMercurySpike
- DarkLichenCoded
- choice.jonestown
- chance_of_rain_tomorrow
- BrokenRockPace
- apexstratagem
- clipsonpodcast
- talkwisdomcut

**Broken (DO NOT USE):**
- miccliparchive (CAPTCHA issues)

## Text Input Method

Uses ADBKeyboard APK with base64 broadcast - simple and reliable:
```python
def type_text(self, text):
    import base64
    text_b64 = base64.b64encode(text.encode('utf-8')).decode('ascii')
    self.adb(f"am broadcast -a ADB_INPUT_B64 --es msg {text_b64}")
```

**DO NOT** use clipboard/paste method - it was causing issues. Direct ADBKeyboard typing works.

## Critical AI Prompt Rules (in post_reel_smart.py)

After typing caption, the AI MUST:
1. Tap "OK" button in top right corner to dismiss caption editor
2. THEN tap "Share" button

The Share button won't work while caption field is still active/focused.

## Known Issues & Fixes Applied

### Issue 1: Caption not typing
**Cause:** Old code used clipboard + paste which didn't work in Instagram
**Fix:** Changed `type_text()` to use ADBKeyboard broadcast directly

### Issue 2: Share button not working after caption
**Cause:** Need to tap OK button first to dismiss caption editor
**Fix:** Updated AI prompt to tap OK before Share

### Issue 3: Upload timeout on larger files
**Cause:** Geelark cloud-to-phone transfer is slow (not your upload speed)
**Status:** Need to investigate further - may need longer timeout or retry logic

## Environment Setup

Required in `.env`:
```
GEELARK_APP_ID=your_app_id
GEELARK_API_KEY=your_api_key
GEELARK_TOKEN=your_token
ANTHROPIC_API_KEY=your_anthropic_key
```

ADB path (hardcoded in scripts):
```python
ADB_PATH = r"C:\Users\asus\Downloads\platform-tools-latest-windows\platform-tools\adb.exe"
```

## Running Single Post

```bash
python post_reel_smart.py <phone_name> <video_path> "<caption>"
```

Example:
```bash
python post_reel_smart.py podmindstudio "chunk_01a/2bears.1cave/ABC123.mp4" "Caption here #hashtags"
```

## Running Batch Post

Current `batch_post.py` needs to be updated to handle the new CSV format. Once updated:

```bash
python batch_post.py chunk_01a phone1 phone2 phone3 --limit 6
```

## GUI

```bash
python post_gui.py
```

Current GUI is single-post only. Needs upgrade for batch mode with:
- Multi-phone selection
- Batch progress tracking
- Results table

## Logging Strategy (To Implement)

**Results CSV** (after every post):
```csv
timestamp,phone,video,status,error,duration_sec,steps
```

**Detailed log file** with phone prefix:
```
[podmindstudio] --- Step 1 ---
[podmindstudio] Action: tap Create button
```

## Testing Priority

1. Test across different Android versions/devices (phones are randomly configured)
2. Round-robin distribution across phones
3. Sequential first, then concurrent once stable
4. Log all failures to identify patterns

## Project Structure

```
geelark-automation/
├── post_reel_smart.py      # Main posting script
├── batch_post.py           # Sequential batch posting
├── batch_post_concurrent.py # Parallel batch posting
├── geelark_client.py       # Geelark API wrapper
├── post_gui.py             # GUI monitor
├── chunk_01a/              # Videos and CSV
│   ├── chunk_01a.csv       # Captions and video paths
│   ├── 2bears.1cave/       # Videos from this source
│   ├── hubermanlab/        # Videos from this source
│   └── ...
├── .taskmaster/            # Project requirements/tasks
│   ├── docs/prd-posting.txt
│   └── tasks/tasks.json
└── .env                    # API keys (not in git)
```

## Next Steps When Resuming

1. Update `batch_post.py` to handle new CSV format
2. Add phone prefix logging
3. Run sequential batch test with 2-3 phones
4. Once stable, test concurrent mode
5. Upgrade GUI for batch monitoring

## Quick Test Command

To verify posting still works:
```bash
python post_reel_smart.py podmindstudio "C:\Users\asus\Desktop\projects\geelark-automation\chunk_01a\2bears.1cave\DJj5lHON58y-2.mp4" "Test post"
```

This is a small 1.4MB video that uploads quickly.
</file>

<file path="dashboard.py">
"""
Real-time Dashboard for Geelark Instagram Automation
Run: python dashboard.py  |  Open: http://localhost:5000
"""
import os, json
from datetime import datetime
from flask import Flask, render_template_string, jsonify, request

app = Flask(__name__)
STATE_FILE = "scheduler_state.json"
LOG_FILE = "scheduler_live.log"

HTML = """
<!DOCTYPE html><html><head><meta charset="UTF-8"><title>Dashboard</title>
<style>
*{margin:0;padding:0;box-sizing:border-box}
body{font-family:sans-serif;background:#1a1a2e;color:#fff;min-height:100vh;padding:20px}
.container{max-width:1400px;margin:0 auto}
header{text-align:center;margin-bottom:20px;padding:15px;background:rgba(255,255,255,0.05);border-radius:10px}
h1{font-size:2em;color:#00d4ff}
.stats{display:flex;gap:15px;justify-content:center;margin-bottom:20px}
.stat{background:rgba(255,255,255,0.08);padding:20px 30px;border-radius:10px;text-align:center}
.stat h3{font-size:0.8em;color:#888;margin-bottom:5px}
.stat-val{font-size:2em;font-weight:bold}
.success{color:#00ff88}.error{color:#ff4757}.pending{color:#ffa502}.active{color:#00d4ff}
.main-grid{display:grid;grid-template-columns:350px 1fr;gap:20px}
.side-panels{display:flex;flex-direction:column;gap:20px}
.panel{background:rgba(255,255,255,0.05);border-radius:10px;padding:15px}
.panel h2{font-size:1em;color:#00d4ff;margin-bottom:10px;border-bottom:1px solid #333;padding-bottom:5px}
.acct{padding:10px;margin:5px 0;background:rgba(255,255,255,0.03);border-radius:5px;display:flex;align-items:center;border-left:3px solid #333}
.acct.success{border-left-color:#00ff88}.acct.in_progress{border-left-color:#00d4ff;background:rgba(0,212,255,0.1)}
.acct.pending{border-left-color:#666}.acct.failed{border-left-color:#ff4757}
.acct-name{flex:1;font-weight:bold}
.acct-status{font-size:0.8em;padding:3px 10px;border-radius:10px;background:rgba(255,255,255,0.1)}
.current{background:rgba(0,212,255,0.1);padding:10px;border-radius:5px;margin-bottom:10px}
.act{padding:8px;margin:3px 0;font-size:0.9em;background:rgba(255,255,255,0.02);border-radius:5px}
.time{color:#666;font-size:0.8em}
.icon{margin-right:8px}
#refresh{position:fixed;top:10px;right:10px;padding:5px 10px;background:rgba(0,212,255,0.2);border-radius:15px;font-size:0.8em;color:#00d4ff}
.log-panel{flex:1;display:flex;flex-direction:column;min-height:500px}
.log-panel h2{display:flex;justify-content:space-between;align-items:center}
.log-controls{display:flex;gap:10px}
.log-controls button{background:rgba(255,255,255,0.1);border:none;color:#888;padding:3px 8px;border-radius:5px;cursor:pointer;font-size:0.8em}
.log-controls button:hover{background:rgba(255,255,255,0.2);color:#fff}
.log-controls button.active{background:rgba(0,212,255,0.3);color:#00d4ff}
#log-container{flex:1;background:#0d0d1a;border-radius:5px;padding:10px;overflow-y:auto;font-family:'Consolas','Monaco',monospace;font-size:12px;line-height:1.5;max-height:600px}
.log-line{padding:2px 0;border-bottom:1px solid rgba(255,255,255,0.03)}
.log-ts{color:#666;margin-right:10px}
.log-msg{color:#ccc}
.log-line.highlight{background:rgba(0,212,255,0.1)}
.log-line.error{color:#ff4757}
.log-line.success{color:#00ff88}
</style></head>
<body><div class="container">
<header><h1>Instagram Automation Dashboard</h1><p id="last">Loading...</p></header>
<div class="stats">
<div class="stat"><h3>SUCCESS</h3><div class="stat-val success" id="s-ok">-</div></div>
<div class="stat"><h3>ACTIVE</h3><div class="stat-val active" id="s-act">-</div></div>
<div class="stat"><h3>PENDING</h3><div class="stat-val pending" id="s-pend">-</div></div>
<div class="stat"><h3>FAILED</h3><div class="stat-val error" id="s-fail">-</div></div>
</div>
<div class="main-grid">
<div class="side-panels">
<div class="panel"><h2>Account Status</h2><div id="current"></div><div id="accts"></div></div>
<div class="panel"><h2>Recent Activity</h2><div id="activity"></div></div>
</div>
<div class="panel log-panel">
<h2>Live Logs <div class="log-controls"><button id="btn-scroll" class="active" onclick="toggleScroll()">Auto-scroll</button><button onclick="clearLogs()">Clear</button></div></h2>
<div id="log-container"></div>
</div>
</div></div>
<div id="refresh">Auto-refresh: 2s</div>
<script>
var lastLogLine=0;
var autoScroll=true;

function toggleScroll(){
  autoScroll=!autoScroll;
  document.getElementById('btn-scroll').className=autoScroll?'active':'';
}

function clearLogs(){
  document.getElementById('log-container').innerHTML='';
  lastLogLine=0;
}

function escapeHtml(t){
  return t.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;');
}

function updateStatus(){
  fetch('/api/status').then(r=>r.json()).then(d=>{
    document.getElementById('s-ok').textContent=d.stats.success;
    document.getElementById('s-act').textContent=d.stats.in_progress;
    document.getElementById('s-pend').textContent=d.stats.pending;
    document.getElementById('s-fail').textContent=d.stats.failed;
    var cj=document.getElementById('current');
    if(d.current_job){cj.innerHTML='<div class="current"><b>Now Posting:</b> '+d.current_job.account+' - '+d.current_job.id+'</div>';}
    else{cj.innerHTML='<div class="current">No active job</div>';}
    var al=document.getElementById('accts');
    al.innerHTML=d.accounts.map(a=>'<div class="acct '+a.status+'"><span class="icon">'+(a.status=='success'?'OK':a.status=='in_progress'?'>>':'--')+'</span><span class="acct-name">'+a.name+'</span><span class="acct-status">'+a.status+'</span></div>').join('');
    var af=document.getElementById('activity');
    af.innerHTML=d.recent_activity.map(a=>'<div class="act"><span class="time">'+a.time+'</span> <b>'+a.account+'</b>: '+a.status+(a.video?' ('+a.video+')':'')+'</div>').join('');
    document.getElementById('last').textContent='Updated: '+new Date().toLocaleTimeString();
  });
}

function updateLogs(){
  fetch('/api/logs?since='+lastLogLine).then(r=>r.json()).then(d=>{
    if(d.lines && d.lines.length>0){
      var container=document.getElementById('log-container');
      d.lines.forEach(function(line){
        var div=document.createElement('div');
        div.className='log-line';
        if(line.indexOf('[OK]')>-1||line.indexOf('SUCCESS')>-1) div.className+=' success';
        else if(line.indexOf('ERROR')>-1||line.indexOf('FAIL')>-1||line.indexOf('error')>-1) div.className+=' error';
        else if(line.indexOf('Step')>-1||line.indexOf('Posting')>-1) div.className+=' highlight';
        // Parse timestamp if present
        var match=line.match(/^\\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\]\\s*(.*)$/);
        if(match){
          div.innerHTML='<span class="log-ts">'+match[1].split(' ')[1]+'</span><span class="log-msg">'+escapeHtml(match[2])+'</span>';
        }else{
          div.innerHTML='<span class="log-msg">'+escapeHtml(line)+'</span>';
        }
        container.appendChild(div);
      });
      lastLogLine=d.last_line;
      if(autoScroll) container.scrollTop=container.scrollHeight;
    }
  });
}

updateStatus();
updateLogs();
setInterval(updateStatus,3000);
setInterval(updateLogs,1500);
</script></body></html>
"""

def load_state():
    if not os.path.exists(STATE_FILE): return {"jobs":[],"accounts":{}}
    try:
        with open(STATE_FILE,'r',encoding='utf-8') as f: return json.load(f)
    except: return {"jobs":[],"accounts":{}}

def get_stats(jobs):
    s={"success":0,"in_progress":0,"pending":0,"failed":0}
    for j in jobs:
        st=j.get('status','pending')
        if st in s: s[st]+=1
    return s

def get_accounts(jobs, accts):
    # accts is a list of dicts with 'name' field
    acc={}
    for a in accts:
        name = a.get('name','') if isinstance(a,dict) else a
        if name: acc[name]={"name":name,"status":"pending"}
    for j in jobs:
        a=j.get('account','')
        if not a: continue
        if a not in acc: acc[a]={"name":a,"status":"pending"}
        st=j.get('status','pending')
        if st=='in_progress': acc[a]["status"]="in_progress"
        elif st=='success' and acc[a]["status"]!="in_progress": acc[a]["status"]="success"
        elif st=='failed' and acc[a]["status"] not in["in_progress","success"]: acc[a]["status"]="failed"
    return list(acc.values())

def get_activity(jobs,limit=20):
    sj=sorted([j for j in jobs if j.get('last_attempt')or j.get('completed_at')],key=lambda x:x.get('completed_at')or x.get('last_attempt')or'',reverse=True)[:limit]
    act=[]
    for j in sj:
        t=j.get('completed_at')or j.get('last_attempt')or''
        if t:
            try: t=datetime.fromisoformat(t).strftime("%H:%M:%S")
            except: pass
        act.append({"time":t,"account":j.get('account','?'),"status":j.get('status','?'),"video":j.get('id','')})
    return act

def get_current(jobs):
    for j in jobs:
        if j.get('status')=='in_progress': return j
    return None

def get_log_lines(since=0, limit=500):
    """Read log lines from file starting at line number 'since'"""
    if not os.path.exists(LOG_FILE):
        return [], 0
    try:
        with open(LOG_FILE, 'r', encoding='utf-8', errors='replace') as f:
            lines = f.readlines()
        # Return lines after 'since' index
        new_lines = [l.rstrip() for l in lines[since:since+limit] if l.strip()]
        return new_lines, len(lines)
    except:
        return [], 0

@app.route('/')
def index(): return render_template_string(HTML)

@app.route('/api/status')
def api_status():
    st=load_state()
    jobs=st.get('jobs',[])
    accts=st.get('accounts',{})
    return jsonify({"stats":get_stats(jobs),"accounts":get_accounts(jobs,accts),"recent_activity":get_activity(jobs),"current_job":get_current(jobs)})

@app.route('/api/logs')
def api_logs():
    since = request.args.get('since', 0, type=int)
    lines, total = get_log_lines(since)
    return jsonify({"lines": lines, "last_line": total, "since": since})

if __name__=='__main__':
    print("\n"+"="*50)
    print("  Instagram Automation Dashboard")
    print("="*50)
    print("\n  Open: http://localhost:5000")
    print("  Ctrl+C to stop\n")
    app.run(host='0.0.0.0',port=5000,debug=False)
</file>

<file path="debug_page_source.py">
"""Debug: Compare Appium page_source vs uiautomator dump XML format"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')

from config import Config, setup_environment
setup_environment()

from appium import webdriver
from appium.options.android import UiAutomator2Options
import subprocess

ADB_PATH = Config.ADB_PATH

# Use a device that's already connected
result = subprocess.run([ADB_PATH, "devices"], capture_output=True, encoding='utf-8')
print("Connected devices:")
print(result.stdout)

# Pick first online device
lines = result.stdout.strip().split('\n')[1:]
device = None
for line in lines:
    if '\tdevice' in line:
        device = line.split('\t')[0]
        break

if not device:
    print("No device found!")
    sys.exit(1)

print(f"\nUsing device: {device}")

# Check Android version
sdk = subprocess.run([ADB_PATH, "-s", device, "shell", "getprop ro.build.version.sdk"],
                     capture_output=True, encoding='utf-8').stdout.strip()
print(f"Android SDK: {sdk}")

# Connect Appium
print("\nConnecting Appium...")
options = UiAutomator2Options()
options.platform_name = "Android"
options.automation_name = "UiAutomator2"
options.device_name = device
options.udid = device
options.no_reset = True
options.new_command_timeout = 300

driver = webdriver.Remote(command_executor="http://127.0.0.1:4723", options=options)
print("Appium connected!")

# Get page_source
print("\n" + "="*60)
print("APPIUM PAGE_SOURCE (first 2000 chars):")
print("="*60)
ps = driver.page_source
print(ps[:2000] if ps else "EMPTY!")
print(f"\nTotal length: {len(ps) if ps else 0}")

# Check if it has <?xml and node elements
print("\n" + "="*60)
print("FORMAT CHECK:")
print("="*60)
print(f"Has <?xml: {'<?xml' in ps}")
print(f"Has <node: {'<node' in ps}")
print(f"Has <hierarchy: {'<hierarchy' in ps}")
print(f"Has bounds=: {'bounds=' in ps}")

# Save full output for inspection
with open("page_source_debug.xml", "w", encoding="utf-8") as f:
    f.write(ps)
print("\nFull page_source saved to page_source_debug.xml")

driver.quit()
print("\nDone!")
</file>

<file path="diagnose_adbkeyboard.py">
"""
Diagnose ADBKeyboard installation state on Geelark phones.
Checks for ghost packages, system apps, and IME settings.
"""
import sys
import time
import subprocess
from geelark_client import GeelarkClient
from config import Config

ADB_PATH = Config.ADB_PATH

PHONES = ["podmindstudio", "miccliparchive", "reelwisdompod_", "talktrackhub"]


def adb(device, cmd, timeout=30):
    """Run ADB shell command"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def diagnose_phone(phone_name):
    """Diagnose ADBKeyboard state on a phone"""
    client = GeelarkClient()

    print(f"\n{'='*60}")
    print(f"DIAGNOSING: {phone_name}")
    print('='*60)

    # Find phone
    phone = None
    for page in range(1, 10):
        result = client.list_phones(page=page, page_size=100)
        for p in result["items"]:
            if p["serialName"] == phone_name:
                phone = p
                break
        if phone:
            break

    if not phone:
        print(f"  ERROR: Phone not found")
        return {"phone": phone_name, "error": "not_found"}

    phone_id = phone["id"]
    print(f"  Found: {phone['serialName']} (Status: {phone['status']})")

    # Start if needed
    if phone["status"] != 0:
        print("  Starting phone...")
        client.start_phone(phone_id)
        for i in range(60):
            time.sleep(2)
            status = client.get_phone_status([phone_id])
            items = status.get("successDetails", [])
            if items and items[0].get("status") == 0:
                break
        time.sleep(3)

    # Enable ADB
    print("  Enabling ADB...")
    client.enable_adb(phone_id)
    time.sleep(3)

    # Connect
    adb_info = client.get_adb_info(phone_id)
    device = f"{adb_info['ip']}:{adb_info['port']}"
    password = adb_info['pwd']

    subprocess.run([ADB_PATH, "connect", device], capture_output=True)
    adb(device, f"glogin {password}")

    results = {"phone": phone_name, "device": device}

    # 1. Check pm path
    print("\n  [1] pm path com.android.adbkeyboard:")
    pm_path = adb(device, "pm path com.android.adbkeyboard")
    print(f"      {pm_path or '(empty - not installed)'}")
    results["pm_path"] = pm_path

    # 2. Check installed packages
    print("\n  [2] pm list packages | grep adbkeyboard:")
    installed = adb(device, "pm list packages | grep -i adbkeyboard")
    print(f"      {installed or '(not in installed list)'}")
    results["installed"] = installed

    # 3. Check ghost packages (uninstalled but retained)
    print("\n  [3] pm list packages -u | grep adbkeyboard (includes ghosts):")
    ghost_check = adb(device, "pm list packages -u | grep -i adbkeyboard")
    print(f"      {ghost_check or '(not in ghost list either)'}")
    results["ghost"] = ghost_check

    # 4. Check system vs user app
    print("\n  [4] pm list packages -s | grep adbkeyboard (system apps):")
    system_pkg = adb(device, "pm list packages -s | grep -i adbkeyboard")
    print(f"      {system_pkg or '(not a system app)'}")
    results["system_pkg"] = system_pkg

    # 5. Check filesystem for APK
    print("\n  [5] Checking filesystem for ADBKeyboard.apk:")
    locations = [
        "/system/app/AdbKeyboard/",
        "/system/app/ADBKeyboard/",
        "/system/priv-app/AdbKeyboard/",
        "/product/app/AdbKeyboard/",
        "/data/app/",
    ]
    for loc in locations:
        files = adb(device, f"ls {loc} 2>/dev/null | grep -i adb")
        if files:
            print(f"      FOUND at {loc}: {files}")
            results["apk_location"] = loc
    if "apk_location" not in results:
        print("      (not found in any standard location)")
        results["apk_location"] = None

    # 6. Check current IME
    print("\n  [6] Current IME setting:")
    current_ime = adb(device, "settings get secure default_input_method")
    print(f"      {current_ime}")
    results["current_ime"] = current_ime

    # 7. Check all IMEs
    print("\n  [7] Available IMEs (ime list -a):")
    ime_list = adb(device, "ime list -a 2>/dev/null | head -20")
    if "adbkeyboard" in ime_list.lower():
        print(f"      ADBKeyboard found in IME list")
        results["ime_registered"] = True
    else:
        print(f"      ADBKeyboard NOT in IME list")
        results["ime_registered"] = False

    # 8. Check package dump
    print("\n  [8] dumpsys package com.android.adbkeyboard (summary):")
    pkg_dump = adb(device, "dumpsys package com.android.adbkeyboard 2>/dev/null | head -30")
    if "Unable to find package" in pkg_dump or not pkg_dump:
        print("      Package not found in package manager")
        results["pkg_dump"] = "not_found"
    else:
        print("      Package exists in package manager database")
        # Check if enabled/disabled
        if "enabled=" in pkg_dump.lower():
            print(f"      Enabled state found in dump")
        results["pkg_dump"] = "exists"

    # Summary
    print("\n  " + "-"*50)
    print("  DIAGNOSIS SUMMARY:")
    if results.get("pm_path"):
        print("    STATUS: INSTALLED and working")
        results["status"] = "installed"
    elif results.get("ghost") and not results.get("installed"):
        print("    STATUS: GHOST PACKAGE (in -u list but not installed)")
        results["status"] = "ghost"
    elif results.get("apk_location"):
        print("    STATUS: APK exists on filesystem but not registered")
        results["status"] = "unregistered"
    else:
        print("    STATUS: NOT INSTALLED (clean slate)")
        results["status"] = "not_installed"

    return results


def main():
    phones_to_check = sys.argv[1:] if len(sys.argv) > 1 else PHONES

    all_results = []
    for phone in phones_to_check:
        try:
            result = diagnose_phone(phone)
            all_results.append(result)
        except Exception as e:
            print(f"\n  ERROR: {e}")
            all_results.append({"phone": phone, "error": str(e)})

    # Final summary
    print("\n" + "="*60)
    print("FINAL SUMMARY")
    print("="*60)
    print(f"{'Phone':<20} {'Status':<15} {'IME Set':<10} {'APK Location'}")
    print("-"*60)
    for r in all_results:
        if "error" in r:
            print(f"{r['phone']:<20} ERROR: {r['error']}")
        else:
            ime_ok = "Yes" if "adbkeyboard" in r.get("current_ime", "").lower() else "No"
            apk = r.get("apk_location", "None")[:20] if r.get("apk_location") else "None"
            print(f"{r['phone']:<20} {r.get('status', 'unknown'):<15} {ime_ok:<10} {apk}")


if __name__ == "__main__":
    main()
</file>

<file path="fix_adbkeyboard.py">
"""
Fix ADBKeyboard installation on Geelark cloud phones.
Handles ghost packages, system app restoration, and fresh installs.

Usage:
    python fix_adbkeyboard.py <phone1> <phone2> ...

Example:
    python fix_adbkeyboard.py miccliparchive reelwisdompod_ talktrackhub
"""
import sys
import os
import time
import subprocess
import base64
from geelark_client import GeelarkClient
from config import Config

ADB_PATH = Config.ADB_PATH
APK_PATH = os.path.join(os.path.dirname(__file__), "ADBKeyboard.apk")
SYSTEM_APK_PATH = os.path.join(os.path.dirname(__file__), "ADBKeyboard_system.apk")


def adb(device, cmd, timeout=30):
    """Run ADB shell command"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def adb_pull(device, remote_path, local_path):
    """Pull file from device"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "pull", remote_path, local_path],
        capture_output=True, timeout=60,
        encoding='utf-8', errors='replace'
    )
    return "pulled" in result.stdout.lower() or result.returncode == 0


def adb_push(device, local_path, remote_path):
    """Push file to device"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "push", local_path, remote_path],
        capture_output=True, timeout=60,
        encoding='utf-8', errors='replace'
    )
    return "pushed" in result.stdout.lower() or result.returncode == 0


def adb_install(device, apk_path):
    """Install APK via ADB"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "install", "-r", apk_path],
        capture_output=True, timeout=120,
        encoding='utf-8', errors='replace'
    )
    stdout = result.stdout.strip() if result.stdout else ""
    stderr = result.stderr.strip() if result.stderr else ""
    return stdout, stderr


def diagnose_state(device):
    """Diagnose ADBKeyboard state on device"""
    pm_path = adb(device, "pm path com.android.adbkeyboard")
    installed = adb(device, "pm list packages | grep -i adbkeyboard")
    ghost = adb(device, "pm list packages -u | grep -i adbkeyboard")
    system_apk = adb(device, "ls /system/app/AdbKeyboard/ 2>/dev/null")

    if pm_path:
        return "installed", pm_path
    elif ghost and not installed:
        if system_apk:
            return "ghost_with_system_apk", system_apk
        else:
            return "ghost_no_apk", None
    else:
        if system_apk:
            return "not_installed_but_apk_exists", system_apk
        else:
            return "clean_slate", None


def fix_phone(phone_name, source_device=None):
    """Fix ADBKeyboard on a single phone"""
    client = GeelarkClient()

    print(f"\n{'='*60}")
    print(f"FIXING: {phone_name}")
    print('='*60)

    # Find phone
    phone = None
    for page in range(1, 10):
        result = client.list_phones(page=page, page_size=100)
        for p in result["items"]:
            if p["serialName"] == phone_name:
                phone = p
                break
        if phone:
            break

    if not phone:
        print(f"  ERROR: Phone not found")
        return False

    phone_id = phone["id"]
    print(f"  Found: {phone['serialName']} (Status: {phone['status']})")

    # Start if needed
    if phone["status"] != 0:
        print("  Starting phone...")
        client.start_phone(phone_id)
        for i in range(60):
            time.sleep(2)
            status = client.get_phone_status([phone_id])
            items = status.get("successDetails", [])
            if items and items[0].get("status") == 0:
                break
        time.sleep(3)

    # Enable ADB
    print("  Enabling ADB...")
    client.enable_adb(phone_id)
    time.sleep(3)

    # Connect
    adb_info = client.get_adb_info(phone_id)
    device = f"{adb_info['ip']}:{adb_info['port']}"
    password = adb_info['pwd']

    subprocess.run([ADB_PATH, "connect", device], capture_output=True)
    adb(device, f"glogin {password}")

    # Diagnose current state
    print("\n  [1] Diagnosing current state...")
    state, extra = diagnose_state(device)
    print(f"      State: {state}")
    if extra:
        print(f"      Extra: {extra}")

    # Apply fix based on state
    if state == "installed":
        print("\n  [2] Already installed! Just verifying IME settings...")

    elif state == "ghost_with_system_apk":
        print("\n  [2] Ghost package with system APK - restoring...")

        # Try to restore system app
        print("      Running: cmd package install-existing com.android.adbkeyboard")
        result = adb(device, "cmd package install-existing com.android.adbkeyboard")
        print(f"      Result: {result}")

        if "installed" in result.lower() or not result:
            print("      Checking if restored...")
            time.sleep(1)
            pm_path = adb(device, "pm path com.android.adbkeyboard")
            if pm_path:
                print(f"      SUCCESS: Package restored! Path: {pm_path}")
            else:
                print("      WARNING: install-existing may have failed")
                # Try enabling instead
                print("      Trying: pm enable com.android.adbkeyboard")
                adb(device, "pm enable com.android.adbkeyboard")
                time.sleep(1)
                pm_path = adb(device, "pm path com.android.adbkeyboard")
                if pm_path:
                    print(f"      SUCCESS after pm enable: {pm_path}")

    elif state == "ghost_no_apk":
        print("\n  [2] Ghost package without system APK - cleaning and installing...")

        # Try to clear the ghost
        print("      Clearing ghost: pm uninstall --user 0 com.android.adbkeyboard")
        adb(device, "pm uninstall --user 0 com.android.adbkeyboard")
        time.sleep(1)

        # Now try fresh install
        if os.path.exists(APK_PATH):
            print(f"      Installing from: {APK_PATH}")
            stdout, stderr = adb_install(device, APK_PATH)
            print(f"      Result: {stdout} {stderr}")
        else:
            print(f"      ERROR: APK not found at {APK_PATH}")
            return False

    elif state == "clean_slate":
        print("\n  [2] Clean slate - fresh install needed...")

        # Try installing APK
        if os.path.exists(APK_PATH):
            print(f"      Installing from: {APK_PATH}")
            stdout, stderr = adb_install(device, APK_PATH)
            print(f"      Result: {stdout} {stderr}")

            if "Success" not in stdout:
                print("      Standard install failed.")
                # Try pushing to /sdcard and installing from there
                print("      Trying push + pm install method...")
                adb_push(device, APK_PATH, "/sdcard/ADBKeyboard.apk")
                result = adb(device, "pm install -r /sdcard/ADBKeyboard.apk")
                print(f"      pm install result: {result}")
        else:
            print(f"      ERROR: APK not found at {APK_PATH}")
            return False

    elif state == "not_installed_but_apk_exists":
        print("\n  [2] APK exists but not registered - trying to register...")
        print("      Running: cmd package install-existing com.android.adbkeyboard")
        result = adb(device, "cmd package install-existing com.android.adbkeyboard")
        print(f"      Result: {result}")

        if "installed" not in result.lower():
            print("      Trying: pm enable com.android.adbkeyboard")
            adb(device, "pm enable com.android.adbkeyboard")

    # Step 3: Verify installation
    print("\n  [3] Verifying installation...")
    time.sleep(1)
    pm_path = adb(device, "pm path com.android.adbkeyboard")
    if not pm_path:
        print("      ERROR: Package still not installed!")
        print("      This device may need Geelark reprovisioning.")
        return False
    print(f"      Package path: {pm_path}")

    # Step 4: Enable IME
    print("\n  [4] Enabling ADBKeyboard IME...")
    adb(device, "ime enable com.android.adbkeyboard/.AdbIME")
    time.sleep(0.5)
    adb(device, "ime set com.android.adbkeyboard/.AdbIME")
    time.sleep(0.5)

    # Also set via settings for persistence
    adb(device, "settings put secure enabled_input_methods com.google.android.inputmethod.latin/com.android.inputmethod.latin.LatinIME:com.android.adbkeyboard/.AdbIME")
    adb(device, "settings put secure default_input_method com.android.adbkeyboard/.AdbIME")

    # Step 5: Verify IME
    print("\n  [5] Verifying IME setting...")
    current_ime = adb(device, "settings get secure default_input_method")
    print(f"      Current IME: {current_ime}")

    if "adbkeyboard" not in current_ime.lower():
        print("      WARNING: IME setting may not have persisted")
        return False

    # Step 6: Test typing
    print("\n  [6] Testing ADBKeyboard broadcast...")
    test_text = "Test 123 🎉"
    text_b64 = base64.b64encode(test_text.encode('utf-8')).decode('ascii')
    result = adb(device, f"am broadcast -a ADB_INPUT_B64 --es msg {text_b64}")
    if "Broadcast completed" in result:
        print(f"      SUCCESS: Broadcast sent for '{test_text}'")
    else:
        print(f"      Broadcast result: {result}")

    print("\n  " + "="*50)
    print("  FIX COMPLETE!")
    print("  " + "="*50)
    return True


def main():
    if len(sys.argv) < 2:
        print("Usage: python fix_adbkeyboard.py <phone1> <phone2> ...")
        print("Example: python fix_adbkeyboard.py miccliparchive reelwisdompod_ talktrackhub")
        sys.exit(1)

    phones = sys.argv[1:]
    results = {}

    for phone in phones:
        try:
            results[phone] = fix_phone(phone)
        except Exception as e:
            print(f"\n  ERROR: {e}")
            import traceback
            traceback.print_exc()
            results[phone] = False

    # Summary
    print("\n" + "="*60)
    print("FIX SUMMARY")
    print("="*60)
    for phone, success in results.items():
        status = "SUCCESS" if success else "FAILED"
        print(f"  {phone}: {status}")

    # Return exit code
    all_success = all(results.values())
    sys.exit(0 if all_success else 1)


if __name__ == "__main__":
    main()
</file>

<file path="geelark_api_docs.txt">
Geelark api docs

2025.10.29
Added a new interface for posting video tasks in Threads
Added a new interface for posting image and text tasks in Threads
2025.10.22
Added new parameters to the cloud phone startup API: hideSideBar, displayTimer
Added a stop callback to the cloud phone callback events
Added a new API for getting the app list
Added a new API for adding apps to Team’s applications
2025.10.21
Added TikTok AI random comment-Asia task interface
Cloud Phone with Android 9 enables ADB functionality
2025.10.16
Cloud phone creation now supports transferring phone numbers
Reddit account management now supports transferring search keywords
New browser interface instructions
Added a new browser interface for creating browsers
Added a new browser interface for modifying browsers
Added a new browser interface for deleting browsers
Added a new browser interface for querying browsers
Added a new browser interface for starting browsers
Added a new browser interface for closing browsers
Added a new browser interface for transferring browsers
2025.10.15
The cloud phone list interface returns the monthly subscription expiration time.
2025.08.26
Cloud phone list now supports filtering by charge mode, and the list includes a charge mode field.
Create TikTok to add videos/photo albums/account maintenance tasks, support transferring notes.
2025.08.20
New cloud phones now support setting the network connection method
Added a new interface for setting the cloud phone network method
Added a new interface for posting videos to Pinterest
Added a new interface for posting images and text to Pinterest
Set Phone Logo / Brand interface
2025.08.19
Upload keybox interface
2025.07.24
TikTok publishes videos and photo albums, and you can get sharing links
Task query interface returns sharing link
Added Instagram automatic login interface
2025.07.21
Uninstalling apps now supports specifying the application package name.
2025.07.14
Add Batch Task Query API
2025.07.10
TikTok video posting task supports transferring cover
Added batch import of contacts to cloud phone interface
Added keybox upload to cloud phone interface
Added TikTok random likes-Asian interface
Added TikTok private message-Asian interface
Added Instagram Reels album interface
2025.07.04
YouTube releases Short interface, the same URL does not have to be transmitted
2025.07.01
The proxy query interface returns the proxy serial number
Added new cloud phone V2 interface
2025.06.26
Added Reddit AI account warmup interface
Added Publish video on Reddit interface
Added Publish pictures and texts on Reddit interface
Added Download apps on Google interface
Added Open the app on Google for browsing interface
Added Send private message on TikTok interface
Added Send private messages on Facebook interface
Added Send private messages on Instagram interface
Added cloud phone transfer interface
Added library-related APIs
2025.06.12
The newly added agent type of the newly built cloud mobile phone does not allow error codes
When modifying the proxy, the newly added proxy type does not allow error codes
When modifying the cloud phone information and adding a new proxy type, error codes are not allowed
Add a task detail interface
Support token verification
2025.05.29
TikTok offers video and photo album Posting tasks and supports tagging AI content
2025.05.15
Creating tasks no longer limits the time interval
Environment group notes can contain up to 500 characters
Create a new cloud phone interface to return cloud phone device information
2025.04.25
The list of cloud phones can be obtained by id query, and the proxy information is returned
2025.04.24
TikTok supports uploading volume when Posting videos and photo albums
A new task process query interface has been added
Add an interface for creating custom tasks
A new Instagram AI account nurturing interface has been added
2025.04.10
Delete the cloud mobile phone interface added the error code in use
The task query interface returns the time consuming field
2025.04.09
TikTok add video/image/maintenance task, If the scheduling time is smaller than the current time, the current time is used.
2025.04.07
TikTok maintenance task parameters modified
2025.04.01
Added Create X(Twitter) to publish content and upload files to the cloud machine task interface in batches
2025.03.25
ADB supports Android 14
2025.03.24
One-click new machine V2 adds a new field: changeBrandModel, which controls whether the cloud phone brand and model are randomized.
2025.03.20
Add automation module, which includes automation tasks for many platforms
2025.03.13
Added cloud mobile phone brand list interface
New cloud mobile phone interface can transmit brand models
2025.03.06
The task in execution can be canceled
When adding a task, the task schedule interval of the same cloud phone cannot be less than 10 minutes
You can specify the retry times and timeout period for publishing videos and galleries
Execute shell, create cloud phone support Android14
2025.02.28
TK Automation - Added task, publishing gallery now includes a gallery title field.
2025.02.10
Cloud phone management: Added cloud phone device information fields (brand, model) to the Get all cloud phones.
2025.02.7
New API: Send SMS to cloud phones.
2025.01.14
TK Automation - Added fields related to publishing video tasks in the task API.
2024.12.25
Launched the API to get cloud phone device IDs.
2024.12.19
Launched the API to set ROOT status.
2024.11.25
Launched screenshot-related APIs.
2024.11.21
Cloud Phone Management - Added device information fields for cloud phones in the cloud phone list.
2024.10.28
Launched the API to download files to cloud phones.
Launched One-click New Device V2 API, which no longer relies on callbacks.
2024.10.09
Launched file upload-related APIs.
TK Automation - Added fields related to publishing video tasks in the task API.
Fixed ADB issue where retrieving ADB information failed.
2024.09.25
Launched One-click New Device-related APIs.
2024.08.28
Launched tag-related APIs.
Launched API to set/get cloud phone GPS.
Launched group-related APIs.
2024.08.13
Launched application management-related APIs.
2024.08.09
Launched ADB-related APIs.
2024.06.04
Launched API interfaces.

Request Instructions
Request Instructions
All API requests must be initiated using POST.
All request bodies should be in JSON format. Please set the request header Content-Type to application/json.
There are two verification methods, including key verification and token verification.
API rate limit: 200 requests per minute, 24,000 requests per hour
Token verification
When making a request, only carry the following request headers
traceId: Use Version 4 UUID
Authorization Set to Bearer: <The token value obtained from the client>
Response Instructions
Key verification
Required Request Headers for Verification
appId: Team AppId
traceId: Unique request ID
ts: Timestamp in milliseconds
nonce: Random number
sign: Signature result
Verification Parameter Generation Method
traceId: Use Version 4 UUID
nonce: Use the first 6 characters of traceId
sign: Concatenate the string TeamAppId + traceId + ts + nonce + TeamApiKey, then generate the SHA256 hexadecimal uppercase digest of the string.
Example of Required Request Headers for Verification
Assuming the team’s ApiKey is YjmFIUuq0oJgSDJ42fxLEb6R1qjjqf, the request headers would be set as follows:
appId: eH6gQR4oHr3FsZpI36La01IW
traceId: db6094ab-3797-4186-84d5-b0b58eebad56
ts: 1716972892166
nonce: db6094
sign: 6280C080AF7C3CCE168F15C913E3444A00A618CB0E16038EED9811D6E3366BDD

When the response code is 200, the response body will be in JSON format.
Response Object Fields
traceId: Unique request ID.
code: Processing result code, 0 indicates success, any other value indicates failure.
msg: Processing result description.
data: Data. Details are as follows:
On successful request: returns response data.
On failed request: returns the reason for failure.
On partially successful request: returns response data and reason for failure.
Processing Result Code Explanation
0 indicates success, any other value indicates failure. If an error code appears, try modifying the request based on the prompt. If the issue persists, please contact customer service and provide the appId, traceId, and the response content. Apart from global error codes, error codes specific to each API are documented in their respective descriptions. Global error codes are as follows:
40000: Unknown error, please contact customer service if this occurs.
40001: Failed to read request body, please contact customer service if this occurs.
40002: The traceId in the request header cannot be empty.
40003: Signature verification failed.
40004: Request parameter validation failed.
40005: Requested resource does not exist.
40006: Partial success in the request, applicable to batch APIs.
40007: Too many requests.The rate limit will be lifted in the next minute.
40008: Invalid pagination parameters.
40009: Batch processing completely failed.
40011: Only for paid user.
41001: Balance not enough.
40012: The api had expire, please use the new api.
47002: Too many concurrent requests. Please try again later.The rate limit will be lifted after two hours.

Request example
Request Example
Token verification
const url = "https://openapi.geelark.com/open/v1/phone/list";

const appToken = "your appToken";

var traceUUid = "yxxyxxxxyxyxxyxxyxxxyxxxyxxyxxyx".replace(
 /[xy]/g,
 function (c) {
 var r = (Math.random() * 16) | 0, 
 v = c == "x" ? r : (r & 0x3) | 0x8; 
 return v.toString(16); 
 }
);

var traceId = traceUUid.toUpperCase();

var data = {
 page: 1,
 pageSize: 10,
 tags: ["tagNew"],
};

fetch(url, {
 method: "POST",
 headers: {
 "Content-Type": "application/json",
 traceId: traceId,
 Authorization: "Bearer " + appToken,
 },
 body: JSON.stringify(data),
})
 .then((res) => res.json())
 .then((res) => {
 console.log(res);
 })
 .catch((err) => {
 console.error(err);
 });

Key verification
const CryptoJS = require("crypto-js");

const url = "https://openapi.geelark.com/open/v1/phone/list"; // Example request URL

const appID = "your appID"; // Your appID
const apiKey = "your apiKey"; // Your apiKey

let timestamp = new Date().getTime().toString(); // Millisecond timestamp

// Generate UUID
var traceUUid = "yxxyxxxxyxyxxyxxyxxxyxxxyxxyxxyx".replace(
 /[xy]/g,
 function (c) {
 var r = (Math.random() * 16) | 0, // Randomly generate a number between 0 and 15
 v = c == "x" ? r : (r & 0x3) | 0x8; // If c is 'y', only take one of 8, 9, a, b
 return v.toString(16); // Convert the number to a hexadecimal string
 }
);

var traceId = traceUUid.toUpperCase();

// nonce is the first 6 characters of traceId
var nonce = traceId.substring(0, 6);

var sign = CryptoJS.SHA256(appID + traceId + timestamp + nonce + apiKey)
 .toString()
 .toUpperCase();

var data = {
 page: 1,
 pageSize: 10,
};

headers = {
 "Content-Type": "application/json",
 appId: appID,
 traceId: traceId,
 ts: timestamp,
 nonce: nonce,
 sign: sign,
};

console.log(headers);

fetch(url, {
 method: "POST",
 headers: {
 "Content-Type": "application/json",
 appId: appID,
 traceId: traceId,
 ts: timestamp,
 nonce: nonce,
 sign: sign,
 },
 body: JSON.stringify(data),
})
 .then((res) => res.json())
 .then((res) => {
 console.log(res);
 })
 .catch((err) => {
 console.error(err);
 });


Create Account Management Task: Directly call the Add Task API.
Create Video or Image Collection Posting Task: First, upload the materials, then call the Add Task API.
Creating Video or Image Collection Posting Task
File Upload

Use the resource access URL obtained in step 1 as the upload URL for the video or image, and then call the Add Task API.

Request Instructions
Overview
Support local API functions
All interface requests are initiated using POST.
All request bodies are in json format. Please set the Content-Type request header to application/json.
API rate limit: 200 times/min, 24,000 times/hour
Preparation before use:
 Check whether the client is open and logged in.
Response Description
When the response code is 200, the response body is json
Response body object fields
traceId Request unique ID.
code Processing result code, 0 represents success, other codes represent failure.
msg Description of the processing result.
data The details are as follows:
When the request is successful, the response data is returned.
If the request fails, the failure reason is returned.
If the request is partially successful, the response data and the failure reason are returned.
Processing result code description
0 indicates success, and other values indicate failure.
If an error code appears, try modifying the request according to the prompts.
If the problem persists, please contact customer service for feedback.
In addition to the global error code, the error code corresponding to each interface is documented in its respective description. The global error codes are as follows:
40000 Unknown error. If this occurs, please contact customer service.
40001 Failed to read the request body. If this occurs, please contact customer service.
40002 The traceId header in the request cannot be empty.
40003 Signature verification failed.
40004 Request parameter verification failed.
40005 The requested resource does not exist.
40006 The request was partially successful. This applies to batch interfaces.
40007 Requests are too frequent. The rate limit will be lifted in the next minute.
40008 Pagination parameter error.
40009 All batch processing failed.
40011 Only for paid users.
41001 Insufficient balance.
40012 The interface has expired. Please use the latest interface.
47002 The number of concurrent requests is too high. Please try again later.
40014 Requests are too frequent. The rate limit will be lifted in two hours.

Request example
Example
const url = "http://localhost:40185/api/v1/browser/start"; // Sample request address



var data = {
 "id": "123456789xxxx"
};

fetch(url, {
 method: "POST",
 headers: {
 "Content-Type": "application/json",
 },
 body: JSON.stringify(data),
})
 .then((res) => res.json())
 .then((res) => {
 console.log(res);
 })
 .catch((err) => {
 console.error(err);
 });
Create new
API Description
The Basic plan supports the creation of only one cloud phone at a time, while the Pro plan supports batch creation.
Request URL
https://openapi.geelark.com/open/v1/phone/add
Request Method
POST
Request Parameters
proxyConfig Static Proxy Parameters
proxyConfig Dynamic Proxy Parameters
Dynamic proxy settings can be configured on the client side first, and then by setting useProxyCfg to true, you can use the already configured information without needing to provide the host, port, and other details again.
androidVersion Corresponding Versions
1 : Android 10
2 : Android 11
3 : Android 12
4 : Android 13
5 : Andorid 10 Live Streaming(Only supports monthly subscription charge mode)
7 : Andorid 14
8 : Android 15
typeId List
1. Static Proxy List
1 : socks5
2 : http
3 : https
2. Dynamic Proxy List
20 IPIDEA
21 IPHTML
22 kookeey
23 Lumatuo
Request Example
{
  "amount": 5,
  "androidVersion": 1,
  "proxyConfig":{
    "typeId": 1,
    "server": "server.com",
    "port": 32080,
    "username": "123465ABCD",
    "password": "123465ABCD"
  },
  "groupName": "group",
  "tagsName": [
    "123",
    "ABC"
  ],
  "remark": ""
}

Response Example
{
    "traceId": "123456ABCDEF",
    "code": 0,
    "msg": "success",
    "data": {
        "totalAmount": 1,
        "successAmount": 1,
        "failAmount": 0,
        "details": [
            {
                "index": 1,
                "code": 0,
                "msg": "success",
                "id": "497652752864775437",
                "profileName": "22 ungrouped",
                "envSerialNo": "22",
                "equipmentInfo": {
                    "countryName": "Thailand",
                    "phoneNumber": "+66877382166",
                    "enableSim": 1,
                    "imei": "863406055475987",
                    "osVersion": "Android 11.0",
                    "wifiBssid": "1C:1D:67:B1:C1:76",
                    "mac": "9C:A5:C0:5F:C5:AD",
                    "bluetoothMac": "D0:15:4A:5B:7E:AE",
                    "timeZone": "Asia/Bangkok"
                 }
            }
        ]
    }
}

Response Data Description
details Creation Response
equipmentInfo Cloud phone equipment info <EquipmentInfo>
Error Codes
Below are specific error codes for this interface. For other error codes, please refer to API Documentation.

Create new V2
API Description
The Basic plan supports the creation of only one cloud phone at a time, while the Pro plan supports batch creation.
Supports model selection. Please first call the cloud phone brand list interface to obtain supported brand model information.
Proxy information, added proxy, dynamic proxy must specify one, added proxy is used first, followed by proxy information.
Request URL
https://openapi.geelark.com/open/v1/phone/addNew
Request Method
POST
Request Parameters
Environment parameter <EnvRowApi>
Request Example
{
 "mobileType": "Android 12",
 "chargeMode": 0,
 "data": [
 {
 "profileName": "myPhone",
 "proxyInformation": "socks5://AD00xx004:3000xxx0002@100.200.200.100:30000",
 "mobileLanguage": "default",
 "profileGroup": "myGroup",
 "profileTags": ["myTag"],
 "profileNote": "remark"
 }
 ]
}

Response Example
{
    "traceId": "123456ABCDEF",
    "code": 0,
    "msg": "success",
    "data": {
        "totalAmount": 1,
        "successAmount": 1,
        "failAmount": 0,
        "details": [
            {
                "index": 1,
                "code": 0,
                "msg": "success",
                "id": "497652752864775437",
                "profileName": "22 ungrouped",
                "envSerialNo": "22",
                "equipmentInfo": {
                    "countryName": "Thailand",
                    "phoneNumber": "+66877382166",
                    "enableSim": 1,
                    "imei": "863406055475987",
                    "osVersion": "Android 11.0",
                    "wifiBssid": "1C:1D:67:B1:C1:76",
                    "mac": "9C:A5:C0:5F:C5:AD",
                    "bluetoothMac": "D0:15:4A:5B:7E:AE",
                    "timeZone": "Asia/Bangkok"
                 }
            }
        ]
    }
}

Response Data Description
details Creation Response
equipmentInfo Cloud phone equipment info <EquipmentInfo>
Error Codes
Below are specific error codes for this interface. For other error codes, please refer to API Documentation.

Get all cloud phones
API Description
Retrieve the list of cloud phones.
Request URL
https://openapi.geelark.com/open/v1/phone/list
Request Method
POST
Request Parameters
Pagination Parameters
Query Parameters (Ignored if empty)
Request Example
{
    "page":1,
    "pageSize":10,
    "serialName": "test",
    "remark":"",
    "groupName":"",
    "tags":[
        "tag1",
        "tag2"
    ]
}

Response Data Description
items Cloud Phone Data <Phone>
group Group Information <Group>
tags Cloud Phone Tags <Tag>
equipmentInfo Cloud phone equipment info <EquipmentInfo>
proxy Proxy info <Proxy>
Response Example
{
    "traceId": "123456ABCDEF",
    "code": 0,
    "msg": "success",
    "data": {
        "total": 1,
        "page": 1,
        "pageSize": 10,
        "items": [
            {
                "id": "123456ABCDEF",
                "serialName": "test",
                "serialNo": "1",
                "group": {
                    "id": "123456ABCDEF",
                    "name": "test group",
                    "remark": "group remark"
                },
                "remark": "env remark",
                "status": 0,
                "tags": [
                    {"name": "hi"},
                    {"name": "test"}
                ],
                "equipmentInfo": {
                    "countryName": "Thailand",
                    "phoneNumber": "+66877382166",
                    "enableSim": 1,
                    "imei": "863406055475987",
                    "osVersion": "Android 11.0",
                    "wifiBssid": "1C:1D:67:B1:C1:76",
                    "mac": "9C:A5:C0:5F:C5:AD",
                    "bluetoothMac": "D0:15:4A:5B:7E:AE",
                    "timeZone": "Asia/Bangkok"
                 },
                "proxy": {
                    "type": "socks5",
                    "server": "129.129.129.129",
                    "port": 30000,
                    "username": "user",
                    "password": "pass"
                }
            }
        ]
    }
}

Error Codes
Error codes can be found in the API Documentation.

Query status
API Description
Retrieve the status of cloud phones.
Request URL
https://openapi.geelark.com/open/v1/phone/status
Request Method
POST
Request Parameters
Query Parameters
Request Example
{
    "ids":[
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF"
    ]
}

Response Data Description
successDetails Success Information <SuccessDetails>
failDetails Failure Information <FailDetails>
Response Example
{
    "code": 0,
    "msg": "成功",
    "traceId": "123456ABCDEF",
    "data": {
        "totalAmount": 4,
        "successAmount": 3,
        "failAmount": 1,
        "successDetails": [
            {
                "id": "123456ABCDEF",
                "serialName": "name1",
                "status": 0
            },
            {
                "id": "123456ABCDEF",
                "serialName": "name2",
                "status": 1
            },
            {
                "id": "123456ABCDEF",
                "serialName": "name3",
                "status": 1
            }
        ],
        "failDetails": [
            {
                "code": 42001,
                "id": "123456ABCDEF",
                "msg": "env not found"
            }
        ]
    }
}

Error Codes
Below are specific error codes for this interface. For other error codes, please refer to API Documentation.


Query status
API Description
Retrieve the status of cloud phones.
Request URL
https://openapi.geelark.com/open/v1/phone/status
Request Method
POST
Request Parameters
Query Parameters
Request Example
{
    "ids":[
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF"
    ]
}

Response Data Description
successDetails Success Information <SuccessDetails>
failDetails Failure Information <FailDetails>
Response Example
{
    "code": 0,
    "msg": "成功",
    "traceId": "123456ABCDEF",
    "data": {
        "totalAmount": 4,
        "successAmount": 3,
        "failAmount": 1,
        "successDetails": [
            {
                "id": "123456ABCDEF",
                "serialName": "name1",
                "status": 0
            },
            {
                "id": "123456ABCDEF",
                "serialName": "name2",
                "status": 1
            },
            {
                "id": "123456ABCDEF",
                "serialName": "name3",
                "status": 1
            }
        ],
        "failDetails": [
            {
                "code": 42001,
                "id": "123456ABCDEF",
                "msg": "env not found"
            }
        ]
    }
}

Error Codes
Below are specific error codes for this interface. For other error codes, please refer to API Documentation.

Start cloud phone
API Description
Batch start cloud phones.
Request URL
https://openapi.geelark.com/open/v1/phone/start
Request Method
POST
Request Parameters
Request Example
{
    "ids":[
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF"
    ]
}

Response Example
{
 "code": 0,
 "msg": "success",
 "traceId": "12345678ABCDEF",
 "data": {
 "totalAmount": 3,
 "successAmount": 1,
 "failAmount": 2,
 "failDetails": [
 {
 "code": 43004,
 "id": "12345678ABCDEFG",
 "msg": "env is expired"
 },
 {
 "code": 42001,
 "id": "12345678ABCDEFG",
 "msg": "env not found"
 }
 ],
 "successDetails": [
 {
 "id": "12345678ABCDEFG",
 "url": "https://speedup.geelark.com/phone-api"
 }
 ]
 }
}

Response Data Description
SuccessDetails Successed Information
FailDetails Failure Information
Error Codes
Below are specific error codes for this interface. For other error codes, please refer to API Documentation.

Stop cloud phone
API Description
Batch shut down cloud phones.
Cloud phones can be shut down when they are in the following state:
Idle: Can be shut down
Remotely Connected: Cannot be shut down
Executing Task: Cannot be shut down
Request URL
https://openapi.geelark.com/open/v1/phone/stop
Request Method
POST
Request Parameters
Request Example
{
    "ids":[
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF",
        "123456ABCDEF"
    ]
}

Response Example
{
    "code": 0,
    "msg": "成功",
    "traceId": "123456ABCDEF",
    "data": {
        "totalAmount": 4,
        "successAmount": 3,
        "failAmount": 1,
        "successDetails": [
            {
                "id": "123456ABCDEF",
                "serialName": "name1",
                "status": 0
            },
            {
                "id": "123456ABCDEF",
                "serialName": "name2",
                "status": 1
            },
            {
                "id": "123456ABCDEF",
                "serialName": "name3",
                "status": 1
            }
        ],
        "failDetails": [
            {
                "code": 42001,
                "id": "123456ABCDEF",
                "msg": "env not found"
            }
        ]
    }
}

Response Data Description
failDetails Failure Information <FailDetails>
Error Codes
Below are specific error codes for this interface. For other error codes, please refer to API Documentation.

Delete cloud phone
API Description
Batch Delete Cloud Phones
Request URL
https://openapi.geelark.com/open/v1/phone/delete
Request Method
POST
Request Parameters
Request Example
{
    "ids":[
        "123456ABCDEF",
        "123456ABCDEF"
    ]
}

Response Data Description
Failure Details <FailDetails>
Response Example
{
    "code": 0,
    "msg": "success",
    "traceId": "12345ABCDEF",
    "data": {
        "totalAmount": 4,
        "successAmount": 2,
        "failAmount": 2,
        "failDetails": [
            {
                "code": 42001,
                "id": "12345ABCDEF",
                "msg": "env not found"
            },
            {
                "code": 43009,
                "id": "12345ABCDEF",
                "msg": "env is started"
            }
        ]
    }
}

Error Codes
Below are specific error codes for the API. For other error codes, please refer to API Call Description.



Get GPS
Interface Description
Query the GPS information of cloud phones, including latitude and longitude.
Request URL
https://openapi.geelark.com/open/v1/phone/gps/get
Request Method
POST
Request Parameters
Request Example
{
 "ids": [
 "528086321789535232"
 ]
}

Response Example
{
 "traceId": "81CA3BD0B7BBB924A1C6B836B298ADA7",
 "code": 0,
 "msg": "success",
 "data": {
 "totalAmount": 1,
 "successAmount": 1,
 "failAmount": 0,
 "list": [
 {
 "id": "528086321789535232",
 "latitude": 1.3024300336837769,
 "longitude": 103.87545776367188
 }
 ]
 }
}

Response Data Description
list GPS Information <GPS>
Error Codes
Below are the specific error codes for this interface. For other error codes, please refer to the API Call Instructions.
Set GPS
Interface Description
Set/update the GPS information of cloud phones, including longitude and latitude.
Longitude range: [-180.0, 180.0]
Latitude range: [-90.0, 90.0]
Request URL
https://openapi.geelark.com/open/v1/phone/gps/set
Request Method
POST
Request Parameters
list Cloud Phone GPS Info <GPS>
Request Example
{
 "list": [
 {
 "id": "528086321789535232",
 "latitude": 1.30243,
 "longitude": 103.87546
 },
 {
 "id": "530011895768286208",
 "latitude": 11.30243,
 "longitude": 104.87546
 }
 ]
}

Response Example
{
 "traceId": "870AE3259C965B45A0D09C92A4EA8F81",
 "code": 0,
 "msg": "success",
 "data": {
 "totalAmount": 2,
 "successAmount": 2,
 "failAmount": 0
 }
}

Response Data Description
Error Codes
Below are the specific error codes for this interface. For other error codes, please refer to the API Call Instructions.

Modify cloud phone information
Interface Description
Warning: Do not operate this api while calling the API to start the cloud phone.
Modify cloud phone information.
Support modifying the cloud phone name.
Support modifying the cloud phone remark.
Support modifying the cloud phone tags.
Support modifying the cloud phone proxy configuration.
Support modifying the cloud phone group.
Support modifying the cloud phone charge mode.
Request URL
https://openapi.geelark.com/open/v1/phone/detail/update
Request Method
POST
Request Parameters
proxyConfig Static Proxy Parameters
proxyConfig Dynamic Proxy Parameters
Dynamic proxy settings can be configured on the client side first, and then by setting useProxyCfg to true, you can use the already configured information without needing to provide the host, port, and other details again.
typeId List
1. Static Proxy List
1 : socks5
2 : http
3 : https
2. Dynamic Proxy List
20 IPIDEA
21 IPHTML
22 kookeey
23 Lumatuo
Request Example
{
 "id": "528086284158239744",
 "name": "api update",
 "remark": "api remark",
 "tagIDs": ["528989565877355520", "528989565877289984"],
 "groupID": "528995439832269824",
 "proxyConfig": {
 "typeId": 1,
 "server": "123.123.123.123",
 "port": 32080,
 "username": "username",
 "password": "password"
 },
 "proxyId": "528989565877355520"
}

Response Example
Success Response
{
 "traceId": "B04B0843BD86D9589AB3BAB6A9EA3D92",
 "code": 0,
 "msg": "success"
}

If some tags in the tag list do not exist, there will be failDetails data; if none of the tags exist, the request will directly return an error, with the code details as shown in the Error Codes section below.
{
 "traceId": "8B38AA778DBCD9519FB9B00D8A593DB3",
 "code": 0,
 "msg": "success",
 "data": {
 "failDetails": [
 {
 "code": 43022,
 "id": "52898956587728998",
 "msg": "tag not found"
 }
 ]
 }
}

Response Data Description
failDetails Tag Addition Failure Info <FailDetails>
Error Codes
Below are the specific error codes for this interface. For other error codes, please refer to the API Call Instructions.

One-click new machine V2
API Description
One-click new machine v2 interface, directly return the execution result.
Request URL
https://openapi.geelark.com/open/v2/phone/newOne
Request Method
POST
Request Parameters
Request Example
{
    "id": "528715748189668352"
}

Response Example
{
 "traceId": "A62BBBF3A294487F9B49B9FFA0F84CA8",
 "code": 0,
 "msg": "success"
}

Error Codes
Below are specific error codes for this interface. For other error codes, please refer to API Documentation.

Screen Shot
API Description
Get a screen shot from cloud phone
Request URL
https://openapi.geelark.com/open/v1/phone/screenShot
Request Method
POST
Request Parameters
Request Example
{
    "id": "528715748189668352"
}

Response Example
{
 "traceId": "A62BBBF3A294487F9B49B9FFA0F84CA8",
 "code": 0,
 "msg": "success",
    "data": {
        "taskId": "1850726441252569088"
    }
}

Response Data Description
Error Codes
The following are specific error codes for this API. For other error codes, please refer to API Call Description
Please refer to Callback Example.

Get screen shot result
API Description
Query the status of cloud phone screenshot task
After requesting a screenshot, you can actively obtain the result through this interface within 30 minutes. If it expires, the retrieval will fail
Request URL
https://openapi.geelark.com/open/v1/phone/screenShot/result
Request Method
POST
Request Parameters
Request Example
{
    "taskId": "528715748189668352"
}

Response Example
{
 "traceId": "A62BBBF3A294487F9B49B9FFA0F84CA8",
 "code": 0,
 "msg": "success",
    "data": {
        "status": 1,
        "downloadLink": "https://zx-cloud-phone-pre.obs.cn-southwest-2.myhuaweicloud.com/envirFileExport/1851511129017700352/IMG_20241122160248.png?AccessKeyId=UFNIPAPFJX2MAGMFGRYZ&Expires=1732264377&Signature=dqV5JYzYDdm0wwAgkZIpDrs%2FL%2FE%3D"
    }
}

Response Data Description
错误码
For error codes, please refer to API Call Description.

Set Root Status
API Description
Set root status, please start the cloud phone before setting root status.
Request URL
https://openapi.geelark.com/open/v1/root/setStatus
Request Method
POST
Request Parameters
Request Example
{
 "ids" : [
 "526209711930868736"
 ],
 "open" : true
}

Response Example
{
 "traceId": "A24A3089958A4BC28E8B89B3AE1A61AC",
 "code": 0,
 "msg": "success",
    "data": {
 "items": [
 {
 "code": 42002,
 "msg": "phone is not running",
 "id": "543483007558772199"
 },
 {
 "code": 0,
 "msg": "success",
 "id": "543483063829554663"
 }
 ]
 }
}

Error Codes
For error codes, please refer to API Call Description.

Get device ID
API Description
Get the cloud phone device ID (please re-obtain the latest ID after one-click new phone), which corresponds to the cloud phone’s unique hardware device ID, which is equivalent to the system’s Andorid_ID. The App can bind to the cloud phone environment by obtaining this ID on the cloud phone. How to obtain the device ID on the App side:
Android 13 system: execute the getprop ro.boot.serialno command through adb
Other systems: execute the getprop ro.serialno command through adb
if(android.os.Build.VERSION.SDK_INT == 33){
 serialNo = Command.exeCommand("getprop ro.boot.serialno");
}else {
 serialNo = Command.exeCommand("getprop ro.serialno");
}

Request URL
https://openapi.geelark.com/open/v1/phone/serialNum/get
Request Method
POST
Request Parameters
Request Example
{
    "id": "528715748189668352"
}

Response Example
{
 "traceId": "89D8C3C08DA4DB5089069D34A3786494",
 "code": 0,
 "msg": "success",
 "data": {
 "serialNum": "r2cbvzlx5bs"
 }
}

Response Data Description
Error Codes
The following are specific error codes for this API. For other error codes, please refer to API Call Description

Send SMS to cloud phone
API Documentation
Send SMS to cloud phone. Before sending, please start the cloud phone first.
Request URL
https://openapi.geelark.com/open/v1/phone/sendSms
Request Method
POST
Request Parameters
Request Example
{
 "id": "526209711930868736",
 "phoneNumber": "+17723504471",
 "text": "your tk code: 6666"
}


{
 "traceId": "9E681400B2983A5390F4B7C8BF1BF2B7",
 "code": 0,
 "msg": "success",
 "data": {}
}


List of cloud mobile phone brands
API Description
Get a list of cloud phone brands
Request URL
https://openapi.geelark.com/open/v1/phone/brand/list
Request Method
POST
Request Parameters
Request Example
{
    "androidVer" : 10
}

Response Example
{
    "traceId": "B0BA8FF29AB60B8ABF4E9A26BF08F7B9",
    "code": 0,
    "msg": "success",
    "data": [
        {
            "surfaceBrandName": "samsung",
            "surfaceModelName": "Galaxy S20+"
        }
    ]
}

Response Data Description
Error Codes
For error codes, please refer to API Call Description

Transfer Cloud Phone
API Description
Transfer Cloud Phone
Request URL
https://openapi.geelark.com/open/v1/phone/transfer
Request Method
POST
Request Parameters
Request Example
{
 "ids": [
 "539893235657500146"
 ],
 "account": "Anna@geelark.com",
 "transferOption": [
 "name",
 "proxy",
 "tag",
 "remark"
 ]
}

Response Example
{
    "traceId": "B0BA8FF29AB60B8ABF4E9A26BF08F7B9",
    "code": 0,
    "msg": "success",
    "data": [
        {
            "successCount": 10,
            "failCount": 2,
            "failEnvIds" : ["539893235657500146"]
        }
    ]
}

Response Data Description
Error Codes
For error codes, please refer to API Call Description

Set net type
API Description
Set up the cloud phone network connection mode
Request URL
https://openapi.geelark.com/open/v1/phone/net/set
Request Method
POST
Request Parameters
Request Example
{
  "id": "528086284158239744",
 "netType": 0
}

Response Example
{
  "traceId": "B04B0843BD86D9589AB3BAB6A9EA3D92",
  "code": 0,
  "msg": "success"
}

Error Codes
For error codes, please refer to API Call Description.

Query task
API Description
Task Query
Request URL
https://openapi.geelark.com/open/v1/task/query
Request Method
POST
Request Parameters
Query Parameters (Ignore if empty)
Request Example
{
    "ids": ["123321", "456654"]
}

Response Data Description
Task
Task Failure Codes and Reasons
Response Example
Task Completed
{
    "traceId": "123456ABCDEF",
    "code": 0,
    "msg": "success",
    "data": {
        "total": 1,
        "items": [
            {
                "id": "123456ABCDEF",
                "planName": "plan123456ABCDEF",
                "taskType": 2,
                "serialName": "test",
                "envId": "123456654321",
                "scheduleAt": 1718744459,
                "status": 3
            }
        ]
    }
}

Task Failed
{
    "traceId": "123456ABCDEF",
    "code": 0,
    "msg": "success",
    "data": {
        "total": 1,
        "items": [
            {
                "id": "123456ABCDEF",
                "planName": "plan123456ABCDEF",
                "taskType": 2,
                "serialName": "test",
                "envId": "123456654321",
                "scheduleAt": 1718744459,
                "status": 4,
                "failCode": 29999,
                "failDesc": "some reason"
            }
        ]
    }
}

Error Codes
For error codes, please refer to API Call Description

--- TABLE ---
Parameter Name | Required | Type | Description | Example
amount | Yes | integer | Total number of cloud phones to create (range: 1-100) | 10
androidVersion | Yes | integer | Cloud phone system version | 1
proxyId | No | string | Proxy ID. You must provide either a Proxy ID or Proxy configuration. Proxy ID takes precedence. | 497548067550006541
proxyConfig | No | object | Proxy configuration | See request example
remark | No | string | Remarks, up to 1500 characters | 12ABCDEF
groupName | No | string | Group name, created automatically if not existing, up to 50 characters | group1
tagsName | No | array[string] | Tag names, created automatically if not existing. The maximum length of a single label is 30 characters | See request example
region | No | string | Specify where the cloud phone is located, optional parameters：cn, sgp | cn
chargeMode | No | int | charge mode | 0 pay per minute, 1 monthly subscription; default is pay per minute
language | No | string | Language of the cloud phone | baseOnIP/default (default is English)，If this parameter is not provided, it will default to English
surfaceBrandName | No | string | Mobile phone brand, obtain the value corresponding to the Android version from the brand list interface, and the brand model should be transmitted at the same time | samsung
surfaceModelName | No | string | Mobile phone model, obtain the value corresponding to the Android version from the brand list interface, and the brand model should be transmitted at the same time | Galaxy S23
netType | No | integer | Networking. 0-Wi-Fi, 1-Mobile. Only supported on Android 12/Android 13/Android 15. Default to mobile network | 0
phoneNumber | No | string | Mobile phone number, automatically generated if empty | +66817806147
--- TABLE ---
Parameter Name | Required | Type | Description | Example
typeId | Yes | integer | Proxy type ID | 1
server | Yes | string | Proxy server hostname | server.com
port | Yes | integer | Proxy server port | 1234
username | Yes | string | Proxy server username | user
password | Yes | string | Proxy server password | password
--- TABLE ---
Parameter Name | Required | Type | Description | Example
useProxyCfg | Yes | bool | Whether to use the already configured proxy | true
typeId | Yes | integer | Proxy type ID | 20
protocol | No | integer | Proxy protocol type: 1 for SOCKS5, 2 for HTTP. | 1
server | No | string | Proxy server hostname | server.com
port | No | integer | Proxy server port | 1234
username | No | string | Proxy server username | user
password | No | string | Proxy server password | password
country | No | string | country | us
region | No | string | region | alabama
city | No | string | city | mobile
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of cloud phones created
successAmount | integer | Number of successful creations
failAmount | integer | Number of failed creations
details | array | Creation response details
--- TABLE ---
Parameter Name | Type | Description
index | integer | Creation index
code | integer | Result code, 0 for success
msg | string | Result message
id | string | Cloud phone ID
profileName | string | Cloud phone name
envSerialNo | string | Cloud phone serial number
equipmentInfo | EquipmentInfo | cloud phone equipment info
--- TABLE ---
Parameter Name | Type | Description
countryName | string | country name
phoneNumber | string | phone number
enableSim | int | is Sim enable : 0 unable 1 enable
imei | string | IMEI
osVersion | string | system version
wifiBssid | string | Wi-Fi MAC Address
mac | string | phone Wi-Fi MAC Address
bluetoothMac | string | bluetooth Mac Address
timeZone | string | timezone
deviceBrand | string | brand
deviceModel | string | model
--- TABLE ---
Error Code | Description
44001 | Batch creation is not allowed, please upgrade to the Pro plan
44002 | Batch creation is not allowed, cloud phone creation limit reached for the plan
44004 | Batch creation is not allowed, maximum daily cloud phone creation limit reached
44006 | phone out of stock
45003 | Proxy banned
45004 | Proxy verification failed
45005 | Region not supported
45001 | The proxy does not exist.
43017 | not enough devices for the monthly plan
43019 | The charge mode of this androidVersion only supports monthly subscription
45008 | Proxy type not allow
--- TABLE ---
Parameter Name | Required | Type | Description | Example
mobileType | Yes | string | Cloud phone type, can be set
Android 10
Android 11
Android 12
Android 13
Android 14
Android 15 | Android 10
chargeMode | No | int | Billing mode, 0-on-demand, 1-monthly, default is on-demand | 0
region | No | string | Specify the computer room where the cloud phone is located. Optional parameters: cn, sgp | cn
data | Yes | array[EnvRowApi] | Environment parameter array, up to 100 | Reference Request Example
--- TABLE ---
Parameter Name | Required | Type | Description | Example
profileName | Yes | string | Cloud Phone Name | myPhone
proxyInformation | No | string | Proxy information, supports http, https, socks5 types | socks5://AD00xx004:3000xxx0002@100.200.200.100:30000
refreshUrl | No | string | Proxy refresh url | http://someaddr
proxyNumber | No | integer | The serial number of the added proxy | 1
dynamicProxy | No | string | Saved dynamic proxy, can be set IPIDEA/IPHTML/kookeey/Luminati(BrightData)/rolaip | IPIDEA
dynamicProxyLocation | No | string | Dynamic proxy country, required when specifying a dynamic proxy | us
mobileLanguage | No | string | The language of the cloud phone. If you set baseOnIP, it will be based on the proxy settings. If you set default or do not set it, it will be in English. | default
profileGroup | No | string | Group name, if it does not exist, create a new one automatically | myGroup
profileTags | No | array[string] | Tag name, if it does not exist, create a new one automatically | Reference Request Example
profileNote | No | string | Remark | remark
surfaceBrandName | No | string | Mobile phone brand, obtain the value corresponding to the Android version from the brand list interface, and the brand model should be transmitted at the same time | samsung
surfaceModelName | No | string | Mobile phone model, obtain the value corresponding to the Android version from the brand list interface, and the brand model should be transmitted at the same time | Galaxy S23
netType | No | integer | Networking. 0-Wi-Fi, 1-Mobile. Only supported on Android 12/Android 13/Android 15. Default to mobile network | 0
phoneNumber | No | string | Mobile phone number, automatically generated if empty | +66817806147
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of cloud phones created
successAmount | integer | Number of successful creations
failAmount | integer | Number of failed creations
details | array | Creation response details
--- TABLE ---
Parameter Name | Type | Description
index | integer | Creation index
code | integer | Result code, 0 for success
msg | string | Result message
id | string | Cloud phone ID
profileName | string | Cloud phone name
envSerialNo | string | Cloud phone serial number
equipmentInfo | EquipmentInfo | cloud phone equipment info
--- TABLE ---
Parameter Name | Type | Description
countryName | string | country name
phoneNumber | string | phone number
enableSim | int | is Sim enable : 0 unable 1 enable
imei | string | IMEI
osVersion | string | system version
wifiBssid | string | Wi-Fi MAC Address
mac | string | phone Wi-Fi MAC Address
bluetoothMac | string | bluetooth Mac Address
timeZone | string | timezone
deviceBrand | string | brand
deviceModel | string | model
--- TABLE ---
Error Code | Description
44001 | Batch creation is not allowed, please upgrade to the Pro plan
44002 | Batch creation is not allowed, cloud phone creation limit reached for the plan
44004 | Batch creation is not allowed, maximum daily cloud phone creation limit reached
50000 | Unknown error
--- TABLE ---
Parameter Name | Required | Type | Description | Example
page | No | integer | Page number, minimum is 1 | 1
pageSize | No | integer | Number of records per page, minimum is 1, maximum is 100 | 10
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | No | array[string] | Cloud phone ID array，The maximum length of the array is 100. If the array is not empty, these two parameters： page pageSize, will not take effect | [“5213214343124321”]
serialName | No | string | Cloud phone name | test
remark | No | string | Cloud phone remark | test
groupName | No | string | Cloud phone group name | test group
tags | No | array[string] | List of cloud phone tag names | See example
chargeMode | No | int | charge mode | 0 pay per minute, 1 monthly subscription; If this field is left empty, all charge mode will be queried.
--- TABLE ---
Parameter Name | Type | Description
total | integer | Total number of cloud phones
page | integer | Page number
pageSize | integer | Page size
items | array[Phone] | List of cloud phones
--- TABLE ---
Parameter Name | Type | Description
id | string | Cloud phone ID
serialName | string | Cloud phone name
serialNo | string | Cloud phone serial number
group | Group | Cloud phone group information
remark | string | Cloud phone remark
status | int | Cloud phone status
0 - Started
1 - Starting
2 - Shut down
tags | array[Tag] | List of cloud phone tags
equipmentInfo | EquipmentInfo | cloud phone equipment info
proxy | Proxy | Proxy info
chargeMode | int | charge mode: 0 pay per minute, 1 monthly subscription
hasBind | bool | Is the device bound to a monthly subscription
monthlyExpire | int | Monthly subscription expiration time, timestamp in seconds
--- TABLE ---
Parameter Name | Type | Description
id | string | Group ID
name | string | Group name
remark | string | Group remark
--- TABLE ---
Parameter Name | Type | Description
name | string | Cloud phone tag name
--- TABLE ---
Parameter Name | Type | Description
countryName | string | country name
phoneNumber | string | phone number
enableSim | int | is Sim enable : 0 unable 1 enable
imei | string | IMEI
osVersion | string | system version
wifiBssid | string | Wi-Fi MAC Address
mac | string | phone Wi-Fi MAC Address
bluetoothMac | string | bluetooth Mac Address
timeZone | string | timezone
deviceBrand | string | brand
deviceModel | string | model
--- TABLE ---
Parameter Name | Type | Description
type | string | Proxy type (socks5, http, https)
server | string | Proxy server
port | int | Proxy port
username | string | Proxy username
password | string | Proxy password
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | Yes | array[string] | List of cloud phone IDs, Limit to 100 elements | See request example
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of requested IDs
successAmount | integer | Total number of successful responses
failAmount | integer | Total number of failed responses
successDetails | array[SuccessDetails] | Information about successful responses
failDetails | array[FailDetails] | Information about failed responses
--- TABLE ---
Parameter Name | Type | Description
id | string | ID of the successful cloud phone
serialName | string | Name of the successful cloud phone
status | integer | Cloud phone status code
0 - Started
1 - Starting
2 - Shut down
3 - Expired
--- TABLE ---
Parameter Name | Type | Description
code | int | Failure code 42001: Cloud phone does not exist
id | string | ID of the failed cloud phone
msg | string | Failure message
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | Yes | array[string] | List of cloud phone IDs, Limit to 100 elements | See request example
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of requested IDs
successAmount | integer | Total number of successful responses
failAmount | integer | Total number of failed responses
successDetails | array[SuccessDetails] | Information about successful responses
failDetails | array[FailDetails] | Information about failed responses
--- TABLE ---
Parameter Name | Type | Description
id | string | ID of the successful cloud phone
serialName | string | Name of the successful cloud phone
status | integer | Cloud phone status code
0 - Started
1 - Starting
2 - Shut down
3 - Expired
--- TABLE ---
Parameter Name | Type | Description
code | int | Failure code 42001: Cloud phone does not exist
id | string | ID of the failed cloud phone
msg | string | Failure message
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | Yes | array[string] | List of cloud phone IDs | See request example
hideSideBar | No | bool | Whether to hide the sidebar | false, defaults to false if not provided
displayTimer | No | bool | Whether to display the timer | false, defaults to false if not provided
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of requested IDs
successAmount | integer | Number of successful starts
successDetails | array[SuccessDetails] | Information about successed
failAmount | integer | Number of failed starts
failDetails | array[FailDetails] | Information about failures
--- TABLE ---
Parameter Name | Type | Description
id | string | ID of the cloud phone
url | string | remote url
--- TABLE ---
Parameter Name | Type | Description
code | integer | Failure code
id | string | ID of the failed cloud phone
msg | string | Failure message
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
43004 | Cloud phone has expired
47004 | Device associated with cloud phone does not exist
43007 | Cloud phone is already in use by another user
45002 | Cloud phone proxy is unavailable
47002 | Cloud phone resources are insufficient
43020 | Cloud phone is currently unavailable, please try again later
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | Yes | array[string] | List of cloud phone IDs | See request example
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of requested IDs
successAmount | integer | Number of successfully shut down IDs
failAmount | integer | Number of failed IDs
failDetails | array[FailDetails] | Information about failures
--- TABLE ---
Parameter Name | Type | Description
code | integer | Error code
id | integer | Cloud phone ID
msg | string | Error message
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
43005 | Cloud phone is executing a task
43006 | Cloud phone is being remotely connected
--- TABLE ---
Parameter | Required | Type | Description | Example
ids | Yes | array[string] | List of cloud phone IDs, Limit to 100 elements | Refer to the request example
--- TABLE ---
Parameter | Type | Description
totalAmount | integer | Total number of requested IDs
successAmount | integer | Total number of successful IDs
failAmount | integer | Total number of failed IDs
failDetails | array[FailDetails] | Failure details
--- TABLE ---
Parameter | Type | Description
code | integer | Error code
id | integer | Cloud phone ID
msg | string | Error message
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
43009 | Cloud phone is started, cannot delete
43010 | Cloud phone is starting, cannot delete
43021 | The cloud phone is in use, please try again later
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | Yes | array[string] | List of cloud phone IDs | Refer to Request Example
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of requested IDs
successAmount | integer | Total number of successful requests
failAmount | integer | Total number of failed requests
list | GPS | GPS information
--- TABLE ---
Parameter Name | Type | Description
id | string | Cloud phone ID
latitude | float | Latitude
longitude | float | Longitude
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
--- TABLE ---
Parameter Name | Required | Type | Description | Example
list | Yes | array[GPS] | Cloud phone GPS info | Refer to Request Example
--- TABLE ---
Parameter Name | Required | Type | Description | Example
id | Yes | string | Cloud phone ID | Refer to Request Example
longitude | Yes | float | Longitude | Refer to Request Example
latitude | Yes | float | Latitude | Refer to Request Example
--- TABLE ---
Parameter Name | Type | Description
totalAmount | integer | Total number of requested IDs
successAmount | integer | Total number of successful requests
failAmount | integer | Total number of failed requests
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
43012 | Latitude/longitude range error
--- TABLE ---
Parameter Name | Required | Type | Description | Example
id | Yes | string | Cloud phone ID | 
name | No | string | New cloud phone name, up to 100 characters | 
remark | No | string | New cloud phone remark, up to 1500 characters | 
groupID | No | string | New cloud phone group ID | 
tagIDs | No | array[string] | New cloud phone tag IDs | 
proxyConfig | No | Proxy | New cloud phone proxy config | 
proxyId | No | string | Proxy Id | 
--- TABLE ---
Parameter Name | Required | Type | Description | Example
typeId | Yes | integer | Proxy type ID | 1
server | Yes | string | Proxy server hostname | server.com
port | Yes | integer | Proxy server port | 1234
username | Yes | string | Proxy server username | user
password | Yes | string | Proxy server password | password
--- TABLE ---
Parameter Name | Required | Type | Description | Example
useProxyCfg | Yes | bool | Whether to use the already configured proxy | true
typeId | Yes | integer | Proxy type ID | 20
protocol | No | integer | Proxy protocol type: 1 for SOCKS5, 2 for HTTP. | 1
server | No | string | Proxy server hostname | server.com
port | No | integer | Proxy server port | 1234
username | No | string | Proxy server username | user
password | No | string | Proxy server password | password
country | No | string | country | us
region | No | string | region | alabama
city | No | string | city | mobile
--- TABLE ---
Parameter Name | Type | Description
failDetails | array[FailDetails] | Tag addition failure info
--- TABLE ---
Parameter Name | Type | Description
code | integer | Error code
id | integer | Tag ID
msg | string | Error msg
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
43022 | Tag does not exist
43032 | Group does not exist
45003 | Proxy region not allowed
45004 | Proxy check failed, check config
45008 | Proxy type not allow
--- TABLE ---
Parameter Name | Required | Type | Description | Example
id | Yes | string | Cloud Phone ID | See request example
changeBrandModel | No | bool | Whether to randomize the brand and model. true: randomize, false: keep unchanged; if not provided, it remains randomize. | true
--- TABLE ---
错误码 | 说明
42001 | cloud phone not exist
44004 | maximum daily cloud phone creation limit reached
43005 | cloud phone is executing task
43006 | cloud phone is occupied by remote
43015 | this cloud phone is not support One-click new machine
45004 | proxy detect fail
--- TABLE ---
Parameter Name | Required | Type | Description | Example
id | Yes | string | clound phone id | Refer to request example
--- TABLE ---
Parameter Name | Type | Description
taskId | string | task id
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
42002 | Cloud phone is not running
--- TABLE ---
Parameter Name | Required | Type | Description | Example
taskId | Yes | string | task id | Refer to request example
--- TABLE ---
Parameter Name | Type | Description
status | int | 0 Acquisition failed；1 In progress；2 Execution succeeded；3 Execution failed
downloadLink | downloadLink | screen shot download link
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | Yes | array[string] | List of cloud phone IDs ( currently supports Android 12,13,14,15 ) | Refer to request example
open | Yes | bool | open/close | false
--- TABLE ---
Error Code | Description
42001 | cloud phone not found
42002 | cloud phone is not running
43016 | this cloud phone does not support root
--- TABLE ---
Parameter Name | Required | Type | Description | Example
id | Yes | string | clound phone id | Refer to request example
--- TABLE ---
Parameter Name | Type | Description
serialNum | string | cloud phone device ID
--- TABLE ---
Error Code | Description
42001 | Cloud phone does not exist
--- TABLE ---
Parameter Name | Required | Type | Description | Example
id | Yes | string | Cloud phone environment ID (Currently supports only Android 12 , 13, 15 devices) | 526209711930868736
phoneNumber | Yes | string | Phone number | +17723504471
text | Yes | string | SMS content | xxxx
--- TABLE ---
Error Code | Description
52001 | This type of cloud phone does not support sending SMS.
--- TABLE ---
Parameter Name | Required | Type | Description | Example
androidVer | Yes | integer | android version, 10-15 | 10
--- TABLE ---
Parameter Name | Type | Description
surfaceBrandName | string | mobile phone brand
surfaceModelName | string | mobile phone model
--- TABLE ---
Parameter Name | Required | Type | Description | Example
account | yes | string | target account | Anna@geelark.com
ids | yes | array[string] | The maximum length limit for the array of the cloud phone ID to be transferred is 200, and any part exceeding 200 will be ignored | 
transferOption | no | arrry[string] | Transfer options with optional parameters：name：cloud phone name，proxy：cloud phone proxy，tag：cloud phone tag，remark：cloud phone remark | [ “name”,”proxy”, “tag”,”remark” ]
--- TABLE ---
Parameter Name | Type | Description
successCount | int | success count
failCount | int | fail count
failEnvIds | array[string] | transfer failed cloud phone id (currently in use or does not exist)
--- TABLE ---
Error Code | Description
40013 | target account not found
43022 | can not transfer to myself
--- TABLE ---
Parameter Name | Required | Type | Description
id | Yes | string | Cloud Phone ID
netType | Yes | integer | Networking. 0-Wi-Fi, 1-Mobile. Only supported on Android 12/Android 13/Android 15
--- TABLE ---
Error Code | Description
42001 | cloud phone not found
--- TABLE ---
Parameter Name | Required | Type | Description | Example
ids | Yes | array[string] | Array of task IDs, up to 100 | See request example
--- TABLE ---
Parameter Name | Type | Description
total | integer | Total number of tasks
items | array[Task] | Array of tasks
--- TABLE ---
Parameter Name | Type | Description
id | string | Task ID
planName | string | Task plan name
taskType | integer | Task type
1 TikTok video posting
2 TikTok AI account warmup
3 TikTok carousel posting
4 TikTok account login
6 TikTok profile editing
42 Custom(Including Facebook, YouTube and other platforms)
serialName | string | Cloud phone name
envId | string | Cloud phone ID
scheduleAt | integer | Scheduled time, timestamp in seconds
status | integer | Task status
1 Waiting
2 In progress
3 Completed
4 Failed
7 Cancelled
failCode | integer | Failure code, refer to task failure codes and reasons
failDesc | string | Failure reason, refer to task failure codes and reasons
cost | integer | The time a task takes to complete or fail (in seconds)
shareLink | string | Share link
--- TABLE ---
Failure Code | Failure Reason
20002 | The machine is performing other tasks
20003 | Execution timeout. Please view the publication on TikTok.
20005 | Task canceled
20006 | The same task was canceled
20007 | Unsupported task type
20008 | Failed because the APP language was modified. You need to change the APP language to English and run it again.
20100 | No network connection
20101 | Agent parameter error
20102 | Failed to set modification parameters
20103 | Failed to restart device
20104 | After successful login, an error occurs when saving login information to the service.
20105 | Installation of tiktok failed
20106 | Failed to install 163 mailbox
20107 | Unable to load video
20108 | No network connection
20109 | Setting proxy via interface failed
20110 | Failed to obtain proxy ip
20111 | Installation of auxiliary apk failed
20112 | Failed to start secondary apk
20113 | The IP address is the same before and after setting the proxy
20114 | The node_addr field is parsed into an entity class error
20115 | Check login failure
20116 | The account is not logged in
20117 | No email account and password
20118 | Failed to obtain IP before setting proxy
20119 | Failed to bind NetService
20120 | Failed to obtain tiktok cookie
20121 | Failed to obtain tiktokInfo
20122 | Failed to start tiktok
20123 | Failed to obtain geoip
20124 | The waiting time to enter the homepage is too long
20125 | Login failed, too many attempts
20126 | Login failed, email not found
20127 | Login failed when switching to email username
20128 | Login failure
20129 | Device offline
20130 | Account password is wrong
20131 | Too many attempts
20132 | Login loading time exceeds 2 minutes
20133 | Slider loading time is too long
20134 | No network when verifying slider
20135 | Failed to obtain tiktok UserName
20136 | Account blocked
20137 | The account has been blocked and you can appeal.
20138 | The circular verification code slider takes too long to load
20139 | Circle slider validation failed
20140 | Slider verification fails to obtain screenshots
20141 | There is no network during circular verification
20142 | Graphic validation failed
20143 | Maximum number of attempts reached
20144 | Incorrect account or password
20145 | Your account has repeatedly violated community guidelines
20200 | Failed to download file, please check the network or try again later
20201 | Failed to upload video, please check whether the network is smooth or try again later
20202 | Failed to upload the video. It has been 0% for five minutes. Please check the network or try again later.
20203 | Failed to upload video, failed for 15 minutes, please check the network or try again later
20204 | Video upload was rejected
20205 | Failed to click the capture button on the main page
20206 | Failed to upload when clicking on the album page
20207 | Album file type click failed
20208 | Failed to download the video file. The specified download file was not found. Please check the network or try again later.
20209 | Failed to select video
20210 | Album next step failed
20211 | Next step of preview page failed
20212 | Preview completed and click Next failed.
20213 | Clicking Publish on the publish page fails
20214 | Clicking Publish Now failed
20215 | Preview completed and waiting for video processing failed
20216 | Failed to push stream to camera
20217 | Recording video from camera failed
20218 | Green screen filter not found
20219 | Failed to switch rear camera
20220 | Download video file connection is empty
20221 | Couldn’t decode. select anther video
20222 | Video sound is not available
20223 | Can’t select Stickers
20224 | Stickers list not found
20225 | Stickers list failed to load
20226 | Failed to download MENTION stickers
20227 | MENTION sticker input box not found
20228 | Publish video@user list failed to load
20229 | The specified user was not found
20230 | Handle video timeout
20231 | Add link control not found
20232 | Add product control not found
20233 | Failed to enter product page
20234 | Product not found
20235 | Modify product name control not found
20236 | Failed to add product
20237 | Product sold out
20238 | Video source is not set for push streaming
20239 | Audio source is not set for push streaming
20240 | Camera recording video waiting timeout
20241 | Product unavailable
20242 | Failed to jump to video details
20243 | Failed to click the Use Music button
20244 | Video music removed
20245 | Timeout waiting for video to load
20246 | Video ID does not exist
20247 | Failed to switch seconds
20248 | Search button not found
20249 | Product URL input box not found
20250 | Add product button not found
20251 | Video publishing failed, saved to drafts
20252 | Background music infringement
20253 | Background music is muted causing failure
20254 | Failed to set default audience
20255 | Your account is permanently restricted from selling products
20256 | Failed to enter product title editing page
20257 | Video upload timed out
20258 | Element not found
20259 | Mention user not found
20260 | Mention user button not found
20261 | User search not found
20262 | When entering the product page, it prompts that there is no network connection.
20263 | Product name contains inappropriate words
20264 | Account temporarily restricted
20265 | Shooting the same video had special effects, causing the mission to fail.
20266 | Failed to add product name, please check whether the product name is compliant
20300 | Registration slider verification failed
20301 | Registration circular verification failed to obtain screenshots
20302 | Failed to enter email verification code
20303 | The email verification code was not found within the specified time.
20304 | Failed to register account and create new password
20305 | Failed to jump to homepage via email
20306 | No clickable registration button found
20307 | Date of birth is illegal or failed to obtain
20308 | Registration failed by clicking on the email address
20309 | Failed to enter email
20310 | The next step after clicking to enter the email address fails.
20311 | The next step after clicking Create Password fails.
20312 | Verification countdown not found
20313 | Resend verification code not found
20314 | Failed to start mailbox app
20315 | Verification code sent too many times
20316 | Skip creation of username failed
20317 | TikTok prompts you to try too many times when registering
20318 | Email login failed
20319 | Email login failed, account locked
20320 | Email login failed, account password is wrong
20321 | Email login failed
20322 | Login password control not found
20323 | Waiting too long after entering the verification code
20324 | Account or password incorrect
20325 | Fail to register
20326 | Account has been registered
20327 | Waiting too long after entering the verification code
20328 | An error message appears after entering the password
20329 | Email verification is required but currently only supports 163 email addresses
20330 | Email is registered
20331 | Birthday next step failed
20332 | Determine the registration entrance failed
20333 | Circular verification code processing exception
20334 | Email verification required
20335 | An exception occurred during registration
20336 | Email verification code execution failed
20337 | The email verification code has expired or timed out
20338 | The input box control for filling in the email verification code was not found.
20339 | The email verification code decoding interface returns an invalid verification code.
20340 | Interests selection failed
20401 | Failed to jump to me
20402 | Failed to click to edit information
20403 | Unable to edit data
20501 | Failed to jump to user page
20502 | There is no network when jumping to the user page
20503 | The specified user could not be found
20504 | An exception occurred when jumping to the user page
20505 | Fan list page failed to load
20506 | Fan list page loading timeout
20507 | Fan list loading timeout
20508 | Failed to load more fans list
20601 | Failed to click window option
20602 | Failed to jump to showcase page
20603 | Failed to jump to add product page
20604 | Failed to enter product URL page
20605 | Failed to enter product URL
20606 | Failed to add product
20607 | This account does not have a shopping cart
20700 | Unsupported type
20701 | Failed to open developer tools
20702 | TikTok Shop button does not exist
20703 | Failed to enter TikTok Shop
20704 | Failed to open shopping cart
20705 | Failed to enter the invitation page
20706 | Agree to invitation page exception
20707 | Failed to click to agree to the invitation
20708 | Invitation failed
20709 | Failed to enter revenue page
20710 | Authorization revenue page exception
20711 | Authorization revenue failed
20712 | Access data authorization failed
20713 | Data authorization failed
20714 | Failed to detect shopping cart permissions
20715 | Click Account Settings Failed
20801 | @ button not found
20802 | List element not found
20803 | No users mentioned were found
20804 | Edit input box not found
20901 | No delete button found
21001 | Top button not found
29997 | Insufficient balance
29998 | The cloud phone has been deleted
29999 | Unknown error
</file>

<file path="geelark_client.py">
"""
Geelark API Client - handles all API calls to Geelark
"""
import os
import uuid
import time
import hashlib
import logging
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from dotenv import load_dotenv

load_dotenv()

API_BASE = "https://openapi.geelark.com"

# Default HTTP timeout in seconds (prevents hanging requests)
DEFAULT_HTTP_TIMEOUT = 30

# Setup logging for API responses (useful for debugging with Geelark support)
logging.basicConfig(
    filename="geelark_api.log",
    level=logging.DEBUG,
    format="%(asctime)s %(levelname)s %(message)s"
)
api_logger = logging.getLogger("geelark_api")


class GeelarkCredentialError(Exception):
    """Raised when Geelark credentials are missing or invalid."""
    pass


class GeelarkClient:
    def __init__(self, token: str = None):
        """
        Initialize GeelarkClient with credential validation and connection pooling.

        Args:
            token: Optional token override. If not provided, reads from GEELARK_TOKEN env var.

        Raises:
            GeelarkCredentialError: If GEELARK_TOKEN is missing.
        """
        self.app_id = os.getenv("GEELARK_APP_ID")
        self.api_key = os.getenv("GEELARK_API_KEY")
        self.token = token or os.getenv("GEELARK_TOKEN")

        # FAIL FAST: Validate credentials at initialization, not deep in posting flow
        if not self.token:
            raise GeelarkCredentialError(
                "GEELARK_TOKEN not found. Set it in .env file or pass token parameter."
            )

        # Create HTTP session with connection pooling for reliability under parallel load
        self.session = requests.Session()
        adapter = HTTPAdapter(
            pool_connections=10,  # Number of connection pools
            pool_maxsize=10,      # Max connections per pool
            max_retries=Retry(
                total=3,
                backoff_factor=0.5,
                status_forcelist=[500, 502, 503, 504]
            )
        )
        self.session.mount('https://', adapter)
        self.session.mount('http://', adapter)

    def _get_headers(self):
        """Generate headers for token-based authentication"""
        trace_id = str(uuid.uuid4()).upper().replace("-", "")
        return {
            "Content-Type": "application/json",
            "traceId": trace_id,
            "Authorization": f"Bearer {self.token}"
        }

    def _request(self, endpoint, data=None, timeout=None):
        """Make API request with full response logging and timeout."""
        url = f"{API_BASE}{endpoint}"
        headers = self._get_headers()
        timeout = timeout or DEFAULT_HTTP_TIMEOUT

        # Log request
        start_time = time.time()
        api_logger.debug(f"REQUEST: {endpoint} data={data}")

        # Use session for connection pooling, add timeout to prevent hanging
        resp = self.session.post(url, json=data or {}, headers=headers, timeout=timeout)
        elapsed = time.time() - start_time

        # Log full response info (for Geelark developer debugging)
        api_logger.info(
            f"RESPONSE: endpoint={endpoint} status={resp.status_code} "
            f"elapsed={elapsed:.2f}s headers={dict(resp.headers)} "
            f"body={resp.text[:1000]}"
        )

        if resp.status_code != 200:
            api_logger.error(f"HTTP ERROR: {resp.status_code} - {resp.text}")
            raise Exception(f"API error: {resp.status_code} - {resp.text}")

        result = resp.json()
        if result.get("code") != 0:
            api_logger.error(f"API ERROR: code={result.get('code')} msg={result.get('msg')}")
            raise Exception(f"API error: {result.get('code')} - {result.get('msg')}")

        return result.get("data")

    def list_phones(self, page=1, page_size=100, group_name=None):
        """List cloud phones"""
        data = {"page": page, "pageSize": page_size}
        if group_name:
            data["groupName"] = group_name
        return self._request("/open/v1/phone/list", data)

    def get_phone_status(self, phone_ids):
        """Get status of specific phones"""
        return self._request("/open/v1/phone/status", {"ids": phone_ids})

    def start_phone(self, phone_id):
        """Start a cloud phone"""
        result = self._request("/open/v1/phone/start", {"ids": [phone_id]})
        if result.get("successAmount", 0) > 0:
            return result["successDetails"][0]
        else:
            fail = result.get("failDetails", [{}])[0]
            raise Exception(f"Failed to start phone: {fail.get('msg')}")

    def stop_phone(self, phone_id):
        """Stop a cloud phone"""
        return self._request("/open/v1/phone/stop", {"ids": [phone_id]})

    def enable_adb(self, phone_id):
        """Enable ADB on a cloud phone"""
        return self._request("/open/v1/adb/setStatus", {"ids": [phone_id], "open": True})

    def disable_adb(self, phone_id):
        """Disable ADB on a cloud phone"""
        return self._request("/open/v1/adb/setStatus", {"ids": [phone_id], "open": False})

    def get_adb_info(self, phone_id):
        """Get ADB connection info (ip, port, password)"""
        result = self._request("/open/v1/adb/getData", {"ids": [phone_id]})
        items = result.get("items", [])
        if items and items[0].get("code") == 0:
            return items[0]
        else:
            msg = items[0].get("msg") if items else "Unknown error"
            raise Exception(f"Failed to get ADB info: {msg}")

    def screenshot(self, phone_id):
        """Request a screenshot from cloud phone"""
        return self._request("/open/v1/phone/screenShot", {"id": phone_id})

    def get_screenshot_result(self, task_id):
        """Get screenshot result (download link)"""
        return self._request("/open/v1/phone/screenShot/result", {"taskId": task_id})

    def wait_for_screenshot(self, phone_id, timeout=30):
        """Take screenshot and wait for result"""
        # Request screenshot
        result = self.screenshot(phone_id)
        task_id = result.get("taskId")

        # Poll for result
        start = time.time()
        while time.time() - start < timeout:
            try:
                result = self.get_screenshot_result(task_id)
                if result.get("status") == 2:  # Success
                    return result.get("downloadLink")
                elif result.get("status") == 3:  # Failed
                    raise Exception("Screenshot failed")
            except:
                pass
            time.sleep(1)

        raise Exception("Screenshot timeout")

    def get_upload_url(self, file_type):
        """Get temporary upload URL for a file"""
        return self._request("/open/v1/upload/getUrl", {"fileType": file_type})

    def upload_file_to_geelark(self, local_path):
        """Upload a local file to Geelark's temp storage, return resource URL"""
        import os

        # Get file extension
        ext = os.path.splitext(local_path)[1].lstrip(".").lower()
        if not ext:
            ext = "mp4"

        # Get upload URL
        result = self.get_upload_url(ext)
        upload_url = result.get("uploadUrl")
        resource_url = result.get("resourceUrl")

        # Upload file via PUT with timeout (use longer timeout for large files)
        with open(local_path, "rb") as f:
            resp = self.session.put(upload_url, data=f, timeout=120)

        if resp.status_code not in [200, 201]:
            raise Exception(f"Failed to upload file: {resp.status_code} {resp.text}")

        return resource_url

    def upload_file_to_phone(self, phone_id, file_url):
        """Upload a file from URL to cloud phone's Downloads folder"""
        return self._request("/open/v1/phone/uploadFile", {
            "id": phone_id,
            "fileUrl": file_url
        })

    def query_upload_status(self, task_id):
        """Query the upload status of a file to cloud phone"""
        return self._request("/open/v1/phone/uploadFile/result", {"taskId": task_id})

    def wait_for_upload(self, task_id, timeout=60, verbose=True):
        """Wait for file upload to phone to complete"""
        start = time.time()
        last_print = 0
        last_status = None
        consecutive_errors = 0

        while time.time() - start < timeout:
            elapsed = int(time.time() - start)
            try:
                result = self.query_upload_status(task_id)
                consecutive_errors = 0  # Reset on success
                status = result.get("status")
                last_status = status

                if status == 2:  # Success
                    return True
                elif status == 3:  # Failed
                    error_msg = result.get("msg", "Unknown error")
                    raise Exception(f"Upload to phone failed: {error_msg}")

                # Print progress every 5 seconds
                if verbose and elapsed - last_print >= 5:
                    status_text = {0: "queued", 1: "uploading", 2: "success", 3: "failed"}.get(status, f"unknown({status})")
                    print(f"    Upload status: {status_text} ({elapsed}s)")
                    last_print = elapsed

            except Exception as e:
                if "failed" in str(e).lower():
                    raise
                consecutive_errors += 1
                if verbose and elapsed - last_print >= 5:
                    print(f"    Upload check error ({consecutive_errors}x): {e} ({elapsed}s)")
                    last_print = elapsed
                # If we get too many consecutive errors, something is wrong
                if consecutive_errors >= 10:
                    raise Exception(f"Upload monitoring failed after {consecutive_errors} consecutive errors: {e}")

            time.sleep(2)

        raise Exception(f"Upload timeout after {timeout}s (last status: {last_status})")

    def set_root_status(self, phone_id, enable=True):
        """Enable or disable root on cloud phone"""
        return self._request("/open/v1/root/setStatus", {
            "ids": [phone_id],
            "open": enable
        })

    def one_click_new_device(self, phone_id, change_brand_model=False):
        """
        One-click new device - resets cloud phone and reinstalls system apps.
        This will wipe the phone and create fresh device environment.
        ADBKeyboard will be reinstalled as a proper system app.

        WARNING: This resets the phone completely - all data and apps will be lost!

        Args:
            phone_id: The cloud phone ID
            change_brand_model: Whether to randomize device brand/model (default False)
        """
        return self._request("/open/v2/phone/newOne", {
            "id": phone_id,
            "changeBrandModel": change_brand_model
        })


if __name__ == "__main__":
    client = GeelarkClient()

    # List first 5 phones
    result = client.list_phones(page_size=5)
    print(f"Total phones: {result['total']}")
    for phone in result["items"]:
        print(f"  {phone['serialName']} - Status: {phone['status']}")
</file>

<file path="geelark_uiautomator2_timeout_report.txt">
=======================================================================
GEELARK UiAutomator2 TIMEOUT REPORT
Date: 2025-12-12
=======================================================================

ISSUE SUMMARY:
--------------
Appium UiAutomator2 instrumentation process intermittently times out
when connecting to Geelark cloud phones. The same device works fine
on retry, suggesting an infrastructure issue rather than a configuration
problem.

KEY FINDING: Binary behavior - initialization takes either ~1 second
(success) OR times out completely at 90 seconds. No middle ground.

DEVICE INFO:
------------
- Phone: podclipcrafters (ID: 596445524454801543)
- ADB Address: 98.98.125.32:20671
- Android Version: 13 (API 33)
- Device Model: Pixel 7 Pro (Google)

APPIUM CONFIGURATION:
---------------------
- Appium Version: 3.1.2
- UiAutomator2 Driver: 6.7.0
- UiAutomator2 Server: 9.9.0
- uiautomator2ServerLaunchTimeout: 90000ms (90 seconds)

=======================================================================
TIMELINE OF EVENTS (Dec 12, 2025):
=======================================================================

[09:50:10] ATTEMPT 1 - FAILED (90s timeout)
-------------------------------------------
  - Session created: a385070c-0a7a-42bb-9ba2-73f2d38fb8f3
  - Device found: 98.98.125.32:20671 (state: device)
  - Settings APK installed successfully (711ms)
  - Forwarding port 6790 -> 8200
  - Sent instrumentation command:
    adb shell am instrument -w -e disableAnalytics true
    io.appium.uiautomator2.server.test/androidx.test.runner.AndroidJUnitRunner
  - Status check to http://127.0.0.1:8200/status
  - Received: "socket hang up"
  - Waited 90 seconds for UiAutomator2 to come online
  - TIMEOUT: "The instrumentation process cannot be initialized within 90000ms timeout"
  - Session deleted

[09:54:46] ATTEMPT 2 - SUCCESS (1.1s!)
--------------------------------------
  - Session created: feea5900-fc7d-43ae-97c5-cade0e3e11ab
  - Device found: 98.98.125.32:20671 (state: device)
  - Settings APK installed successfully (491ms)
  - Forwarding port 6790 -> 8200
  - Sent instrumentation command (same as attempt 1)
  - Initial "socket hang up" (expected - server starting)
  - Second status check: SUCCESS!
  - "The initialization of the instrumentation process took 1104ms"
  - Session ready, device info retrieved
  - Instrumentation output: "OK (1 test)" - exited cleanly

=======================================================================
GEELARK API RESPONSES (all successful):
=======================================================================

All Geelark API calls return code 0 (success):

1. /open/v1/phone/list - 200 OK (~700ms)
   Response: {"code":0,"msg":"success","data":{"total":200,...}}

2. /open/v1/phone/start - 200 OK (~860ms)
   Response: {"code":0,"msg":"success","data":{"totalAmount":1,"successAmount":1,...}}

3. /open/v1/phone/status - 200 OK (~630ms)
   Response: {"code":0,"msg":"success","data":{"totalAmount":1,"successAmount":1,"successDetails":[{"status":1}]}}

4. /open/v1/adb/setStatus - 200 OK (~770ms)
   Response: {"code":0,"msg":"success"}

5. /open/v1/adb/getData - 200 OK (~670ms)
   Response: {"code":0,"msg":"success","data":{"items":[{"code":0,"ip":"98.98.125.32","pwd":"e11826","port":"20671"}]}}

=======================================================================
APPIUM ERROR LOGS (from failed attempts):
=======================================================================

ERROR 1: Appium Settings App Timeout
------------------------------------
2025-12-12 09:55:48,122 DEBUG Remote response: status=500
data={"value":{"error":"unknown error",
  "message":"Appium Settings app is not running after 5000ms",
  "stacktrace":"UnknownError: Appium Settings app is not running after 5000ms
    at SettingsApp.requireRunning...
    at AndroidUiautomator2Driver.pushSettingsApp..."
}}

ERROR 2: glogin Session Lost During Operation
---------------------------------------------
2025-12-12 09:56:03,280 DEBUG Remote response: status=500
data={"value":{"error":"unknown error",
  "message":"Error getting device API level. Original error: The actual output
    'error: you should run glogin to login first' cannot be converted to an integer",
  "stacktrace":"...at ADB.getApiLevel..."
}}

This error indicates the ADB authentication (glogin) is being lost DURING
Appium's initialization, even though glogin succeeded initially.

=======================================================================
KEY OBSERVATIONS:
=======================================================================

1. BINARY BEHAVIOR: Works in ~1 second OR fails after 90 second timeout.
   There's no partial success or slow initialization - it's all or nothing.

2. API LAYER IS STABLE: All Geelark API endpoints work perfectly.
   - Phone starts successfully
   - Status checks return correct data
   - ADB data (ip, port, password) is retrieved correctly

3. GLOGIN AUTHENTICATION WORKS: Initial ADB connection succeeds.
   - `adb connect` works
   - `glogin` authentication succeeds
   - Device state shows as "device"

4. FAILURE POINT: During `am instrument` command execution.
   - The Android instrumentation service on the cloud phone
     either responds immediately or doesn't respond at all.

5. INTERMITTENT: Same device, same config - retry succeeds.
   - This rules out configuration issues
   - Suggests resource contention or tunnel instability

=======================================================================
POSSIBLE CAUSES (for Geelark investigation):
=======================================================================

1. Resource contention on the cloud phone (CPU/memory under load)
   - When busy, instrumentation service doesn't start
   - When idle, it starts immediately

2. ADB tunnel becoming unresponsive under load
   - Port forwarding (6790->8200) may not route packets
   - Could be network-level issue in the tunnel

3. glogin session being invalidated during heavy operations
   - The "you should run glogin to login first" error suggests
     the ADB session authentication expires mid-operation

4. Android instrumentation service throttling
   - Android may delay or block `am instrument` on cloud phones
   - Could be a battery/performance optimization feature

5. UiAutomator2 server process being killed by Android
   - System may be killing the instrumentation process
   - Could be due to memory pressure or security policy

=======================================================================
WORKAROUND IMPLEMENTED:
=======================================================================

- Auto-retry with 15-second delay between attempts
- Account-level cooldown after 3 consecutive failures
- Heartbeat monitoring to detect stuck processes

RETRY SUCCESS RATE: ~50-70% (most failures succeed on retry)

=======================================================================
REQUEST FOR GEELARK:
=======================================================================

Could you investigate why the `am instrument` command doesn't respond
on the first attempt but works on retry? Specifically:

1. Is there any resource throttling on cloud phones?
2. Are there logs on the Geelark side showing ADB tunnel issues?
3. Is there a way to "warm up" the instrumentation service?
4. Can the glogin session timeout be extended?

TRACE IDs from successful API calls (for correlation):
- 703501C36DB142719AD3C0FC9C15C5D6 (adb/getData)
- 1D616B0BC18E4992BF127AE36FCB9182 (adb/setStatus)
- 778AB4C90A824ACA8AD1992E72AE6DDD (phone/start)

=======================================================================
CONTACT:
--------
Please let me know if you need any additional logs or information
to help diagnose this issue.
=======================================================================
</file>

<file path="page_source_debug.xml">
<?xml version='1.0' encoding='UTF-8' standalone='yes' ?>
<hierarchy index="0" class="hierarchy" rotation="0" width="720" height="1344">
  <android.widget.FrameLayout index="0" package="com.android.launcher3" class="android.widget.FrameLayout" text="" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,0][720,1440]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="0" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6">
    <android.widget.LinearLayout index="0" package="com.android.launcher3" class="android.widget.LinearLayout" text="" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,0][720,1440]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="1" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6">
      <android.widget.FrameLayout index="0" package="com.android.launcher3" class="android.widget.FrameLayout" text="" resource-id="android:id/content" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,0][720,1440]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="2" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6">
        <android.widget.FrameLayout index="0" package="com.android.launcher3" class="android.widget.FrameLayout" text="" resource-id="com.android.launcher3:id/launcher" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,0][720,1440]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="1" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6">
          <android.widget.FrameLayout index="0" package="com.android.launcher3" class="android.widget.FrameLayout" text="" resource-id="com.android.launcher3:id/drag_layer" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,0][720,1440]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="1" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6">
            <android.view.View index="0" package="com.android.launcher3" class="android.view.View" text="" resource-id="com.android.launcher3:id/scrim_view" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,0][720,1440]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="6" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
            <android.widget.RelativeLayout index="1" package="com.android.launcher3" class="android.widget.RelativeLayout" text="" resource-id="com.android.launcher3:id/apps_view" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,0][720,1440]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="7" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6">
              <androidx.recyclerview.widget.RecyclerView index="0" package="com.android.launcher3" class="androidx.recyclerview.widget.RecyclerView" text="" resource-id="com.android.launcher3:id/apps_list_view" checkable="false" checked="false" clickable="false" enabled="true" focusable="true" focused="false" long-clickable="false" password="false" scrollable="true" selected="false" bounds="[0,126][720,1440]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="1" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6">
                <android.widget.TextView index="0" package="com.android.launcher3" class="android.widget.TextView" text="Appium Settings" content-desc="Appium Settings" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[22,175][191,415]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="1" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="1" package="com.android.launcher3" class="android.widget.TextView" text="Calculator" content-desc="Calculator" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[191,175][360,415]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="2" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="2" package="com.android.launcher3" class="android.widget.TextView" text="Calendar" content-desc="Calendar" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[360,175][529,415]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="3" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="3" package="com.android.launcher3" class="android.widget.TextView" text="Chrome" content-desc="Chrome" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[529,175][698,415]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="4" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="4" package="com.android.launcher3" class="android.widget.TextView" text="Clock" content-desc="Clock" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[22,415][191,655]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="5" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="5" package="com.android.launcher3" class="android.widget.TextView" text="Cloud phone service" content-desc="Cloud phone service" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[191,415][360,655]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="6" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="6" package="com.android.launcher3" class="android.widget.TextView" text="Contacts" content-desc="Contacts" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[360,415][529,655]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="7" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="7" package="com.android.launcher3" class="android.widget.TextView" text="Facebook" content-desc="Facebook" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[529,415][698,655]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="8" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="8" package="com.android.launcher3" class="android.widget.TextView" text="Files" content-desc="Files" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[22,655][191,895]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="9" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="9" package="com.android.launcher3" class="android.widget.TextView" text="Gallery" content-desc="Gallery" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[191,655][360,895]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="10" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="10" package="com.android.launcher3" class="android.widget.TextView" text="Instagram" content-desc="Instagram" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[360,655][529,895]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="11" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="11" package="com.android.launcher3" class="android.widget.TextView" text="Messaging" content-desc="Messaging" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[529,655][698,895]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="12" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="12" package="com.android.launcher3" class="android.widget.TextView" text="Open Camera" content-desc="Open Camera" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[22,895][191,1135]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="13" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="13" package="com.android.launcher3" class="android.widget.TextView" text="Phone" content-desc="Phone" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[191,895][360,1135]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="14" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="14" package="com.android.launcher3" class="android.widget.TextView" text="Play Games" content-desc="Play Games" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[360,895][529,1135]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="15" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="15" package="com.android.launcher3" class="android.widget.TextView" text="Play Store" content-desc="Play Store" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[529,895][698,1135]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="16" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="16" package="com.android.launcher3" class="android.widget.TextView" text="Search" content-desc="Search" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[22,1135][191,1375]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="17" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="17" package="com.android.launcher3" class="android.widget.TextView" text="Settings" content-desc="Settings" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[191,1135][360,1375]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="18" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="18" package="com.android.launcher3" class="android.widget.TextView" text="TikTok" content-desc="TikTok" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[360,1135][529,1375]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="19" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
                <android.widget.TextView index="19" package="com.android.launcher3" class="android.widget.TextView" text="YouTube" content-desc="YouTube" resource-id="com.android.launcher3:id/icon" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[529,1135][698,1375]" displayed="true" a11y-important="true" screen-reader-focusable="false" drawing-order="20" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
              </androidx.recyclerview.widget.RecyclerView>
              <android.widget.LinearLayout index="1" package="com.android.launcher3" class="android.widget.LinearLayout" text="" resource-id="com.android.launcher3:id/all_apps_header" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,126][720,195]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="2" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
              <android.widget.EditText index="2" package="com.android.launcher3" class="android.widget.EditText" text="  Search apps" resource-id="com.android.launcher3:id/search_container_all_apps" checkable="false" checked="false" clickable="true" enabled="true" focusable="true" focused="false" long-clickable="true" password="false" scrollable="false" selected="false" bounds="[53,87][666,165]" displayed="true" hint="  Search apps" a11y-important="true" screen-reader-focusable="false" input-type="532481" drawing-order="4" showing-hint="true" text-entry-key="false" multiline="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" max-text-length="5000" content-invalid="false" window-id="6" />
              <android.view.View index="4" package="com.android.launcher3" class="android.view.View" text="" resource-id="com.android.launcher3:id/fast_scroller" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[667,126][720,1440]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="3" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
            </android.widget.RelativeLayout>
            <android.view.View index="3" package="com.android.launcher3" class="android.view.View" text="" content-desc="Home" checkable="false" checked="false" clickable="false" enabled="true" focusable="false" focused="false" long-clickable="false" password="false" scrollable="false" selected="false" bounds="[0,48][720,1344]" displayed="true" a11y-important="false" screen-reader-focusable="false" drawing-order="1" showing-hint="false" text-entry-key="false" dismissable="false" a11y-focused="false" heading="false" live-region="0" context-clickable="false" content-invalid="false" window-id="6" />
          </android.widget.FrameLayout>
        </android.widget.FrameLayout>
      </android.widget.FrameLayout>
    </android.widget.LinearLayout>
  </android.widget.FrameLayout>
</hierarchy>
</file>

<file path="parallel_config.py">
"""
Parallel Worker Configuration for Multi-Process Appium Orchestration.

This module defines the configuration for running multiple posting workers
in parallel, each with its own isolated Appium server instance.

Architecture:
    - Each worker is a separate Python PROCESS (not thread)
    - Each worker gets its own Appium server on a unique port
    - Each worker gets a unique systemPort range for UiAutomator2
    - Workers communicate only via filesystem (CSV progress tracking)
    - No shared memory or threading - true process isolation

Port Allocation Strategy:
    - Appium ports: 4723, 4725, 4727, ... (odd numbers to avoid conflicts)
    - systemPort ranges: 8200-8209, 8210-8219, 8220-8229, ...
    - Each worker reserves 10 systemPorts for UiAutomator2 sessions
"""

import os
from dataclasses import dataclass, field
from typing import List, Optional

# Import centralized config for default values
from config import Config


@dataclass
class WorkerConfig:
    """Configuration for a single worker process."""
    worker_id: int
    appium_port: int
    system_port_start: int
    system_port_end: int
    log_file: str
    appium_log_file: str

    @property
    def system_port(self) -> int:
        """Get the primary systemPort for this worker."""
        return self.system_port_start

    @property
    def appium_url(self) -> str:
        """Get the Appium server URL for this worker."""
        return f"http://127.0.0.1:{self.appium_port}"

    def validate(self) -> None:
        """Validate this worker configuration."""
        if self.appium_port < 1024 or self.appium_port > 65535:
            raise ValueError(f"Worker {self.worker_id}: Invalid Appium port {self.appium_port}")
        if self.system_port_start < 1024 or self.system_port_end > 65535:
            raise ValueError(f"Worker {self.worker_id}: Invalid systemPort range")
        if self.system_port_start >= self.system_port_end:
            raise ValueError(f"Worker {self.worker_id}: systemPort start must be < end")


@dataclass
class ParallelConfig:
    """
    Configuration for the parallel posting orchestrator.

    Attributes:
        num_workers: Number of parallel worker processes to run
        workers: List of per-worker configurations
        progress_file: Path to the shared progress CSV (file-locked)
        logs_dir: Directory for worker and Appium logs
        shutdown_timeout: Seconds to wait for workers to finish on shutdown
        job_timeout: Maximum seconds for a single job before timeout
        delay_between_jobs: Seconds to wait between jobs (per worker)
        max_posts_per_account_per_day: Maximum successful posts per account per day (1-4)
        android_sdk_path: Path to Android SDK
        adb_path: Path to ADB executable
    """
    # Use centralized config for defaults
    num_workers: int = Config.DEFAULT_NUM_WORKERS
    workers: List[WorkerConfig] = field(default_factory=list)
    progress_file: str = Config.PROGRESS_FILE
    logs_dir: str = Config.LOGS_DIR
    shutdown_timeout: int = Config.SHUTDOWN_TIMEOUT
    job_timeout: int = Config.JOB_TIMEOUT
    delay_between_jobs: int = Config.DELAY_BETWEEN_JOBS
    max_posts_per_account_per_day: int = Config.MAX_POSTS_PER_ACCOUNT_PER_DAY
    max_attempts: int = Config.MAX_RETRY_ATTEMPTS
    retry_delay_minutes: float = Config.RETRY_DELAY_MINUTES
    android_sdk_path: str = Config.ANDROID_SDK_PATH
    adb_path: str = Config.ADB_PATH

    def __post_init__(self):
        """Generate worker configs if not provided."""
        if not self.workers:
            self.workers = self._generate_worker_configs(self.num_workers)
        self._validate()

    def _generate_worker_configs(self, n: int) -> List[WorkerConfig]:
        """
        Generate N worker configurations with non-overlapping resources.

        Port allocation:
            - Appium: 4723, 4725, 4727, ... (odd ports starting from 4723)
            - systemPort: 8200-8209, 8210-8219, 8220-8229, ...
        """
        configs = []
        base_appium_port = Config.APPIUM_BASE_PORT
        base_system_port = Config.SYSTEM_PORT_BASE
        system_port_range = Config.SYSTEM_PORT_RANGE

        for i in range(n):
            worker = WorkerConfig(
                worker_id=i,
                appium_port=base_appium_port + (i * 2),  # 4723, 4725, 4727...
                system_port_start=base_system_port + (i * system_port_range),
                system_port_end=base_system_port + (i * system_port_range) + system_port_range - 1,
                log_file=os.path.join(self.logs_dir, f"worker_{i}.log"),
                appium_log_file=os.path.join(self.logs_dir, f"appium_{i}.log"),
            )
            configs.append(worker)

        return configs

    def _validate(self) -> None:
        """Validate the entire configuration for conflicts."""
        # Validate max_posts_per_account_per_day
        if not 1 <= self.max_posts_per_account_per_day <= 4:
            raise ValueError(f"max_posts_per_account_per_day must be 1-4, got {self.max_posts_per_account_per_day}")

        # Validate each worker
        for worker in self.workers:
            worker.validate()

        # Check for Appium port conflicts
        appium_ports = [w.appium_port for w in self.workers]
        if len(appium_ports) != len(set(appium_ports)):
            raise ValueError("Duplicate Appium ports detected!")

        # Check for systemPort range overlaps
        for i, w1 in enumerate(self.workers):
            for j, w2 in enumerate(self.workers):
                if i >= j:
                    continue
                # Check if ranges overlap
                if (w1.system_port_start <= w2.system_port_end and
                    w2.system_port_start <= w1.system_port_end):
                    raise ValueError(
                        f"Worker {w1.worker_id} and {w2.worker_id} have overlapping systemPort ranges!"
                    )

    def get_worker(self, worker_id: int) -> WorkerConfig:
        """Get configuration for a specific worker."""
        for w in self.workers:
            if w.worker_id == worker_id:
                return w
        raise ValueError(f"Worker {worker_id} not found in configuration")

    def ensure_logs_dir(self) -> None:
        """Create logs directory if it doesn't exist."""
        os.makedirs(self.logs_dir, exist_ok=True)

    def get_env_vars(self) -> dict:
        """Get environment variables needed for Appium/ADB."""
        # Include npm global path for appium command
        npm_path = os.path.join(os.environ.get('APPDATA', ''), 'npm')
        return {
            'ANDROID_HOME': self.android_sdk_path,
            'ANDROID_SDK_ROOT': self.android_sdk_path,
            'PATH': os.pathsep.join([
                os.path.join(self.android_sdk_path, 'platform-tools'),
                npm_path,  # For appium command
                os.environ.get('PATH', '')
            ])
        }


# Default configuration for 3 workers
DEFAULT_CONFIG = ParallelConfig(num_workers=3)


def get_config(num_workers: int = 3) -> ParallelConfig:
    """Get a parallel configuration with the specified number of workers."""
    return ParallelConfig(num_workers=num_workers)


def print_config(config: ParallelConfig) -> None:
    """Print configuration summary."""
    print(f"\n{'='*60}")
    print(f"PARALLEL POSTING CONFIGURATION")
    print(f"{'='*60}")
    print(f"Workers: {config.num_workers}")
    print(f"Progress file: {config.progress_file}")
    print(f"Logs directory: {config.logs_dir}")
    print(f"Max posts per account per day: {config.max_posts_per_account_per_day}")
    print(f"Shutdown timeout: {config.shutdown_timeout}s")
    print(f"Job timeout: {config.job_timeout}s")
    print(f"\nWorker Allocations:")
    print(f"{'-'*60}")
    print(f"{'Worker':<8} {'Appium Port':<12} {'systemPort Range':<20} {'Log File'}")
    print(f"{'-'*60}")
    for w in config.workers:
        print(f"{w.worker_id:<8} {w.appium_port:<12} {w.system_port_start}-{w.system_port_end:<14} {w.log_file}")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    # Demo: print configuration for 1, 2, 3, and 5 workers
    for n in [1, 2, 3, 5]:
        config = get_config(n)
        print_config(config)
</file>

<file path="parallel_orchestrator.py">
"""
Parallel Posting Orchestrator - Main Entry Point.

This is the main script for running parallel posting workers. It:
1. Seeds the progress file from scheduler_state.json
2. Starts N worker processes (each with its own Appium server)
3. Monitors worker processes
4. Handles clean shutdown (Ctrl+C stops all workers and phones)

Usage:
    # Start 3 parallel workers
    python parallel_orchestrator.py --workers 3 --run

    # Check status
    python parallel_orchestrator.py --status

    # Stop all (kill any running workers and phones)
    python parallel_orchestrator.py --stop-all

    # Seed progress file without running
    python parallel_orchestrator.py --seed-only

Architecture:
    Orchestrator (this script)
        │
        ├── Worker 0 (subprocess) ──► Appium:4723 ──► Device
        ├── Worker 1 (subprocess) ──► Appium:4725 ──► Device
        └── Worker 2 (subprocess) ──► Appium:4727 ──► Device

    All workers read/write to: parallel_progress.csv (file-locked)
"""

import os
import sys
import time
import signal
import socket
import subprocess
import json
import argparse
import logging
import shutil
from datetime import datetime
from typing import List, Optional, Dict, Tuple

# Import centralized config and set up environment FIRST
from config import Config, setup_environment
setup_environment()

from parallel_config import ParallelConfig, get_config, print_config
from progress_tracker import ProgressTracker
from appium_server_manager import cleanup_all_appium_servers, check_all_appium_servers
from geelark_client import GeelarkClient


# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [ORCHESTRATOR] %(levelname)s %(message)s'
)
logger = logging.getLogger(__name__)

# Global state
_worker_processes: List[subprocess.Popen] = []
_shutdown_requested = False
_active_config: Optional[ParallelConfig] = None


def check_for_running_orchestrators() -> Tuple[bool, List[str]]:
    """
    Check if other orchestrator processes are running.

    CRITICAL: This must be called BEFORE starting any workers.
    Multiple orchestrators running simultaneously causes race conditions
    and can result in duplicate posts or accounts getting >1 post per day.

    Returns:
        (has_conflicts: bool, list of conflicting process descriptions)
    """
    current_pid = os.getpid()
    conflicts = []

    if sys.platform == 'win32':
        try:
            # Use WMIC to get command lines (tasklist doesn't show command line)
            result = subprocess.run(
                ['wmic', 'process', 'where', "name='python.exe'", 'get', 'processid,commandline'],
                capture_output=True, text=True, timeout=15
            )

            for line in result.stdout.split('\n'):
                line = line.strip()
                if not line or 'CommandLine' in line:
                    continue

                # Check if this is an orchestrator process
                if 'parallel_orchestrator.py' in line and '--run' in line:
                    # Extract PID (last numeric part of line)
                    parts = line.split()
                    pid = None
                    for part in reversed(parts):
                        if part.isdigit():
                            pid = int(part)
                            break

                    if pid and pid != current_pid:
                        conflicts.append(f"PID {pid}: parallel_orchestrator.py --run")

        except Exception as e:
            logger.warning(f"Could not check for running orchestrators: {e}")
    else:
        # Unix/Linux/Mac
        try:
            result = subprocess.run(
                ['ps', 'aux'],
                capture_output=True, text=True, timeout=10
            )

            for line in result.stdout.split('\n'):
                if 'parallel_orchestrator.py' in line and '--run' in line:
                    parts = line.split()
                    if len(parts) >= 2:
                        pid = int(parts[1])
                        if pid != current_pid:
                            conflicts.append(f"PID {pid}: parallel_orchestrator.py --run")

        except Exception as e:
            logger.warning(f"Could not check for running orchestrators: {e}")

    return len(conflicts) > 0, conflicts


def is_port_in_use(port: int) -> Tuple[bool, Optional[str]]:
    """
    Check if a port is in use.

    Returns:
        (in_use: bool, process_info: str or None)
    """
    # First try socket check
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.settimeout(1)
        result = s.connect_ex(('127.0.0.1', port))
        if result != 0:
            return False, None

    # Port is in use - try to find what's using it
    process_info = None
    if sys.platform == 'win32':
        try:
            result = subprocess.run(
                ['netstat', '-ano'],
                capture_output=True, text=True, timeout=10
            )
            for line in result.stdout.split('\n'):
                if f':{port}' in line and 'LISTENING' in line:
                    parts = line.split()
                    if parts:
                        pid = parts[-1]
                        # Get process name
                        name_result = subprocess.run(
                            ['tasklist', '/FI', f'PID eq {pid}', '/FO', 'CSV', '/NH'],
                            capture_output=True, text=True, timeout=5
                        )
                        if name_result.stdout.strip():
                            process_info = f"PID {pid}: {name_result.stdout.strip().split(',')[0].strip('\"')}"
                        else:
                            process_info = f"PID {pid}"
                        break
        except Exception:
            process_info = "unknown process"
    else:
        try:
            result = subprocess.run(
                ['lsof', '-ti', f':{port}'],
                capture_output=True, text=True, timeout=5
            )
            if result.stdout.strip():
                pid = result.stdout.strip().split('\n')[0]
                process_info = f"PID {pid}"
        except Exception:
            process_info = "unknown process"

    return True, process_info


def is_healthy_appium(port: int) -> bool:
    """Check if a healthy Appium server is running on the port."""
    try:
        from urllib.request import urlopen, Request
        from urllib.error import URLError
        import json as json_module

        url = f"http://127.0.0.1:{port}/status"
        req = Request(url, method='GET')
        with urlopen(req, timeout=3) as response:
            data = json_module.loads(response.read().decode())
            return data.get('value', {}).get('ready', False)
    except:
        return False


def check_ports_status(config: ParallelConfig) -> Tuple[List[str], List[str], List[str]]:
    """
    Check status of all required ports.

    Returns:
        (reusable_ports, blocked_ports, free_ports) - lists of status messages
    """
    reusable = []  # Ports with healthy Appium we can reuse
    blocked = []   # Ports in use by non-Appium processes
    free = []      # Ports that are free

    for worker in config.workers:
        port = worker.appium_port

        # First check if there's a healthy Appium
        if is_healthy_appium(port):
            reusable.append(f"Port {port} (Worker {worker.worker_id}): Healthy Appium - will REUSE")
        # Then check if port is in use by something else
        elif is_port_in_use(port)[0]:
            in_use, proc_info = is_port_in_use(port)
            msg = f"Port {port} (Worker {worker.worker_id}): BLOCKED"
            if proc_info:
                msg += f" by {proc_info}"
            blocked.append(msg)
        else:
            free.append(f"Port {port} (Worker {worker.worker_id}): Free - will START new Appium")

    return reusable, blocked, free


def check_all_ports_available(config: ParallelConfig) -> Tuple[bool, List[str]]:
    """
    Check if all required ports are available or reusable.

    Args:
        config: Parallel configuration

    Returns:
        (all_ok: bool, list of conflict messages)
    """
    reusable, blocked, free = check_ports_status(config)

    # Log the status
    for msg in reusable:
        logger.info(f"  {msg}")
    for msg in free:
        logger.info(f"  {msg}")
    for msg in blocked:
        logger.warning(f"  {msg}")

    # Only blocked ports are a problem
    return len(blocked) == 0, blocked


def kill_process_on_port(port: int) -> bool:
    """Kill whatever process is using a port."""
    if sys.platform == 'win32':
        try:
            result = subprocess.run(
                ['netstat', '-ano'],
                capture_output=True, text=True, timeout=10
            )
            for line in result.stdout.split('\n'):
                if f':{port}' in line and 'LISTENING' in line:
                    parts = line.split()
                    if parts:
                        pid = parts[-1]
                        if pid.isdigit():
                            subprocess.run(['taskkill', '/F', '/PID', pid],
                                         capture_output=True, timeout=10)
                            logger.info(f"Killed process on port {port} (PID {pid})")
                            return True
        except Exception as e:
            logger.warning(f"Error killing process on port {port}: {e}")
    else:
        try:
            result = subprocess.run(
                ['lsof', '-ti', f':{port}'],
                capture_output=True, text=True, timeout=5
            )
            for pid in result.stdout.strip().split('\n'):
                if pid.isdigit():
                    subprocess.run(['kill', '-9', pid], capture_output=True)
                    logger.info(f"Killed process on port {port} (PID {pid})")
                    return True
        except Exception as e:
            logger.warning(f"Error killing process on port {port}: {e}")
    return False


def ensure_ports_available(config: ParallelConfig, force_kill: bool = False) -> bool:
    """
    Ensure all required ports are available or have healthy Appium servers.

    Strategy:
    - Healthy Appium servers: REUSE (don't touch)
    - Blocked by other processes: KILL if force_kill=True
    - Free ports: OK (will start new Appium)

    Args:
        config: Parallel configuration
        force_kill: If True, kill processes blocking ports

    Returns:
        True if all ports are ready (reusable or free)
    """
    logger.info("Checking port status...")

    reusable, blocked, free = check_ports_status(config)

    # Log status
    for msg in reusable:
        logger.info(f"  {msg}")
    for msg in free:
        logger.info(f"  {msg}")

    if not blocked:
        logger.info("All ports ready!")
        return True

    # Report blocked ports
    logger.warning(f"Found {len(blocked)} blocked port(s):")
    for msg in blocked:
        logger.warning(f"  {msg}")

    if not force_kill:
        logger.error("Use --force-kill-ports to kill blocking processes")
        return False

    # Kill ONLY blocked ports (not healthy Appium)
    logger.info("Force killing blocked ports (healthy Appium will be preserved)...")
    for worker in config.workers:
        port = worker.appium_port
        # Only kill if blocked (not healthy Appium)
        if not is_healthy_appium(port) and is_port_in_use(port)[0]:
            kill_process_on_port(port)

    time.sleep(2)  # Give OS time to release ports

    # Verify
    reusable, blocked, free = check_ports_status(config)
    if blocked:
        logger.error("Some ports still blocked after killing processes:")
        for msg in blocked:
            logger.error(f"  - {msg}")
        return False

    logger.info("All ports now ready!")
    return True


def setup_signal_handlers():
    """Set up signal handlers for clean shutdown."""
    global _shutdown_requested

    def handle_signal(signum, frame):
        global _shutdown_requested, _active_config
        if not _shutdown_requested:
            _shutdown_requested = True
            logger.info(f"\nReceived signal {signum}, initiating graceful shutdown...")
            logger.info("Press Ctrl+C again to force kill")
        else:
            logger.warning("Force killing all processes...")
            force_kill_all(_active_config)
            sys.exit(1)

    if sys.platform == 'win32':
        signal.signal(signal.SIGBREAK, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)
    signal.signal(signal.SIGINT, handle_signal)


def stop_all_phones() -> int:
    """Stop all running Geelark phones."""
    logger.info("Stopping all running phones...")
    try:
        client = GeelarkClient()
        stopped = 0
        for page in range(1, 20):
            result = client.list_phones(page=page, page_size=100)
            for phone in result.get('items', []):
                if phone.get('status') == 1:
                    client.stop_phone(phone['id'])
                    logger.info(f"  Stopped: {phone.get('serialName', 'unknown')}")
                    stopped += 1
            if len(result.get('items', [])) < 100:
                break
        logger.info(f"Stopped {stopped} phone(s)")
        return stopped
    except Exception as e:
        logger.error(f"Error stopping phones: {e}")
        return 0


def kill_all_appium_ports(config: ParallelConfig) -> int:
    """Kill ALL processes on ALL Appium ports (regardless of health)."""
    killed = 0
    for worker in config.workers:
        port = worker.appium_port
        if is_port_in_use(port)[0]:
            if kill_process_on_port(port):
                killed += 1
    return killed


def disconnect_all_adb() -> None:
    """Disconnect all stale ADB connections."""
    logger.info("Disconnecting all ADB connections...")
    try:
        adb_path = Config.ADB_PATH  # Use centralized config
        if os.path.exists(adb_path):
            subprocess.run([adb_path, 'disconnect'], capture_output=True, timeout=10)
            logger.info("  ADB disconnected all")
    except Exception as e:
        logger.warning(f"Error disconnecting ADB: {e}")


def reset_day(progress_file: str, archive_dir: str = None) -> Tuple[bool, str]:
    """
    Reset for a new day by archiving the current progress file.

    CRITICAL: This is the ONLY safe way to start fresh for a new day.
    NEVER delete the progress file manually - use this command.

    The operation:
    1. Check for running orchestrators (refuse to reset if any are running)
    2. Archive current progress file to parallel_progress_YYYYMMDD.csv
    3. Create fresh progress CSV with headers only

    Args:
        progress_file: Path to progress CSV
        archive_dir: Optional directory for archives (default: same as progress file)

    Returns:
        (success: bool, message: str)
    """
    # Check for running orchestrators first
    has_conflicts, conflicts = check_for_running_orchestrators()
    if has_conflicts:
        return False, f"Cannot reset while orchestrator(s) running: {conflicts}"

    if not os.path.exists(progress_file):
        return False, f"Progress file not found: {progress_file}"

    # Determine archive directory
    if archive_dir is None:
        archive_dir = os.path.dirname(progress_file) or '.'

    # Compute archive filename with today's date
    today = datetime.now().strftime('%Y%m%d')
    base_name = os.path.splitext(os.path.basename(progress_file))[0]
    archive_name = f"{base_name}_{today}.csv"
    archive_path = os.path.join(archive_dir, archive_name)

    # Handle existing archive (add suffix)
    counter = 1
    while os.path.exists(archive_path):
        archive_name = f"{base_name}_{today}_{counter}.csv"
        archive_path = os.path.join(archive_dir, archive_name)
        counter += 1

    try:
        # Read final stats before archiving
        tracker = ProgressTracker(progress_file)
        stats = tracker.get_stats()
        logger.info(f"Archiving progress file with stats: {stats}")

        # Move (atomic rename where possible)
        shutil.move(progress_file, archive_path)
        logger.info(f"Archived to: {archive_path}")

        # Remove lock file if exists
        lock_file = progress_file + '.lock'
        if os.path.exists(lock_file):
            os.remove(lock_file)

        # Create fresh progress file with headers only
        with open(progress_file, 'w', encoding='utf-8', newline='') as f:
            import csv
            writer = csv.DictWriter(f, fieldnames=ProgressTracker.COLUMNS)
            writer.writeheader()
        logger.info(f"Created fresh progress file: {progress_file}")

        return True, f"Archived to {archive_path}, fresh progress file created"

    except Exception as e:
        return False, f"Reset failed: {e}"


def validate_progress_file(progress_file: str) -> bool:
    """
    Check if progress file is valid (not empty/corrupt).

    CRITICAL: This function NO LONGER deletes files automatically.
    The progress file is the daily ledger and must be preserved.
    If the file is empty or corrupt, operator must manually use --reset-day.

    Returns:
        True if file is valid or doesn't exist
        False if file exists but is empty/corrupt (DOES NOT DELETE - requires manual fix)
    """
    if not os.path.exists(progress_file):
        return True

    try:
        # Check file size first
        file_size = os.path.getsize(progress_file)
        if file_size == 0:
            logger.error(f"Progress file {progress_file} is empty (0 bytes). "
                        f"Use --reset-day to archive and create a fresh ledger.")
            return False

        import csv
        with open(progress_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            rows = list(reader)
            if len(rows) == 0:
                logger.error(f"Progress file {progress_file} has header but no data rows. "
                            f"Use --reset-day to archive and create a fresh ledger.")
                return False
        return True
    except Exception as e:
        logger.error(f"Progress file {progress_file} appears corrupt: {e}. "
                    f"Use --reset-day to archive and create a fresh ledger.")
        return False


def full_cleanup(config: ParallelConfig, release_claims: bool = True) -> None:
    """
    Complete cleanup of ALL resources.

    Call this:
    - At startup before any workers
    - On shutdown/Ctrl+C
    - On --stop-all command

    Cleans up:
    1. ALL running phones (they cost money!)
    2. ALL processes on Appium ports
    3. ALL stale ADB connections
    4. Empty/corrupt progress files
    5. Release stale claimed jobs back to pending
    """
    logger.info("="*60)
    logger.info("FULL CLEANUP - Freeing all resources")
    logger.info("="*60)

    # 1. Stop ALL phones first (they cost money!)
    phones_stopped = stop_all_phones()

    # 2. Kill ALL Appium port processes
    logger.info("Killing all processes on Appium ports...")
    ports_killed = kill_all_appium_ports(config)
    logger.info(f"  Killed {ports_killed} port process(es)")

    # 3. Disconnect stale ADB
    disconnect_all_adb()

    # 4. Validate progress file
    validate_progress_file(config.progress_file)

    # 5. Release any stale claimed jobs (workers crashed mid-job)
    if release_claims and os.path.exists(config.progress_file):
        try:
            tracker = ProgressTracker(config.progress_file)
            released = tracker.release_stale_claims(max_age_seconds=0)
            if released > 0:
                logger.info(f"  Released {released} stale claimed job(s) back to pending")
        except Exception as e:
            logger.warning(f"  Could not release stale claims: {e}")

    # Give OS time to release resources
    time.sleep(2)

    logger.info("="*60)
    logger.info(f"CLEANUP COMPLETE: {phones_stopped} phones stopped, {ports_killed} ports freed")
    logger.info("="*60)


def seed_progress_file(
    config: ParallelConfig,
    state_file: str = "scheduler_state.json",
    accounts_filter: List[str] = None
) -> int:
    """
    Seed the progress file from scheduler state.

    Args:
        config: Parallel config
        state_file: Path to scheduler_state.json
        accounts_filter: Optional list of accounts to include

    Returns:
        Number of jobs seeded
    """
    logger.info(f"Seeding progress file from {state_file}...")

    if not os.path.exists(state_file):
        logger.error(f"State file not found: {state_file}")
        return 0

    tracker = ProgressTracker(config.progress_file)

    # Check if progress file already exists with pending jobs
    if tracker.exists():
        stats = tracker.get_stats()
        if stats['pending'] > 0 or stats['claimed'] > 0:
            logger.warning(f"Progress file already has {stats['pending']} pending, {stats['claimed']} claimed jobs")
            logger.warning("Use --force-reseed to overwrite")
            return 0

    try:
        # redistribute=False preserves original job order and account assignments
        # Account-level locking in claim_next_job handles conflict prevention
        # Pass max_posts_per_account_per_day from config for daily limit enforcement
        count = tracker.seed_from_scheduler_state(
            state_file,
            accounts_filter,
            redistribute=False,
            max_posts_per_account_per_day=config.max_posts_per_account_per_day
        )
        logger.info(f"Seeded {count} jobs (max {config.max_posts_per_account_per_day} posts/account/day)")
        return count
    except Exception as e:
        logger.error(f"Error seeding: {e}")
        return 0


def start_worker_process(worker_id: int, config: ParallelConfig) -> subprocess.Popen:
    """Start a single worker subprocess."""
    cmd = [
        sys.executable,
        'parallel_worker.py',
        '--worker-id', str(worker_id),
        '--num-workers', str(config.num_workers),
        '--progress-file', config.progress_file,
        '--delay', str(config.delay_between_jobs)
    ]

    logger.info(f"Starting worker {worker_id}...")

    # Get environment with Android SDK
    env = os.environ.copy()
    env.update(config.get_env_vars())

    if sys.platform == 'win32':
        proc = subprocess.Popen(
            cmd,
            env=env,
            creationflags=subprocess.CREATE_NEW_PROCESS_GROUP
        )
    else:
        proc = subprocess.Popen(
            cmd,
            env=env,
            start_new_session=True
        )

    logger.info(f"Worker {worker_id} started with PID {proc.pid}")
    return proc


def start_all_workers(config: ParallelConfig) -> List[subprocess.Popen]:
    """Start all worker processes."""
    global _worker_processes

    processes = []
    for worker in config.workers:
        proc = start_worker_process(worker.worker_id, config)
        processes.append(proc)
        time.sleep(60)  # Stagger starts - 60s between workers for Geelark ADB setup to complete

    _worker_processes = processes
    return processes


def stop_all_workers(processes: List[subprocess.Popen], timeout: int = 30) -> None:
    """Stop all worker processes gracefully."""
    logger.info(f"Stopping {len(processes)} worker(s)...")

    # Send termination signal
    for proc in processes:
        if proc.poll() is None:
            try:
                if sys.platform == 'win32':
                    proc.send_signal(signal.CTRL_BREAK_EVENT)
                else:
                    proc.terminate()
            except Exception as e:
                logger.warning(f"Error signaling process {proc.pid}: {e}")

    # Wait for graceful shutdown
    deadline = time.time() + timeout
    while time.time() < deadline:
        all_done = all(proc.poll() is not None for proc in processes)
        if all_done:
            break
        time.sleep(1)

    # Force kill any remaining
    for proc in processes:
        if proc.poll() is None:
            logger.warning(f"Force killing worker PID {proc.pid}")
            proc.kill()

    logger.info("All workers stopped")


def force_kill_all(config: ParallelConfig = None):
    """Force kill all workers and cleanup all resources."""
    global _worker_processes

    # Kill all worker processes
    for proc in _worker_processes:
        if proc.poll() is None:
            try:
                proc.kill()
            except:
                pass

    # Full cleanup if we have config
    if config:
        full_cleanup(config)
    else:
        # Fallback: just stop phones and kill common ports
        stop_all_phones()
        for port in [4723, 4725, 4727, 4729, 4731]:
            kill_process_on_port(port)


def monitor_workers(processes: List[subprocess.Popen], config: ParallelConfig) -> None:
    """Monitor worker processes until all complete or shutdown requested."""
    global _shutdown_requested

    tracker = ProgressTracker(config.progress_file)

    logger.info("Monitoring workers... (Ctrl+C to stop)")

    last_status_time = 0
    status_interval = 30  # Print status every 30 seconds

    while not _shutdown_requested:
        # Check if all workers have exited
        all_done = all(proc.poll() is not None for proc in processes)
        if all_done:
            logger.info("All workers have exited")
            break

        # Print periodic status
        now = time.time()
        if now - last_status_time >= status_interval:
            stats = tracker.get_stats()
            active_workers = sum(1 for p in processes if p.poll() is None)
            logger.info(
                f"Status: {stats['success']} success, {stats['failed']} failed, "
                f"{stats['pending']} pending, {stats['claimed']} in-progress | "
                f"{active_workers}/{len(processes)} workers active"
            )
            last_status_time = now

        time.sleep(1)

    # If shutdown requested, stop workers
    if _shutdown_requested:
        stop_all_workers(processes, timeout=config.shutdown_timeout)


def show_status(config: ParallelConfig) -> None:
    """Show current status of progress and Appium servers."""
    print("\n" + "="*60)
    print("PARALLEL POSTING STATUS")
    print("="*60)

    # Progress stats
    tracker = ProgressTracker(config.progress_file)
    if tracker.exists():
        stats = tracker.get_stats()
        print(f"\nProgress ({config.progress_file}):")
        print(f"  Total jobs:  {stats['total']}")
        print(f"  Pending:     {stats['pending']}")
        print(f"  In-progress: {stats['claimed']}")
        print(f"  Retrying:    {stats.get('retrying', 0)}")
        print(f"  Success:     {stats['success']}")
        print(f"  Failed:      {stats['failed']}")

        if stats['success'] + stats['failed'] > 0:
            success_rate = stats['success'] / (stats['success'] + stats['failed']) * 100
            print(f"  Success rate: {success_rate:.1f}%")

        # Per-worker stats
        worker_stats = tracker.get_worker_stats()
        if worker_stats:
            print("\n  Per-worker:")
            for wid, ws in sorted(worker_stats.items()):
                print(f"    Worker {wid}: {ws['success']} success, {ws['failed']} failed")
    else:
        print(f"\nProgress file not found: {config.progress_file}")
        print("  Run with --seed-only or --run to create it")

    # Appium server status
    print("\nAppium Servers:")
    appium_status = check_all_appium_servers(config)
    for wid, status in sorted(appium_status.items()):
        state = "RUNNING" if status['healthy'] else "NOT RUNNING"
        print(f"  Worker {wid}: port {status['port']} - {state}")

    # Running phones
    print("\nGeelark Phones:")
    try:
        client = GeelarkClient()
        result = client.list_phones(page_size=100)
        running = [p for p in result.get('items', []) if p.get('status') == 1]
        if running:
            for phone in running:
                print(f"  RUNNING: {phone.get('serialName', 'unknown')}")
        else:
            print("  No phones currently running")
    except Exception as e:
        print(f"  Error checking phones: {e}")

    print("="*60 + "\n")


def run_parallel_posting(
    num_workers: int = 3,
    state_file: str = "scheduler_state.json",
    force_reseed: bool = False,
    force_kill_ports: bool = False,
    accounts: List[str] = None,
    retry_all_failed: bool = True,
    retry_include_non_retryable: bool = False
) -> Dict:
    """
    Main entry point to run parallel posting.

    Args:
        num_workers: Number of parallel workers
        state_file: Path to scheduler state file
        force_reseed: Force reseed progress file even if it exists
        force_kill_ports: Force kill processes blocking required ports
        accounts: List of accounts to use (required for distribution)

    Returns:
        Dict with results: {success_count, failed_count, ...}
    """
    global _active_config

    setup_signal_handlers()

    config = get_config(num_workers=num_workers)
    _active_config = config  # Store for signal handler

    # CRITICAL: Check for other running orchestrators BEFORE anything else
    # Multiple orchestrators = race conditions = duplicate posts
    logger.info("Checking for other running orchestrators...")
    has_conflicts, conflicts = check_for_running_orchestrators()
    if has_conflicts:
        logger.error("="*60)
        logger.error("CONFLICT: Other orchestrator processes are running!")
        logger.error("="*60)
        for conflict in conflicts:
            logger.error(f"  - {conflict}")
        logger.error("")
        logger.error("Running multiple orchestrators simultaneously causes:")
        logger.error("  - Race conditions in job claiming")
        logger.error("  - Duplicate posts to accounts")
        logger.error("  - Accounts exceeding daily post limits")
        logger.error("")
        logger.error("Please stop the other orchestrator(s) first, or use --stop-all")
        logger.error("="*60)
        return {'error': 'orchestrator_conflict', 'conflicts': conflicts}
    logger.info("No conflicting orchestrators found")

    print_config(config)

    # Ensure logs directory exists
    config.ensure_logs_dir()

    # FULL CLEANUP at startup - stop ALL phones, kill ALL ports, clear stale ADB
    # This ensures we start from a clean state every time
    full_cleanup(config)

    # Seed progress file
    tracker = ProgressTracker(config.progress_file)

    # CRITICAL: Retry all failed jobs from previous runs
    # This ensures jobs that failed before get another chance
    if retry_all_failed and tracker.exists():
        stats_before = tracker.get_stats()
        if stats_before['failed'] > 0:
            logger.info("="*60)
            logger.info("RETRYING FAILED JOBS FROM PREVIOUS RUNS")
            logger.info("="*60)
            count = tracker.retry_all_failed(include_non_retryable=retry_include_non_retryable)
            if count > 0:
                logger.info(f"Reset {count} failed jobs to RETRYING status")
            logger.info("="*60)

    if force_reseed and tracker.exists():
        logger.info("Force reseeding - removing existing progress file")
        os.remove(config.progress_file)
        if os.path.exists(config.progress_file + '.lock'):
            os.remove(config.progress_file + '.lock')

    if not tracker.exists() or force_reseed:
        if not accounts:
            logger.error("No accounts specified. Use --accounts phone1,phone2 to specify accounts")
            return {'error': 'no_accounts'}
        count = seed_progress_file(config, state_file, accounts)
        if count == 0:
            logger.error("No jobs to process. Check scheduler_state.json")
            return {'error': 'no_jobs'}

    # Show initial stats
    stats = tracker.get_stats()
    logger.info(f"Starting with {stats['pending']} pending jobs")

    # Start workers
    processes = start_all_workers(config)

    # Monitor until complete
    try:
        monitor_workers(processes, config)
    finally:
        # FULL CLEANUP on exit - stop phones, free ports, clear ADB
        full_cleanup(config)

    # Final stats
    final_stats = tracker.get_stats()
    logger.info("="*60)
    logger.info("FINAL RESULTS")
    logger.info(f"  Success:  {final_stats['success']}")
    logger.info(f"  Failed:   {final_stats['failed']}")
    logger.info(f"  Retrying: {final_stats.get('retrying', 0)}")
    logger.info(f"  Pending:  {final_stats['pending']}")
    logger.info("="*60)

    return final_stats


def main():
    """CLI entry point."""
    parser = argparse.ArgumentParser(
        description='Parallel Posting Orchestrator',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Run with 3 workers
  python parallel_orchestrator.py --workers 3 --run

  # Check current status
  python parallel_orchestrator.py --status

  # Stop everything
  python parallel_orchestrator.py --stop-all

  # Just seed progress file
  python parallel_orchestrator.py --seed-only
        """
    )

    parser.add_argument('--workers', '-w', type=int, default=3,
                        help='Number of parallel workers (default: 3)')
    parser.add_argument('--state-file', default='scheduler_state.json',
                        help='Path to scheduler state file')
    parser.add_argument('--run', action='store_true',
                        help='Run parallel posting')
    parser.add_argument('--status', action='store_true',
                        help='Show current status')
    parser.add_argument('--stop-all', action='store_true',
                        help='Stop all workers, Appium servers, and phones')
    parser.add_argument('--seed-only', action='store_true',
                        help='Only seed progress file, do not run')
    parser.add_argument('--force-reseed', action='store_true',
                        help='Force reseed progress file even if exists')
    parser.add_argument('--force-kill-ports', action='store_true',
                        help='Force kill processes blocking required ports')
    parser.add_argument('--accounts', '-a',
                        help='Comma-separated list of accounts to use (e.g., phone1,phone2)')
    parser.add_argument('--reset-day', action='store_true',
                        help='Archive current progress file and start fresh for new day')
    parser.add_argument('--retry-all-failed', action='store_true',
                        help='Reset all failed jobs back to retrying status (runs automatically with --run)')
    parser.add_argument('--retry-include-non-retryable', action='store_true',
                        help='When retrying, also include non-retryable errors (logged out, suspended, etc.)')

    args = parser.parse_args()

    # Parse accounts list if provided
    accounts_list = None
    if args.accounts:
        accounts_list = [a.strip() for a in args.accounts.split(',') if a.strip()]

    config = get_config(num_workers=args.workers)

    if args.reset_day:
        logger.info("="*60)
        logger.info("DAILY RESET - Archiving progress file for new day")
        logger.info("="*60)
        success, message = reset_day(config.progress_file)
        if success:
            logger.info(message)
            logger.info("Ready for new day. Run with --run to start posting.")
        else:
            logger.error(message)
            sys.exit(1)

    elif args.retry_all_failed:
        # Standalone retry-all-failed command
        if not os.path.exists(config.progress_file):
            logger.error(f"Progress file not found: {config.progress_file}")
            sys.exit(1)

        tracker = ProgressTracker(config.progress_file)
        stats_before = tracker.get_stats()
        logger.info(f"Current stats: {stats_before['failed']} failed, {stats_before.get('retrying', 0)} retrying")

        count = tracker.retry_all_failed(include_non_retryable=args.retry_include_non_retryable)
        if count > 0:
            stats_after = tracker.get_stats()
            logger.info(f"Reset {count} failed jobs to retrying status")
            logger.info(f"New stats: {stats_after['failed']} failed, {stats_after.get('retrying', 0)} retrying")
        else:
            logger.info("No failed jobs found to retry")

    elif args.status:
        show_status(config)

    elif args.stop_all:
        logger.info("Stopping everything...")
        full_cleanup(config)
        logger.info("Done")

    elif args.seed_only:
        count = seed_progress_file(config, args.state_file, accounts_list)
        if count > 0:
            logger.info(f"Progress file ready with {count} jobs")
        else:
            logger.error("Failed to seed progress file")
            sys.exit(1)

    elif args.run:
        # SAFETY CHECK: --force-reseed requires --reset-day to prevent accidental mid-day reseeds
        # that could result in duplicate posts or exceeded daily limits
        if args.force_reseed and os.path.exists(config.progress_file):
            logger.error("SAFETY: --force-reseed is not allowed when progress file exists!")
            logger.error("  The progress file is the daily ledger and tracks posting limits.")
            logger.error("  Reseeding mid-day can cause duplicate posts and exceed daily limits.")
            logger.error("")
            logger.error("  To start a new day: python parallel_orchestrator.py --reset-day")
            logger.error("  Then run normally without --force-reseed")
            sys.exit(1)

        results = run_parallel_posting(
            num_workers=args.workers,
            state_file=args.state_file,
            force_reseed=args.force_reseed,
            force_kill_ports=args.force_kill_ports,
            accounts=accounts_list,
            retry_all_failed=True,  # Always retry failed jobs on start
            retry_include_non_retryable=args.retry_include_non_retryable
        )
        if results.get('error'):
            sys.exit(1)

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
</file>

<file path="parallel_worker.py">
"""
Parallel Worker Process for Multi-Appium Posting.

This module implements a single worker process that:
1. Starts its own dedicated Appium server
2. Claims and processes jobs from the shared progress tracker
3. Uses the existing SmartInstagramPoster for actual posting
4. Handles clean shutdown on signals

Each worker is completely isolated - its own Appium server, own systemPort,
own log file. Workers only communicate via the file-locked progress CSV.

Usage (typically called by orchestrator):
    python parallel_worker.py --worker-id 0 --num-workers 3

Or programmatically:
    from parallel_worker import run_worker
    run_worker(worker_id=0, config=parallel_config)
"""

import os
import sys
import time
import signal
import logging
import argparse
import traceback
from datetime import datetime
from typing import Optional

# Import centralized config and set up environment FIRST
from config import Config, setup_environment
setup_environment()

import subprocess

from parallel_config import ParallelConfig, WorkerConfig, get_config
from appium_server_manager import AppiumServerManager, AppiumServerError
from progress_tracker import ProgressTracker
from geelark_client import GeelarkClient
# Import consolidated ADB helpers from device_connection
from device_connection import (
    wait_for_adb_device as wait_for_adb,
    is_adb_device_alive as ensure_device_alive,
    reconnect_adb_device as reconnect_adb
)


# Global flag for clean shutdown
_shutdown_requested = False


# Worker lifecycle states (for state machine approach)
class WorkerState:
    """
    Worker lifecycle states for the state machine approach.

    State transitions:
        STARTING -> ADB_PENDING -> ADB_READY -> APPIUM_READY -> JOB_RUNNING
        Any state -> ERROR_RECOVERY -> STARTING
        Any state -> SHUTDOWN
    """
    STARTING = 'starting'        # Worker initializing
    ADB_PENDING = 'adb_pending'  # Waiting for ADB device to appear
    ADB_READY = 'adb_ready'      # ADB device is connected
    APPIUM_READY = 'appium_ready'  # Appium session is ready
    JOB_RUNNING = 'job_running'  # Executing a posting job
    ERROR_RECOVERY = 'error_recovery'  # Handling errors, restarting
    SHUTDOWN = 'shutdown'        # Clean shutdown requested


# Note: wait_for_adb, ensure_device_alive, reconnect_adb are now imported
# from device_connection module (consolidated ADB helpers)


def setup_signal_handlers():
    """Set up signal handlers for clean shutdown."""
    global _shutdown_requested

    def handle_signal(signum, frame):
        global _shutdown_requested
        _shutdown_requested = True
        logging.info(f"Received signal {signum}, requesting shutdown...")

    if sys.platform == 'win32':
        signal.signal(signal.SIGBREAK, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)
    signal.signal(signal.SIGINT, handle_signal)


def setup_worker_logging(worker_config: WorkerConfig) -> logging.Logger:
    """Set up logging for this worker."""
    # Create logs directory
    os.makedirs(os.path.dirname(worker_config.log_file) or '.', exist_ok=True)

    # Create worker-specific logger
    logger = logging.getLogger(f"worker_{worker_config.worker_id}")
    logger.setLevel(logging.INFO)

    # File handler
    fh = logging.FileHandler(worker_config.log_file, encoding='utf-8')
    fh.setFormatter(logging.Formatter(
        f'%(asctime)s [W{worker_config.worker_id}] %(levelname)s %(message)s'
    ))
    logger.addHandler(fh)

    # Console handler
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter(
        f'%(asctime)s [Worker {worker_config.worker_id}] %(levelname)s %(message)s'
    ))
    logger.addHandler(ch)

    return logger


def stop_phone_by_name(phone_name: str, logger: logging.Logger) -> bool:
    """Stop a phone by its name."""
    try:
        client = GeelarkClient()
        result = client.list_phones(page_size=100)
        for phone in result.get('items', []):
            if phone.get('serialName') == phone_name and phone.get('status') == 1:
                client.stop_phone(phone['id'])
                logger.info(f"Stopped phone: {phone_name}")
                return True
        return False
    except Exception as e:
        logger.warning(f"Error stopping phone {phone_name}: {e}")
        return False


def kill_appium_sessions(appium_url: str, logger: logging.Logger):
    """Kill any existing sessions on this Appium server to prevent orphaned sessions."""
    import urllib.request
    import json

    try:
        # Get all sessions
        req = urllib.request.Request(f"{appium_url}/sessions", method='GET')
        with urllib.request.urlopen(req, timeout=5) as response:
            data = json.loads(response.read().decode())
            sessions = data.get('value', [])

            for session in sessions:
                session_id = session.get('id')
                if session_id:
                    try:
                        # Delete this session
                        del_req = urllib.request.Request(
                            f"{appium_url}/session/{session_id}",
                            method='DELETE'
                        )
                        urllib.request.urlopen(del_req, timeout=5)
                        logger.info(f"Killed orphaned Appium session: {session_id[:8]}...")
                    except Exception as e:
                        logger.debug(f"Failed to kill session {session_id[:8]}: {e}")
    except Exception as e:
        logger.debug(f"Could not check Appium sessions: {e}")


def execute_posting_job(
    job: dict,
    worker_config: WorkerConfig,
    config: ParallelConfig,
    logger: logging.Logger,
    tracker=None,
    worker_id: int = None
) -> tuple:
    """
    Execute a single posting job.

    Args:
        job: Job dict from progress tracker
        worker_config: This worker's configuration
        config: Overall parallel config
        logger: Logger instance
        tracker: ProgressTracker instance for verification
        worker_id: Worker ID for verification

    Returns:
        (success: bool, error_message: str)
    """
    # Import here to avoid circular imports and ensure ANDROID_HOME is set
    from post_reel_smart import SmartInstagramPoster

    account = job['account']
    video_path = job['video_path']
    caption = job['caption']
    job_id = job['job_id']

    # Kill any orphaned Appium sessions before starting (prevents session limit issues)
    kill_appium_sessions(worker_config.appium_url, logger)

    # SAFETY CHECK: Verify job is still valid before posting (prevents duplicates)
    if tracker and worker_id is not None:
        is_valid, error = tracker.verify_job_before_post(job_id, worker_id)
        if not is_valid:
            logger.warning(f"Job {job_id} failed pre-post verification: {error}")
            return False, f"Pre-post verification failed: {error}"

    logger.info(f"Starting job {job_id}: posting to {account}")
    logger.info(f"  Video: {video_path}")
    logger.info(f"  Caption: {caption[:50]}...")

    poster = None
    try:
        # Create poster with this worker's Appium URL and systemPort
        poster = SmartInstagramPoster(
            phone_name=account,
            system_port=worker_config.system_port,
            appium_url=worker_config.appium_url
        )

        # Connect to device
        logger.info(f"Connecting to device via {worker_config.appium_url}...")
        poster.connect()

        # Post the video
        logger.info("Posting video...")
        success = poster.post(video_path, caption, humanize=True)

        if success:
            logger.info(f"Job {job_id} completed successfully!")
            return True, ""
        else:
            error = poster.last_error_message or "Post returned False"
            logger.error(f"Job {job_id} failed: {error}")
            return False, error

    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        logger.error(f"Job {job_id} exception: {error_msg}")
        logger.debug(traceback.format_exc())
        return False, error_msg

    finally:
        # Always clean up
        try:
            if poster:
                poster.cleanup()
        except Exception as e:
            logger.warning(f"Cleanup error: {e}")

        # Always stop the phone
        stop_phone_by_name(account, logger)


def run_worker(
    worker_id: int,
    config: ParallelConfig,
    progress_file: str = None,
    delay_between_jobs: int = None
) -> dict:
    """
    Main worker loop.

    Args:
        worker_id: This worker's ID
        config: Parallel configuration
        progress_file: Override progress file path
        delay_between_jobs: Override delay between jobs

    Returns:
        Dict with worker stats: {jobs_completed, jobs_failed, ...}
    """
    global _shutdown_requested

    worker_config = config.get_worker(worker_id)
    logger = setup_worker_logging(worker_config)

    progress_file = progress_file or config.progress_file
    delay = delay_between_jobs if delay_between_jobs is not None else config.delay_between_jobs

    logger.info("="*60)
    logger.info(f"WORKER {worker_id} STARTING")
    logger.info(f"  Appium port: {worker_config.appium_port}")
    logger.info(f"  Appium URL: {worker_config.appium_url}")
    logger.info(f"  systemPort: {worker_config.system_port}")
    logger.info(f"  Progress file: {progress_file}")
    logger.info("="*60)

    # Stats tracking
    stats = {
        'worker_id': worker_id,
        'jobs_completed': 0,
        'jobs_failed': 0,
        'start_time': datetime.now().isoformat(),
        'end_time': None,
        'exit_reason': None
    }

    # Initialize progress tracker
    tracker = ProgressTracker(progress_file)

    # Start Appium server
    appium_manager = AppiumServerManager(worker_config, config)

    try:
        logger.info("Starting Appium server...")
        appium_manager.start(timeout=60)
        logger.info(f"Appium ready at {worker_config.appium_url}")

    except AppiumServerError as e:
        logger.error(f"Failed to start Appium: {e}")
        stats['exit_reason'] = f"Appium start failed: {e}"
        return stats

    try:
        # Main job processing loop
        while not _shutdown_requested:
            # Check if there are any remaining jobs
            progress_stats = tracker.get_stats()
            if progress_stats['pending'] == 0 and progress_stats['claimed'] == 0:
                logger.info("No more jobs to process, exiting")
                stats['exit_reason'] = "all_jobs_complete"
                break

            # Ensure Appium is healthy before each job
            # This will reuse existing healthy servers or restart if needed
            try:
                appium_manager.ensure_healthy()
            except AppiumServerError as e:
                logger.error(f"Appium health check failed: {e}")
                stats['exit_reason'] = f"Appium unhealthy: {e}"
                break

            # Release any stale claims (jobs claimed but never completed)
            released = tracker.release_stale_claims(max_age_seconds=600)
            if released > 0:
                logger.info(f"Released {released} stale job claims")

            # Try to claim a RETRY job first (jobs that failed but can be retried)
            job = tracker.claim_retry_job(worker_id, max_posts_per_account_per_day=config.max_posts_per_account_per_day)
            is_retry = job is not None

            if job is None:
                # No retry jobs, try to claim a regular pending job
                job = tracker.claim_next_job(worker_id, max_posts_per_account_per_day=config.max_posts_per_account_per_day)

            if job is None:
                # No jobs available - check if we should wait or exit
                # Also check for retrying jobs that might become ready
                retry_jobs = tracker.get_retry_jobs()
                if progress_stats['claimed'] > 0 or len(retry_jobs) > 0:
                    logger.debug(f"Waiting for jobs... (claimed: {progress_stats['claimed']}, retrying: {len(retry_jobs)})")
                    time.sleep(5)
                    continue
                else:
                    logger.info("No more jobs, exiting")
                    stats['exit_reason'] = "all_jobs_complete"
                    break

            # Execute the job
            job_id = job['job_id']
            attempt_info = f" (retry attempt {job.get('attempts', '?')})" if is_retry else ""
            logger.info(f"Processing job {job_id}{attempt_info}")

            try:
                success, error = execute_posting_job(
                    job, worker_config, config, logger,
                    tracker=tracker, worker_id=worker_id
                )

                if success:
                    tracker.update_job_status(job_id, 'success', worker_id)
                    stats['jobs_completed'] += 1
                else:
                    # Pass retry_delay_minutes for automatic retry handling
                    tracker.update_job_status(
                        job_id, 'failed', worker_id, error=error,
                        retry_delay_minutes=config.retry_delay_minutes
                    )
                    stats['jobs_failed'] += 1

            except Exception as e:
                error_msg = f"{type(e).__name__}: {str(e)}"
                logger.error(f"Unhandled exception processing job {job_id}: {error_msg}")
                tracker.update_job_status(
                    job_id, 'failed', worker_id, error=error_msg,
                    retry_delay_minutes=config.retry_delay_minutes
                )
                stats['jobs_failed'] += 1

            # Delay before next job
            if not _shutdown_requested and delay > 0:
                logger.info(f"Waiting {delay}s before next job...")
                time.sleep(delay)

        if _shutdown_requested:
            stats['exit_reason'] = "shutdown_requested"
            logger.info("Shutdown requested, stopping worker")

    finally:
        # Clean shutdown
        logger.info("Cleaning up...")

        # Stop Appium server
        try:
            appium_manager.stop()
        except Exception as e:
            logger.warning(f"Error stopping Appium: {e}")

        stats['end_time'] = datetime.now().isoformat()

        logger.info("="*60)
        logger.info(f"WORKER {worker_id} FINISHED")
        logger.info(f"  Jobs completed: {stats['jobs_completed']}")
        logger.info(f"  Jobs failed: {stats['jobs_failed']}")
        logger.info(f"  Exit reason: {stats['exit_reason']}")
        logger.info("="*60)

    return stats


def main():
    """CLI entry point for worker process."""
    parser = argparse.ArgumentParser(description='Parallel Posting Worker')
    parser.add_argument('--worker-id', type=int, required=True, help='Worker ID (0-indexed)')
    parser.add_argument('--num-workers', type=int, default=3, help='Total number of workers')
    parser.add_argument('--progress-file', default='parallel_progress.csv', help='Progress CSV file')
    parser.add_argument('--delay', type=int, default=10, help='Delay between jobs in seconds')

    args = parser.parse_args()

    # Set up signal handlers
    setup_signal_handlers()

    # Create config
    config = get_config(num_workers=args.num_workers)

    # Run worker
    stats = run_worker(
        worker_id=args.worker_id,
        config=config,
        progress_file=args.progress_file,
        delay_between_jobs=args.delay
    )

    # Exit with appropriate code
    if stats.get('exit_reason') == 'all_jobs_complete':
        sys.exit(0)
    elif stats.get('jobs_failed', 0) > 0 and stats.get('jobs_completed', 0) == 0:
        sys.exit(1)  # All jobs failed
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="phone_connector.py">
"""
Phone Connector - shared helper for phone connection in setup scripts.

This module provides a lightweight interface for the find→start→enable ADB→connect
flow used by setup scripts (setup_adbkeyboard.py, setup_clipboard_helper.py, etc.)

For full posting workflow with Appium, use DeviceConnectionManager instead.
"""
import subprocess
import time
from typing import Optional, Tuple

from config import Config
from geelark_client import GeelarkClient


ADB_PATH = Config.ADB_PATH


class PhoneConnector:
    """Lightweight helper for phone connection in setup scripts."""

    def __init__(self, geelark_client: GeelarkClient = None):
        """
        Initialize the connector.

        Args:
            geelark_client: Optional GeelarkClient instance (for dependency injection).
        """
        self.client = geelark_client or GeelarkClient()

    def find_phone(self, phone_name: str) -> Optional[dict]:
        """Find a phone by name or ID.

        Args:
            phone_name: Phone serial name or ID.

        Returns:
            Phone info dict with id, serialName, status, etc., or None if not found.
        """
        for page in range(1, 10):
            result = self.client.list_phones(page=page, page_size=100)
            for phone in result.get("items", []):
                if phone.get("serialName") == phone_name or phone.get("id") == phone_name:
                    return phone
            if len(result.get("items", [])) < 100:
                break
        return None

    def ensure_running(self, phone_id: str, timeout: int = 120) -> bool:
        """Ensure phone is running, start if needed.

        Args:
            phone_id: Phone ID from find_phone().
            timeout: Max seconds to wait for phone to start.

        Returns:
            True if phone is running.
        """
        # Check current status
        status_result = self.client.get_phone_status([phone_id])
        items = status_result.get("successDetails", [])
        if items and items[0].get("status") == 0:
            return True  # Already running

        # Start phone
        print("  Starting phone...")
        self.client.start_phone(phone_id)

        # Wait for ready
        deadline = time.time() + timeout
        while time.time() < deadline:
            time.sleep(2)
            status_result = self.client.get_phone_status([phone_id])
            items = status_result.get("successDetails", [])
            if items and items[0].get("status") == 0:
                print(f"    Phone ready")
                return True

        print(f"    Phone start timeout after {timeout}s")
        return False

    def connect_adb(self, phone_id: str) -> Tuple[str, str]:
        """Enable ADB and establish connection.

        Args:
            phone_id: Phone ID.

        Returns:
            Tuple of (device_string, password) e.g. ("192.168.1.1:5555", "abc123")

        Raises:
            Exception: If ADB cannot be enabled.
        """
        # Enable ADB
        print("  Enabling ADB...")
        self.client.enable_adb(phone_id)
        time.sleep(5)

        # Get ADB info
        adb_info = self.client.get_adb_info(phone_id)
        if not adb_info or not adb_info.get('ip') or not adb_info.get('port'):
            raise Exception("Failed to get ADB info")

        device = f"{adb_info['ip']}:{adb_info['port']}"
        password = adb_info.get('pwd', '')

        # Connect via ADB
        print(f"  Connecting to {device}...")
        subprocess.run([ADB_PATH, "connect", device], capture_output=True)
        time.sleep(1)

        # Authenticate with glogin
        if password:
            result = subprocess.run(
                [ADB_PATH, "-s", device, "shell", f"glogin {password}"],
                capture_output=True, encoding='utf-8', errors='replace', timeout=30
            )
            login_result = result.stdout.strip() if result.stdout else ""
            print(f"  Login: {login_result or 'OK'}")

        return device, password

    def setup_for_adb(self, phone_name: str) -> Tuple['GeelarkClient', str, str, str]:
        """Full setup flow: find → start → connect ADB.

        This is the main convenience method for setup scripts.

        Args:
            phone_name: Phone serial name.

        Returns:
            Tuple of (client, phone_id, device_string, password)

        Raises:
            Exception: If phone not found or setup fails.
        """
        # Find phone
        print(f"Finding phone: {phone_name}")
        phone = self.find_phone(phone_name)
        if not phone:
            raise Exception(f"Phone not found: {phone_name}")

        phone_id = phone["id"]
        print(f"  Found: {phone.get('serialName')} (Status: {phone.get('status')})")

        # Ensure running
        if phone.get("status") != 0:
            if not self.ensure_running(phone_id):
                raise Exception(f"Failed to start phone: {phone_name}")
            time.sleep(5)

        # Connect ADB
        device, password = self.connect_adb(phone_id)

        return self.client, phone_id, device, password


def adb_shell(device: str, cmd: str, timeout: int = 30) -> str:
    """Run ADB shell command on a device.

    Convenience function for setup scripts.

    Args:
        device: Device string (e.g., "192.168.1.1:5555")
        cmd: Shell command to run.
        timeout: Command timeout in seconds.

    Returns:
        Command output as string.
    """
    result = subprocess.run(
        [ADB_PATH, "-s", device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def adb_install(device: str, apk_path: str, timeout: int = 120) -> str:
    """Install APK on a device.

    Convenience function for setup scripts.

    Args:
        device: Device string.
        apk_path: Path to APK file.
        timeout: Installation timeout in seconds.

    Returns:
        Installation output.
    """
    result = subprocess.run(
        [ADB_PATH, "-s", device, "install", "-r", apk_path],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""
</file>

<file path="post_gui.py">
"""
Simple GUI to monitor Instagram posting progress.
Shows real-time output from post_reel_smart.py
"""
import sys
import os

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

import tkinter as tk
from tkinter import ttk, scrolledtext, filedialog, messagebox
import subprocess
import threading
import queue
import csv


class PostingMonitor:
    def __init__(self, root):
        self.root = root
        self.root.title("Instagram Posting Monitor")
        self.root.geometry("900x700")

        self.process = None
        self.output_queue = queue.Queue()

        self.setup_ui()
        self.load_csv_data()

    def setup_ui(self):
        # Main frame
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.pack(fill=tk.BOTH, expand=True)

        # Top section - Configuration
        config_frame = ttk.LabelFrame(main_frame, text="Configuration", padding="10")
        config_frame.pack(fill=tk.X, pady=(0, 10))

        # Phone selection
        ttk.Label(config_frame, text="Phone:").grid(row=0, column=0, sticky=tk.W, padx=5)
        self.phone_var = tk.StringVar(value="miccliparchive")
        phone_combo = ttk.Combobox(config_frame, textvariable=self.phone_var, width=20)
        phone_combo['values'] = ('miccliparchive', 'reelwisdompod_', 'podmindstudio', 'talktrackhub')
        phone_combo.grid(row=0, column=1, sticky=tk.W, padx=5)

        # Video selection
        ttk.Label(config_frame, text="Video:").grid(row=0, column=2, sticky=tk.W, padx=5)
        self.video_var = tk.StringVar()
        self.video_combo = ttk.Combobox(config_frame, textvariable=self.video_var, width=50)
        self.video_combo.grid(row=0, column=3, sticky=tk.W, padx=5)
        self.video_combo.bind('<<ComboboxSelected>>', self.on_video_selected)

        # Caption display
        caption_frame = ttk.LabelFrame(main_frame, text="Caption", padding="10")
        caption_frame.pack(fill=tk.X, pady=(0, 10))

        self.caption_text = scrolledtext.ScrolledText(caption_frame, height=4, wrap=tk.WORD)
        self.caption_text.pack(fill=tk.X)

        # Status section
        status_frame = ttk.LabelFrame(main_frame, text="Status", padding="10")
        status_frame.pack(fill=tk.X, pady=(0, 10))

        self.status_var = tk.StringVar(value="Ready")
        self.status_label = ttk.Label(status_frame, textvariable=self.status_var, font=('Arial', 12, 'bold'))
        self.status_label.pack(side=tk.LEFT)

        self.progress = ttk.Progressbar(status_frame, mode='indeterminate', length=200)
        self.progress.pack(side=tk.RIGHT, padx=10)

        # Buttons
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill=tk.X, pady=(0, 10))

        self.start_btn = ttk.Button(button_frame, text="Start Posting", command=self.start_posting)
        self.start_btn.pack(side=tk.LEFT, padx=5)

        self.stop_btn = ttk.Button(button_frame, text="Stop", command=self.stop_posting, state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=5)

        ttk.Button(button_frame, text="Clear Log", command=self.clear_log).pack(side=tk.LEFT, padx=5)

        ttk.Button(button_frame, text="Reload CSV", command=self.load_csv_data).pack(side=tk.RIGHT, padx=5)

        # Log output
        log_frame = ttk.LabelFrame(main_frame, text="Log Output", padding="10")
        log_frame.pack(fill=tk.BOTH, expand=True)

        self.log_text = scrolledtext.ScrolledText(log_frame, height=20, wrap=tk.WORD,
                                                   font=('Consolas', 10))
        self.log_text.pack(fill=tk.BOTH, expand=True)

        # Configure tags for colored output
        self.log_text.tag_config('info', foreground='black')
        self.log_text.tag_config('success', foreground='green')
        self.log_text.tag_config('error', foreground='red')
        self.log_text.tag_config('step', foreground='blue')
        self.log_text.tag_config('action', foreground='purple')

    def load_csv_data(self):
        """Load video/caption data from CSV"""
        csv_path = r'C:\Users\asus\Desktop\projects\geelark-automation\chunk_01a\chunk_01a.csv'
        self.posts = []

        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    original_path = row.get('Shortcode', '').strip()
                    if not original_path:
                        continue

                    # Replace spoofed with chunk_01a
                    video_path = original_path.replace('spoofed', 'chunk_01a')

                    if os.path.exists(video_path):
                        caption = row.get('Text', '').strip()
                        # Extract short name from path
                        short_name = os.path.basename(video_path)
                        folder = os.path.basename(os.path.dirname(video_path))
                        display_name = f"{folder}/{short_name}"

                        self.posts.append({
                            'display': display_name,
                            'path': video_path,
                            'caption': caption
                        })

            # Update combobox
            self.video_combo['values'] = [p['display'] for p in self.posts]
            if self.posts:
                self.video_combo.current(0)
                self.on_video_selected(None)

            self.log(f"Loaded {len(self.posts)} videos from CSV", 'success')

        except Exception as e:
            self.log(f"Error loading CSV: {e}", 'error')

    def on_video_selected(self, event):
        """Update caption when video is selected"""
        idx = self.video_combo.current()
        if 0 <= idx < len(self.posts):
            self.caption_text.delete('1.0', tk.END)
            self.caption_text.insert('1.0', self.posts[idx]['caption'])

    def log(self, message, tag='info'):
        """Add message to log"""
        self.log_text.insert(tk.END, message + '\n', tag)
        self.log_text.see(tk.END)

    def clear_log(self):
        """Clear the log"""
        self.log_text.delete('1.0', tk.END)

    def start_posting(self):
        """Start the posting process"""
        idx = self.video_combo.current()
        if idx < 0 or idx >= len(self.posts):
            messagebox.showerror("Error", "Please select a video")
            return

        post = self.posts[idx]
        phone = self.phone_var.get()

        self.log(f"\n{'='*50}", 'info')
        self.log(f"Starting post to {phone}", 'step')
        self.log(f"Video: {post['path']}", 'info')
        self.log(f"Caption: {post['caption'][:100]}...", 'info')
        self.log(f"{'='*50}\n", 'info')

        # Disable start, enable stop
        self.start_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.NORMAL)
        self.progress.start()
        self.status_var.set("Connecting...")

        # Run in background thread
        self.running = True
        thread = threading.Thread(target=self.run_posting, args=(phone, post['path'], post['caption']))
        thread.daemon = True
        thread.start()

        # Start checking output
        self.check_output()

    def run_posting(self, phone, video_path, caption):
        """Run the posting script in a subprocess"""
        try:
            script_path = os.path.join(os.path.dirname(__file__), 'post_reel_smart.py')

            self.process = subprocess.Popen(
                [sys.executable, '-u', script_path, phone, video_path, caption],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                encoding='utf-8',
                errors='replace',
                bufsize=1,
                cwd=os.path.dirname(__file__)
            )

            # Read output line by line
            for line in iter(self.process.stdout.readline, ''):
                if not self.running:
                    break
                self.output_queue.put(line.rstrip())

            self.process.wait()
            exit_code = self.process.returncode

            if exit_code == 0:
                self.output_queue.put(('SUCCESS', 'Post completed successfully!'))
            else:
                self.output_queue.put(('FAILED', f'Post failed with exit code {exit_code}'))

        except Exception as e:
            self.output_queue.put(('ERROR', str(e)))
        finally:
            self.output_queue.put(('DONE', None))

    def check_output(self):
        """Check for new output from the subprocess"""
        try:
            while True:
                item = self.output_queue.get_nowait()

                if isinstance(item, tuple):
                    msg_type, msg = item
                    if msg_type == 'DONE':
                        self.posting_finished()
                        return
                    elif msg_type == 'SUCCESS':
                        self.log(f"\n{msg}", 'success')
                        self.status_var.set("SUCCESS!")
                    elif msg_type == 'FAILED':
                        self.log(f"\n{msg}", 'error')
                        self.status_var.set("FAILED")
                    elif msg_type == 'ERROR':
                        self.log(f"\nERROR: {msg}", 'error')
                        self.status_var.set("ERROR")
                else:
                    # Regular log line
                    line = item

                    # Color code based on content
                    if '--- Step' in line:
                        self.log(line, 'step')
                        # Update status with step number
                        self.status_var.set(line.strip('- '))
                    elif '[TAP]' in line or 'Action:' in line:
                        self.log(line, 'action')
                    elif '[SUCCESS]' in line or '[OK]' in line:
                        self.log(line, 'success')
                    elif '[ERROR]' in line or '[FAIL]' in line or 'ERROR' in line:
                        self.log(line, 'error')
                    elif 'Uploading' in line or 'Connecting' in line or 'Opening' in line:
                        self.log(line, 'step')
                        self.status_var.set(line.strip())
                    else:
                        self.log(line, 'info')

        except queue.Empty:
            pass

        # Schedule next check
        if self.running:
            self.root.after(100, self.check_output)

    def posting_finished(self):
        """Called when posting is complete"""
        self.running = False
        self.process = None
        self.start_btn.config(state=tk.NORMAL)
        self.stop_btn.config(state=tk.DISABLED)
        self.progress.stop()

    def stop_posting(self):
        """Stop the posting process"""
        self.running = False
        if self.process:
            self.process.terminate()
            self.log("\nPosting stopped by user", 'error')
            self.status_var.set("Stopped")
        self.posting_finished()


def main():
    root = tk.Tk()
    app = PostingMonitor(root)
    root.mainloop()


if __name__ == "__main__":
    main()
</file>

<file path="post_reel_smart.py">
"""
Post a video to Instagram Reels via Geelark cloud phone.
Uses uiautomator dump + Claude analysis for flexible navigation.

Usage:
    python post_reel_smart.py <phone_name> <video_path> <caption>
"""
import sys
import os

# Fix Windows console encoding for emojis
if sys.platform == 'win32':
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')

# Import centralized config and set up environment FIRST
from config import Config, setup_environment
setup_environment()

import time
import re
import json
import random
import xml.etree.ElementTree as ET
import anthropic
from geelark_client import GeelarkClient

# Appium imports
from appium import webdriver
from appium.options.android import UiAutomator2Options
from appium.webdriver.common.appiumby import AppiumBy

# Device connection management (extracted for better separation)
from device_connection import DeviceConnectionManager
# AI analysis (extracted for better separation)
from claude_analyzer import ClaudeUIAnalyzer
# UI interactions (extracted for better separation)
from appium_ui_controller import AppiumUIController

# Use centralized paths and screen coordinates
APPIUM_SERVER = Config.DEFAULT_APPIUM_URL

# Screen coordinates from centralized config
SCREEN_CENTER_X = Config.SCREEN_CENTER_X
SCREEN_CENTER_Y = Config.SCREEN_CENTER_Y
FEED_TOP_Y = Config.FEED_TOP_Y
FEED_BOTTOM_Y = Config.FEED_BOTTOM_Y
REELS_TOP_Y = Config.REELS_TOP_Y
REELS_BOTTOM_Y = Config.REELS_BOTTOM_Y
NOTIFICATIONS_TOP_Y = Config.NOTIFICATIONS_TOP_Y
STORY_NEXT_TAP_X = Config.STORY_NEXT_TAP_X
SWIPE_DURATION_FAST = Config.SWIPE_DURATION_FAST
SWIPE_DURATION_SLOW = Config.SWIPE_DURATION_SLOW
SWIPE_DURATION_MAX = Config.SWIPE_DURATION_MAX


class SmartInstagramPoster:
    def __init__(self, phone_name, system_port=8200, appium_url=None):
        # Use DeviceConnectionManager for all connection lifecycle
        self._conn = DeviceConnectionManager(
            phone_name=phone_name,
            system_port=system_port,
            appium_url=appium_url or APPIUM_SERVER
        )
        # Expose client for compatibility
        self.client = self._conn.client
        # AI analyzer for UI analysis (extracted for better separation)
        self._analyzer = ClaudeUIAnalyzer()
        self.anthropic = self._analyzer.client  # For backwards compatibility
        self.phone_name = phone_name
        # UI controller (created lazily when Appium is connected)
        self._ui_controller = None
        # State tracking
        self.video_uploaded = False
        self.caption_entered = False
        self.share_clicked = False
        # Error tracking
        self.last_error_type = None
        self.last_error_message = None
        self.last_screenshot_path = None

    # Properties to expose connection state for compatibility
    @property
    def phone_id(self):
        return self._conn.phone_id

    @phone_id.setter
    def phone_id(self, value):
        self._conn.phone_id = value

    @property
    def device(self):
        return self._conn.device

    @device.setter
    def device(self, value):
        self._conn.device = value

    @property
    def appium_driver(self):
        return self._conn.appium_driver

    @appium_driver.setter
    def appium_driver(self, value):
        self._conn.appium_driver = value

    @property
    def system_port(self):
        return self._conn.system_port

    @property
    def appium_url(self):
        return self._conn.appium_url

    @property
    def ui_controller(self):
        """Get or create the UI controller (requires Appium to be connected)."""
        if self._ui_controller is None and self.appium_driver is not None:
            self._ui_controller = AppiumUIController(self.appium_driver)
        return self._ui_controller

    def adb(self, cmd, timeout=30):
        """Run ADB shell command - delegates to DeviceConnectionManager"""
        return self._conn.adb_command(cmd, timeout=timeout)

    def is_uiautomator2_crash(self, exception):
        """Check if exception indicates UiAutomator2 crashed on device"""
        return self._conn.is_uiautomator2_crash(exception)

    def reconnect_appium(self):
        """Reconnect Appium driver after UiAutomator2 crash"""
        # Reset UI controller since driver is being replaced
        self._ui_controller = None
        return self._conn.reconnect_appium()

    def tap(self, x, y):
        """Tap at coordinates using Appium - delegates to AppiumUIController"""
        if self.ui_controller:
            self.ui_controller.tap(x, y)
        else:
            raise Exception("Appium driver not connected - cannot tap")

    def swipe(self, x1, y1, x2, y2, duration_ms=300):
        """Swipe from one point to another - delegates to AppiumUIController"""
        if self.ui_controller:
            self.ui_controller.swipe(x1, y1, x2, y2, duration_ms)
        else:
            raise Exception("Appium driver not connected - cannot swipe")

    def press_key(self, keycode):
        """Press a key - delegates to AppiumUIController"""
        if self.ui_controller:
            self.ui_controller.press_key(keycode)
        else:
            raise Exception("Appium driver not connected - cannot press key")

    def random_delay(self, min_sec=0.5, max_sec=2.0):
        """Random delay between actions to appear more human"""
        delay = random.uniform(min_sec, max_sec)
        time.sleep(delay)

    def _humanize_scroll_feed(self):
        """Scroll through the feed randomly. Returns True if action performed."""
        print("  - Scrolling feed...")
        scroll_count = random.randint(1, 3)
        for _ in range(scroll_count):
            self.swipe(SCREEN_CENTER_X, FEED_BOTTOM_Y, SCREEN_CENTER_X, FEED_TOP_Y, random.randint(SWIPE_DURATION_SLOW, SWIPE_DURATION_MAX))
            self.random_delay(1.0, 3.0)
        # Scroll back up sometimes
        if random.random() < 0.3:
            self.swipe(SCREEN_CENTER_X, FEED_TOP_Y, SCREEN_CENTER_X, FEED_BOTTOM_Y, SWIPE_DURATION_FAST)
            self.random_delay(0.5, 1.5)
        return True

    def _humanize_view_story(self):
        """View stories randomly. Returns True if action performed."""
        print("  - Viewing a story...")
        elements, _ = self.dump_ui()
        story_elements = [e for e in elements if 'story' in e.get('desc', '').lower() and 'unseen' in e.get('desc', '').lower()]
        if not story_elements:
            return False

        story = random.choice(story_elements)
        self.tap(story['center'][0], story['center'][1])
        view_time = random.uniform(3, 8)
        print(f"    Watching for {view_time:.1f}s...")
        time.sleep(view_time)
        # Tap through a few more stories sometimes
        if random.random() < 0.5:
            for _ in range(random.randint(1, 3)):
                self.tap(STORY_NEXT_TAP_X, SCREEN_CENTER_Y)  # Tap right side to skip to next story
                time.sleep(random.uniform(2, 5))
        # Go back
        self.press_key('KEYCODE_BACK')
        self.random_delay(1.0, 2.0)
        return True

    def _humanize_scroll_reels(self):
        """Browse reels randomly. Returns True if action performed."""
        print("  - Browsing reels...")
        elements, _ = self.dump_ui()
        reels_tab = [e for e in elements if 'reels' in e.get('desc', '').lower() and e['clickable']]
        if not reels_tab:
            return False

        self.tap(reels_tab[0]['center'][0], reels_tab[0]['center'][1])
        self.random_delay(2.0, 4.0)
        # Watch a few reels
        for _ in range(random.randint(1, 3)):
            watch_time = random.uniform(3, 10)
            print(f"    Watching reel for {watch_time:.1f}s...")
            time.sleep(watch_time)
            # Sometimes double-tap to like
            if random.random() < 0.15:
                print("    Double-tap like!")
                self.tap(SCREEN_CENTER_X, SCREEN_CENTER_Y)
                time.sleep(0.1)
                self.tap(SCREEN_CENTER_X, SCREEN_CENTER_Y)
                self.random_delay(0.5, 1.0)
            # Swipe to next reel
            self.swipe(SCREEN_CENTER_X, REELS_BOTTOM_Y, SCREEN_CENTER_X, REELS_TOP_Y, SWIPE_DURATION_SLOW)
            self.random_delay(0.5, 1.5)
        # Go back to home
        elements, _ = self.dump_ui()
        home_tab = [e for e in elements if 'home' in e.get('desc', '').lower() and e['clickable']]
        if home_tab:
            self.tap(home_tab[0]['center'][0], home_tab[0]['center'][1])
        self.random_delay(1.0, 2.0)
        return True

    def _humanize_check_notifications(self):
        """Check notifications randomly. Returns True if action performed."""
        print("  - Checking notifications...")
        elements, _ = self.dump_ui()
        notif_btn = [e for e in elements if ('notification' in e.get('desc', '').lower() or 'activity' in e.get('desc', '').lower()) and e['clickable']]
        if not notif_btn:
            return False

        self.tap(notif_btn[0]['center'][0], notif_btn[0]['center'][1])
        self.random_delay(2.0, 4.0)
        # Scroll through notifications
        if random.random() < 0.5:
            self.swipe(SCREEN_CENTER_X, NOTIFICATIONS_TOP_Y, SCREEN_CENTER_X, FEED_TOP_Y, SWIPE_DURATION_FAST)
            self.random_delay(1.0, 2.0)
        # Go back
        self.press_key('KEYCODE_BACK')
        self.random_delay(1.0, 2.0)
        return True

    def humanize_before_post(self):
        """Perform random human-like actions before posting"""
        print("\n[HUMANIZE] Performing random actions before posting...")
        actions_done = 0
        max_actions = random.randint(2, 4)

        # Dispatch table for humanize actions
        action_handlers = {
            'scroll_feed': self._humanize_scroll_feed,
            'view_story': self._humanize_view_story,
            'scroll_reels': self._humanize_scroll_reels,
            'check_notifications': self._humanize_check_notifications,
        }

        for _ in range(max_actions):
            action = random.choice(list(action_handlers.keys()))
            if action_handlers[action]():
                actions_done += 1
            if actions_done >= max_actions:
                break

        print(f"[HUMANIZE] Completed {actions_done} random actions")
        # Small delay before proceeding
        self.random_delay(1.0, 3.0)

    def humanize_after_post(self):
        """Perform random human-like actions after posting"""
        print("\n[HUMANIZE] Performing random actions after posting...")

        # Wait a bit to see the "Sharing" confirmation
        self.random_delay(2.0, 4.0)

        actions = []
        if random.random() < 0.4:
            actions.append('scroll_feed')
        if random.random() < 0.3:
            actions.append('check_profile')
        if random.random() < 0.2:
            actions.append('view_story')

        for action in actions:
            if action == 'scroll_feed':
                print("  - Scrolling feed after post...")
                for _ in range(random.randint(1, 2)):
                    self.swipe(SCREEN_CENTER_X, FEED_BOTTOM_Y, SCREEN_CENTER_X, FEED_TOP_Y, random.randint(SWIPE_DURATION_SLOW, SWIPE_DURATION_MAX))
                    self.random_delay(1.5, 3.0)

            elif action == 'check_profile':
                print("  - Checking profile...")
                elements, _ = self.dump_ui()
                profile_tab = [e for e in elements if 'profile' in e.get('desc', '').lower() and e['clickable']]
                if profile_tab:
                    self.tap(profile_tab[0]['center'][0], profile_tab[0]['center'][1])
                    self.random_delay(2.0, 4.0)
                    # Go back to home
                    elements, _ = self.dump_ui()
                    home_tab = [e for e in elements if 'home' in e.get('desc', '').lower() and e['clickable']]
                    if home_tab:
                        self.tap(home_tab[0]['center'][0], home_tab[0]['center'][1])
                    self.random_delay(1.0, 2.0)

            elif action == 'view_story':
                print("  - Viewing a story after post...")
                elements, _ = self.dump_ui()
                story_elements = [e for e in elements if 'story' in e.get('desc', '').lower() and 'unseen' in e.get('desc', '').lower()]
                if story_elements:
                    story = random.choice(story_elements)
                    self.tap(story['center'][0], story['center'][1])
                    time.sleep(random.uniform(3, 6))
                    self.press_key('KEYCODE_BACK')
                    self.random_delay(1.0, 2.0)

        print("[HUMANIZE] Post-posting actions completed")

    def wait_for_upload_complete(self, timeout=60):
        """Wait for Instagram upload to complete by polling UI.

        Returns True if upload confirmed complete, False if timeout.
        """
        print(f"  Waiting for upload to complete (max {timeout}s)...")
        start_time = time.time()
        last_progress = None
        stuck_count = 0

        while time.time() - start_time < timeout:
            elements, xml = self.dump_ui()

            # Convert all text/desc to lowercase for searching
            all_text = ' '.join([
                (e.get('text', '') + ' ' + e.get('desc', '')).lower()
                for e in elements
            ])

            # Check for success indicators
            success_indicators = [
                'your reel has been shared',
                'reel shared',
                'shared to reels',
                'post shared',
            ]
            for indicator in success_indicators:
                if indicator in all_text:
                    print(f"    Upload complete: found '{indicator}'")
                    return True

            # Check if we're back on feed/profile (upload finished)
            if 'home' in all_text and 'reels' in all_text and 'profile' in all_text:
                # We're on the main Instagram screen with bottom nav
                if 'sharing to reels' not in all_text and 'uploading' not in all_text:
                    print("    Upload complete: back on main screen")
                    return True

            # Check for still uploading
            if 'sharing to reels' in all_text or 'uploading' in all_text:
                # Try to get progress
                for e in elements:
                    text = e.get('text', '') + e.get('desc', '')
                    if '%' in text or any(c.isdigit() for c in text):
                        # Found progress indicator
                        if text != last_progress:
                            print(f"    Upload in progress: {text[:50]}")
                            last_progress = text
                            stuck_count = 0
                        else:
                            stuck_count += 1
                        break
                else:
                    print("    Upload in progress...")

            # If stuck for too long, might be done
            if stuck_count > 5:
                print("    Progress unchanged, checking if done...")

            time.sleep(2)

        print(f"    Upload wait timeout after {timeout}s")
        return False

    def detect_error_state(self, elements=None):
        """Detect account/app error states from UI.

        Returns tuple: (error_type, error_message) or (None, None) if no error.
        """
        if elements is None:
            elements, _ = self.dump_ui()

        # Combine all text for searching
        all_text = ' '.join([
            (e.get('text', '') + ' ' + e.get('desc', '')).lower()
            for e in elements
        ])

        # Error patterns to detect
        error_patterns = {
            'suspended': [
                'account has been suspended',
                'account has been disabled',
                'your account was disabled',
                'we suspended your account',
                'account is disabled',
            ],
            'captcha': [
                'confirm it\'s you',
                'we detected unusual activity',
                'verify your identity',
                'security check',
                'enter the code',
                'we noticed suspicious',
                'confirm your account',
            ],
            'action_blocked': [
                'action blocked',
                'try again later',
                'we limit how often',
                'you\'re temporarily blocked',
                'please wait',
            ],
            'logged_out': [
                'log in to instagram',
                'create new account',
                'sign up',
                'don\'t have an account',
            ],
            'app_update': [
                'update instagram',
                'update required',
                'new version available',
            ],
            'rate_limited': [
                'please wait a few minutes',
                'too many requests',
                'slow down',
            ],
        }

        for error_type, patterns in error_patterns.items():
            for pattern in patterns:
                if pattern in all_text:
                    return (error_type, pattern)

        return (None, None)

    def take_error_screenshot(self, account_name, error_type):
        """Take screenshot for error documentation.

        Returns screenshot path or None if failed.
        """
        import os
        from datetime import datetime

        # Create screenshots directory
        screenshot_dir = os.path.join(os.path.dirname(__file__), 'error_screenshots')
        os.makedirs(screenshot_dir, exist_ok=True)

        # Generate filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{account_name}_{error_type}_{timestamp}.png"
        filepath = os.path.join(screenshot_dir, filename)

        try:
            if self.appium_driver:
                self.appium_driver.save_screenshot(filepath)
                print(f"    Screenshot saved: {filename}")
                return filepath
        except Exception as e:
            print(f"    Failed to save screenshot: {e}")

        return None

    def _handle_tap_and_type(self, action, elements, caption):
        """Handle tap_and_type action - keyboard management and caption typing.

        Returns True if caller should `continue` to next loop iteration.
        """
        # Prevent re-typing if caption already entered - just tap Share instead
        if self.caption_entered:
            print("  [SKIP] Caption already entered! Tapping Share instead.")
            share_elements = [e for e in elements if e.get('text', '').lower() == 'share' or e.get('desc', '').lower() == 'share']
            if share_elements:
                self.tap(share_elements[0]['center'][0], share_elements[0]['center'][1])
                self.share_clicked = True
            return True  # continue to next step

        idx = action.get('element_index', 0)
        text = action.get('text', caption)

        # Step 1: Check if keyboard is already up
        print("  Checking if keyboard is up...")
        keyboard_up = self.is_keyboard_visible()

        if not keyboard_up:
            # Step 2: Tap the caption field
            if 0 <= idx < len(elements):
                elem = elements[idx]
                print(f"  Keyboard not up. Tapping caption field at ({elem['center'][0]}, {elem['center'][1]})")
                self.tap(elem['center'][0], elem['center'][1])
                time.sleep(1.5)

            # Step 3: Check again if keyboard is up
            print("  Checking keyboard again...")
            keyboard_up = self.is_keyboard_visible()

            if not keyboard_up:
                # Step 4: Try tapping again
                print("  Keyboard still not up. Tapping again...")
                if 0 <= idx < len(elements):
                    elem = elements[idx]
                    self.tap(elem['center'][0], elem['center'][1])
                    time.sleep(1.5)
                keyboard_up = self.is_keyboard_visible()

        if keyboard_up:
            print(f"  Keyboard is up. Typing: {text[:50]}...")
            self.type_text(text)
            time.sleep(1)

            # Step 5: Best-effort verification (uiautomator often hides caption text)
            print("  Verifying caption was typed...")
            verify_elements, _ = self.dump_ui()
            caption_found = any(text[:20] in elem.get('text', '') for elem in verify_elements)
            if caption_found:
                print("  Caption appears in UI dump.")
            else:
                print("  Caption not visible in UI dump (normal for IG caption field); assuming entered.")
            self.caption_entered = True

            # Hide keyboard
            self.press_key('KEYCODE_BACK')
            time.sleep(0.5)
        else:
            print("  ERROR: Could not get keyboard to appear. Will retry on next step.")

        return False  # don't skip, continue normally

    # --- Action handlers for dispatch table (Command pattern) ---

    def _action_home(self, action, elements):
        """Handle 'home' action - go to home screen."""
        print("  [HOME] Going to home screen...")
        self.press_key('KEYCODE_HOME')
        time.sleep(2)

    def _action_open_instagram(self, action, elements):
        """Handle 'open_instagram' action - restart Instagram app."""
        print("  [OPEN] Opening Instagram...")
        self.adb("am force-stop com.instagram.android")
        time.sleep(1)
        self.adb("monkey -p com.instagram.android 1")
        time.sleep(4)

    def _action_tap(self, action, elements):
        """Handle 'tap' action - tap an element by index."""
        idx = action.get('element_index', 0)
        if 0 <= idx < len(elements):
            elem = elements[idx]
            self.tap(elem['center'][0], elem['center'][1])
        else:
            print(f"  Invalid element index: {idx}")

    def _action_back(self, action, elements):
        """Handle 'back' action - press back key."""
        self.press_key('KEYCODE_BACK')

    def _action_scroll_down(self, action, elements):
        """Handle 'scroll_down' action - swipe down."""
        self.adb(f"input swipe {SCREEN_CENTER_X} {FEED_BOTTOM_Y} {SCREEN_CENTER_X} {FEED_TOP_Y} {SWIPE_DURATION_FAST}")

    def _action_scroll_up(self, action, elements):
        """Handle 'scroll_up' action - swipe up."""
        self.adb(f"input swipe {SCREEN_CENTER_X} {FEED_TOP_Y} {SCREEN_CENTER_X} {FEED_BOTTOM_Y} {SWIPE_DURATION_FAST}")

    def _get_action_handlers(self):
        """Return dispatch table mapping action names to handler methods.

        Note: 'done' and 'tap_and_type' have special handling in post() and are not included.
        """
        return {
            'home': self._action_home,
            'open_instagram': self._action_open_instagram,
            'tap': self._action_tap,
            'back': self._action_back,
            'scroll_down': self._action_scroll_down,
            'scroll_up': self._action_scroll_up,
        }

    def _track_action_for_loop_detection(self, action, elements, recent_actions, loop_threshold):
        """Track action signature for loop detection.

        Modifies recent_actions in place.
        """
        action_signature = action['action']
        if action['action'] == 'tap' and 'element_index' in action:
            idx = action.get('element_index', 0)
            if 0 <= idx < len(elements):
                x, y = elements[idx]['center']
                action_signature = f"tap_{x}_{y}"
        recent_actions.append(action_signature)
        if len(recent_actions) > loop_threshold:
            recent_actions.pop(0)

    def _check_and_recover_from_loop(self, recent_actions, loop_recovery_count, loop_threshold, max_recoveries):
        """Check for stuck loop and attempt recovery.

        Returns tuple: (should_abort: bool, new_recovery_count: int, should_clear_actions: bool)
        """
        # Check for loop - if last N actions are all identical, we're stuck
        if len(recent_actions) < loop_threshold or len(set(recent_actions)) != 1:
            return (False, loop_recovery_count, False)  # No loop detected

        # Loop detected!
        loop_recovery_count += 1
        print(f"\n  [LOOP DETECTED] Same action '{recent_actions[0]}' repeated {loop_threshold} times!")
        print(f"  [RECOVERY] Attempt {loop_recovery_count}/{max_recoveries}")

        if loop_recovery_count > max_recoveries:
            print("  [ABORT] Too many loop recoveries, giving up")
            return (True, loop_recovery_count, False)  # Should abort

        # Recovery: press back 5 times and restart Instagram
        print("  Pressing BACK 5 times to escape stuck state...")
        for _ in range(5):
            self.press_key('KEYCODE_BACK')
            time.sleep(0.5)

        print("  Reopening Instagram...")
        self.adb("am force-stop com.instagram.android")
        time.sleep(2)
        self.adb("monkey -p com.instagram.android 1")
        time.sleep(5)

        print("  [RECOVERY] Restarted - continuing")
        return (False, loop_recovery_count, True)  # Continue, but clear actions

    def is_keyboard_visible(self):
        """Check if the keyboard is currently visible on screen"""
        # Method 1: Check dumpsys for keyboard visibility
        result = self.adb("dumpsys input_method | grep mInputShown")
        if "mInputShown=true" in result:
            return True

        # Method 2: Check window visibility
        result = self.adb("dumpsys window | grep -i keyboard")
        if "isVisible=true" in result.lower() or "mhasfocus=true" in result.lower():
            return True

        # Method 3: Check if InputMethod window is visible
        result = self.adb("dumpsys window windows | grep -E 'mCurrentFocus|mFocusedApp'")
        if "InputMethod" in result:
            return True

        return False

    def type_text(self, text):
        """Type text - delegates to AppiumUIController"""
        if self.ui_controller:
            return self.ui_controller.type_text(text)
        else:
            print("    ERROR: Appium driver not connected!")
            return False

    def dump_ui(self):
        """Dump UI hierarchy and return parsed elements using Appium (required)"""
        elements = []
        xml_str = ""

        if not self.appium_driver:
            raise Exception("Appium driver not connected - cannot dump UI")

        try:
            xml_str = self.appium_driver.page_source
        except Exception as e:
            error_str = str(e)
            error_type = type(e).__name__
            print(f"  [UI DUMP ERROR] {error_type}: {error_str[:200]}")

            if self.is_uiautomator2_crash(e):
                print(f"  [RECOVERY] UiAutomator2 crashed, reconnecting...")
                if self.reconnect_appium():
                    try:
                        xml_str = self.appium_driver.page_source
                    except Exception as e2:
                        raise Exception(f"Appium reconnect failed: {type(e2).__name__}: {e2}")
                else:
                    raise Exception("Appium reconnect failed")
            else:
                # Capture full error details for debugging
                import traceback
                print(f"  [FULL ERROR]\n{traceback.format_exc()}")
                raise Exception(f"UI dump failed ({error_type}): {error_str[:100]}")

        if '<?xml' not in xml_str:
            return elements, xml_str

        xml_clean = xml_str[xml_str.find('<?xml'):]
        try:
            root = ET.fromstring(xml_clean)
            # Appium uses class names as tags (android.widget.TextView), not <node>
            # So iterate over ALL elements
            for elem in root.iter():
                text = elem.get('text', '')
                desc = elem.get('content-desc', '')
                res_id = elem.get('resource-id', '')
                bounds = elem.get('bounds', '')
                clickable = elem.get('clickable', 'false')

                if bounds and (text or desc or clickable == 'true'):
                    # Parse bounds [x1,y1][x2,y2]
                    m = re.match(r'\[(\d+),(\d+)\]\[(\d+),(\d+)\]', bounds)
                    if m:
                        x1, y1, x2, y2 = map(int, m.groups())
                        cx, cy = (x1+x2)//2, (y1+y2)//2
                        elements.append({
                            'text': text,
                            'desc': desc,
                            'id': res_id.split('/')[-1] if '/' in res_id else res_id,
                            'bounds': bounds,
                            'center': (cx, cy),
                            'clickable': clickable == 'true'
                        })
        except ET.ParseError as e:
            print(f"  XML parse error: {e}")

        return elements, xml_str

    def analyze_ui(self, elements, caption):
        """Use Claude to analyze UI and decide next action - delegates to ClaudeUIAnalyzer"""
        return self._analyzer.analyze(
            elements=elements,
            caption=caption,
            video_uploaded=self.video_uploaded,
            caption_entered=self.caption_entered,
            share_clicked=self.share_clicked
        )

    def connect(self):
        """Find phone and connect via ADB - delegates to DeviceConnectionManager"""
        return self._conn.connect()

    def verify_adb_connection(self):
        """Verify device is still connected via ADB. Returns True if connected."""
        return self._conn.verify_adb_connection()

    def reconnect_adb(self):
        """Re-establish ADB connection if it dropped. Returns True on success."""
        return self._conn.reconnect_adb()

    def connect_appium(self, retries=3):
        """Connect Appium driver - REQUIRED for automation to work"""
        return self._conn.connect_appium(retries=retries)

    def upload_video(self, video_path):
        """Upload video to phone"""
        print(f"\nUploading video: {video_path}")

        resource_url = self.client.upload_file_to_geelark(video_path)
        print(f"  Cloud: {resource_url}")

        upload_result = self.client.upload_file_to_phone(self.phone_id, resource_url)
        task_id = upload_result.get("taskId")
        self.client.wait_for_upload(task_id)
        print("  Video on phone!")

        # Trigger media scanner
        self.adb("am broadcast -a android.intent.action.MEDIA_SCANNER_SCAN_FILE -d file:///sdcard/Download/")
        time.sleep(3)

        # Clean up old screenshots
        print("  Cleaning screenshots...")
        self.adb("rm -f /sdcard/DCIM/Camera/IMG_*.png")
        self.adb("rm -f /sdcard/Pictures/Screenshots/*.png")

        self.video_uploaded = True
        return True

    def post(self, video_path, caption, max_steps=30, humanize=False):
        """Main posting flow with smart navigation

        Args:
            video_path: Path to video file
            caption: Caption text for the post
            max_steps: Maximum navigation steps
            humanize: If True, perform random human-like actions before/after posting
        """

        # Upload video first
        self.upload_video(video_path)

        # Open Instagram
        print("\nOpening Instagram...")
        self.adb("am force-stop com.instagram.android")
        time.sleep(2)
        self.adb("monkey -p com.instagram.android 1")
        time.sleep(5)

        # Humanize before posting
        if humanize:
            self.humanize_before_post()

        # Loop detection - track recent actions to detect stuck states
        recent_actions = []  # List of (action_type, x, y) tuples
        LOOP_THRESHOLD = 5  # If 5 consecutive same actions, we're stuck
        loop_recovery_count = 0  # How many times we've tried to recover
        MAX_LOOP_RECOVERIES = 2  # Give up after this many recovery attempts

        # Vision-action loop
        for step in range(max_steps):
            print(f"\n--- Step {step + 1} ---")

            # Dump UI
            elements, raw_xml = self.dump_ui()
            if not elements:
                print("  No UI elements found, waiting...")
                time.sleep(2)
                continue

            # Check for account/app errors
            error_type, error_msg = self.detect_error_state(elements)
            if error_type:
                print(f"  [ERROR DETECTED] {error_type}: {error_msg}")
                self.last_error_type = error_type
                self.last_error_message = error_msg
                self.last_screenshot_path = self.take_error_screenshot(self.phone_name, error_type)
                return False

            # Show what we see (all elements)
            print(f"  Found {len(elements)} elements")
            for elem in elements:
                parts = []
                if elem['text']:
                    parts.append(f"'{elem['text']}'")
                if elem['desc']:
                    parts.append(f"desc='{elem['desc']}'")
                if parts:
                    print(f"    {elem['bounds']} {' | '.join(parts)}")

            # Ask Claude what to do
            print("  Analyzing...")
            try:
                action = self.analyze_ui(elements, caption)
            except Exception as e:
                print(f"  Analysis error: {e}")
                time.sleep(2)
                continue

            print(f"  Action: {action['action']} - {action.get('reason', '')}")

            # Update state (only video_selected and share_clicked from Claude's analysis)
            # caption_entered is ONLY set after we actually type the caption
            if action.get('video_selected'):
                self.video_uploaded = True
            if action.get('share_clicked'):
                self.share_clicked = True

            # Execute action using dispatch table (Command pattern)
            action_name = action['action']

            # Special case: 'done' - returns from function
            if action_name == 'done':
                print("\n[SUCCESS] Share initiated!")
                # Wait for upload to actually complete (poll UI for confirmation)
                if self.wait_for_upload_complete(timeout=60):
                    print("[SUCCESS] Upload confirmed complete!")
                else:
                    print("[WARNING] Upload confirmation timeout - may still be processing")
                if humanize:
                    self.humanize_after_post()
                return True

            # Special case: 'tap_and_type' - needs caption and has continue logic
            if action_name == 'tap_and_type':
                if self._handle_tap_and_type(action, elements, caption):
                    continue  # Helper handled it and wants to skip to next step

            # Dispatch table for standard actions
            action_handlers = self._get_action_handlers()
            if action_name in action_handlers:
                action_handlers[action_name](action, elements)

            # Track action and check for stuck loops
            self._track_action_for_loop_detection(action, elements, recent_actions, LOOP_THRESHOLD)
            should_abort, loop_recovery_count, should_clear = self._check_and_recover_from_loop(
                recent_actions, loop_recovery_count, LOOP_THRESHOLD, MAX_LOOP_RECOVERIES
            )
            if should_abort:
                return False
            if should_clear:
                recent_actions.clear()

            time.sleep(1)

        print(f"\n[FAILED] Max steps ({max_steps}) reached")
        return False

    def cleanup(self):
        """Cleanup after posting - delegates to DeviceConnectionManager"""
        print("\nCleaning up...")
        try:
            self.adb("rm -f /sdcard/Download/*.mp4")
        except Exception:
            pass  # Ignore cleanup errors - video deletion is best-effort
        # Delegate connection cleanup to DeviceConnectionManager
        self._conn.disconnect()


def main():
    if len(sys.argv) < 4:
        print("Usage: python post_reel_smart.py <phone_name> <video_path> <caption>")
        print('Example: python post_reel_smart.py talktrackhub video.mp4 "Check this out!"')
        sys.exit(1)

    phone_name = sys.argv[1]
    video_path = sys.argv[2]
    caption = sys.argv[3]

    if not os.path.exists(video_path):
        print(f"Video not found: {video_path}")
        sys.exit(1)

    poster = SmartInstagramPoster(phone_name)

    try:
        poster.connect()
        success = poster.post(video_path, caption)
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        poster.cleanup()


if __name__ == "__main__":
    main()
</file>

<file path="posting_dashboard.py">
"""
Posting Dashboard - Full GUI for Instagram posting automation.

Features:
- Add multiple video folders
- Manage accounts
- Configure retry/humanize/delay settings
- Start/Stop/Pause scheduler
- Real-time status and progress
- Job queue view
"""
import sys
import os

# Fix Windows console encoding
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

import tkinter as tk
from tkinter import ttk, scrolledtext, filedialog, messagebox
import threading
from datetime import datetime

from posting_scheduler import PostingScheduler, PostStatus


class PostingDashboard:
    def __init__(self, root):
        self.root = root
        self.root.title("Instagram Posting Dashboard")
        self.root.geometry("1100x800")

        # Initialize scheduler
        self.scheduler = PostingScheduler()
        self.scheduler.on_status_update = self.log
        self.scheduler.on_job_complete = self.on_job_complete

        self.setup_ui()
        self.refresh_all()

        # Auto-refresh stats every 2 seconds
        self.auto_refresh()

    def setup_ui(self):
        # Main container with left and right panels
        main_paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

        # Left panel - Configuration
        left_frame = ttk.Frame(main_paned, width=400)
        main_paned.add(left_frame, weight=1)

        # Right panel - Status and logs
        right_frame = ttk.Frame(main_paned, width=600)
        main_paned.add(right_frame, weight=2)

        # === LEFT PANEL ===

        # Video Folders Section
        folders_frame = ttk.LabelFrame(left_frame, text="Video Folders", padding=10)
        folders_frame.pack(fill=tk.X, pady=(0, 10))

        self.folders_listbox = tk.Listbox(folders_frame, height=4)
        self.folders_listbox.pack(fill=tk.X, pady=(0, 5))

        folders_btn_frame = ttk.Frame(folders_frame)
        folders_btn_frame.pack(fill=tk.X)
        ttk.Button(folders_btn_frame, text="Add Folder", command=self.add_folder).pack(side=tk.LEFT, padx=2)
        ttk.Button(folders_btn_frame, text="Remove", command=self.remove_folder).pack(side=tk.LEFT, padx=2)
        ttk.Button(folders_btn_frame, text="Reload", command=self.reload_folders).pack(side=tk.LEFT, padx=2)

        # Accounts Section
        accounts_frame = ttk.LabelFrame(left_frame, text="Accounts", padding=10)
        accounts_frame.pack(fill=tk.X, pady=(0, 10))

        self.accounts_listbox = tk.Listbox(accounts_frame, height=6, selectmode=tk.EXTENDED)
        self.accounts_listbox.pack(fill=tk.X, pady=(0, 5))

        accounts_btn_frame = ttk.Frame(accounts_frame)
        accounts_btn_frame.pack(fill=tk.X)
        ttk.Button(accounts_btn_frame, text="Add", command=self.add_account).pack(side=tk.LEFT, padx=2)
        ttk.Button(accounts_btn_frame, text="Remove", command=self.remove_account).pack(side=tk.LEFT, padx=2)

        # Add account entry
        self.account_entry = ttk.Entry(accounts_frame)
        self.account_entry.pack(fill=tk.X, pady=(5, 0))
        self.account_entry.bind('<Return>', lambda e: self.add_account())

        # Settings Section
        settings_frame = ttk.LabelFrame(left_frame, text="Settings", padding=10)
        settings_frame.pack(fill=tk.X, pady=(0, 10))

        # Humanize
        self.humanize_var = tk.BooleanVar(value=self.scheduler.humanize)
        ttk.Checkbutton(settings_frame, text="Humanize (random actions)",
                       variable=self.humanize_var, command=self.save_settings).pack(anchor=tk.W)

        # Test retry mode
        self.test_retry_var = tk.BooleanVar(value=self.scheduler.test_retry_mode)
        ttk.Checkbutton(settings_frame, text="TEST MODE: Force 1st attempt to fail",
                       variable=self.test_retry_var, command=self.save_settings).pack(anchor=tk.W)

        # Max retries
        retry_frame = ttk.Frame(settings_frame)
        retry_frame.pack(fill=tk.X, pady=5)
        ttk.Label(retry_frame, text="Max retries:").pack(side=tk.LEFT)
        self.retries_var = tk.StringVar(value=str(self.scheduler.max_retries))
        retry_spin = ttk.Spinbox(retry_frame, from_=1, to=10, width=5,
                                  textvariable=self.retries_var, command=self.save_settings)
        retry_spin.pack(side=tk.LEFT, padx=5)

        # Retry delay (in seconds for UI, stored as minutes internally)
        delay_frame = ttk.Frame(settings_frame)
        delay_frame.pack(fill=tk.X, pady=5)
        ttk.Label(delay_frame, text="Retry delay (sec):").pack(side=tk.LEFT)
        retry_secs = int(self.scheduler.retry_delay_minutes * 60)
        self.retry_delay_var = tk.StringVar(value=str(retry_secs))
        delay_spin = ttk.Spinbox(delay_frame, from_=5, to=300, width=5,
                                  textvariable=self.retry_delay_var, command=self.save_settings)
        delay_spin.pack(side=tk.LEFT, padx=5)

        # Post delay
        post_delay_frame = ttk.Frame(settings_frame)
        post_delay_frame.pack(fill=tk.X, pady=5)
        ttk.Label(post_delay_frame, text="Delay between posts (s):").pack(side=tk.LEFT)
        self.post_delay_var = tk.StringVar(value=str(self.scheduler.delay_between_posts))
        post_delay_spin = ttk.Spinbox(post_delay_frame, from_=10, to=300, width=5,
                                       textvariable=self.post_delay_var, command=self.save_settings)
        post_delay_spin.pack(side=tk.LEFT, padx=5)

        # Posts per day
        ppd_frame = ttk.Frame(settings_frame)
        ppd_frame.pack(fill=tk.X, pady=5)
        ttk.Label(ppd_frame, text="Posts per account/day:").pack(side=tk.LEFT)
        self.ppd_var = tk.StringVar(value=str(self.scheduler.posts_per_account_per_day))
        ppd_spin = ttk.Spinbox(ppd_frame, from_=1, to=10, width=5,
                                textvariable=self.ppd_var, command=self.save_settings)
        ppd_spin.pack(side=tk.LEFT, padx=5)

        # Control Buttons
        control_frame = ttk.LabelFrame(left_frame, text="Control", padding=10)
        control_frame.pack(fill=tk.X, pady=(0, 10))

        btn_row1 = ttk.Frame(control_frame)
        btn_row1.pack(fill=tk.X, pady=2)

        self.start_btn = ttk.Button(btn_row1, text="START", command=self.start_scheduler)
        self.start_btn.pack(side=tk.LEFT, padx=2, expand=True, fill=tk.X)

        self.pause_btn = ttk.Button(btn_row1, text="PAUSE", command=self.pause_scheduler, state=tk.DISABLED)
        self.pause_btn.pack(side=tk.LEFT, padx=2, expand=True, fill=tk.X)

        self.stop_btn = ttk.Button(btn_row1, text="STOP", command=self.stop_scheduler, state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=2, expand=True, fill=tk.X)

        btn_row2 = ttk.Frame(control_frame)
        btn_row2.pack(fill=tk.X, pady=2)

        ttk.Button(btn_row2, text="Retry All Failed", command=self.retry_all_failed).pack(side=tk.LEFT, padx=2, expand=True, fill=tk.X)
        ttk.Button(btn_row2, text="View Report", command=self.show_error_report).pack(side=tk.LEFT, padx=2, expand=True, fill=tk.X)
        ttk.Button(btn_row2, text="Clear Log", command=self.clear_log).pack(side=tk.LEFT, padx=2, expand=True, fill=tk.X)

        # === RIGHT PANEL ===

        # Stats Section
        stats_frame = ttk.LabelFrame(right_frame, text="Status", padding=10)
        stats_frame.pack(fill=tk.X, pady=(0, 10))

        # Status indicator
        status_row = ttk.Frame(stats_frame)
        status_row.pack(fill=tk.X, pady=5)

        self.status_indicator = tk.Label(status_row, text="STOPPED", bg="gray", fg="white",
                                         font=('Arial', 12, 'bold'), width=15)
        self.status_indicator.pack(side=tk.LEFT, padx=5)

        # Stats labels
        stats_grid = ttk.Frame(stats_frame)
        stats_grid.pack(fill=tk.X)

        self.stats_labels = {}
        stats = [
            ('total', 'Total Jobs'),
            ('pending', 'Pending'),
            ('success', 'Success'),
            ('retrying', 'Retrying'),
            ('failed', 'Failed'),
        ]

        for i, (key, label) in enumerate(stats):
            ttk.Label(stats_grid, text=f"{label}:").grid(row=0, column=i*2, padx=5, sticky=tk.E)
            self.stats_labels[key] = ttk.Label(stats_grid, text="0", font=('Arial', 11, 'bold'))
            self.stats_labels[key].grid(row=0, column=i*2+1, padx=(0, 15), sticky=tk.W)

        # Progress bar
        self.progress = ttk.Progressbar(stats_frame, mode='determinate', length=400)
        self.progress.pack(fill=tk.X, pady=10)

        # Job Queue Section
        queue_frame = ttk.LabelFrame(right_frame, text="Job Queue", padding=10)
        queue_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 10))

        # Treeview for jobs
        columns = ('id', 'account', 'status', 'attempts', 'error')
        self.jobs_tree = ttk.Treeview(queue_frame, columns=columns, show='headings', height=10)

        self.jobs_tree.heading('id', text='Video ID')
        self.jobs_tree.heading('account', text='Account')
        self.jobs_tree.heading('status', text='Status')
        self.jobs_tree.heading('attempts', text='Attempts')
        self.jobs_tree.heading('error', text='Last Error')

        self.jobs_tree.column('id', width=150)
        self.jobs_tree.column('account', width=120)
        self.jobs_tree.column('status', width=80)
        self.jobs_tree.column('attempts', width=60)
        self.jobs_tree.column('error', width=200)

        scrollbar = ttk.Scrollbar(queue_frame, orient=tk.VERTICAL, command=self.jobs_tree.yview)
        self.jobs_tree.configure(yscrollcommand=scrollbar.set)

        self.jobs_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        # Context menu for jobs
        self.jobs_menu = tk.Menu(self.root, tearoff=0)
        self.jobs_menu.add_command(label="Retry Selected", command=self.retry_selected_job)
        self.jobs_tree.bind('<Button-3>', self.show_jobs_menu)

        # Log Section
        log_frame = ttk.LabelFrame(right_frame, text="Log", padding=10)
        log_frame.pack(fill=tk.BOTH, expand=True)

        self.log_text = scrolledtext.ScrolledText(log_frame, height=12, wrap=tk.WORD,
                                                   font=('Consolas', 9))
        self.log_text.pack(fill=tk.BOTH, expand=True)

        # Configure log tags
        self.log_text.tag_config('info', foreground='black')
        self.log_text.tag_config('success', foreground='green')
        self.log_text.tag_config('error', foreground='red')
        self.log_text.tag_config('warning', foreground='orange')

    def log(self, message: str, tag: str = 'info'):
        """Add message to log"""
        # Detect tag from message content
        if '[OK]' in message or 'success' in message.lower():
            tag = 'success'
        elif '[FAIL]' in message or '[ERROR]' in message or 'error' in message.lower():
            tag = 'error'
        elif '[RETRY]' in message or 'retry' in message.lower():
            tag = 'warning'

        self.log_text.insert(tk.END, message + '\n', tag)
        self.log_text.see(tk.END)

    def clear_log(self):
        self.log_text.delete('1.0', tk.END)

    def add_folder(self):
        folder = filedialog.askdirectory(title="Select Video Folder")
        if folder:
            count = self.scheduler.add_video_folder(folder)
            self.refresh_folders()
            self.refresh_jobs()
            if count > 0:
                messagebox.showinfo("Success", f"Added {count} videos from folder")

    def remove_folder(self):
        selection = self.folders_listbox.curselection()
        if selection:
            folder = self.folders_listbox.get(selection[0])
            if folder in self.scheduler.video_folders:
                self.scheduler.video_folders.remove(folder)
                self.scheduler.save_state()
                self.refresh_folders()

    def reload_folders(self):
        """Reload all folders to pick up new videos"""
        for folder in self.scheduler.video_folders[:]:
            self.scheduler.add_video_folder(folder)
        self.refresh_jobs()
        self.log("Reloaded all folders")

    def add_account(self):
        name = self.account_entry.get().strip()
        if name:
            self.scheduler.add_account(name)
            self.account_entry.delete(0, tk.END)
            self.refresh_accounts()

    def remove_account(self):
        selection = self.accounts_listbox.curselection()
        for idx in reversed(selection):
            name = self.accounts_listbox.get(idx)
            self.scheduler.remove_account(name)
        self.refresh_accounts()

    def save_settings(self):
        """Save settings from UI to scheduler"""
        try:
            self.scheduler.humanize = self.humanize_var.get()
            self.scheduler.test_retry_mode = self.test_retry_var.get()
            self.scheduler.max_retries = int(self.retries_var.get())
            self.scheduler.retry_delay_minutes = float(self.retry_delay_var.get()) / 60  # Convert seconds to minutes
            self.scheduler.delay_between_posts = int(self.post_delay_var.get())
            self.scheduler.posts_per_account_per_day = int(self.ppd_var.get())
            self.scheduler.save_state()
        except ValueError:
            pass

    def start_scheduler(self):
        if not self.scheduler.accounts:
            messagebox.showerror("Error", "Add at least one account first")
            return
        if not self.scheduler.jobs:
            messagebox.showerror("Error", "Add a video folder first")
            return

        self.scheduler.start()
        self.start_btn.config(state=tk.DISABLED)
        self.pause_btn.config(state=tk.NORMAL)
        self.stop_btn.config(state=tk.NORMAL)
        self.update_status_indicator()

    def pause_scheduler(self):
        if self.scheduler.paused:
            self.scheduler.resume()
            self.pause_btn.config(text="PAUSE")
        else:
            self.scheduler.pause()
            self.pause_btn.config(text="RESUME")
        self.update_status_indicator()

    def stop_scheduler(self):
        self.scheduler.stop()
        self.start_btn.config(state=tk.NORMAL)
        self.pause_btn.config(state=tk.DISABLED, text="PAUSE")
        self.stop_btn.config(state=tk.DISABLED)
        self.update_status_indicator()

    def retry_all_failed(self):
        self.scheduler.retry_all_failed()
        self.refresh_jobs()

    def show_error_report(self):
        """Show error report in a popup window"""
        report = self.scheduler.generate_error_report()

        # Create popup window
        popup = tk.Toplevel(self.root)
        popup.title("Error Report")
        popup.geometry("700x500")

        # Report text area
        report_text = scrolledtext.ScrolledText(popup, wrap=tk.WORD, font=('Consolas', 10))
        report_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # Get formatted text report
        report_content = self.scheduler.get_report_text()
        report_text.insert('1.0', report_content)
        report_text.config(state=tk.DISABLED)

        # Button frame
        btn_frame = ttk.Frame(popup)
        btn_frame.pack(fill=tk.X, padx=10, pady=(0, 10))

        def save_report():
            filepath = filedialog.asksaveasfilename(
                defaultextension=".json",
                filetypes=[("JSON files", "*.json"), ("All files", "*.*")],
                initialfile=f"error_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            if filepath:
                self.scheduler.save_error_report(filepath)
                messagebox.showinfo("Saved", f"Report saved to:\n{filepath}")

        def open_screenshots():
            screenshot_dir = os.path.join(os.path.dirname(__file__), 'error_screenshots')
            if os.path.exists(screenshot_dir):
                os.startfile(screenshot_dir)
            else:
                messagebox.showinfo("Info", "No screenshots folder found yet")

        ttk.Button(btn_frame, text="Save JSON Report", command=save_report).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="Open Screenshots Folder", command=open_screenshots).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="Close", command=popup.destroy).pack(side=tk.RIGHT, padx=5)

    def retry_selected_job(self):
        selection = self.jobs_tree.selection()
        for item in selection:
            job_id = self.jobs_tree.item(item)['values'][0]
            self.scheduler.retry_failed_job(job_id)
        self.refresh_jobs()

    def show_jobs_menu(self, event):
        selection = self.jobs_tree.selection()
        if selection:
            self.jobs_menu.post(event.x_root, event.y_root)

    def on_job_complete(self, job, success):
        """Called when a job completes"""
        self.root.after(100, self.refresh_jobs)
        self.root.after(100, self.refresh_stats)

    def refresh_all(self):
        self.refresh_folders()
        self.refresh_accounts()
        self.refresh_jobs()
        self.refresh_stats()

    def refresh_folders(self):
        self.folders_listbox.delete(0, tk.END)
        for folder in self.scheduler.video_folders:
            display = os.path.basename(folder) or folder
            self.folders_listbox.insert(tk.END, folder)

    def refresh_accounts(self):
        self.accounts_listbox.delete(0, tk.END)
        for name, acc in self.scheduler.accounts.items():
            display = f"{name} ({acc.total_posts} posts)"
            self.accounts_listbox.insert(tk.END, name)

    def refresh_jobs(self):
        # Clear tree
        for item in self.jobs_tree.get_children():
            self.jobs_tree.delete(item)

        # Add jobs (show non-success first)
        jobs_sorted = sorted(
            self.scheduler.jobs.values(),
            key=lambda j: (j.status == PostStatus.SUCCESS.value, j.id)
        )

        for job in jobs_sorted[:100]:  # Limit display
            status_display = job.status.upper()
            error_display = job.last_error[:50] if job.last_error else ""

            # Color coding
            tags = ()
            if job.status == PostStatus.SUCCESS.value:
                tags = ('success',)
            elif job.status == PostStatus.FAILED.value:
                tags = ('failed',)
            elif job.status == PostStatus.RETRYING.value:
                tags = ('retrying',)
            elif job.status == PostStatus.IN_PROGRESS.value:
                tags = ('inprogress',)

            self.jobs_tree.insert('', tk.END, values=(
                job.id,
                job.account or '-',
                status_display,
                f"{job.attempts}/{job.max_attempts}",
                error_display
            ), tags=tags)

        # Configure tag colors
        self.jobs_tree.tag_configure('success', foreground='green')
        self.jobs_tree.tag_configure('failed', foreground='red')
        self.jobs_tree.tag_configure('retrying', foreground='orange')
        self.jobs_tree.tag_configure('inprogress', foreground='blue')

    def refresh_stats(self):
        stats = self.scheduler.get_stats()

        self.stats_labels['total'].config(text=str(stats['total_jobs']))
        self.stats_labels['pending'].config(text=str(stats['pending']))
        self.stats_labels['success'].config(text=str(stats['success']), foreground='green')
        self.stats_labels['retrying'].config(text=str(stats['retrying']), foreground='orange')
        self.stats_labels['failed'].config(text=str(stats['failed']), foreground='red')

        # Update progress bar
        total = stats['total_jobs']
        if total > 0:
            completed = stats['success'] + stats['failed']
            self.progress['value'] = (completed / total) * 100
        else:
            self.progress['value'] = 0

        self.update_status_indicator()

    def update_status_indicator(self):
        if self.scheduler.running:
            if self.scheduler.paused:
                self.status_indicator.config(text="PAUSED", bg="orange")
            else:
                self.status_indicator.config(text="RUNNING", bg="green")
        else:
            self.status_indicator.config(text="STOPPED", bg="gray")

    def auto_refresh(self):
        """Auto-refresh stats every 2 seconds"""
        if self.scheduler.running:
            self.refresh_stats()
            self.refresh_jobs()
        self.root.after(2000, self.auto_refresh)

    def on_close(self):
        """Clean up on window close"""
        if self.scheduler.running:
            if messagebox.askyesno("Confirm", "Scheduler is running. Stop and exit?"):
                self.scheduler.stop()
            else:
                return
        self.root.destroy()


def main():
    root = tk.Tk()
    app = PostingDashboard(root)
    root.protocol("WM_DELETE_WINDOW", app.on_close)
    root.mainloop()


if __name__ == "__main__":
    main()
</file>

<file path="posting_scheduler.py">
"""
Posting Scheduler - Core queue/retry/state management system.

Features:
- Load videos from multiple folders
- Track posting state (posted, pending, failed, retrying)
- Auto-retry failed posts with configurable attempts/delay
- Schedule: one post per account per day
- State persistence to survive restarts
- Per-phase timeout protection
- Proper logging with phase info
- Single-instance lock to prevent multiple schedulers
"""
import os
import sys

# Import centralized config and set up environment FIRST (before any Appium imports)
from config import Config, setup_environment
setup_environment()

import csv
import json
import time
import glob
import logging
import threading
import traceback
import atexit
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, Callable, Set
from enum import Enum
from geelark_client import GeelarkClient

# === SINGLE-INSTANCE LOCK MECHANISM ===
LOCK_FILE = "scheduler.lock"

def is_process_running(pid: int) -> bool:
    """Check if a process with given PID is still running."""
    if sys.platform == 'win32':
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            PROCESS_QUERY_LIMITED_INFORMATION = 0x1000
            handle = kernel32.OpenProcess(PROCESS_QUERY_LIMITED_INFORMATION, False, pid)
            if handle:
                kernel32.CloseHandle(handle)
                return True
            return False
        except:
            # Fallback: try tasklist
            import subprocess
            result = subprocess.run(['tasklist', '/FI', f'PID eq {pid}'],
                                   capture_output=True, text=True)
            return str(pid) in result.stdout
    else:
        # Unix/Linux/Mac
        try:
            os.kill(pid, 0)
            return True
        except OSError:
            return False

def acquire_lock() -> bool:
    """Acquire single-instance lock. Returns True if successful, False if another instance running."""
    current_pid = os.getpid()
    stale_threshold_minutes = 2  # Lock considered stale if heartbeat older than this

    if os.path.exists(LOCK_FILE):
        try:
            with open(LOCK_FILE, 'r') as f:
                lock_data = json.load(f)
            old_pid = lock_data.get('pid')
            old_started = lock_data.get('started', 'unknown')
            last_heartbeat = lock_data.get('last_heartbeat')

            if old_pid and is_process_running(old_pid):
                # Process is running, but check if heartbeat is stale
                if last_heartbeat:
                    try:
                        hb_time = datetime.fromisoformat(last_heartbeat)
                        if datetime.now() - hb_time > timedelta(minutes=stale_threshold_minutes):
                            print(f"[LOCK] Lock heartbeat stale (last: {last_heartbeat}). Process may be hung.")
                            print(f"[LOCK] Taking over from stale lock (PID {old_pid})")
                            # Proceed to take over
                        else:
                            # Process running and heartbeat recent - truly in use
                            print(f"[LOCK ERROR] Another scheduler instance is already running!")
                            print(f"  PID: {old_pid}")
                            print(f"  Started: {old_started}")
                            print(f"  Last heartbeat: {last_heartbeat}")
                            print(f"  Lock file: {LOCK_FILE}")
                            print(f"\nIf you're sure no other instance is running, delete {LOCK_FILE} and try again.")
                            return False
                    except:
                        # Can't parse heartbeat, check process only
                        print(f"[LOCK ERROR] Another scheduler instance is already running!")
                        print(f"  PID: {old_pid}")
                        print(f"  Started: {old_started}")
                        print(f"  Lock file: {LOCK_FILE}")
                        print(f"\nIf you're sure no other instance is running, delete {LOCK_FILE} and try again.")
                        return False
                else:
                    # No heartbeat recorded yet, trust process check
                    print(f"[LOCK ERROR] Another scheduler instance is already running!")
                    print(f"  PID: {old_pid}")
                    print(f"  Started: {old_started}")
                    print(f"  Lock file: {LOCK_FILE}")
                    print(f"\nIf you're sure no other instance is running, delete {LOCK_FILE} and try again.")
                    return False
            else:
                print(f"[LOCK] Stale lock file found (PID {old_pid} not running). Taking over.")
        except Exception as e:
            print(f"[LOCK] Could not read lock file: {e}. Taking over.")

    # Write new lock file
    lock_data = {
        'pid': current_pid,
        'started': datetime.now().isoformat(),
        'hostname': os.environ.get('COMPUTERNAME', 'unknown')
    }
    with open(LOCK_FILE, 'w') as f:
        json.dump(lock_data, f)

    print(f"[LOCK] Acquired lock (PID {current_pid})")
    return True

def release_lock():
    """Release the single-instance lock."""
    current_pid = os.getpid()

    if os.path.exists(LOCK_FILE):
        try:
            with open(LOCK_FILE, 'r') as f:
                lock_data = json.load(f)
            # Only delete if we own the lock
            if lock_data.get('pid') == current_pid:
                os.remove(LOCK_FILE)
                print(f"[LOCK] Released lock (PID {current_pid})")
        except Exception as e:
            print(f"[LOCK] Error releasing lock: {e}")

# Register cleanup on exit
atexit.register(release_lock)
# === END SINGLE-INSTANCE LOCK ===


# === APPIUM HEALTH CHECK ===
def check_appium_health(port: int = 4723) -> bool:
    """Check if Appium server is running and healthy."""
    import urllib.request
    import urllib.error

    try:
        url = f"http://127.0.0.1:{port}/status"
        req = urllib.request.Request(url, method='GET')
        with urllib.request.urlopen(req, timeout=5) as response:
            data = json.loads(response.read().decode())
            return data.get('value', {}).get('ready', False)
    except (urllib.error.URLError, ConnectionRefusedError, TimeoutError, Exception) as e:
        return False

def kill_appium_processes():
    """Kill Appium server processes only (NOT all node.exe - that would kill Claude Code!)."""
    import subprocess
    if sys.platform == 'win32':
        # Use WMIC to find and kill only Appium node processes
        # This targets processes with 'appium' in command line, not ALL node.exe
        try:
            # Find Appium process IDs using WMIC
            result = subprocess.run(
                ['wmic', 'process', 'where', "commandline like '%appium%'", 'get', 'processid'],
                capture_output=True, text=True
            )
            for line in result.stdout.strip().split('\n'):
                line = line.strip()
                if line and line.isdigit():
                    subprocess.run(['taskkill', '/F', '/PID', line], capture_output=True)
                    print(f"[APPIUM] Killed Appium process PID {line}")
        except Exception as e:
            logger.warning(f"Error killing Appium processes: {e}")
    else:
        subprocess.run(['pkill', '-f', 'appium'], capture_output=True)
    time.sleep(2)

def get_android_env() -> dict:
    """Get environment with ANDROID_HOME/ANDROID_SDK_ROOT properly set.

    This ensures Appium can find the Android SDK regardless of how
    the parent process was started.
    """
    from config import Config, get_adb_env
    return get_adb_env()


def restart_appium(port: int = 4723) -> bool:
    """Attempt to restart Appium server with proper Android SDK environment."""
    print("[APPIUM] Killing existing Appium processes only...")
    kill_appium_processes()

    print("[APPIUM] Starting fresh Appium server...")
    import subprocess

    # Get environment with ANDROID_HOME properly set
    env = get_android_env()
    print(f"[APPIUM] Using ANDROID_HOME={env.get('ANDROID_HOME')}")

    # Start Appium in background with proper environment
    if sys.platform == 'win32':
        subprocess.Popen(
            ['appium', '--address', '127.0.0.1', '--port', str(port)],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            env=env,
            creationflags=subprocess.CREATE_NEW_PROCESS_GROUP
        )
    else:
        subprocess.Popen(
            ['appium', '--address', '127.0.0.1', '--port', str(port)],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            env=env,
            start_new_session=True
        )

    # Wait for Appium to start
    for i in range(30):
        time.sleep(1)
        if check_appium_health(port):
            print(f"[APPIUM] Server ready on port {port}")
            return True

    print("[APPIUM] Failed to start server after 30s")
    return False
# === END APPIUM HEALTH CHECK ===

# Fix Windows console encoding
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

# Live log file for dashboard streaming
LIVE_LOG_FILE = "scheduler_live.log"

class TeeWriter:
    """Write to both stdout and a log file with timestamps"""
    def __init__(self, original_stdout, log_file):
        self.original = original_stdout
        self.log_file = log_file
        self.line_buffer = ""

    def write(self, text):
        self.original.write(text)
        self.original.flush()
        # Write to log file with timestamp for each line
        self.line_buffer += text
        while '\n' in self.line_buffer:
            line, self.line_buffer = self.line_buffer.split('\n', 1)
            if line.strip():
                ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                try:
                    with open(self.log_file, 'a', encoding='utf-8') as f:
                        f.write(f"[{ts}] {line}\n")
                        f.flush()
                except:
                    pass

    def flush(self):
        self.original.flush()

# Install the tee writer to capture all print output
sys.stdout = TeeWriter(sys.stdout, LIVE_LOG_FILE)

# Setup proper logging
logging.basicConfig(
    filename="geelark_batch.log",
    level=logging.INFO,
    format="%(asctime)s %(levelname)s [%(name)s] %(message)s"
)
logger = logging.getLogger("geelark")


class PostStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    SUCCESS = "success"
    FAILED = "failed"
    RETRYING = "retrying"


@dataclass
class PostJob:
    """A single post job"""
    id: str  # unique id: shortcode
    video_path: str
    caption: str
    account: str = ""  # assigned account
    status: str = "pending"
    attempts: int = 0
    max_attempts: int = 3
    last_error: str = ""
    last_attempt: str = ""
    completed_at: str = ""
    source_folder: str = ""
    error_type: str = ""  # suspended, captcha, action_blocked, etc.
    screenshot_path: str = ""  # path to error screenshot

    def to_dict(self):
        return asdict(self)

    @classmethod
    def from_dict(cls, data):
        return cls(**data)


def get_already_posted_from_csv() -> Set[str]:
    """Load all successfully posted shortcodes from batch_results_*.csv files AND scheduler_state.json.

    Returns a set of shortcodes that have already been posted successfully.
    This prevents duplicate posts even across scheduler restarts.
    """
    posted = set()

    # 1. Read from batch_results CSV files
    for filepath in glob.glob("batch_results_*.csv"):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if row.get('status') == 'success':
                        # Handle both 'shortcode' column and first column as shortcode
                        shortcode = row.get('shortcode') or list(row.values())[0] if row else None
                        if shortcode:
                            posted.add(shortcode)
        except Exception as e:
            logger.warning(f"Could not read {filepath}: {e}")

    # 2. Also read from scheduler_state.json (catches successes before CSV write was added)
    state_file = "scheduler_state.json"
    if os.path.exists(state_file):
        try:
            with open(state_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for job in data.get('jobs', []):
                if job.get('status') == 'success':
                    posted.add(job.get('id'))
        except Exception as e:
            logger.warning(f"Could not read {state_file}: {e}")

    return posted


def get_accounts_posted_today() -> Set[str]:
    """Get all accounts that have successfully posted TODAY.

    This prevents the same account from posting twice in one day.
    """
    today = datetime.now().strftime("%Y%m%d")
    posted_accounts = set()

    # 1. Read from today's batch_results CSV files
    for filepath in glob.glob(f"batch_results_{today}*.csv"):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if row.get('status') == 'success':
                        # Handle both 'phone' and 'account' column names
                        account = row.get('phone') or row.get('account')
                        if account:
                            posted_accounts.add(account)
        except Exception as e:
            logger.warning(f"Could not read {filepath}: {e}")

    # 2. Also read from scheduler_state.json
    state_file = "scheduler_state.json"
    if os.path.exists(state_file):
        try:
            with open(state_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for job in data.get('jobs', []):
                if job.get('status') == 'success':
                    account = job.get('account')
                    if account:
                        posted_accounts.add(account)
        except Exception as e:
            logger.warning(f"Could not read {state_file}: {e}")

    return posted_accounts


def log_and_mark_failed(account: str, shortcode: str, phase: str, exc: Exception):
    """Log failure with full context and stack trace."""
    logger.exception(
        f"Post failed: account={account}, shortcode={shortcode}, phase={phase}",
        extra={"account": account, "shortcode": shortcode, "phase": phase}
    )
    return {
        'phase': phase,
        'error_type': type(exc).__name__,
        'error_msg': str(exc)[:200]
    }


def write_result_to_csv(shortcode: str, account: str, status: str, error: str = ""):
    """Write a single result to batch_results CSV file.

    This ensures duplicate protection works even if the scheduler crashes,
    since get_already_posted_from_csv() reads from these files.
    """
    timestamp = datetime.now().isoformat()
    date_str = datetime.now().strftime("%Y%m%d")
    filename = f"batch_results_{date_str}.csv"

    # Check if file exists to determine if we need headers
    file_exists = os.path.exists(filename)

    try:
        with open(filename, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(['shortcode', 'phone', 'status', 'error', 'timestamp'])
            writer.writerow([shortcode, account, status, error, timestamp])
        logger.info(f"write_result_to_csv: {shortcode} -> {filename}")
    except Exception as e:
        logger.error(f"write_result_to_csv failed: {e}")


def close_all_running_phones(account_names: Set[str] = None) -> int:
    """Close ALL running phones, or only those matching account_names if provided.

    This is CRITICAL - must be called at script start and end to prevent
    wasting cloud phone minutes on phones left running.

    Args:
        account_names: Optional set of account names to filter. If None, closes ALL running phones.

    Returns:
        Number of phones stopped
    """
    try:
        client = GeelarkClient()
        result = client.list_phones(page_size=100)
        phones = result.get('items', [])

        # Find running phones (status 1 = running)
        running = [p for p in phones if p.get('status') == 1]

        if not running:
            logger.info("close_all_running_phones: No phones currently running")
            return 0

        # Filter by account names if provided
        if account_names:
            to_stop = [p for p in running if p.get('serialName') in account_names]
        else:
            to_stop = running  # Stop ALL running phones

        stopped = 0
        for phone in to_stop:
            phone_id = phone['id']
            name = phone.get('serialName', phone_id)
            try:
                client.stop_phone(phone_id)
                print(f"  [CLEANUP] Stopped phone: {name}")
                logger.info(f"close_all_running_phones: Stopped {name}")
                stopped += 1
            except Exception as e:
                print(f"  [CLEANUP] Failed to stop {name}: {e}")
                logger.warning(f"close_all_running_phones: Failed to stop {name}: {e}")

        if stopped > 0:
            print(f"[CLEANUP] Stopped {stopped} running phone(s)")

        return stopped

    except Exception as e:
        logger.error(f"close_all_running_phones failed: {e}")
        print(f"[CLEANUP ERROR] {e}")
        return 0


@dataclass
class AccountState:
    """Track posting state for an account"""
    name: str
    last_post_date: str = ""  # YYYY-MM-DD
    posts_today: int = 0
    total_posts: int = 0
    total_failures: int = 0
    consecutive_failures: int = 0  # Track consecutive failures for backoff
    cooldown_until: str = ""  # ISO timestamp when account can be used again

    def can_post_today(self, max_per_day: int = 1) -> bool:
        today = datetime.now().strftime("%Y-%m-%d")
        if self.last_post_date != today:
            return True
        return self.posts_today < max_per_day

    def is_on_cooldown(self) -> bool:
        """Check if account is in cooldown period."""
        if not self.cooldown_until:
            return False
        try:
            cooldown_end = datetime.fromisoformat(self.cooldown_until)
            return datetime.now() < cooldown_end
        except:
            return False

    def record_post(self, success: bool, is_infra_error: bool = False):
        """Record a post attempt.

        Args:
            success: Whether the post succeeded
            is_infra_error: True if failure was infrastructure (ADB/Appium/glogin)
        """
        today = datetime.now().strftime("%Y-%m-%d")
        if self.last_post_date != today:
            self.posts_today = 0
        self.last_post_date = today

        if success:
            self.posts_today += 1
            self.total_posts += 1
            self.consecutive_failures = 0  # Reset on success
            self.cooldown_until = ""  # Clear any cooldown
        else:
            self.total_failures += 1
            self.consecutive_failures += 1

            # Apply backoff for repeated infra failures
            if is_infra_error and self.consecutive_failures >= 3:
                # Put account on 10-minute cooldown
                cooldown_minutes = min(10 * self.consecutive_failures, 60)  # Max 60 min
                self.cooldown_until = (datetime.now() + timedelta(minutes=cooldown_minutes)).isoformat()
                logger.warning(f"Account {self.name} on cooldown for {cooldown_minutes}min after {self.consecutive_failures} consecutive failures")


class PostingScheduler:
    """Main scheduler that manages the posting queue"""

    def __init__(self, state_file: str = "scheduler_state.json"):
        self.state_file = state_file
        self.jobs: Dict[str, PostJob] = {}  # id -> PostJob
        self.accounts: Dict[str, AccountState] = {}  # name -> AccountState
        self.video_folders: List[str] = []

        # Settings
        self.max_retries = 3
        self.retry_delay_minutes = 0.25  # 15 seconds
        self.posts_per_account_per_day = 1
        self.humanize = True
        self.delay_between_posts = 10  # seconds
        self.test_retry_mode = False  # If True, first attempt always fails

        # Runtime
        self.running = False
        self.paused = False
        self.worker_thread: Optional[threading.Thread] = None
        self.heartbeat_thread: Optional[threading.Thread] = None
        self.heartbeat_interval = 30  # seconds
        self.on_status_update: Optional[Callable] = None  # callback for GUI
        self.on_job_complete: Optional[Callable] = None

        # Appium health tracking
        self.appium_consecutive_failures = 0
        self.max_appium_failures_before_restart = 3

        # Load saved state
        self.load_state()

    def load_state(self):
        """Load state from disk"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # Load jobs
                for job_data in data.get('jobs', []):
                    job = PostJob.from_dict(job_data)
                    self.jobs[job.id] = job

                # Load accounts
                for acc_data in data.get('accounts', []):
                    acc = AccountState(**acc_data)
                    self.accounts[acc.name] = acc

                # Load settings
                settings = data.get('settings', {})
                self.max_retries = settings.get('max_retries', 3)
                self.retry_delay_minutes = settings.get('retry_delay_minutes', 5)
                self.posts_per_account_per_day = settings.get('posts_per_account_per_day', 1)
                self.humanize = settings.get('humanize', True)
                self.delay_between_posts = settings.get('delay_between_posts', 10)
                self.video_folders = settings.get('video_folders', [])

                self._log(f"Loaded state: {len(self.jobs)} jobs, {len(self.accounts)} accounts")
            except Exception as e:
                self._log(f"Error loading state: {e}")

    def save_state(self):
        """Save state to disk"""
        data = {
            'jobs': [job.to_dict() for job in self.jobs.values()],
            'accounts': [asdict(acc) for acc in self.accounts.values()],
            'settings': {
                'max_retries': self.max_retries,
                'retry_delay_minutes': self.retry_delay_minutes,
                'posts_per_account_per_day': self.posts_per_account_per_day,
                'humanize': self.humanize,
                'delay_between_posts': self.delay_between_posts,
                'video_folders': self.video_folders,
            },
            'saved_at': datetime.now().isoformat()
        }

        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

    def _log(self, message: str):
        """Log message and notify GUI"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        full_msg = f"[{timestamp}] {message}"
        print(full_msg)
        if self.on_status_update:
            self.on_status_update(full_msg)

    def add_video_folder(self, folder_path: str) -> int:
        """Add a video folder and load its posts"""
        if not os.path.isdir(folder_path):
            self._log(f"Folder not found: {folder_path}")
            return 0

        if folder_path not in self.video_folders:
            self.video_folders.append(folder_path)

        # Find CSV file
        csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
        if not csv_files:
            self._log(f"No CSV file in {folder_path}")
            return 0

        csv_path = os.path.join(folder_path, csv_files[0])

        # Load already-posted shortcodes from CSV logs (bulletproof duplicate protection)
        already_posted = get_already_posted_from_csv()
        if already_posted:
            self._log(f"Found {len(already_posted)} already-posted shortcodes in CSV logs")

        # Build video map from subfolders
        videos = {}
        for item in os.listdir(folder_path):
            item_path = os.path.join(folder_path, item)
            if os.path.isdir(item_path):
                for f in os.listdir(item_path):
                    if f.endswith('.mp4'):
                        shortcode = f.replace('.mp4', '')
                        videos[shortcode] = os.path.join(item_path, f)

        # Load from CSV
        added = 0
        skipped_duplicate = 0
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            columns = reader.fieldnames or []

            # Find video column
            video_col = None
            for col in columns:
                if 'Video' in col or 'Image' in col or col == 'Shortcode':
                    video_col = col
                    break

            if not video_col:
                self._log(f"No video column in CSV")
                return 0

            for row in reader:
                caption = row.get('Text', '').strip()
                video_ref = row.get(video_col, '').strip()

                if not video_ref or not caption:
                    continue

                # Find video path
                video_path = None
                shortcode = video_ref

                if video_ref in videos:
                    video_path = videos[video_ref]
                elif os.path.exists(video_ref):
                    video_path = video_ref
                    shortcode = os.path.basename(video_ref).replace('.mp4', '')

                if video_path and os.path.exists(video_path):
                    # Skip if already posted (from CSV logs)
                    if shortcode in already_posted:
                        skipped_duplicate += 1
                        continue
                    # Skip if already in jobs queue
                    if shortcode in self.jobs:
                        continue

                    job = PostJob(
                        id=shortcode,
                        video_path=video_path,
                        caption=caption,
                        source_folder=folder_path
                    )
                    self.jobs[shortcode] = job
                    added += 1

        self._log(f"Added {added} videos from {os.path.basename(folder_path)} (skipped {skipped_duplicate} already-posted)")
        logger.info(f"add_video_folder: added={added}, skipped_duplicate={skipped_duplicate}, folder={folder_path}")
        self.save_state()
        return added

    def add_account(self, name: str):
        """Add an account to post to"""
        if name not in self.accounts:
            self.accounts[name] = AccountState(name=name)
            self._log(f"Added account: {name}")
            self.save_state()

    def remove_account(self, name: str):
        """Remove an account"""
        if name in self.accounts:
            del self.accounts[name]
            self.save_state()

    def get_next_job(self) -> Optional[PostJob]:
        """Get next job that's ready to post"""
        # Get accounts that already posted today from CSV logs (this is the ground truth)
        accounts_posted_today = get_accounts_posted_today()

        # Find accounts that can post today (not in CSV logs as already posted, not on cooldown)
        available_accounts = [
            acc for acc in self.accounts.values()
            if acc.can_post_today(self.posts_per_account_per_day)
            and acc.name not in accounts_posted_today
            and not acc.is_on_cooldown()  # Skip accounts on infra error cooldown
        ]

        # Log accounts on cooldown for visibility
        on_cooldown = [acc.name for acc in self.accounts.values() if acc.is_on_cooldown()]
        if on_cooldown:
            logger.debug(f"Accounts on cooldown: {on_cooldown}")

        if not available_accounts:
            return None

        available_names = [a.name for a in available_accounts]

        # Find pending jobs first (priority)
        for job in self.jobs.values():
            if job.status == PostStatus.PENDING.value:
                # Assign to first available account
                job.account = available_accounts[0].name
                return job

        # Then check retrying jobs
        for job in self.jobs.values():
            if job.status == PostStatus.RETRYING.value:
                # Check if retry delay has passed
                if job.last_attempt:
                    last = datetime.fromisoformat(job.last_attempt)
                    retry_after = last + timedelta(minutes=self.retry_delay_minutes)
                    if datetime.now() < retry_after:
                        continue  # Not ready yet

                # Reassign to any available account (original may be at limit)
                if job.account in available_names:
                    return job
                elif available_accounts:
                    # Original account unavailable, use another
                    job.account = available_accounts[0].name
                    return job

        return None

    def get_retry_jobs(self) -> List[PostJob]:
        """Get jobs that are waiting to retry"""
        return [j for j in self.jobs.values() if j.status == PostStatus.RETRYING.value]

    def get_failed_jobs(self) -> List[PostJob]:
        """Get permanently failed jobs"""
        return [j for j in self.jobs.values() if j.status == PostStatus.FAILED.value]

    def get_pending_jobs(self) -> List[PostJob]:
        """Get pending jobs"""
        return [j for j in self.jobs.values() if j.status == PostStatus.PENDING.value]

    def get_success_jobs(self) -> List[PostJob]:
        """Get successful jobs"""
        return [j for j in self.jobs.values() if j.status == PostStatus.SUCCESS.value]

    def execute_job(self, job: PostJob) -> bool:
        """Execute a single posting job with per-phase timeouts and logging"""
        from post_reel_smart import SmartInstagramPoster

        job.status = PostStatus.IN_PROGRESS.value
        job.attempts += 1
        job.last_attempt = datetime.now().isoformat()
        self.save_state()

        self._log(f"Posting {job.id} to {job.account} (attempt {job.attempts}/{job.max_attempts})")
        logger.info(f"execute_job START: job={job.id}, account={job.account}, attempt={job.attempts}")

        phase = "init"
        start_time = time.time()
        poster = None

        try:
            # TEST MODE: Force failure on first attempt
            if self.test_retry_mode and job.attempts == 1:
                self._log(f"[TEST MODE] Simulating failure on first attempt")
                raise Exception("TEST MODE: Simulated failure for retry testing")

            # Phase 1: Connect (timeout: 90s)
            phase = "connect"
            phase_start = time.time()
            poster = SmartInstagramPoster(job.account)
            poster.connect()
            logger.info(f"phase={phase} completed in {time.time()-phase_start:.1f}s")

            # Check overall timeout (120s for the whole job)
            if time.time() - start_time > 120:
                raise TimeoutError(f"Job exceeded total timeout after {phase}")

            # Phase 2: Post to Instagram (timeout handled inside post_reel_smart)
            phase = "instagram_post"
            phase_start = time.time()
            success = poster.post(job.video_path, job.caption, humanize=self.humanize)
            logger.info(f"phase={phase} completed in {time.time()-phase_start:.1f}s, success={success}")

            # Phase 3: Cleanup (handled in finally block)
            phase = "cleanup"

            total_time = time.time() - start_time
            if success:
                job.status = PostStatus.SUCCESS.value
                job.completed_at = datetime.now().isoformat()
                job.last_error = ""
                self.accounts[job.account].record_post(True)
                self._log(f"[OK] {job.id} posted successfully ({total_time:.1f}s)")
                logger.info(f"execute_job SUCCESS: job={job.id}, total_time={total_time:.1f}s")

                # Write to CSV for duplicate protection across restarts
                write_result_to_csv(job.id, job.account, "success")

                if self.on_job_complete:
                    self.on_job_complete(job, True)

                self.save_state()
                return True
            else:
                raise Exception("Post returned False")

        except Exception as e:
            error_msg = str(e)
            error_type_name = type(e).__name__
            job.last_error = f"[{phase}] {error_type_name}: {error_msg}"
            self._log(f"[FAIL] {job.id} at phase={phase}: {error_type_name}: {error_msg}")

            # Log with full stack trace
            log_and_mark_failed(job.account, job.id, phase, e)

            # Classify infrastructure errors (ADB/Appium/glogin issues)
            infra_error_patterns = [
                'ADB', 'adb', 'device offline', 'glogin', 'phone not running',
                'Appium', 'appium', 'UiAutomator', 'WebDriver', 'uiautomator',
                'connection refused', 'Connection refused', 'timeout', 'Timeout',
                'EADDRINUSE', 'actively refused', 'Cannot connect'
            ]
            is_infra_error = any(pattern in error_msg for pattern in infra_error_patterns) or \
                any(pattern in error_type_name for pattern in infra_error_patterns)

            if is_infra_error:
                self._log(f"[INFRA ERROR] Detected infrastructure error for {job.account}")
                logger.warning(f"Infrastructure error for {job.account}: {error_msg[:100]}")

            # Capture error details from poster if available
            if poster:
                if poster.last_error_type:
                    job.error_type = poster.last_error_type
                    self._log(f"[ERROR TYPE] {poster.last_error_type}: {poster.last_error_message}")
                if poster.last_screenshot_path:
                    job.screenshot_path = poster.last_screenshot_path
                    self._log(f"[SCREENSHOT] {poster.last_screenshot_path}")
                # Cleanup is handled in finally block

            # Decide: retry or permanent fail
            # Don't retry account-level errors (suspended, captcha, logged_out)
            non_retryable_errors = ['suspended', 'captcha', 'logged_out', 'action_blocked']
            if job.error_type in non_retryable_errors:
                job.status = PostStatus.FAILED.value
                self._log(f"[FAILED] {job.id} - non-retryable error: {job.error_type}")
            elif job.attempts >= job.max_attempts:
                job.status = PostStatus.FAILED.value
                self._log(f"[FAILED] {job.id} exhausted all retries")
            else:
                job.status = PostStatus.RETRYING.value
                self._log(f"[RETRY] {job.id} will retry in {self.retry_delay_minutes} min")

            # Record with is_infra_error to trigger account cooldown if needed
            self.accounts[job.account].record_post(False, is_infra_error=is_infra_error)

            if self.on_job_complete:
                self.on_job_complete(job, False)

            self.save_state()
            return False

        finally:
            # CRITICAL: ALWAYS ensure the phone is stopped after each job
            # This runs regardless of success, failure, or exception
            try:
                if poster:
                    poster.cleanup()
            except Exception as cleanup_err:
                logger.warning(f"Cleanup error: {cleanup_err}")

            # Double-check: explicitly stop this account's phone via API
            try:
                close_all_running_phones({job.account})
            except Exception as stop_err:
                logger.warning(f"Phone stop error for {job.account}: {stop_err}")

    def retry_failed_job(self, job_id: str):
        """Manually retry a failed job"""
        if job_id in self.jobs:
            job = self.jobs[job_id]
            if job.status == PostStatus.FAILED.value:
                job.status = PostStatus.RETRYING.value
                job.attempts = 0  # Reset attempts
                self._log(f"Reset {job_id} for retry")
                self.save_state()

    def retry_all_failed(self):
        """Reset all failed jobs for retry"""
        count = 0
        for job in self.jobs.values():
            if job.status == PostStatus.FAILED.value:
                job.status = PostStatus.RETRYING.value
                job.attempts = 0
                count += 1
        if count:
            self._log(f"Reset {count} failed jobs for retry")
            self.save_state()

    def _heartbeat_loop(self):
        """Periodically update lock file to prove we're still alive.

        This allows other instances to detect truly stale locks
        (process crashed without releasing lock).
        """
        while self.running:
            try:
                if os.path.exists(LOCK_FILE):
                    with open(LOCK_FILE, 'r') as f:
                        lock_data = json.load(f)
                    # Only update if we own the lock
                    if lock_data.get('pid') == os.getpid():
                        lock_data['last_heartbeat'] = datetime.now().isoformat()
                        with open(LOCK_FILE, 'w') as f:
                            json.dump(lock_data, f)
            except Exception as e:
                logger.warning(f"Heartbeat error: {e}")
            time.sleep(self.heartbeat_interval)

    def _worker_loop(self):
        """Main worker loop - robust with exception handling and Appium health checks"""
        self._log("Worker started")

        while self.running:
            try:
                if self.paused:
                    time.sleep(1)
                    continue

                # === APPIUM HEALTH CHECK ===
                # Check Appium health before processing a job
                if not check_appium_health():
                    self.appium_consecutive_failures += 1
                    self._log(f"[APPIUM] Health check failed ({self.appium_consecutive_failures}/{self.max_appium_failures_before_restart})")

                    if self.appium_consecutive_failures >= self.max_appium_failures_before_restart:
                        self._log("[APPIUM] Attempting auto-restart...")
                        if restart_appium():
                            self.appium_consecutive_failures = 0
                            self._log("[APPIUM] Restart successful")
                        else:
                            self._log("[APPIUM] Restart failed, waiting 60s...")
                            time.sleep(60)
                            continue
                    else:
                        # Wait and retry health check
                        time.sleep(10)
                        continue
                else:
                    # Reset counter on successful health check
                    if self.appium_consecutive_failures > 0:
                        self._log("[APPIUM] Health check passed, resetting failure counter")
                    self.appium_consecutive_failures = 0
                # === END APPIUM HEALTH CHECK ===

                job = self.get_next_job()

                if job:
                    self.execute_job(job)

                    # Delay before next post
                    if self.running and not self.paused:
                        self._log(f"Waiting {self.delay_between_posts}s before next post...")
                        time.sleep(self.delay_between_posts)
                else:
                    # No jobs ready, check for retry jobs
                    retry_jobs = self.get_retry_jobs()
                    if retry_jobs:
                        # Find next retry time
                        next_retry = None
                        for rj in retry_jobs:
                            if rj.last_attempt:
                                retry_at = datetime.fromisoformat(rj.last_attempt) + timedelta(minutes=self.retry_delay_minutes)
                                if next_retry is None or retry_at < next_retry:
                                    next_retry = retry_at

                        if next_retry:
                            wait_secs = (next_retry - datetime.now()).total_seconds()
                            if wait_secs > 0:
                                self._log(f"Next retry in {int(wait_secs)}s")

                    # Wait before checking again
                    time.sleep(5)

            except Exception as loop_error:
                # Catch ANY exception to keep the worker loop alive
                self._log(f"[WORKER ERROR] Unexpected error in worker loop: {type(loop_error).__name__}: {loop_error}")
                logger.exception("Worker loop exception - continuing")
                # Save state and continue
                try:
                    self.save_state()
                except:
                    pass
                time.sleep(10)  # Brief pause before continuing
                continue

        self._log("Worker stopped")

    def start(self):
        """Start the scheduler"""
        if self.running:
            return

        # CRITICAL: Close any running phones BEFORE starting
        # This prevents wasting minutes from previous crashed/interrupted runs
        self._log("[STARTUP] Checking for orphaned running phones...")
        account_names = set(self.accounts.keys()) if self.accounts else None
        stopped = close_all_running_phones(account_names)
        if stopped:
            self._log(f"[STARTUP] Closed {stopped} orphaned phone(s)")

        self.running = True
        self.paused = False

        # Start heartbeat thread to keep lock file fresh
        self.heartbeat_thread = threading.Thread(target=self._heartbeat_loop, daemon=True)
        self.heartbeat_thread.start()
        self._log("[HEARTBEAT] Started heartbeat thread")

        # Start worker thread
        self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)
        self.worker_thread.start()
        self._log("Scheduler started")

    def stop(self):
        """Stop the scheduler"""
        self.running = False
        if self.worker_thread:
            self.worker_thread.join(timeout=5)

        # CRITICAL: Close ALL running phones when stopping
        # This ensures no phones are left running after script ends
        self._log("[SHUTDOWN] Closing all managed phones...")
        account_names = set(self.accounts.keys()) if self.accounts else None
        stopped = close_all_running_phones(account_names)
        if stopped:
            self._log(f"[SHUTDOWN] Closed {stopped} phone(s)")

        self._log("Scheduler stopped")
        self.save_state()

    def pause(self):
        """Pause the scheduler"""
        self.paused = True
        self._log("Scheduler paused")

    def resume(self):
        """Resume the scheduler"""
        self.paused = False
        self._log("Scheduler resumed")

    def get_stats(self) -> dict:
        """Get current statistics"""
        accounts_on_cooldown = [acc.name for acc in self.accounts.values() if acc.is_on_cooldown()]
        return {
            'total_jobs': len(self.jobs),
            'pending': len(self.get_pending_jobs()),
            'success': len(self.get_success_jobs()),
            'retrying': len(self.get_retry_jobs()),
            'failed': len(self.get_failed_jobs()),
            'accounts': len(self.accounts),
            'accounts_on_cooldown': accounts_on_cooldown,
            'running': self.running,
            'paused': self.paused,
            'appium_healthy': check_appium_health(),
        }

    def generate_error_report(self) -> dict:
        """Generate a report of all errors grouped by type.

        Returns:
            dict: {
                'summary': {error_type: count},
                'accounts_by_error': {error_type: [account_list]},
                'details': [{job_id, account, error_type, error, screenshot}]
            }
        """
        failed_jobs = self.get_failed_jobs()

        # Group by error type
        by_error_type = {}
        for job in failed_jobs:
            error_type = job.error_type or 'unknown'
            if error_type not in by_error_type:
                by_error_type[error_type] = []
            by_error_type[error_type].append(job)

        # Build summary
        summary = {et: len(jobs) for et, jobs in by_error_type.items()}

        # Accounts by error type
        accounts_by_error = {}
        for error_type, jobs in by_error_type.items():
            accounts_by_error[error_type] = list(set(j.account for j in jobs))

        # Detailed list
        details = []
        for job in failed_jobs:
            details.append({
                'job_id': job.id,
                'account': job.account,
                'error_type': job.error_type or 'unknown',
                'error': job.last_error,
                'screenshot': job.screenshot_path,
                'attempts': job.attempts,
            })

        return {
            'summary': summary,
            'accounts_by_error': accounts_by_error,
            'details': details,
            'total_failed': len(failed_jobs),
        }

    def save_error_report(self, filepath: str = None) -> str:
        """Save error report to a file.

        Args:
            filepath: Optional path. Defaults to error_report_YYYYMMDD_HHMMSS.json

        Returns:
            Path to saved report file
        """
        if not filepath:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = f"error_report_{timestamp}.json"

        report = self.generate_error_report()
        report['generated_at'] = datetime.now().isoformat()

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        self._log(f"Error report saved: {filepath}")
        return filepath

    def get_report_text(self) -> str:
        """Generate human-readable error report text."""
        report = self.generate_error_report()

        lines = []
        lines.append("=" * 50)
        lines.append("ERROR REPORT")
        lines.append("=" * 50)
        lines.append(f"Total Failed: {report['total_failed']}")
        lines.append("")

        if report['summary']:
            lines.append("SUMMARY BY ERROR TYPE:")
            for error_type, count in sorted(report['summary'].items(), key=lambda x: -x[1]):
                lines.append(f"  - {error_type}: {count}")
            lines.append("")

            lines.append("AFFECTED ACCOUNTS:")
            for error_type, accounts in report['accounts_by_error'].items():
                lines.append(f"  [{error_type}]")
                for acc in accounts:
                    lines.append(f"    - {acc}")
            lines.append("")

            lines.append("SCREENSHOTS:")
            screenshots = [d for d in report['details'] if d['screenshot']]
            if screenshots:
                for d in screenshots:
                    lines.append(f"  - {d['account']} ({d['error_type']}): {d['screenshot']}")
            else:
                lines.append("  No screenshots captured")
        else:
            lines.append("No errors to report!")

        lines.append("=" * 50)
        return "\n".join(lines)


# CLI interface for testing
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Posting Scheduler CLI')
    parser.add_argument('--add-folder', help='Add video folder')
    parser.add_argument('--add-accounts', nargs='+', help='Add accounts')
    parser.add_argument('--status', action='store_true', help='Show status')
    parser.add_argument('--run', action='store_true', help='Run scheduler')
    parser.add_argument('--retry-all', action='store_true', help='Retry all failed jobs')
    parser.add_argument('--force', action='store_true', help='Force run even if lock exists')

    args = parser.parse_args()

    # Acquire single-instance lock if running the scheduler
    if args.run:
        if args.force and os.path.exists(LOCK_FILE):
            print(f"[FORCE] Removing existing lock file")
            os.remove(LOCK_FILE)

        if not acquire_lock():
            print("\n[ABORT] Cannot start scheduler - another instance is running.")
            print("Use --force to override (only if you're sure no other instance is running)")
            sys.exit(1)

    scheduler = PostingScheduler()

    if args.add_folder:
        scheduler.add_video_folder(args.add_folder)

    if args.add_accounts:
        for acc in args.add_accounts:
            scheduler.add_account(acc)

    if args.retry_all:
        scheduler.retry_all_failed()

    if args.status:
        stats = scheduler.get_stats()
        print("\n=== Scheduler Status ===")
        print(f"Jobs: {stats['total_jobs']} total")
        print(f"  - Pending: {stats['pending']}")
        print(f"  - Success: {stats['success']}")
        print(f"  - Retrying: {stats['retrying']}")
        print(f"  - Failed: {stats['failed']}")
        print(f"Accounts: {stats['accounts']}")
        print(f"Running: {stats['running']}")

        # Show Appium health
        appium_status = "HEALTHY" if stats['appium_healthy'] else "NOT READY"
        print(f"\nAppium: {appium_status}")

        # Show accounts on cooldown
        if stats['accounts_on_cooldown']:
            print(f"\nAccounts on cooldown ({len(stats['accounts_on_cooldown'])}):")
            for acc in stats['accounts_on_cooldown']:
                print(f"  - {acc}")

        # Show lock status
        if os.path.exists(LOCK_FILE):
            try:
                with open(LOCK_FILE, 'r') as f:
                    lock_data = json.load(f)
                pid = lock_data.get('pid')
                started = lock_data.get('started', 'unknown')
                last_hb = lock_data.get('last_heartbeat', 'never')
                running = is_process_running(pid) if pid else False
                print(f"\nLock: PID {pid} ({'RUNNING' if running else 'STALE'})")
                print(f"  Started: {started}")
                print(f"  Last heartbeat: {last_hb}")
            except:
                print(f"\nLock: {LOCK_FILE} exists but unreadable")
        else:
            print(f"\nLock: No active lock")

    if args.run:
        print("Starting scheduler (Ctrl+C to stop)...")
        scheduler.start()
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            scheduler.stop()
            release_lock()
</file>

<file path="progress_tracker.py">
"""
CSV-Based Progress Tracker with File Locking and Retry Support.

This module provides thread-safe and process-safe job tracking for parallel workers.
It uses file locking to ensure only one worker can claim a job at a time, preventing
duplicate posts across multiple worker processes.

Key features:
- File-based locking using portalocker (cross-platform)
- Atomic writes via temp file + rename
- Claim jobs with worker_id tracking
- Resume support - unclaimed jobs stay pending across restarts
- Status transitions: pending -> claimed -> success/failed/retrying
- Automatic retry with configurable max_attempts and retry_delay
- Non-retryable error classification (suspended, captcha, loggedout, actionblocked)

Usage:
    tracker = ProgressTracker("progress.csv")

    # Seed from input jobs (orchestrator does this once)
    tracker.seed_from_scheduler_state("scheduler_state.json")

    # Workers claim and process jobs
    job = tracker.claim_next_job(worker_id=0)
    if job:
        # ... process job ...
        tracker.update_job_status(job['job_id'], 'success', worker_id=0)
        # Or on failure with retry:
        tracker.update_job_status(job['job_id'], 'failed', worker_id=0, error='...',
                                  max_attempts=3, retry_delay_minutes=5)
"""

import os
import csv
import json
import time
import shutil
import tempfile
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Any
from dataclasses import dataclass

# Cross-platform file locking
try:
    import portalocker
    HAS_PORTALOCKER = True
except ImportError:
    HAS_PORTALOCKER = False
    # Fallback for Windows without portalocker
    import msvcrt

logger = logging.getLogger(__name__)


class FileLockError(Exception):
    """Raised when file lock cannot be acquired."""
    pass


class ProgressTracker:
    """
    Process-safe progress tracker using CSV with file locking.

    The progress CSV has columns:
        - job_id: Unique identifier (typically the video shortcode)
        - account: Account name to post with
        - video_path: Path to video file
        - caption: Caption text
        - status: pending/claimed/success/failed/skipped
        - worker_id: Which worker claimed/processed this job
        - claimed_at: Timestamp when claimed
        - completed_at: Timestamp when completed
        - error: Error message if failed
    """

    # CSV columns (extended for retry support)
    COLUMNS = [
        'job_id', 'account', 'video_path', 'caption', 'status',
        'worker_id', 'claimed_at', 'completed_at', 'error',
        'attempts', 'max_attempts', 'retry_at', 'error_type'
    ]

    # Valid status values
    STATUS_PENDING = 'pending'
    STATUS_CLAIMED = 'claimed'
    STATUS_SUCCESS = 'success'
    STATUS_FAILED = 'failed'
    STATUS_SKIPPED = 'skipped'
    STATUS_RETRYING = 'retrying'

    # Non-retryable error types - these failures should not be retried
    NON_RETRYABLE_ERRORS = {'suspended', 'captcha', 'loggedout', 'actionblocked', 'banned'}

    # Error classification patterns (Strategy pattern)
    # Maps error_type -> list of substrings to match in error message
    ERROR_PATTERNS = {
        'suspended': ['suspended', 'account has been suspended'],
        'captcha': ['captcha', 'verify'],
        'loggedout': ['log in', 'logged out', 'sign up'],
        'actionblocked': ['action blocked', 'try again later'],
        'banned': ['banned', 'disabled'],
    }

    # Default retry settings
    DEFAULT_MAX_ATTEMPTS = 3
    DEFAULT_RETRY_DELAY_MINUTES = 5

    def __init__(self, progress_file: str, lock_timeout: float = 30.0):
        """
        Initialize the progress tracker.

        Args:
            progress_file: Path to the progress CSV file
            lock_timeout: Maximum seconds to wait for file lock
        """
        self.progress_file = progress_file
        self.lock_file = progress_file + '.lock'
        self.lock_timeout = lock_timeout

    def _acquire_lock(self, file_handle) -> None:
        """Acquire exclusive lock on the file."""
        if HAS_PORTALOCKER:
            portalocker.lock(file_handle, portalocker.LOCK_EX)
        else:
            # Windows fallback
            msvcrt.locking(file_handle.fileno(), msvcrt.LK_NBLCK, 1)

    def _release_lock(self, file_handle) -> None:
        """Release the file lock."""
        if HAS_PORTALOCKER:
            portalocker.unlock(file_handle)
        else:
            # Windows fallback
            try:
                file_handle.seek(0)
                msvcrt.locking(file_handle.fileno(), msvcrt.LK_UNLCK, 1)
            except:
                pass

    def _read_all_jobs(self) -> List[Dict[str, Any]]:
        """Read all jobs from the progress file."""
        if not os.path.exists(self.progress_file):
            return []

        jobs = []
        with open(self.progress_file, 'r', encoding='utf-8', newline='') as f:
            self._acquire_lock(f)
            try:
                reader = csv.DictReader(f)
                for row in reader:
                    jobs.append(row)
            finally:
                self._release_lock(f)
        return jobs

    def _write_all_jobs(self, jobs: List[Dict[str, Any]]) -> None:
        """
        Write all jobs to the progress file atomically.

        Uses temp file + rename for atomic write.
        """
        # Write to temp file first
        fd, temp_path = tempfile.mkstemp(suffix='.csv', dir=os.path.dirname(self.progress_file) or '.')

        try:
            with os.fdopen(fd, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=self.COLUMNS)
                writer.writeheader()
                for job in jobs:
                    # Ensure all columns exist
                    row = {col: job.get(col, '') for col in self.COLUMNS}
                    writer.writerow(row)

            # Atomic rename (works on Windows if destination doesn't exist)
            if os.path.exists(self.progress_file):
                os.remove(self.progress_file)
            shutil.move(temp_path, self.progress_file)

        except Exception as e:
            # Clean up temp file on error
            try:
                os.unlink(temp_path)
            except:
                pass
            raise e

    def _locked_operation(self, operation):
        """
        Execute an operation with file locking.

        Args:
            operation: Callable that takes (jobs) and returns (jobs, result)

        Returns:
            The result from the operation
        """
        # Use a separate lock file for coordination
        os.makedirs(os.path.dirname(self.lock_file) or '.', exist_ok=True)

        with open(self.lock_file, 'w') as lock_handle:
            self._acquire_lock(lock_handle)
            try:
                jobs = self._read_all_jobs() if os.path.exists(self.progress_file) else []
                jobs, result = operation(jobs)
                if jobs is not None:
                    self._write_all_jobs(jobs)
                return result
            finally:
                self._release_lock(lock_handle)

    def exists(self) -> bool:
        """Check if progress file exists."""
        return os.path.exists(self.progress_file)

    def _load_success_counts(self) -> Dict[str, int]:
        """
        Load success counts per account from existing progress file.

        Returns:
            Dict mapping account name to number of successful posts
        """
        success_counts = {}
        if not os.path.exists(self.progress_file):
            return success_counts

        with open(self.progress_file, 'r', encoding='utf-8', newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('status') == self.STATUS_SUCCESS:
                    acc = row.get('account', '')
                    if acc:
                        success_counts[acc] = success_counts.get(acc, 0) + 1
        return success_counts

    def _load_assigned_counts(self) -> Dict[str, int]:
        """
        Load assigned counts per account from existing progress file.

        Assigned = pending + claimed + success + retrying (any job that "counts" toward daily limit)

        CRITICAL: This prevents reusing accounts within a batch when reseeding.
        For max_posts_per_account_per_day=1, each account should only appear once
        in the entire day's ledger (pending/claimed/success/retrying).

        Returns:
            Dict mapping account name to number of assigned jobs
        """
        assigned_counts = {}
        if not os.path.exists(self.progress_file):
            return assigned_counts

        active_statuses = {self.STATUS_PENDING, self.STATUS_CLAIMED,
                          self.STATUS_SUCCESS, self.STATUS_RETRYING}

        with open(self.progress_file, 'r', encoding='utf-8', newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('status') in active_statuses:
                    acc = row.get('account', '')
                    if acc:
                        assigned_counts[acc] = assigned_counts.get(acc, 0) + 1
        return assigned_counts

    def seed_from_scheduler_state(
        self,
        state_file: str,
        account_list: List[str] = None,
        redistribute: bool = True,
        max_posts_per_account_per_day: int = 1
    ) -> int:
        """
        Seed progress file from scheduler_state.json.

        CRITICAL: Enforces per-account daily posting limits!
        - Builds success_count_by_account dict from existing progress file
        - Only assigns jobs to accounts with success_count < max_posts_per_account_per_day
        - Tracks in-memory counts during seeding to prevent exceeding limits
        - Each account can be assigned at most 1 job per seeding pass (no reuse in same batch)

        Args:
            state_file: Path to scheduler_state.json
            account_list: Optional list of accounts to use (overrides state file accounts)
            redistribute: If True, redistribute jobs evenly across accounts
            max_posts_per_account_per_day: Max successful posts per account per day (default 1)

        Returns:
            Number of NEW jobs seeded (not counting existing jobs)
        """
        if not os.path.exists(state_file):
            raise FileNotFoundError(f"Scheduler state file not found: {state_file}")

        with open(state_file, 'r', encoding='utf-8') as f:
            state = json.load(f)

        jobs_data = state.get('jobs', [])
        accounts = account_list or [acc['name'] for acc in state.get('accounts', [])]

        # CRITICAL: Build assigned_count_by_account from existing progress file
        # This tracks ALL jobs assigned to each account TODAY (pending, claimed, success, retrying)
        # Using assigned counts (not just success) prevents same-account reuse within a batch
        assigned_count_by_account = self._load_assigned_counts()
        existing_job_ids = set()
        existing_jobs = []

        if os.path.exists(self.progress_file):
            existing_jobs = self._read_all_jobs()
            for job in existing_jobs:
                existing_job_ids.add(job.get('job_id', ''))

        # Log accounts that are at or over the daily limit
        accounts_at_limit = [acc for acc in accounts if assigned_count_by_account.get(acc, 0) >= max_posts_per_account_per_day]
        if accounts_at_limit:
            logger.info(f"EXCLUDING {len(accounts_at_limit)} accounts at daily limit ({max_posts_per_account_per_day}): {sorted(accounts_at_limit)}")

        # Filter accounts - only those with assigned_count < max_posts_per_account_per_day
        available_accounts = [
            acc for acc in accounts
            if assigned_count_by_account.get(acc, 0) < max_posts_per_account_per_day
        ]
        logger.info(f"Available accounts for new jobs: {len(available_accounts)} (excluded {len(accounts_at_limit)} at daily limit)")

        # Filter to pending/retrying jobs that haven't been added yet
        pending_jobs = [
            j for j in jobs_data
            if j.get('status') in ('pending', 'retrying') and j.get('id', '') not in existing_job_ids
        ]

        if not pending_jobs:
            logger.info("No new pending jobs to seed")
            return 0

        if not available_accounts:
            logger.info(f"No available accounts - all {len(accounts)} have hit daily limit of {max_posts_per_account_per_day}")
            return 0

        # CRITICAL: Assign jobs with daily limit tracking
        # Copy assigned counts to track in-memory during this seeding pass
        seeding_assigned_counts = dict(assigned_count_by_account)
        new_jobs = []
        accounts_used_this_batch = set()  # Each account gets at most 1 job per batch

        for job in pending_jobs:
            # Find an account that:
            # 1. Is not already used in this batch
            # 2. Has assigned_count < max_posts_per_account_per_day
            assigned_account = ''
            for acc in available_accounts:
                if acc in accounts_used_this_batch:
                    continue
                if seeding_assigned_counts.get(acc, 0) >= max_posts_per_account_per_day:
                    continue
                assigned_account = acc
                accounts_used_this_batch.add(acc)
                # Increment in-memory count
                # This prevents assigning more than max_posts_per_account_per_day jobs
                # even when max > 1
                seeding_assigned_counts[acc] = seeding_assigned_counts.get(acc, 0) + 1
                break

            new_jobs.append({
                'job_id': job.get('id', ''),
                'account': assigned_account,  # Empty string if no account available
                'video_path': job.get('video_path', ''),
                'caption': job.get('caption', ''),
                'status': self.STATUS_PENDING,
                'worker_id': '',
                'claimed_at': '',
                'completed_at': '',
                'error': '',
                'attempts': '0',
                'max_attempts': str(self.DEFAULT_MAX_ATTEMPTS),
                'retry_at': '',
                'error_type': ''
            })

        # Combine existing jobs with new jobs
        all_jobs = existing_jobs + new_jobs

        # Log distribution for visibility
        assigned_count = sum(1 for j in new_jobs if j['account'])
        unassigned_count = sum(1 for j in new_jobs if not j['account'])
        logger.info(f"Seeded {len(new_jobs)} NEW jobs: {assigned_count} assigned to accounts, {unassigned_count} unassigned")
        logger.info(f"Using {len(accounts_used_this_batch)} accounts this batch (max {max_posts_per_account_per_day} posts/account/day)")
        logger.info(f"Total jobs in progress file: {len(all_jobs)}")

        self._write_all_jobs(all_jobs)
        return len(new_jobs)

    def seed_from_jobs(self, jobs: List[Dict[str, Any]]) -> int:
        """
        Seed progress file from a list of job dictionaries.

        Args:
            jobs: List of dicts with keys: job_id, account, video_path, caption

        Returns:
            Number of jobs seeded
        """
        progress_jobs = []
        for job in jobs:
            progress_jobs.append({
                'job_id': job.get('job_id', job.get('id', '')),
                'account': job.get('account', ''),
                'video_path': job.get('video_path', ''),
                'caption': job.get('caption', ''),
                'status': self.STATUS_PENDING,
                'worker_id': '',
                'claimed_at': '',
                'completed_at': '',
                'error': ''
            })

        self._write_all_jobs(progress_jobs)
        logger.info(f"Seeded {len(progress_jobs)} jobs")
        return len(progress_jobs)

    def _within_daily_limit(self, account: str, success_counts: Dict[str, int], max_per_day: int) -> bool:
        """
        Check if an account is within its daily posting limit.

        Args:
            account: Account name to check
            success_counts: Dict of account -> success count
            max_per_day: Maximum posts allowed per day

        Returns:
            True if account can still post, False if at/over limit
        """
        return success_counts.get(account, 0) < max_per_day

    def claim_next_job(self, worker_id: int, max_posts_per_account_per_day: int = 1) -> Optional[Dict[str, Any]]:
        """
        Claim the next pending job for a worker.

        This operation is atomic - only one worker can claim a job even if
        multiple workers call this simultaneously.

        IMPORTANT (Defense in Depth):
        1. Jobs without an assigned account are SKIPPED (waiting for account)
        2. Account-level locking - a worker will NOT claim a job if
           another worker already has a job claimed for the same account.
        3. Daily limit check - a worker will NOT claim a job if the account
           has already hit max_posts_per_account_per_day successful posts.

        Args:
            worker_id: ID of the worker claiming the job
            max_posts_per_account_per_day: Max successful posts per account per day (default 1)

        Returns:
            The claimed job dict, or None if no pending jobs available
        """
        def _claim_operation(jobs):
            # First, find all accounts currently being processed (claimed by any worker)
            accounts_in_use = set()

            # DEFENSE IN DEPTH: Build success counts to check daily limits
            success_counts = {}
            for job in jobs:
                if job.get('status') == self.STATUS_CLAIMED:
                    account = job.get('account', '')
                    if account:
                        accounts_in_use.add(account)
                elif job.get('status') == self.STATUS_SUCCESS:
                    account = job.get('account', '')
                    if account:
                        success_counts[account] = success_counts.get(account, 0) + 1

            if accounts_in_use:
                logger.debug(f"Accounts currently in use: {accounts_in_use}")

            # Find accounts at daily limit
            accounts_at_limit = {acc for acc, cnt in success_counts.items() if cnt >= max_posts_per_account_per_day}
            if accounts_at_limit:
                logger.debug(f"Accounts at daily limit ({max_posts_per_account_per_day}): {accounts_at_limit}")

            # Find a pending job that:
            # 1. HAS an account assigned
            # 2. Account is NOT currently in use
            # 3. Account has NOT hit daily limit (defense in depth)
            for job in jobs:
                if job.get('status') == self.STATUS_PENDING:
                    account = job.get('account', '')

                    # Skip jobs without an assigned account (waiting for one to be freed)
                    if not account:
                        continue

                    if account in accounts_in_use:
                        # Skip - another worker is already processing this account
                        logger.debug(f"Skipping job {job['job_id']} - account {account} in use")
                        continue

                    # DEFENSE IN DEPTH: Check daily limit
                    if account in accounts_at_limit:
                        logger.warning(f"Skipping job {job['job_id']} - account {account} at daily limit of {max_posts_per_account_per_day}")
                        continue

                    # Claim this job
                    job['status'] = self.STATUS_CLAIMED
                    job['worker_id'] = str(worker_id)
                    job['claimed_at'] = datetime.now().isoformat()
                    logger.info(f"Worker {worker_id} claimed job {job['job_id']} (account: {account})")
                    return jobs, dict(job)

            # No available jobs (either none pending, all have accounts in use, or all waiting for accounts)
            return jobs, None

        return self._locked_operation(_claim_operation)

    def verify_job_before_post(self, job_id: str, worker_id: int) -> tuple:
        """
        Verify a job is still valid before actually posting.

        This is a safety check to prevent duplicate posts. Call this right before
        the actual Instagram posting to ensure:
        1. The job is still claimed by this worker (not stolen/completed)
        2. No duplicate success exists for this exact job

        Args:
            job_id: The job ID to verify
            worker_id: The worker attempting to post

        Returns:
            (is_valid: bool, error_message: str)
        """
        def _verify_operation(jobs):
            for job in jobs:
                if job.get('job_id') == job_id:
                    status = job.get('status', '')
                    claimed_by = job.get('worker_id', '')

                    if status == 'success':
                        return None, (False, f"Job already completed successfully")

                    if status == 'claimed':
                        if str(claimed_by) == str(worker_id):
                            return None, (True, "")
                        else:
                            return None, (False, f"Job claimed by worker {claimed_by}, not {worker_id}")

                    if status == 'pending':
                        return None, (False, f"Job is pending, not claimed")

                    return None, (False, f"Unexpected status: {status}")

            return None, (False, f"Job {job_id} not found")

        return self._locked_operation(_verify_operation)

    def _classify_error(self, error: str) -> str:
        """
        Classify an error message into an error type.

        Uses ERROR_PATTERNS dict for pattern matching (Strategy pattern).
        Returns one of the NON_RETRYABLE_ERRORS or empty string for retryable errors.
        """
        error_lower = error.lower() if error else ''

        for error_type, patterns in self.ERROR_PATTERNS.items():
            if any(pattern in error_lower for pattern in patterns):
                return error_type

        return ''  # Retryable

    def update_job_status(
        self,
        job_id: str,
        status: str,
        worker_id: int,
        error: str = '',
        retry_delay_minutes: float = None
    ) -> bool:
        """
        Update the status of a job with automatic retry logic.

        RETRY BEHAVIOR:
        - On success: marks job as success
        - On failure:
          - Increments attempts counter
          - If error is non-retryable (suspended, captcha, loggedout, actionblocked, banned):
            marks as failed immediately
          - If attempts < max_attempts: marks as retrying with retry_at timestamp
          - If attempts >= max_attempts: marks as failed (permanent)

        Args:
            job_id: The job ID to update
            status: New status (success/failed/skipped)
            worker_id: Worker that processed the job
            error: Error message if failed
            retry_delay_minutes: Minutes before retry (default: DEFAULT_RETRY_DELAY_MINUTES)

        Returns:
            True if job was found and updated
        """
        if retry_delay_minutes is None:
            retry_delay_minutes = self.DEFAULT_RETRY_DELAY_MINUTES

        def _update_operation(jobs):
            for job in jobs:
                if job.get('job_id') == job_id:
                    job['worker_id'] = str(worker_id)
                    job['completed_at'] = datetime.now().isoformat()
                    job['error'] = error[:500] if error else ''  # Truncate long errors

                    if status == self.STATUS_SUCCESS:
                        # Success - job is done
                        job['status'] = self.STATUS_SUCCESS
                        logger.info(f"Worker {worker_id} completed job {job_id} successfully")

                    elif status == self.STATUS_FAILED:
                        # Failure - check if we should retry
                        attempts_str = job.get('attempts') or '0'
                        attempts = int(attempts_str) + 1
                        max_attempts_str = job.get('max_attempts') or str(self.DEFAULT_MAX_ATTEMPTS)
                        max_attempts = int(max_attempts_str)
                        job['attempts'] = str(attempts)

                        # Classify the error
                        error_type = self._classify_error(error)
                        job['error_type'] = error_type

                        if error_type in self.NON_RETRYABLE_ERRORS:
                            # Non-retryable error - fail permanently
                            job['status'] = self.STATUS_FAILED
                            logger.warning(f"Worker {worker_id} job {job_id} FAILED (non-retryable: {error_type})")

                        elif attempts >= max_attempts:
                            # Max attempts reached - fail permanently
                            job['status'] = self.STATUS_FAILED
                            logger.warning(f"Worker {worker_id} job {job_id} FAILED (max attempts {max_attempts} reached)")

                        else:
                            # Retryable - set to retrying with delay
                            job['status'] = self.STATUS_RETRYING
                            retry_at = datetime.now() + timedelta(minutes=retry_delay_minutes)
                            job['retry_at'] = retry_at.isoformat()
                            logger.info(f"Worker {worker_id} job {job_id} will RETRY in {retry_delay_minutes} min (attempt {attempts}/{max_attempts})")

                    else:
                        # Other status (skipped, etc.)
                        job['status'] = status
                        logger.info(f"Worker {worker_id} updated job {job_id} to {status}")

                    return jobs, True

            logger.warning(f"Job {job_id} not found in progress file")
            return jobs, False

        return self._locked_operation(_update_operation)

    def get_retry_jobs(self) -> List[Dict[str, Any]]:
        """
        Get all jobs that are in RETRYING status and ready to be retried.

        A job is ready for retry if:
        - status == RETRYING
        - retry_at timestamp has passed (or is empty)

        Returns:
            List of job dicts ready for retry
        """
        if not os.path.exists(self.progress_file):
            return []

        jobs = self._read_all_jobs()
        ready_jobs = []
        now = datetime.now()

        for job in jobs:
            if job.get('status') == self.STATUS_RETRYING:
                retry_at_str = job.get('retry_at', '')
                if retry_at_str:
                    try:
                        retry_at = datetime.fromisoformat(retry_at_str)
                        if now >= retry_at:
                            ready_jobs.append(job)
                    except ValueError:
                        # Invalid timestamp, allow retry
                        ready_jobs.append(job)
                else:
                    # No retry_at set, allow immediately
                    ready_jobs.append(job)

        return ready_jobs

    def claim_retry_job(self, worker_id: int, max_posts_per_account_per_day: int = 1) -> Optional[Dict[str, Any]]:
        """
        Claim a job that is ready to be retried.

        Similar to claim_next_job but only looks at RETRYING jobs whose
        retry_at timestamp has passed.

        Args:
            worker_id: ID of the worker claiming the job
            max_posts_per_account_per_day: Max successful posts per account per day

        Returns:
            The claimed job dict, or None if no retry jobs available
        """
        def _claim_retry_operation(jobs):
            now = datetime.now()

            # Build success counts for daily limit check
            success_counts = {}
            accounts_in_use = set()

            for job in jobs:
                acc = job.get('account', '')
                if not acc:
                    continue
                if job.get('status') == self.STATUS_CLAIMED:
                    accounts_in_use.add(acc)
                elif job.get('status') == self.STATUS_SUCCESS:
                    success_counts[acc] = success_counts.get(acc, 0) + 1

            # Find a RETRYING job ready to retry
            for job in jobs:
                if job.get('status') != self.STATUS_RETRYING:
                    continue

                acc = job.get('account', '')
                if not acc:
                    continue

                # Check retry_at
                retry_at_str = job.get('retry_at', '')
                if retry_at_str:
                    try:
                        retry_at = datetime.fromisoformat(retry_at_str)
                        if now < retry_at:
                            continue  # Not ready yet
                    except ValueError:
                        pass  # Invalid timestamp, allow retry

                # Check account not in use
                if acc in accounts_in_use:
                    continue

                # Check daily limit
                if success_counts.get(acc, 0) >= max_posts_per_account_per_day:
                    continue

                # Claim this job
                job['status'] = self.STATUS_CLAIMED
                job['worker_id'] = str(worker_id)
                job['claimed_at'] = now.isoformat()
                job['retry_at'] = ''  # Clear retry_at
                logger.info(f"Worker {worker_id} claimed RETRY job {job['job_id']} (account: {acc}, attempt {job.get('attempts', '?')})")
                return jobs, dict(job)

            return jobs, None

        return self._locked_operation(_claim_retry_operation)

    def retry_failed_job(self, job_id: str) -> bool:
        """
        Reset a single failed job back to RETRYING status for another attempt.

        This allows jobs that permanently failed (hit max_attempts or non-retryable error)
        to be retried again. Resets attempts to 0 and clears error_type.

        Args:
            job_id: The job ID to retry

        Returns:
            True if job was found and reset to retrying
        """
        def _retry_operation(jobs):
            for job in jobs:
                if job.get('job_id') == job_id:
                    if job.get('status') != self.STATUS_FAILED:
                        logger.warning(f"Job {job_id} is not failed (status: {job.get('status')}), cannot retry")
                        return jobs, False

                    # Reset job for retry
                    job['status'] = self.STATUS_RETRYING
                    job['attempts'] = '0'  # Reset attempts
                    job['error_type'] = ''  # Clear error type
                    job['retry_at'] = ''  # Clear retry delay - ready immediately
                    job['worker_id'] = ''  # Clear worker assignment
                    job['completed_at'] = ''  # Clear completion time
                    logger.info(f"Job {job_id} reset to RETRYING status")
                    return jobs, True

            logger.warning(f"Job {job_id} not found")
            return jobs, False

        return self._locked_operation(_retry_operation)

    def retry_all_failed(self, include_non_retryable: bool = False) -> int:
        """
        Reset ALL failed jobs back to RETRYING status.

        This is a convenience method to bulk-retry jobs that hit max_attempts
        or had transient failures. Call this at the start of a run to give
        previously failed jobs another chance.

        Args:
            include_non_retryable: If True, also retry jobs with non-retryable
                                   error types (suspended, captcha, loggedout, etc.).
                                   Default False - only retry jobs with retryable errors.

        Returns:
            Number of jobs reset to retrying
        """
        def _retry_all_operation(jobs):
            count = 0
            for job in jobs:
                if job.get('status') != self.STATUS_FAILED:
                    continue

                # Check error type
                error_type = job.get('error_type', '')
                if not include_non_retryable and error_type in self.NON_RETRYABLE_ERRORS:
                    logger.debug(f"Skipping job {job.get('job_id')} - non-retryable error: {error_type}")
                    continue

                # Reset job for retry
                job['status'] = self.STATUS_RETRYING
                job['attempts'] = '0'  # Reset attempts
                job['retry_at'] = ''  # Clear retry delay - ready immediately
                job['worker_id'] = ''  # Clear worker assignment
                job['completed_at'] = ''  # Clear completion time
                # Note: We keep error_type for logging, it will be overwritten on next failure
                count += 1
                logger.info(f"Job {job.get('job_id')} reset to RETRYING (was: {error_type or 'retryable error'})")

            if count > 0:
                logger.info(f"Reset {count} failed jobs to RETRYING status")
            else:
                logger.info("No failed jobs found to retry")

            return jobs, count

        return self._locked_operation(_retry_all_operation)

    def release_claimed_job(self, job_id: str, worker_id: int) -> bool:
        """
        Release a claimed job back to pending status.

        Useful if a worker crashes or is interrupted before completing.

        Args:
            job_id: The job ID to release
            worker_id: Worker that had claimed the job

        Returns:
            True if job was found and released
        """
        def _release_operation(jobs):
            for job in jobs:
                if job.get('job_id') == job_id and job.get('worker_id') == str(worker_id):
                    if job.get('status') == self.STATUS_CLAIMED:
                        job['status'] = self.STATUS_PENDING
                        job['worker_id'] = ''
                        job['claimed_at'] = ''
                        logger.info(f"Released job {job_id} back to pending")
                        return jobs, True
            return jobs, False

        return self._locked_operation(_release_operation)

    def release_stale_claims(self, max_age_seconds: int = 600) -> int:
        """
        Release jobs that have been claimed for too long without completing.

        Args:
            max_age_seconds: Maximum age of claim before releasing (default 10 min)

        Returns:
            Number of jobs released
        """
        def _release_stale_operation(jobs):
            released = 0
            now = datetime.now()
            for job in jobs:
                if job.get('status') == self.STATUS_CLAIMED:
                    claimed_at = job.get('claimed_at', '')
                    if claimed_at:
                        try:
                            claim_time = datetime.fromisoformat(claimed_at)
                            age = (now - claim_time).total_seconds()
                            if age > max_age_seconds:
                                job['status'] = self.STATUS_PENDING
                                job['worker_id'] = ''
                                job['claimed_at'] = ''
                                logger.info(f"Released stale claim on {job['job_id']} (age: {age:.0f}s)")
                                released += 1
                        except:
                            pass
            return jobs, released

        return self._locked_operation(_release_stale_operation)

    def get_stats(self) -> Dict[str, int]:
        """Get job status statistics."""
        jobs = self._read_all_jobs()
        stats = {
            'total': len(jobs),
            'pending': 0,
            'claimed': 0,
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'retrying': 0
        }
        for job in jobs:
            status = job.get('status', '')
            if status in stats:
                stats[status] += 1
        return stats

    def get_worker_stats(self) -> Dict[int, Dict[str, int]]:
        """Get statistics per worker."""
        jobs = self._read_all_jobs()
        worker_stats = {}
        for job in jobs:
            worker_id = job.get('worker_id', '')
            if worker_id:
                try:
                    wid = int(worker_id)
                    if wid not in worker_stats:
                        worker_stats[wid] = {'success': 0, 'failed': 0, 'claimed': 0}
                    status = job.get('status', '')
                    if status in worker_stats[wid]:
                        worker_stats[wid][status] += 1
                except ValueError:
                    pass
        return worker_stats

    def is_complete(self) -> bool:
        """Check if all jobs are complete (no pending, claimed, or retrying)."""
        stats = self.get_stats()
        return stats['pending'] == 0 and stats['claimed'] == 0 and stats['retrying'] == 0


if __name__ == "__main__":
    # Demo/test
    import sys

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s'
    )

    # Create a test progress file
    test_file = "test_progress.csv"
    tracker = ProgressTracker(test_file)

    print("\n1. Seeding with test jobs...")
    test_jobs = [
        {'job_id': 'video1', 'account': 'account_a', 'video_path': '/path/to/v1.mp4', 'caption': 'Test 1'},
        {'job_id': 'video2', 'account': 'account_b', 'video_path': '/path/to/v2.mp4', 'caption': 'Test 2'},
        {'job_id': 'video3', 'account': 'account_a', 'video_path': '/path/to/v3.mp4', 'caption': 'Test 3'},
    ]
    tracker.seed_from_jobs(test_jobs)
    print(f"   Stats: {tracker.get_stats()}")

    print("\n2. Worker 0 claims a job...")
    job = tracker.claim_next_job(worker_id=0)
    print(f"   Claimed: {job['job_id']} for account {job['account']}")
    print(f"   Stats: {tracker.get_stats()}")

    print("\n3. Worker 1 claims a job...")
    job = tracker.claim_next_job(worker_id=1)
    print(f"   Claimed: {job['job_id']} for account {job['account']}")
    print(f"   Stats: {tracker.get_stats()}")

    print("\n4. Worker 0 completes job as success...")
    tracker.update_job_status('video1', 'success', worker_id=0)
    print(f"   Stats: {tracker.get_stats()}")

    print("\n5. Worker 1 fails job...")
    tracker.update_job_status('video2', 'failed', worker_id=1, error='Test error')
    print(f"   Stats: {tracker.get_stats()}")

    print("\n6. Worker 0 claims another job...")
    job = tracker.claim_next_job(worker_id=0)
    if job:
        print(f"   Claimed: {job['job_id']}")
    else:
        print("   No more pending jobs!")
    print(f"   Stats: {tracker.get_stats()}")

    print("\n7. Checking worker stats...")
    print(f"   {tracker.get_worker_stats()}")

    print("\n8. Cleanup test file...")
    os.remove(test_file)
    if os.path.exists(test_file + '.lock'):
        os.remove(test_file + '.lock')
    print("   Done!")
</file>

<file path="README.md">
# Geelark Instagram Automation

Automated Instagram Reel posting to Geelark cloud phones using AI-driven UI navigation.

## Core Concept

The automation follows a simple, reliable loop:

```
1. UI dump (uiautomator dump)
2. Send elements to Claude
3. Claude decides what to tap
4. Execute tap
5. Repeat until done
```

**Every single step uses this loop. No exceptions. No hardcoded coordinates. No skipping steps.**

## How It Works

### The Loop (post_reel_smart.py)

```python
for step in range(max_steps):
    # 1. Dump UI
    elements = dump_ui()

    # 2. Ask Claude what to do
    action = analyze_ui(elements, caption)

    # 3. Execute action
    if action['action'] == 'tap':
        tap(elements[action['element_index']]['center'])
    elif action['action'] == 'tap_and_type':
        tap(element)
        type_text(caption)
    elif action['action'] == 'back':
        press_back()
    elif action['action'] == 'done':
        return True
```

### Claude's Job

Claude receives:
- List of all UI elements with bounds, text, descriptions
- Current state (video uploaded? caption entered?)
- The caption to post

Claude returns:
- Which element to tap (by index)
- Or special actions: back, scroll, done
- Never gives up - if something unexpected appears, press back and continue

### Error Recovery

If unexpected screens appear (Play Store, popups, wrong app):
1. Press back button
2. If that doesn't work, press home button
3. Reopen Instagram
4. Continue the loop

**The AI should NEVER return "error" and give up.** It should always try to recover.

## Files

### Core Scripts

| File | Purpose |
|------|---------|
| `post_reel_smart.py` | Main posting script - THE WORKING ONE |
| `geelark_client.py` | Geelark API wrapper (phones, ADB, uploads) |

### Scheduler & Dashboard

| File | Purpose |
|------|---------|
| `posting_scheduler.py` | **MAIN SCRIPT** - scheduler with tracking, retry, state persistence |
| `dashboard.py` | Real-time web dashboard at http://localhost:5000 |

### Archived (DO NOT USE)

| File | Purpose |
|------|---------|
| `batch_post.py` | ARCHIVED - no tracking, causes duplicates |
| `batch_post_concurrent.py` | ARCHIVED - same issues |

## Usage

### Single Post

```bash
python post_reel_smart.py <phone_name> <video_path> "<caption>"
```

Example:
```bash
python post_reel_smart.py miccliparchive video.mp4 "Check out this clip!"
```

### Batch Post (ALWAYS USE THIS)

```bash
# Add videos and accounts, then run
python posting_scheduler.py --add-folder chunk_01c --add-accounts phone1 phone2 --run

# Check status
python posting_scheduler.py --status

# Retry all failed
python posting_scheduler.py --retry-all
```

Example:
```bash
python posting_scheduler.py --add-folder chunk_01c --add-accounts miccliparchive reelwisdompod_ podmindstudio --run
```

### Dashboard

```bash
# Start dashboard in separate terminal
python dashboard.py
# Open http://localhost:5000
```

## Setup

### Requirements

1. Python 3.8+
2. ADB (Android Debug Bridge)
3. Anthropic API key
4. Geelark account with API access

### Environment Variables (.env)

```
GEELARK_APP_ID=your_app_id
GEELARK_API_KEY=your_api_key
GEELARK_TOKEN=your_token
ANTHROPIC_API_KEY=your_anthropic_key
```

### ADB Path

Edit `ADB_PATH` in `post_reel_smart.py`:
```python
ADB_PATH = r"C:\path\to\adb.exe"
```

## Instagram Posting Flow

The AI navigates through these screens:

1. **Home Feed** - Tap Create/+ button (bottom nav or top left "Create New")
2. **Post Type Selection** - Tap "REEL" option
3. **Gallery** - Select the uploaded video thumbnail
4. **Video Preview** - Tap "Next"
5. **Edit Screen** - Tap "Next" (skip editing)
6. **Caption Screen** - Tap caption field, type caption, hide keyboard
7. **Share** - Tap "Share" button
8. **Confirmation** - See "Sharing to Reels" or return to feed = done

## Geelark API Flow

1. **Find phone** by name via `/open/v1/phone/list`
2. **Start phone** if not running via `/open/v1/phone/start`
3. **Enable ADB** via `/open/v1/adb/setStatus`
4. **Get ADB info** (ip, port, password) via `/open/v1/adb/getData`
5. **Connect ADB** with `adb connect ip:port` then `glogin password`
6. **Upload video** to Geelark cloud, then to phone's Downloads folder
7. **Run posting loop** (UI dump + Claude + tap)
8. **Cleanup** - delete video, disable ADB

## Key Technical Details

### UI Dump

```bash
adb shell uiautomator dump /sdcard/ui.xml
adb shell cat /sdcard/ui.xml
```

Returns XML with all UI elements including:
- `text` - visible text
- `content-desc` - accessibility description
- `bounds` - [x1,y1][x2,y2] coordinates
- `clickable` - whether element is tappable

### Text Input

Uses ADBKeyboard with base64 encoding for special characters:
```python
text_b64 = base64.b64encode(text.encode('utf-8')).decode('ascii')
adb shell am broadcast -a ADB_INPUT_B64 --es msg {text_b64}
```

### Geelark ADB Authentication

Geelark cloud phones require special login after ADB connect:
```bash
adb shell glogin {password}
```

## Chunk Folder Structure

For batch posting, organize videos in folders:

```
va_chunk_05/
  chunk_05.csv          # Shortcode,Text columns
  ABC123-1.mp4          # Video file (shortcode + "-1.mp4")
  DEF456-1.mp4
  ...
```

CSV format:
```csv
Shortcode,Text
ABC123,"Caption for first video"
DEF456,"Caption for second video"
```

## Troubleshooting

### "Phone not found"
- Check phone name matches exactly (case-sensitive)
- Phone might be on a different page - script searches up to 10 pages

### "Upload timeout"
- Check Geelark dashboard for phone status
- Phone might be offline or slow
- Increase timeout in `wait_for_upload()`

### "Unexpected screen" (Play Store, etc.)
- AI should press back and recover
- If it keeps happening, phone might have popups that need manual dismissal

### "Caption not typed"
- ADBKeyboard might not be installed
- Check if keyboard is set as default input method on the phone

### Unicode/Emoji errors on Windows
- Scripts include UTF-8 encoding fix at top
- Make sure it runs BEFORE any other imports
</file>

<file path="reprovision_phone.py">
"""
Reprovision Geelark phones using "One-click New Device" API.
This resets the phone completely and reinstalls ADBKeyboard as a system app.

WARNING: This will WIPE ALL DATA on the phone including:
- Installed apps
- Logged-in accounts (Instagram, etc.)
- All files and settings

Usage:
    python reprovision_phone.py <phone_name>

Example:
    python reprovision_phone.py reelwisdompod_
"""
import sys
import time
import subprocess
from geelark_client import GeelarkClient
from config import Config

ADB_PATH = Config.ADB_PATH


def adb(device, cmd, timeout=30):
    """Run ADB shell command"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def check_adbkeyboard(device):
    """Check if ADBKeyboard is properly installed"""
    pm_path = adb(device, "pm path com.android.adbkeyboard")
    return bool(pm_path)


def reprovision_phone(phone_name, confirm=True):
    """Reprovision a phone using Geelark one-click new device API"""
    client = GeelarkClient()

    print(f"\n{'='*60}")
    print(f"REPROVISIONING: {phone_name}")
    print('='*60)

    # Find phone
    print("Finding phone...")
    phone = None
    for page in range(1, 10):
        result = client.list_phones(page=page, page_size=100)
        for p in result["items"]:
            if p["serialName"] == phone_name:
                phone = p
                break
        if phone:
            break

    if not phone:
        print(f"  ERROR: Phone not found: {phone_name}")
        return False

    phone_id = phone["id"]
    print(f"  Found: {phone['serialName']} (ID: {phone_id})")
    print(f"  Current status: {phone['status']}")

    # Confirm
    if confirm:
        print(f"\n  WARNING: This will WIPE ALL DATA on {phone_name}!")
        print("  - All installed apps will be removed")
        print("  - Logged-in accounts will be logged out")
        print("  - All files will be deleted")
        print()
        response = input("  Type 'YES' to confirm: ")
        if response != 'YES':
            print("  Aborted.")
            return False

    # Call one-click new device API
    print("\n  Calling Geelark One-Click New Device API...")
    try:
        result = client.one_click_new_device(phone_id, change_brand_model=False)
        print(f"  API Response: {result}")
    except Exception as e:
        print(f"  ERROR: API call failed: {e}")
        return False

    # Wait for phone to reprovision (this can take 1-2 minutes)
    print("\n  Waiting for phone to reprovision...")
    print("  This may take 1-2 minutes...")

    # The phone will restart, so we need to wait for it to come back online
    for i in range(90):  # Wait up to 3 minutes
        time.sleep(2)
        try:
            status = client.get_phone_status([phone_id])
            items = status.get("successDetails", [])
            if items and items[0].get("status") == 0:
                print(f"    Phone is online after {(i+1)*2}s")
                break
        except:
            pass
        if (i + 1) % 15 == 0:
            print(f"    Still waiting... ({(i+1)*2}s)")
    else:
        print("  WARNING: Phone may still be reprovisioning. Check Geelark dashboard.")

    # Give it a moment to fully boot
    print("  Waiting for full boot...")
    time.sleep(10)

    # Enable ADB and verify
    print("\n  Verifying ADBKeyboard installation...")
    try:
        client.enable_adb(phone_id)
        time.sleep(5)

        adb_info = client.get_adb_info(phone_id)
        device = f"{adb_info['ip']}:{adb_info['port']}"
        password = adb_info['pwd']

        subprocess.run([ADB_PATH, "connect", device], capture_output=True)
        adb(device, f"glogin {password}")

        if check_adbkeyboard(device):
            pm_path = adb(device, "pm path com.android.adbkeyboard")
            print(f"  SUCCESS: ADBKeyboard installed at {pm_path}")

            # Set as default IME
            adb(device, "ime enable com.android.adbkeyboard/.AdbIME")
            adb(device, "ime set com.android.adbkeyboard/.AdbIME")
            print("  ADBKeyboard set as default IME")

            return True
        else:
            print("  WARNING: ADBKeyboard still not installed after reprovisioning")
            print("  Check Geelark dashboard or contact support")
            return False

    except Exception as e:
        print(f"  ERROR during verification: {e}")
        return False


def main():
    if len(sys.argv) < 2:
        print("Usage: python reprovision_phone.py <phone_name>")
        print("Example: python reprovision_phone.py reelwisdompod_")
        print()
        print("WARNING: This will WIPE ALL DATA on the phone!")
        sys.exit(1)

    phone_name = sys.argv[1]

    # Check for --yes flag to skip confirmation
    confirm = "--yes" not in sys.argv

    success = reprovision_phone(phone_name, confirm=confirm)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
</file>

<file path="requirements.txt">
python-dotenv
requests
anthropic
Appium-Python-Client
</file>

<file path="scheduler_watchdog.py">
#!/usr/bin/env python3
"""
External watchdog for posting_scheduler.py

Monitors:
1. Is the scheduler PID from scheduler.lock still alive?
2. Has scheduler_live.log been updated in the last X minutes?

If either check fails, kills and restarts the scheduler.

Usage:
  python scheduler_watchdog.py              # Run once
  python scheduler_watchdog.py --loop       # Run continuously every 2 minutes
  python scheduler_watchdog.py --loop 5     # Run continuously every 5 minutes
"""

import os
import sys
import json
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path

# Configuration
SCRIPT_DIR = Path(__file__).parent
SCHEDULER_SCRIPT = SCRIPT_DIR / "posting_scheduler.py"
LOCK_FILE = SCRIPT_DIR / "scheduler.lock"
LOG_FILE = SCRIPT_DIR / "scheduler_live.log"
WATCHDOG_LOG = SCRIPT_DIR / "watchdog.log"

# Thresholds
MAX_LOG_STALE_MINUTES = 5  # Restart if log hasn't been updated in this many minutes
MAX_HEARTBEAT_STALE_MINUTES = 3  # Restart if heartbeat is stale


def log(msg: str):
    """Log to both console and file"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{timestamp}] {msg}"
    print(line)
    with open(WATCHDOG_LOG, "a", encoding="utf-8") as f:
        f.write(line + "\n")


def is_pid_alive(pid: int) -> bool:
    """Check if a process with given PID is running"""
    try:
        # Windows-specific check
        result = subprocess.run(
            ["tasklist", "/FI", f"PID eq {pid}", "/NH"],
            capture_output=True,
            text=True,
            shell=True
        )
        return str(pid) in result.stdout
    except Exception as e:
        log(f"Error checking PID {pid}: {e}")
        return False


def kill_process(pid: int) -> bool:
    """Kill a process by PID"""
    try:
        result = subprocess.run(
            ["taskkill", "/F", "/PID", str(pid)],
            capture_output=True,
            text=True,
            shell=True
        )
        return "SUCCESS" in result.stdout or "not found" in result.stderr.lower()
    except Exception as e:
        log(f"Error killing PID {pid}: {e}")
        return False


def stop_all_phones():
    """Stop any running Geelark phones to prevent billing"""
    log("Stopping all running phones...")
    try:
        # Import and use GeelarkClient
        sys.path.insert(0, str(SCRIPT_DIR))
        from geelark_client import GeelarkClient

        client = GeelarkClient()
        stopped = 0
        for page in range(1, 20):
            result = client.list_phones(page=page, page_size=100)
            for phone in result['items']:
                if phone['status'] == 1:  # Running
                    client.stop_phone(phone['id'])
                    log(f"  Stopped: {phone['serialName']}")
                    stopped += 1
            if len(result['items']) < 100:
                break
        log(f"  Total stopped: {stopped}")
        return stopped
    except Exception as e:
        log(f"Error stopping phones: {e}")
        return 0


def get_lock_info() -> dict:
    """Read scheduler.lock file"""
    if not LOCK_FILE.exists():
        return None
    try:
        with open(LOCK_FILE, "r") as f:
            return json.load(f)
    except Exception as e:
        log(f"Error reading lock file: {e}")
        return None


def get_log_mtime() -> datetime:
    """Get last modification time of scheduler_live.log"""
    if not LOG_FILE.exists():
        return None
    try:
        mtime = os.path.getmtime(LOG_FILE)
        return datetime.fromtimestamp(mtime)
    except Exception as e:
        log(f"Error getting log mtime: {e}")
        return None


def start_scheduler() -> int:
    """Start the scheduler and return the new PID"""
    log("Starting scheduler...")
    try:
        # Start scheduler in background
        process = subprocess.Popen(
            [sys.executable, str(SCHEDULER_SCRIPT), "--run"],
            cwd=str(SCRIPT_DIR),
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            creationflags=subprocess.CREATE_NEW_PROCESS_GROUP if os.name == 'nt' else 0
        )
        log(f"  Started scheduler with PID {process.pid}")

        # Wait a moment for lock file to be created
        time.sleep(3)

        # Verify it started
        lock_info = get_lock_info()
        if lock_info:
            log(f"  Confirmed running: PID {lock_info['pid']}")
            return lock_info['pid']
        else:
            log("  Warning: Lock file not created yet")
            return process.pid
    except Exception as e:
        log(f"Error starting scheduler: {e}")
        return None


def check_and_restart() -> bool:
    """
    Check scheduler health and restart if needed.
    Returns True if scheduler is healthy, False if it was restarted.
    """
    log("=" * 50)
    log("Watchdog check starting...")

    # Check 1: Is there a lock file?
    lock_info = get_lock_info()
    if not lock_info:
        log("No lock file found - scheduler not running")
        stop_all_phones()
        start_scheduler()
        return False

    pid = lock_info['pid']
    last_heartbeat = datetime.fromisoformat(lock_info.get('last_heartbeat', lock_info['started']))

    log(f"Lock file: PID={pid}, last_heartbeat={last_heartbeat}")

    # Check 2: Is the PID alive?
    if not is_pid_alive(pid):
        log(f"PID {pid} is NOT alive - scheduler crashed!")
        stop_all_phones()
        LOCK_FILE.unlink(missing_ok=True)
        start_scheduler()
        return False

    # Check 3: Is heartbeat recent?
    heartbeat_age = datetime.now() - last_heartbeat
    if heartbeat_age > timedelta(minutes=MAX_HEARTBEAT_STALE_MINUTES):
        log(f"Heartbeat is stale ({heartbeat_age.total_seconds():.0f}s old) - scheduler frozen!")
        stop_all_phones()
        kill_process(pid)
        LOCK_FILE.unlink(missing_ok=True)
        start_scheduler()
        return False

    # Check 4: Is log file being updated?
    log_mtime = get_log_mtime()
    if log_mtime:
        log_age = datetime.now() - log_mtime
        log(f"Log file last updated: {log_age.total_seconds():.0f}s ago")

        if log_age > timedelta(minutes=MAX_LOG_STALE_MINUTES):
            log(f"Log is stale ({log_age.total_seconds():.0f}s old) - scheduler may be stuck!")
            # Don't restart just for stale log if heartbeat is OK
            # The scheduler might just be waiting between posts
            log("  (Heartbeat OK, not restarting - scheduler may be waiting)")

    log(f"Scheduler healthy: PID {pid} running, heartbeat {heartbeat_age.total_seconds():.0f}s ago")
    return True


def main():
    """Main entry point"""
    loop_mode = "--loop" in sys.argv
    loop_interval = 2  # minutes

    # Check for custom interval
    for i, arg in enumerate(sys.argv):
        if arg == "--loop" and i + 1 < len(sys.argv):
            try:
                loop_interval = int(sys.argv[i + 1])
            except ValueError:
                pass

    if loop_mode:
        log(f"Watchdog starting in loop mode (every {loop_interval} minutes)")
        log("Press Ctrl+C to stop")

        while True:
            try:
                check_and_restart()
                time.sleep(loop_interval * 60)
            except KeyboardInterrupt:
                log("Watchdog stopped by user")
                break
            except Exception as e:
                log(f"Watchdog error: {e}")
                time.sleep(60)  # Wait a minute before retrying
    else:
        # Single check
        check_and_restart()


if __name__ == "__main__":
    main()
</file>

<file path="setup_adbkeyboard.py">
"""
Install and enable ADBKeyboard on Geelark cloud phones.
This keyboard allows typing special characters via ADB.

Usage:
    python setup_adbkeyboard.py <phone1> <phone2> ...

Example:
    python setup_adbkeyboard.py miccliparchive reelwisdompod_ podmindstudio
"""
import sys
import os

from phone_connector import PhoneConnector, adb_shell, adb_install

APK_PATH = os.path.join(os.path.dirname(__file__), "ADBKeyboard.apk")


def setup_phone(phone_name):
    """Setup ADBKeyboard on a single phone"""
    print(f"\n{'='*50}")
    print(f"Setting up ADBKeyboard on: {phone_name}")
    print('='*50)

    # Use shared PhoneConnector for find → start → ADB connect
    connector = PhoneConnector()
    try:
        client, phone_id, device, password = connector.setup_for_adb(phone_name)
    except Exception as e:
        print(f"  ERROR: {e}")
        return False

    # Force uninstall first (clean slate)
    print("  Uninstalling existing ADBKeyboard (if any)...")
    uninstall_result = adb_shell(device, "pm uninstall com.android.adbkeyboard")
    print(f"    {uninstall_result or 'Not installed'}")

    # Install fresh APK
    print(f"  Installing ADBKeyboard.apk (fresh)...")
    install_result = adb_install(device, APK_PATH)
    print(f"    {install_result}")
    if "Success" not in install_result:
        print("  ERROR: Installation failed")
        return False

    # Enable ADBKeyboard as an input method
    print("  Enabling ADBKeyboard input method...")
    adb_shell(device, "ime enable com.android.adbkeyboard/.AdbIME")

    # Set as default input method
    print("  Setting ADBKeyboard as default...")
    adb_shell(device, "ime set com.android.adbkeyboard/.AdbIME")

    # Verify
    print("  Verifying...")
    current_ime = adb_shell(device, "settings get secure default_input_method")
    if "adbkeyboard" in current_ime.lower():
        print(f"  SUCCESS: ADBKeyboard is now the default keyboard")
        return True
    else:
        print(f"  WARNING: Current IME is: {current_ime}")
        return False


def main():
    if len(sys.argv) < 2:
        print("Usage: python setup_adbkeyboard.py <phone1> <phone2> ...")
        print("Example: python setup_adbkeyboard.py miccliparchive reelwisdompod_ podmindstudio")
        sys.exit(1)

    if not os.path.exists(APK_PATH):
        print(f"ERROR: ADBKeyboard.apk not found at {APK_PATH}")
        sys.exit(1)

    phones = sys.argv[1:]
    results = {}

    for phone in phones:
        try:
            results[phone] = setup_phone(phone)
        except Exception as e:
            print(f"  ERROR: {e}")
            results[phone] = False

    # Summary
    print("\n" + "="*50)
    print("SETUP COMPLETE")
    print("="*50)
    for phone, success in results.items():
        status = "OK" if success else "FAILED"
        print(f"  {phone}: {status}")


if __name__ == "__main__":
    main()
</file>

<file path="setup_clipboard_helper.py">
"""
Install ClipboardHelper APK on Geelark cloud phones.
This app enables clipboard access via ADB for typing Unicode text, emojis, and newlines.

Usage:
    python setup_clipboard_helper.py <phone1> <phone2> ...

Example:
    python setup_clipboard_helper.py miccliparchive reelwisdompod_ podmindstudio
"""
import sys
import os
import base64

from phone_connector import PhoneConnector, adb_shell, adb_install

APK_PATH = os.path.join(os.path.dirname(__file__), "ClipboardHelper.apk")


def setup_phone(phone_name):
    """Setup ClipboardHelper on a single phone"""
    print(f"\n{'='*50}")
    print(f"Setting up ClipboardHelper on: {phone_name}")
    print('='*50)

    # Use shared PhoneConnector for find → start → ADB connect
    connector = PhoneConnector()
    try:
        client, phone_id, device, password = connector.setup_for_adb(phone_name)
    except Exception as e:
        print(f"  ERROR: {e}")
        return False

    # Check if already installed
    print("  Checking if ClipboardHelper is installed...")
    packages = adb_shell(device, "pm list packages | grep geelark.clipboard")
    if "com.geelark.clipboard" in packages:
        print("  ClipboardHelper already installed!")
    else:
        # Install APK
        print(f"  Installing ClipboardHelper.apk...")
        install_result = adb_install(device, APK_PATH)
        print(f"    {install_result}")
        if "Success" not in install_result:
            print("  ERROR: Installation failed")
            return False

    # Test clipboard functionality (basic smoke test)
    print("  Testing clipboard...")
    test_text = "ClipboardHelper OK\nSecond line test"
    text_b64 = base64.b64encode(test_text.encode('utf-8')).decode('ascii')
    result = adb_shell(
        device,
        f"am start -n com.geelark.clipboard/.CopyActivity -a com.geelark.clipboard.COPY --es base64 {text_b64}"
    )
    if "Error" in result or "Exception" in result:
        print(f"  WARNING: ClipboardHelper test may have failed: {result}")
    else:
        print("  SUCCESS: ClipboardHelper activity invoked (clipboard should be set)")

    return True


def main():
    if len(sys.argv) < 2:
        print("Usage: python setup_clipboard_helper.py <phone1> <phone2> ...")
        print("Example: python setup_clipboard_helper.py miccliparchive reelwisdompod_ podmindstudio")
        sys.exit(1)

    if not os.path.exists(APK_PATH):
        print(f"ERROR: ClipboardHelper.apk not found at {APK_PATH}")
        print("Run the build script first: ClipboardHelper/build.ps1")
        sys.exit(1)

    phones = sys.argv[1:]
    results = {}

    for phone in phones:
        try:
            results[phone] = setup_phone(phone)
        except Exception as e:
            print(f"  ERROR: {e}")
            results[phone] = False

    # Summary
    print("\n" + "="*50)
    print("SETUP COMPLETE")
    print("="*50)
    for phone, success in results.items():
        status = "OK" if success else "FAILED"
        print(f"  {phone}: {status}")


if __name__ == "__main__":
    main()
</file>

<file path="test_appium_typing.py">
"""
Quick test of Appium typing in SmartInstagramPoster
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

import os
os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'

from appium import webdriver
from appium.options.android import UiAutomator2Options
from appium.webdriver.common.appiumby import AppiumBy
import time

# Android 15 phone - test device
DEVICE = "98.98.125.37:20865"
APPIUM_SERVER = "http://127.0.0.1:4723"

def test_appium_typing():
    """Test Appium typing with emojis"""
    print(f"Connecting to {DEVICE}...")

    options = UiAutomator2Options()
    options.platform_name = "Android"
    options.automation_name = "UiAutomator2"
    options.device_name = DEVICE
    options.udid = DEVICE
    options.no_reset = True
    options.new_command_timeout = 300
    options.set_capability("appium:adbExecTimeout", 60000)

    driver = webdriver.Remote(command_executor=APPIUM_SERVER, options=options)
    print(f"[OK] Connected! Android {driver.capabilities.get('platformVersion')}")

    # Tap Google search bar to get a text field
    print("Looking for search bar...")
    try:
        # Look for Google search widget
        search = driver.find_element(AppiumBy.CLASS_NAME, "android.widget.TextView")
        if search and "Google" in (search.text or ""):
            print("Found Google search bar, tapping...")
            search.click()
            time.sleep(2)

            # Now find the search input
            edit_texts = driver.find_elements(AppiumBy.CLASS_NAME, "android.widget.EditText")
            if edit_texts:
                print(f"Found {len(edit_texts)} EditText fields")
                et = edit_texts[0]

                # Type with emojis!
                test_text = "Hello World! Emoji test"
                print(f"Typing: {test_text}")
                et.send_keys(test_text)
                time.sleep(1)

                typed = et.text
                print(f"Got: {typed}")

                if "Hello" in typed:
                    print("\n[SUCCESS] Appium typing works on Android 15!")
                else:
                    print("\n[PARTIAL] Text field interaction worked")
            else:
                print("No EditText found after clicking search")
        else:
            print("No Google search bar found - checking for any EditText...")
            edit_texts = driver.find_elements(AppiumBy.CLASS_NAME, "android.widget.EditText")
            print(f"Found {len(edit_texts)} EditText fields on screen")

    except Exception as e:
        print(f"Search test error: {e}")
        print("This is OK - the key is that Appium connected!")

    # Take screenshot to show current state
    driver.save_screenshot("appium_typing_test.png")
    print("\nScreenshot saved to appium_typing_test.png")

    driver.quit()
    print("\n[OK] Test complete - Appium is working!")
    return True

if __name__ == "__main__":
    test_appium_typing()
</file>

<file path="test_appium.py">
"""
Test Appium connection to Geelark cloud phone and Unicode typing
"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

from appium import webdriver
from appium.options.android import UiAutomator2Options
from appium.webdriver.common.appiumby import AppiumBy
import time
import os

os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'

DEVICE = "98.98.125.37:20865"

def test_appium_connection():
    """Test connecting to Geelark phone via Appium"""

    options = UiAutomator2Options()
    options.platform_name = "Android"
    options.automation_name = "UiAutomator2"
    options.device_name = DEVICE
    options.udid = DEVICE
    options.no_reset = True
    options.new_command_timeout = 300
    options.set_capability("appium:adbExecTimeout", 60000)
    options.set_capability("appium:uiautomator2ServerInstallTimeout", 120000)

    print(f"Connecting to {DEVICE} via Appium...")

    try:
        driver = webdriver.Remote(
            command_executor="http://127.0.0.1:4723",
            options=options
        )
        print("[OK] Connected successfully!")
        print(f"    Platform Version: {driver.capabilities.get('platformVersion')}")

        # Find text fields on screen
        print("\nCurrent screen elements:")
        elements = driver.find_elements(AppiumBy.CLASS_NAME, "android.widget.EditText")
        print(f"    Found {len(elements)} EditText fields")

        if elements:
            print("\nTesting Unicode typing...")
            el = elements[0]
            el.click()
            time.sleep(0.5)

            # Clear and type
            el.clear()
            test_text = "Hello World emoji test"
            el.send_keys(test_text)
            time.sleep(1)

            typed = el.text
            print(f"    Typed: {test_text}")
            print(f"    Got: {typed}")

            if "Hello" in typed:
                print("\n[OK] TYPING WORKS ON ANDROID 15!")
        else:
            print("    No text fields on current screen")
            print("    But connection works - that's the key!")

        # Take screenshot
        driver.save_screenshot("appium_test.png")
        print("\n    Screenshot saved to appium_test.png")

        driver.quit()
        print("\n[OK] TEST PASSED: Appium works with Android 15 Geelark phone!")
        return True

    except Exception as e:
        print(f"[ERROR] {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    test_appium_connection()
</file>

<file path="test_connection.py">
"""
Test connecting to a Geelark phone via ADB
"""
import time
from geelark_client import GeelarkClient
from adb_controller import ADBController

def test_connection(phone_name):
    client = GeelarkClient()

    # Find phone
    print(f"Looking for phone: {phone_name}")
    result = client.list_phones(page_size=100)
    phone = None
    for p in result["items"]:
        if p["serialName"] == phone_name:
            phone = p
            break

    if not phone:
        print(f"Phone not found: {phone_name}")
        return

    phone_id = phone["id"]
    print(f"Found: {phone['serialName']} (ID: {phone_id}, Status: {phone['status']})")

    # Start if not running
    if phone["status"] != 0:
        print("Starting phone...")
        client.start_phone(phone_id)
        print("Waiting 30 seconds for boot...")
        time.sleep(30)

    # Enable ADB
    print("Enabling ADB...")
    client.enable_adb(phone_id)
    print("Waiting 5 seconds...")
    time.sleep(5)

    # Get ADB info
    print("Getting ADB info...")
    adb_info = client.get_adb_info(phone_id)
    print(f"IP: {adb_info['ip']}")
    print(f"Port: {adb_info['port']}")
    print(f"Password: {adb_info['pwd']}")

    # Connect
    print("\nConnecting via ADB...")
    adb = ADBController(adb_info["ip"], adb_info["port"], adb_info["pwd"])

    if adb.connect():
        print("\n✓ Connected successfully!")

        # Test a command
        print("\nTesting shell command...")
        result = adb.shell("getprop ro.product.model")
        print(f"Device model: {result}")

        # Take screenshot
        print("\nTaking screenshot...")
        if adb.screenshot_to_file("test_screenshot.png"):
            print("✓ Screenshot saved to test_screenshot.png")
        else:
            print("✗ Screenshot failed")

        adb.disconnect()
    else:
        print("\n✗ Connection failed")

    # Cleanup
    print("\nDisabling ADB...")
    client.disable_adb(phone_id)
    print("Done!")

if __name__ == "__main__":
    test_connection("talkloopclips")
</file>

<file path="test_dump_ui_fix.py">
"""Test the fixed dump_ui on Android 15"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
import os
os.environ['ANDROID_HOME'] = r'C:\Users\asus\Downloads\android-sdk'

from appium import webdriver
from appium.options.android import UiAutomator2Options
import xml.etree.ElementTree as ET
import re

DEVICE = "98.98.125.37:21293"  # Android 15

print(f"Connecting Appium to {DEVICE}...")
options = UiAutomator2Options()
options.platform_name = "Android"
options.automation_name = "UiAutomator2"
options.device_name = DEVICE
options.udid = DEVICE
options.no_reset = True
options.new_command_timeout = 300

driver = webdriver.Remote(command_executor="http://127.0.0.1:4723", options=options)
print(f"Connected! Android {driver.capabilities.get('platformVersion')}")

# Get page_source
print("\nGetting page_source...")
xml_str = driver.page_source

# Parse with FIXED logic (iter() not iter('node'))
elements = []
if '<?xml' in xml_str:
    xml_clean = xml_str[xml_str.find('<?xml'):]
    root = ET.fromstring(xml_clean)

    for elem in root.iter():  # FIXED: iter() not iter('node')
        text = elem.get('text', '')
        desc = elem.get('content-desc', '')
        res_id = elem.get('resource-id', '')
        bounds = elem.get('bounds', '')
        clickable = elem.get('clickable', 'false')

        if bounds and (text or desc or clickable == 'true'):
            m = re.match(r'\[(\d+),(\d+)\]\[(\d+),(\d+)\]', bounds)
            if m:
                x1, y1, x2, y2 = map(int, m.groups())
                cx, cy = (x1+x2)//2, (y1+y2)//2
                elements.append({
                    'text': text,
                    'desc': desc,
                    'id': res_id.split('/')[-1] if '/' in res_id else res_id,
                    'bounds': bounds,
                    'center': (cx, cy),
                    'clickable': clickable == 'true'
                })

print(f"\n[RESULT] Found {len(elements)} UI elements!")
print("\nFirst 10 elements:")
for i, elem in enumerate(elements[:10]):
    parts = []
    if elem['text']:
        parts.append(f"'{elem['text']}'")
    if elem['desc']:
        parts.append(f"desc='{elem['desc']}'")
    if elem['id']:
        parts.append(f"id={elem['id']}")
    print(f"  {i+1}. {elem['bounds']} {' | '.join(parts)}")

driver.quit()
print("\n[OK] dump_ui fix WORKS on Android 15!")
</file>

<file path="test_escape.py">
text = 'Rhonda Patrick (@foundmyfitness) tackles the mental battle'
special_chars = ['(', ')', '@', '#', '&', ';', '<', '>', '|', '$', '`', '\\', '"', "'"]
escaped = text
for char in special_chars + [' ']:
    if char == ' ':
        escaped = escaped.replace(char, '%s')
    else:
        escaped = escaped.replace(char, '\\' + char)
print(f'Original: {text}')
print(f'Escaped: {escaped}')
print(f'Command: input text "{escaped}"')
</file>

<file path="test_full_flow_android15.py">
"""Test full Instagram posting flow on Android 15 with Appium"""
import sys
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')

from config import Config, setup_environment
setup_environment()

from appium import webdriver
from appium.options.android import UiAutomator2Options
from appium.webdriver.common.appiumby import AppiumBy
import xml.etree.ElementTree as ET
import re
import time

DEVICE = "98.98.125.37:21293"  # Android 15

def dump_ui(driver):
    """Parse page_source into elements"""
    elements = []
    xml_str = driver.page_source

    if '<?xml' not in xml_str:
        return elements

    xml_clean = xml_str[xml_str.find('<?xml'):]
    root = ET.fromstring(xml_clean)

    for elem in root.iter():
        text = elem.get('text', '')
        desc = elem.get('content-desc', '')
        res_id = elem.get('resource-id', '')
        bounds = elem.get('bounds', '')
        clickable = elem.get('clickable', 'false')

        if bounds and (text or desc or clickable == 'true'):
            m = re.match(r'\[(\d+),(\d+)\]\[(\d+),(\d+)\]', bounds)
            if m:
                x1, y1, x2, y2 = map(int, m.groups())
                cx, cy = (x1+x2)//2, (y1+y2)//2
                elements.append({
                    'text': text,
                    'desc': desc,
                    'id': res_id.split('/')[-1] if '/' in res_id else res_id,
                    'bounds': bounds,
                    'center': (cx, cy),
                    'clickable': clickable == 'true'
                })
    return elements

print(f"Connecting Appium to {DEVICE}...")
options = UiAutomator2Options()
options.platform_name = "Android"
options.automation_name = "UiAutomator2"
options.device_name = DEVICE
options.udid = DEVICE
options.no_reset = True
options.new_command_timeout = 300

driver = webdriver.Remote(command_executor="http://127.0.0.1:4723", options=options)
print(f"Connected! Android {driver.capabilities.get('platformVersion')}")

# Open Instagram
print("\nOpening Instagram...")
driver.press_keycode(3)  # HOME
time.sleep(1)

# Start Instagram via am start (using Appium's executeScript)
# Note: This requires adb_shell to be enabled, fallback to regular ADB
import subprocess
ADB = Config.ADB_PATH
subprocess.run([ADB, "-s", DEVICE, "shell", "am", "force-stop", "com.instagram.android"])
time.sleep(1)
subprocess.run([ADB, "-s", DEVICE, "shell", "monkey", "-p", "com.instagram.android", "1"])
time.sleep(5)

# Dump UI
print("\nDumping UI...")
for step in range(5):
    elements = dump_ui(driver)
    print(f"\nStep {step+1}: Found {len(elements)} elements")

    if elements:
        print("Some elements:")
        for elem in elements[:8]:
            parts = []
            if elem['text']:
                parts.append(f"'{elem['text'][:30]}'")
            if elem['desc']:
                parts.append(f"desc='{elem['desc'][:30]}'")
            if parts:
                print(f"  {elem['bounds']} {' | '.join(parts)}")

        # Look for Create button
        create = [e for e in elements if 'create' in (e['text'] + e['desc']).lower()]
        if create:
            print(f"\n[FOUND] Create button at {create[0]['center']}")
            driver.tap([create[0]['center']])
            time.sleep(2)
    else:
        print("  No elements, waiting...")
        time.sleep(2)

driver.save_screenshot("android15_test.png")
print("\nScreenshot saved to android15_test.png")

driver.quit()
print("\n[OK] Test complete!")
</file>

<file path="test_geelark_api.py">
"""
Test Geelark API connection - list all cloud phones
"""
import os
import uuid
import time
import hashlib
import requests
from dotenv import load_dotenv

load_dotenv()

API_BASE = "https://openapi.geelark.com"
APP_ID = os.getenv("GEELARK_APP_ID")
API_KEY = os.getenv("GEELARK_API_KEY")
TOKEN = os.getenv("GEELARK_TOKEN")


def get_headers_key_auth():
    """Generate headers for key-based authentication"""
    trace_id = str(uuid.uuid4()).upper().replace("-", "")
    timestamp = str(int(time.time() * 1000))
    nonce = trace_id[:6]

    # sign = SHA256(appId + traceId + ts + nonce + apiKey).upper()
    sign_string = APP_ID + trace_id + timestamp + nonce + API_KEY
    sign = hashlib.sha256(sign_string.encode()).hexdigest().upper()

    return {
        "Content-Type": "application/json",
        "appId": APP_ID,
        "traceId": trace_id,
        "ts": timestamp,
        "nonce": nonce,
        "sign": sign
    }


def get_headers_token_auth():
    """Generate headers for token-based authentication"""
    trace_id = str(uuid.uuid4()).upper().replace("-", "")

    return {
        "Content-Type": "application/json",
        "traceId": trace_id,
        "Authorization": f"Bearer {TOKEN}"
    }


def list_phones():
    """List all cloud phones"""
    url = f"{API_BASE}/open/v1/phone/list"

    # Try token auth first
    headers = get_headers_token_auth()
    data = {"page": 1, "pageSize": 10}

    print(f"Calling {url}")
    print(f"Headers: {headers}")

    resp = requests.post(url, json=data, headers=headers)
    print(f"Status: {resp.status_code}")
    print(f"Response: {resp.text[:1000]}")

    if resp.status_code == 200:
        result = resp.json()
        if result.get("code") == 0:
            items = result.get("data", {}).get("items", [])
            print(f"\nFound {len(items)} cloud phones:")
            for phone in items:
                print(f"  - {phone.get('serialName')} (ID: {phone.get('id')}, Status: {phone.get('status')})")
            return items

    # If token auth fails, try key auth
    print("\nToken auth failed, trying key auth...")
    headers = get_headers_key_auth()
    resp = requests.post(url, json=data, headers=headers)
    print(f"Status: {resp.status_code}")
    print(f"Response: {resp.text[:1000]}")

    if resp.status_code == 200:
        result = resp.json()
        if result.get("code") == 0:
            items = result.get("data", {}).get("items", [])
            print(f"\nFound {len(items)} cloud phones:")
            for phone in items:
                print(f"  - {phone.get('serialName')} (ID: {phone.get('id')}, Status: {phone.get('status')})")
            return items

    return []


if __name__ == "__main__":
    list_phones()
</file>

<file path="test_retry_state2.json">
{
  "jobs": [
    {
      "id": "TEST-RETRY-002",
      "video_path": "chunk_01c/2bears.1cave/DMbMMftoiDC-2.mp4",
      "caption": "Testing retry logic - this should actually post now",
      "account": "podtalkvault",
      "status": "in_progress",
      "attempts": 1,
      "max_attempts": 3,
      "last_error": "",
      "last_attempt": "2025-12-11T15:08:39.133309",
      "completed_at": "",
      "source_folder": ""
    }
  ],
  "accounts": [
    {
      "name": "podtalkvault",
      "last_post_date": "",
      "posts_today": 0,
      "total_posts": 0,
      "total_failures": 0
    }
  ],
  "settings": {
    "max_retries": 3,
    "retry_delay_minutes": 0.25,
    "posts_per_account_per_day": 1,
    "humanize": false,
    "delay_between_posts": 30,
    "video_folders": []
  },
  "saved_at": "2025-12-11T15:08:39.133343"
}
</file>

<file path="test_typing.py">
"""
Test script to verify text input methods work on Geelark phones.
Tests ClipboardHelper + paste, and ADBKeyboard broadcast.
"""
import sys
import os
import time
import subprocess
import base64

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

from geelark_client import GeelarkClient
from config import Config

ADB_PATH = Config.ADB_PATH


def adb(device, cmd, timeout=30):
    """Run ADB shell command"""
    result = subprocess.run(
        [ADB_PATH, "-s", device, "shell", cmd],
        capture_output=True, timeout=timeout,
        encoding='utf-8', errors='replace'
    )
    return result.stdout.strip() if result.stdout else ""


def connect_phone(phone_name):
    """Connect to a Geelark phone and return device string"""
    client = GeelarkClient()

    print(f"Finding phone: {phone_name}")
    phone = None
    for page in range(1, 10):
        result = client.list_phones(page=page, page_size=100)
        for p in result["items"]:
            if p["serialName"] == phone_name:
                phone = p
                break
        if phone:
            break

    if not phone:
        raise Exception(f"Phone not found: {phone_name}")

    phone_id = phone["id"]
    print(f"Found: {phone['serialName']} (Status: {phone['status']})")

    # Start if needed
    if phone["status"] != 0:
        print("Starting phone...")
        client.start_phone(phone_id)
        for i in range(60):
            time.sleep(2)
            status = client.get_phone_status([phone_id])
            items = status.get("successDetails", [])
            if items and items[0].get("status") == 0:
                break
        time.sleep(5)

    # Enable ADB
    print("Enabling ADB...")
    client.enable_adb(phone_id)
    time.sleep(5)

    # Get ADB info
    adb_info = client.get_adb_info(phone_id)
    device = f"{adb_info['ip']}:{adb_info['port']}"
    password = adb_info['pwd']

    # Connect
    print(f"Connecting to {device}...")
    subprocess.run([ADB_PATH, "connect", device], capture_output=True)

    # Login
    login_result = adb(device, f"glogin {password}")
    print(f"Login: {login_result or 'OK'}")

    return device, client, phone_id


def test_clipboard_helper(device, test_text):
    """Test ClipboardHelper APK"""
    print(f"\n{'='*50}")
    print("TEST 1: ClipboardHelper APK")
    print('='*50)

    # Check if installed
    result = adb(device, "pm path com.geelark.clipboard")
    if "package:" in result:
        print(f"  ClipboardHelper installed: {result}")
    else:
        print("  ERROR: ClipboardHelper NOT installed!")
        return False

    # Set clipboard
    text_b64 = base64.b64encode(test_text.encode('utf-8')).decode('ascii')
    print(f"  Setting clipboard with base64 text...")
    result = adb(device, f"am start -n com.geelark.clipboard/.ClipboardActivity -a com.geelark.clipboard.COPY --es base64 {text_b64}")
    print(f"  Result: {result[:100] if result else 'Activity started'}")
    time.sleep(1)

    return True


def test_adbkeyboard(device, test_text):
    """Test ADBKeyboard broadcast"""
    print(f"\n{'='*50}")
    print("TEST 2: ADBKeyboard Broadcast")
    print('='*50)

    # Check if installed
    result = adb(device, "pm path com.android.adbkeyboard")
    if "package:" in result:
        print(f"  ADBKeyboard installed: {result}")
    else:
        print("  ERROR: ADBKeyboard NOT installed!")
        return False

    # Check current IME
    current_ime = adb(device, "settings get secure default_input_method")
    print(f"  Current IME: {current_ime}")

    if "adbkeyboard" not in current_ime.lower():
        print("  WARNING: ADBKeyboard is not the default IME!")
        print("  Setting ADBKeyboard as default...")
        adb(device, "settings put secure default_input_method com.android.adbkeyboard/.AdbIME")
        time.sleep(0.5)
        current_ime = adb(device, "settings get secure default_input_method")
        print(f"  New IME: {current_ime}")

    # Send text via broadcast
    text_b64 = base64.b64encode(test_text.encode('utf-8')).decode('ascii')
    print(f"  Sending text via ADB_INPUT_B64 broadcast...")
    result = adb(device, f"am broadcast -a ADB_INPUT_B64 --es msg {text_b64}")
    print(f"  Result: {result[:100] if result else 'Broadcast sent'}")

    return True


def test_in_notes_app(device, test_text):
    """Open a notes app and try to type"""
    print(f"\n{'='*50}")
    print("TEST 3: Actual Typing in Notes App")
    print('='*50)

    # Try to open a simple text input - use Google Keep or default notes
    print("  Opening Google search (has text field)...")
    adb(device, "am start -a android.intent.action.VIEW -d 'https://www.google.com'")
    time.sleep(5)

    # Tap in search area (approximate center-top)
    print("  Tapping search field...")
    adb(device, "input tap 360 200")
    time.sleep(2)

    # Check if keyboard is visible
    result = adb(device, "dumpsys input_method | grep mInputShown")
    print(f"  Keyboard status: {result}")

    # Method 1: Try ADBKeyboard broadcast
    print("\n  Attempting ADBKeyboard broadcast...")
    text_b64 = base64.b64encode(test_text.encode('utf-8')).decode('ascii')
    adb(device, f"am broadcast -a ADB_INPUT_B64 --es msg {text_b64}")
    time.sleep(1)

    print("  Check the phone screen - did text appear in the search field?")

    return True


def test_long_press_paste(device, test_text):
    """Test long-press paste method"""
    print(f"\n{'='*50}")
    print("TEST 4: Long-Press Paste Method")
    print('='*50)

    # First set clipboard
    text_b64 = base64.b64encode(test_text.encode('utf-8')).decode('ascii')
    print("  Setting clipboard via ClipboardHelper...")
    adb(device, f"am start -n com.geelark.clipboard/.ClipboardActivity -a com.geelark.clipboard.COPY --es base64 {text_b64}")
    time.sleep(1)

    # Open a text field (Google search)
    print("  Opening Google for text field...")
    adb(device, "am start -a android.intent.action.VIEW -d 'https://www.google.com'")
    time.sleep(5)

    # Tap search field
    print("  Tapping search field...")
    adb(device, "input tap 360 200")
    time.sleep(1)

    # Long press to show paste menu
    print("  Long-pressing to show paste menu...")
    adb(device, "input swipe 360 200 360 200 800")
    time.sleep(1)

    # Look for paste button in UI
    print("  Checking for paste menu...")
    adb(device, "uiautomator dump /sdcard/ui.xml")
    xml = adb(device, "cat /sdcard/ui.xml")

    if "paste" in xml.lower():
        print("  FOUND 'paste' in UI - attempting to tap it...")
        # Try to find and tap paste
        # This is a rough tap at where paste usually appears
        adb(device, "input tap 360 150")
        time.sleep(1)
        print("  Check phone - did text paste?")
        return True
    else:
        print("  No 'paste' option found in UI")
        print("  UI contains:", xml[:500] if xml else "empty")
        return False


def main():
    if len(sys.argv) < 2:
        print("Usage: python test_typing.py <phone_name>")
        print("Example: python test_typing.py miccliparchive")
        sys.exit(1)

    phone_name = sys.argv[1]
    test_text = "Test 123 with emoji 🎉 and newline\nSecond line!"

    try:
        device, client, phone_id = connect_phone(phone_name)

        print(f"\nTest text: {test_text}")
        print("="*50)

        # Run tests
        test_clipboard_helper(device, test_text)
        test_adbkeyboard(device, test_text)
        test_in_notes_app(device, "Hello from ADBKeyboard!")
        test_long_press_paste(device, test_text)

        print(f"\n{'='*50}")
        print("TESTS COMPLETE")
        print("="*50)
        print("\nPlease check the phone screen to see which methods worked.")
        print("Look for the test text in any text fields.")

        # Cleanup
        print("\nDisabling ADB...")
        client.disable_adb(phone_id)

    except Exception as e:
        print(f"ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
</file>

<file path="update_type_text.py">
"""Update type_text function to use clipboard method"""
import re

filepath = 'C:/Users/asus/Desktop/projects/geelark-automation/post_reel_smart.py'

# Read file
with open(filepath, 'r', encoding='utf-8') as f:
    content = f.read()

# New type_text function with clipboard method
new_func = '''    def type_text(self, text):
        """Type text via clipboard + paste - supports full Unicode, emojis, newlines"""
        import base64

        # ClipboardHelper APK method (works on Android 10-15)
        # Encode text to base64 for safe transmission of Unicode/emojis/newlines
        text_b64 = base64.b64encode(text.encode('utf-8')).decode('ascii')

        # Set clipboard via our custom ClipboardHelper activity
        result = self.adb(f"am start -a com.geelark.clipboard.COPY --es base64 {text_b64}")
        print(f"    ClipboardHelper: {result[:80] if result else 'started'}")
        time.sleep(0.5)  # Give activity time to set clipboard

        # Paste from clipboard (Ctrl+V / KEYCODE_PASTE)
        self.adb("input keyevent 279")  # KEYCODE_PASTE
        time.sleep(0.3)

        # Verify paste worked
        verify_elements, _ = self.dump_ui()
        text_found = any(text[:20] in elem.get('text', '') for elem in verify_elements)

        if not text_found:
            print("    KEYCODE_PASTE failed, trying long-press paste...")
            # Long press to get paste menu
            self.adb("input swipe 360 400 360 400 1000")
            time.sleep(0.5)

            # Look for Paste button
            paste_elements, _ = self.dump_ui()
            paste_btn = [e for e in paste_elements if 'paste' in e.get('text', '').lower() or 'paste' in e.get('desc', '').lower()]
            if paste_btn:
                self.tap(paste_btn[0]['center'][0], paste_btn[0]['center'][1])
            else:
                # Fallback to ADBKeyboard
                print("    Trying ADBKeyboard fallback...")
                self.adb(f"am broadcast -a ADB_INPUT_B64 --es msg {text_b64}")

        return True

'''

# Find and replace type_text function using regex
pattern = r'(    def type_text\(self, text\):.*?)(    def dump_ui)'
content_new = re.sub(pattern, new_func + r'\2', content, flags=re.DOTALL)

# Write back
with open(filepath, 'w', encoding='utf-8') as f:
    f.write(content_new)

print('Updated type_text function successfully!')
</file>

<file path="vision.py">
"""
Vision module - uses Claude to analyze screenshots and determine actions
"""
import anthropic
import base64
import os


def encode_image(image_path):
    """Encode image to base64"""
    with open(image_path, "rb") as f:
        return base64.standard_b64encode(f.read()).decode("utf-8")


def analyze_screen(image_path, task_context):
    """
    Analyze screenshot and return action to take.

    Args:
        image_path: Path to screenshot image
        task_context: What we're trying to do (e.g., "post a video to Instagram")

    Returns:
        dict with:
            - action: "tap", "type", "swipe", "back", "done", "error"
            - x, y: coordinates for tap
            - text: text to type
            - message: explanation
    """
    client = anthropic.Anthropic()

    image_data = encode_image(image_path)

    prompt = f"""You are controlling an Android phone to {task_context}.

Look at this screenshot and tell me exactly what action to take next.

Respond in this exact JSON format:
{{
    "action": "tap" | "type" | "swipe" | "back" | "done" | "wait" | "error",
    "x": <x coordinate for tap>,
    "y": <y coordinate for tap>,
    "text": "<text to type if action is type>",
    "swipe": {{"x1": 0, "y1": 0, "x2": 0, "y2": 0}} if swipe,
    "message": "<brief explanation of what you see and why this action>"
}}

Important:
- Give exact pixel coordinates based on what you see
- If you see the target completed (e.g., post was shared), return "done"
- If something is wrong (error dialog, unexpected screen), return "error"
- If loading/processing, return "wait"
- Be precise with coordinates - aim for center of buttons/fields

Only output the JSON, nothing else."""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=500,
        messages=[{
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": image_data
                    }
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        }]
    )

    # Parse JSON response
    import json
    text = response.content[0].text.strip()

    # Handle markdown code blocks
    if text.startswith("```"):
        text = text.split("```")[1]
        if text.startswith("json"):
            text = text[4:]
        text = text.strip()

    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        return {
            "action": "error",
            "message": f"JSON parse error: {e}. Raw response: {text[:200]}"
        }


def analyze_for_instagram_post(image_path, caption, video_uploaded=False):
    """
    Specialized analyzer for Instagram posting flow.

    Args:
        image_path: Screenshot path
        caption: The caption to post
        video_uploaded: Whether video has been selected already
    """
    client = anthropic.Anthropic()

    image_data = encode_image(image_path)

    if not video_uploaded:
        context = """posting a Reel/video to Instagram.
Current step: Need to tap the + button to create a new post, then select Reel, then select the video from gallery."""
    else:
        context = f"""posting a Reel/video to Instagram.
The video has been selected. Now we need to:
1. Add this caption: {caption}
2. Tap Share/Post to publish

If you see a caption field, type the caption.
If you see Share/Post button and caption is entered, tap it."""

    prompt = f"""You are controlling an Android phone to {context}

Look at this screenshot and tell me exactly what action to take next.

Respond in this exact JSON format:
{{
    "action": "tap" | "type" | "swipe" | "back" | "done" | "wait" | "error",
    "x": <x coordinate for tap>,
    "y": <y coordinate for tap>,
    "text": "<text to type if action is type>",
    "swipe": {{"x1": 0, "y1": 0, "x2": 0, "y2": 0}},
    "message": "<brief explanation of what you see and why this action>",
    "video_selected": true/false (set true if video appears to be selected/uploaded)
}}

Common Instagram UI elements:
- + button (create): usually bottom center
- Reel option: after tapping +
- Gallery: shows recent videos
- Next button: top right
- Caption field: text input area
- Share button: top right on final screen

Only output the JSON, nothing else."""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=500,
        messages=[{
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": image_data
                    }
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        }]
    )

    import json
    text = response.content[0].text.strip()

    if text.startswith("```"):
        text = text.split("```")[1]
        if text.startswith("json"):
            text = text[4:]
        text = text.strip()

    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        return {
            "action": "error",
            "message": f"JSON parse error: {e}. Raw response: {text[:200]}",
            "video_selected": False
        }


if __name__ == "__main__":
    print("Vision module loaded successfully")
    print("Usage: result = analyze_screen('screenshot.png', 'post video to Instagram')")
</file>

</files>
